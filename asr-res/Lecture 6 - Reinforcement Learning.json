{"Data": {"TaskId": 5973612120, "Status": 2, "StatusStr": "success", "Result": "[0:8.940,0:36.480]  Hi everyone, welcome back. Today, I think that these two lectures today are really exciting because they start to move beyond. You know, a lot of what we've talked about in the class so far, which is focusing a lot on really static data sets and specifically in today. In this lecture right now I'm going to start to talk about how we can learn about this very long standing field of how we can specifically marry two topics. The first topic being reinforcement learning.\n[0:36.480,0:46.480]  Which has existed for many, many decades, together with a lot of the very recent advances in deep learning, which you've already started learning about as part of this course.\n[0:46.840,1:19.260]  Now this marriage of these two fields is actually really fascinating to me, particularly because like I said, it moves away from this whole paradigm of ah, or really this whole paradigm that we've been exposed to in the class thus far. And that paradigm is really how we can build a deep learning model using some data set. But that data set is typically fixed in in our world, right? We collect, we go out and go collect that data set, we deploy it on our machine learning or deep learning algorithm and then we can evaluate on a brand new data set.\n[1:19.260,1:58.940]  But that is very different than the way things work in the real world. In the real world, you have your deep learning model actually deployed together with the data together, out into reality, exploring, interacting with its environment and trying out a whole bunch of different actions and different things in that environment in order to be able to learn how to best perform any particular task that may need to accomplish. And typically we want to be able to do this without explicit human supervision, right. This is the key motivation of reinforcement learning. You're going to try and learn through reinforcement, making mistakes in your world and then collecting data on those mistakes to learn how to improve.\n[1:59.440,2:25.740]  Now, this is obviously a huge field in or a huge topic in the field of robotics and autonomy. You can think of self driving cars and robot manipulation, but also very recently we've started seeing incredible advances of deep reinforcement learning, specifically also on the side of game play and strategy making as well. So one really cool thing is that now you can even imagine right this.\n[2:26.060,2:38.460]  This combination of robotics, together with gameplay right now, training robots to play against us in the real world, and I'll just play this very short video on starcraft and deepmind.\n[2:41.800,3:42.280]  Perfect information and to display in real time. It also requires long term planning and the ability to choose what action to take from millions and millions of possibilities. I'm hoping for a five zero not to lose any games, but I think the realistic goal would be four and one in my favor. I think he looks more confident and Taylor was quite nervous before. The room was much more tense this time. Really didn't know what to expect. He's been playing starra pretty much since he five, I wasn't expecting AI to be that good. Everything that he did was proper, it was calculated and it was done well. I thought I'm learning something. I would consider myself a good player, right? But I lost every single one of my games.\n[3:42.280,3:47.600]  Where away had won.\n[3:48.500,4:28.460]  So let's take maybe a start and take a step back, first of all, and think about how reinforcement learning fits into this whole paradigm of all of the different topics that you've been exposed to in this class so far. So as a whole, I think that we've really covered two different types of learning in this course to date. Right up until now we've really started focusing in the beginning part of the lectures, firstly on what we call supervised learning. Supervised learning is in this domain where we're given data in the form of x's, our inputs and our labels y, and our goal here is to learn a function or a neural network that can learn to predict y given our inputs X.\n[4:28.460,4:40.680]  So, for example, if you consider this example of an Apple observing a bunch of images of apples, we want to detect, you know, in the future if we see a new image of an Apple, to detect that this is indeed an Apple.\n[4:40.680,5:36.340]  Now, the second class of learning approaches that we've discovered yesterday in yesterday's lecture was that of unsupervised learning. And in these algorithms you have only access to the data. There's no notion of labels, right? This is what we learned about yesterday in these types of algorithms. You're not trying to predict a label, but you're trying to uncover some of the underlying structure. What we were calling basically these latent variables, these hidden features in your data. So for example, in this Apple example, right using unsupervised learning. The analogous example would basically be to build a model that could understand and cluster certain certain parts of these images together. And maybe it doesn't have to understand that necessarily this is an image of an Apple. But it needs to understand that, you know, this image of the red Apple is similar. It has the same latent features and same semantic meaning as this black and white outline sketch of the Apple.\n[5:37.560,6:20.960]  Now, in today's lecture we're going to talk about yet another type of learning algorithms, right in reinforcement learning. We're going to be only given data in the form of what are called state action pairs. Right now states are observations, right. This is what the agent, let's call it, the neural network is going to observe. It's what it sees. The actions are the behaviors that this agent takes in those particular states. So the goal of reinforcement learning is to build an agent that can learn how to maximize what are called rewards. This is the third component that is specific to reinforcement learning and you want to maximize all of those rewards over many, many time steps in the future.\n[6:20.960,6:39.060]  So again, in this Apple example, we might now see that the agent doesn't necessarily learn that, okay, this is an Apple or it looks like these other apples. Now it has to learn to, let's say, eat the Apple, take an action, eat that Apple, because it has learned that eating that Apple makes it live longer or survive because it doesn't starve.\n[6:39.460,7:2.640]  So in today, right, like I said, we're going to be focusing exclusively on this third type of learning paradigm, which is reinforcement learning. And before we go any further, I just want to start by building up some very key terminology and like, basically background for all of you so that we're all on the same page when we start discussing some of the more complex components of today's lecture.\n[7:2.640,7:31.500]  So let's start by building up, you know, some of this terminology. The first main piece of terminology is that of an agent. An agent is a being basically that can take actions. For example, you can think of an agent as a machine, right? That is, let's say an autonomous drone that is making a delivery. Or for example, in a game, it could be super Mario that's navigating inside of your video video game.\n[7:31.500,7:45.160]  The algorithm itself, it's important to remember that the algorithm is the agent, right? We're trying to build an agent that can do these tasks, and the algorithm is that agent. So in life, for example, all of you are agents in life.\n[7:45.320,7:59.760]  The environment is the other kind of contrary approach or the contrary perspective to the agent. The environment is simply the world where that agent lives and where it operates, right where it exists and it moves around in.\n[7:59.880,8:45.480]  The agent can send commands to that environment in the form of what are called actions. You can take actions in that environment and let's call for notation purposes. Let's say the possible set of all actions that it could take is let's say a set of capital a right now. It should be noted that agents at any point in time could choose amongst this, let's say list of possible actions. But of course in some situations your action space does not necessarily need to be a finite space. Maybe you could take actions in a continuous space. For example, when you're driving a car, you're taking actions on a continuous angle space of what angle you want to steer that car. It's not necessarily just going right or left or straight, you may steer at any continuous degree.\n[8:46.740,9:9.940]  Observations is essentially how the environment responds back to the agent, right? The environment can tell the agent you know what it should be seeing based on those actions that it just took, and it responds in the form of what is called a state. A state is simply a concrete and immediate situation that the agent finds itself in at that particular moment.\n[9:10.440,9:53.560]  Now it's important to remember that unlike other types of learning that we've covered in this course, reinforcement learning is a bit unique because it has one more component here in addition to these other components, which is called the reward. Now the reward is a feedback by which we measure, or we can try to measure the success of a particular agent in its environment. So, for example, in a video game, when Mario grabs a coin, for example, he wins points, right? So from a given state, an agent can send out any form of actions to take some decisions, and those actions may or may not result in rewards being collected and accumulated over time.\n[9:53.560,10:23.160]  Now, it's also very important to remember that not all actions result in immediate rewards. You may take some actions that will result in a reward in a delayed fashion, maybe in a few time steps down the future, maybe in life, maybe years, you may take an action today that results in a reward many some time from now. And, but essentially all of these try to effectively evaluate some way of measuring the success of a particular action that an agent takes.\n[10:23.160,10:43.080]  So, for example, when we look at the total rewards that an agent accumulates over the course of its lifetime, we can simply sum up all of the rewards that an agent gets after a certain time t right? So this capital r of t is the sum of all rewards from that point on into the future into infinity.\n[10:43.480,11:28.000]  And that can be expanded to look exactly like this. It's rewarded time t plus the word time t plus one, plus t plus two, and so on and so forth. Often it's actually very useful for all of us to consider not only the sum of all of these rewards, but instead what's called the discounted sum. So you can see here I've added this gamma factor in front of all of the rewards. And that discounting factor is essentially multiplied by every future reward that the agent sees and it's discovered by the agent. And the reason that we want to do this is actually this dampening factor is designed to make future rewards essentially worth less than rewards that we might see at this instant, at this moment right now.\n[11:28.000,11:33.740]  Now, you can think of this as basically enforcing some kind of short term.\n[11:33.820,12:5.400]  Greiness in the algorithm, right. So for example, if I offered you a reward of five dollars today or a reward of five dollars and ten years from now, I think all of you would prefer that five dollars today simply because we have that same discounting factor applied to this. To this processing. We have that factor that that five dollars is not worth as much to us if it's given to us ten years in the future. And that's exactly how this is captured here as well. Mathematically, this discounting factor is like multiply, like I said, multiply that every single.\n[12:5.400,12:24.380]  Future award exponentially. And it's important to understand that also. Typically this discounting factor is, you know, between zero and one, there are some exceptional cases where maybe you want some strange behaviors and have a discounting factor greater than one, but in general that's not something we're going to be talking about today.\n[12:24.380,12:50.400]  Now finally, it's very important in reinforcement learning, this special function called the q function, which ties in a lot of these different components that I've just shared with you altogether. Now let's look at what this q function is, right? So we already covered this r of t function right? R of t is the discounted sum of rewards from time t all the way into the future time infinity.\n[12:50.400,13:42.020]  But remember that this rf t right, it's discounted number one and number two, we're going to try and build A Q function that captures the the maximum or the best action that we could take that will maximize this reward. So let me say that one more time in a different way. The q function takes as input two different things. The first is the state that you're currently in and the second is a possible action that you could execute in this particular state. So here's of t is that stay at time T A of t is that action that you may want to take at time t, and the q function of these two pieces is going to denote or capture what the expected total return would be of that agent if it took that action in that particular state.\n[13:42.620,14:15.220]  Now, one thing that I think maybe we should all be asking ourselves now is this seems like a really powerful function, right? If you had access to this type of a function, this q function, I think you could actually perform a lot of tasks right off the BAT, right? So if you wanted to, for example, understand how to what actions to take in a particular state, and let's suppose I gave you this magical cue function, does anyone have any ideas of how you could transform that cue function to directly infer what action should be taken?\n[14:17.320,15:8.680]  Given a state, you can look at your possible action space and pick the one that gives you the highest q value. Exactly, so that's exactly right. So just to repeat that one more time, the q function tells us for any possible action, right? What is the expected reward for that action to be taken? So if we wanted to take a specific action given in a specific state, ultimately we need to, you know, figure out which action is the best action. The way we do that from A Q function is simply to pick the action that will maximize our future reward. And we can simply try out number one, if we have a discrete action space, we can simply try out all possible actions, compute their q value for every single possible actions based on the state that we currently find ourselves in, and then we pick the action that is going to result in the highest q value.\n[15:9.620,15:20.620]  If we have a continuous action space, maybe we do something a bit more intelligent, maybe following the gradients along this q value curve and maximizing it as part of an optimization procedure.\n[15:20.620,15:48.340]  But generally in this lecture, what I want to focus on is actually how we can obtain this q function. To start with, I I kind of skipped a lot of steps in that last slide where I just said let's suppose I give you this magical q function, how can you determine what action to take? But in reality we're not given that q function. We have to learn that q function using deep learning. And that's what today's lecture is going to be talking about primarily is first of all, how can we construct and learn that q function from data.\n[15:48.340,16:21.700]  And then of course, the final step is use that q function to, you know, take some actions in the real world. And broadly speaking, there are two classes of reinforcement learning algorithms that we're going to briefly touch on as part of today's lecture. The first class is what's going to be called value learning, and that's exactly this process that we've just talked about. Value learning tries to estimate our q function, right? So to find that q function q given our state and our action, and then use that q function to, you know, optimize for the best action to take given a particular state that we find ourselves in.\n[16:21.700,16:49.120]  The second class of algorithms, which we'll touch on right at the end of today's lecture, is kind of a different framing of this same approach. But instead of first optimizing the q function and finding A Q value and then using that q function to optimize our actions, what if we just try to directly optimize our policy, which is what action to take based on a particular state that we find ourselves in? If we do that, if we can obtain this function, right?\n[16:49.120,17:16.160]  Then we can directly sample from that policy distribution to obtain the optimal action. We'll talk more details about that later in the lecture, but first let's cover this first class of approaches, which is q learning approaches, and we'll build up that intuition and that knowledge onto the second part of policy learning. So maybe let's start by just digging a bit deeper into the q function specifically just to start to understand, you know, how we could estimate this in the beginning.\n[17:16.160,18:1.100]  So first let me introduce this game. Maybe some of you recognize this. This is the game of called atari breakout. The the game here is essentially one where the agent is able to move left or right, this paddle on the bottom left or right. And the objective is to move it in a way that this ball that's coming down towards the bottom of the screen can be, you know, bounced off of your paddle, reflected back up, and essentially you want to break out, right, reflect that ball back up to the top of the screen towards the rainbow portion and keep breaking off. Every time you hit a pixel on the top of the screen, you break off that pixel. And the objective of the game is to basically eliminate all of those rainbow pixels, right? So you want to keep hitting that ball against the top of the screen until you remove all the pixels.\n[18:1.580,18:34.060]  Now the q function tells us, you know, the expected total return or the total reward that we can expect based on a given state and action pair that we may find ourselves in this game. Now, the first point I want to make here is that sometimes even for us as humans to understand what the q value should be is sometimes quite unintuitive, right? So here's one example. Let's say we find these two state action pairs right here is a and b two different options that we can be presented with in this game.\n[18:34.060,19:11.940]  A the ball is coming straight down towards us. That's our state. Our action is to do nothing and simply reflect that ball back up vertically up. The second situation. The state is basically that the ball is coming slightly at an angle. We're not quite underneath it yet and we need to move towards it and actually hit that ball in a way that you know will will make it and not Miss it hopefully right? So hopefully that ball doesn't pass below us and the game would be over. Can you imagine, you know which of these two options might have a higher q value for the network? Which one would result in a.\n[19:11.940,19:15.960]  Rate of reward for the neural network or for the agent.\n[19:17.160,19:23.740]  So how many people believe a would result in a higher return?\n[19:23.860,19:25.680]  How about b?\n[19:26.180,19:30.620]  Okay, how about someone who picked b? Can you tell me why? B.\n[19:32.000,19:35.600]  Agency, you're actually doing something.\n[19:35.600,20:36.000]  Okay, yeah about more for the for a you only have like the maximum you can take off is like one because after you reflect your automatically background more than exactly and actually there's a very interesting thing. So when I first saw this actually it's ah, it was very unintuitive for me. Y A is actually working much worse than b but in general with this very conservative action of b, your kind of exactly like you said, the two answers were implying is that a is a very conservative action. You're kind of only going up and down. It will achieve a good reward. It will solve the game, right? In fact it solves the game exactly like this right here. You can see in general this action is going to be quite conservative. It's just bouncing up, hitting one point at a time from the top and breaking off very slowly. The board that you can see here. But in general you see the part of the board that's being broken off is towards the center of the board, right? Not much on.\n[20:36.000,21:32.760]  Edges of the board. If you look at b now with b, you're kind of having agency. Like one of the answers said you're coming towards the ball and what that implies is that you're sometimes going to actually hit the corner of your paddle and have a very extreme angle on your paddle and hit the sides of the board as well. And it turns out that the algorithm, the agent can actually learn that hitting the sides of the board can have some kind of unexpected consequences that look like this. So here you see it trying to enact that policy. It's targeting the sides of the board, but once it reaches a breakout on the side of the board, it found this hack in the solution where now it's breaking off a ton of points. So that was kind of a trick that this neural network learned. It was a way that it even moves away from the ball as it's coming down just so we could move back towards it, just to hit it on the corner and execute on those those corner parts of the board and break out a lot of pieces for free almost.\n[21:33.460,21:57.100]  So now that we can see that sometimes obtaining the q function can be a little bit unintuitive, but the key point here is that if we have the q function, we can directly use it to determine, you know, what is the best action that we can take in any given state that we find ourselves in? So now the question naturally is how can we train a neural network that can indeed learn this q function?\n[21:57.180,22:28.940]  So the type of the neural network here, naturally, because we have a function that takes as input two things, let's imagine our neural network will also take as input these two objects as well. One object is going to be the state of the board. You can think of this as simply the pixels that are on the screen describing that board. So it's an image of the board at a particular time. Maybe you want to even provide two or three images to give it some sense of temporal information and some past history as well. But all of that information can be combined together and provided to the network in the form of a state.\n[22:28.940,22:51.740]  And in addition to that, you may also want to provide some actions as well, right? So in this case, the actions that a neural network or an agent could take in this game is to move to the right, to the left, to stay still. And those could be three different actions that could be provided and parameterized to the input of a neural network. The goal here is to, you know, estimate the single number output.\n[22:51.740,23:35.160]  That measures what is the expected value or the expected q value of this neural network at this particular state action pair. Now oftentimes what you'll see is that if you wanted to evaluate, let's suppose a very large action space, it's going to be very inefficient to try the approach on the left with with a very large action space. Because what it would mean is that you'd have to run your neural network forward many different times one time for every single element of your action space. So what if instead you only provided it an input of your state and as output you gave it, let's say all n different q values, one q value for every single possible action. That way you only need to run your neural network once for the given state that you're in.\n[23:35.160,23:46.140]  And then that neural network will tell you for all possible actions, what's the maximum? You simply then look at that output and pick the action that has the K S Q value.\n[23:46.840,24:36.200]  Now, what would happen? Right. So actually the question I want to pose here is really, you know, we want to train one of these two networks. Let's stick with the network on the right for simplicity, just since it's a much more efficient version of the network on the left. And the question is, you know, how do we actually train that network on the right? And specifically I want all of you to think about really the best case scenario just to start with how an agent would perform ideally in a particular situation or what would happen if an agent took all of the ideal actions at any given state. This would mean that essentially the target return right, the, the predicted or the the value that we're trying to predict. The target is going to always be maximized, right? And this can serve as essentially the ground truth to the agent.\n[24:36.200,25:6.420]  Now, for example, to do this, we want to formulate a loss function that's going to essentially represent our expected return if we're able to take all of the best actions, right. So, for example, if we select an initial reward plus selecting some action in our action space that maximizes our expected return, then for the next future state we need to apply that discounting factor and recursively apply the same equation, and that simply turns into our target.\n[25:6.420,25:27.900]  Right now we can ask basically what does our neural network predict, right? So that's our target. And we recall from previous lectures if we have a target value in this case, our q value is a continuous variable. We have also a predicted variable that is going to come as part of the output of every single one of these potential actions that could be taken.\n[25:28.800,25:51.140]  We can define what's called A Q loss, which is essentially just a very simple mean squared error loss between these two continuous variables. We minimize their distance over two over many, many different iterations of buying our neural network in this environment, observing actions and observing not only the actions but most importantly after the action is.\n[25:51.140,26:8.320]  Committed or executed, we can see exactly the ground truth, expected return, right? So we have the ground truth labels to train and supervise this model directly from the actions that were executed as part of random selection, for example.\n[26:8.320,26:9.680]  Now.\n[26:9.680,26:35.140]  Let me just stop right there and maybe summarize the whole process one more time and maybe a bit different terminology just to give everyone kind of a different perspective on this same problem. So our deep neural network that we're trying to train looks like this, right? It takes as input. A state is trying to output n different numbers. Those n different numbers correspond to the q value associated to n different actions. One q value per action.\n[26:36.100,26:46.180]  Here the actions in atari breakout, for example, should be three actions. We can either go left, we can go right, or we can do nothing. We can stay where we are.\n[26:48.620,27:21.580]  Right. So the next step from this we saw if we have this hue value output, what we can do with it is we can make an action or we can even let me be more formal about it. We can develop what's called a policy function. Policy function is a function that given a state, it determines what is the best action. So that's different than the q function, right? The q function tells us given a state, what is the best or what is the value, the return of every action that we could take. The policy function tells us one step more than that.\n[27:21.580,28:21.860]  Given, given a state, what is the best action, right? So it's a very end to end way of thinking about, you know, the agent's decision making process based on what I see right now, what is the action that I should take? And we can determine that policy function directly from the q function itself simply by maximizing and optimizing all of the different q values for all of the different actions that we see here. So for example, here we can see that given this state, the q function as the result of these three different values has A Q value of twenty. If it goes to the left, has A Q value of three, if it stays in the same place and it has A Q value of zero, it's going to basically die after this iteration if it moves to the right because you can see that the ball is coming to the left of it. If it moves to the right, the game is over, right. So it needs to move to the left in order to do that in order to continue the game. And the q value reflects that. The optimal action here is simply going to be the maximum of these three q values. In this case it's going to be.\n[28:21.860,28:28.540]  Twenty, and then the action is going to be the corresponding action that comes from that twenty, which is moving left.\n[28:29.240,28:30.900]  Now.\n[28:31.020,28:54.440]  We can send this action back to the environment in the form of the game to execute the next step, right. And as the agent moves through this environment, it's going to be responded with not only by new pixels that come from the game, but more importantly, some reward signal. Now it's very important to remember that the reward signals in pong, or sorry in atari, breakout.\n[28:54.440,29:16.060]  Are very sparse, right? You get a reward, not necessarily based on the action that you take at this exact moment. It usually takes a few time steps for that ball to travel back up to the top of the screen. So usually your rewards will be quite delayed, maybe at least by several time steps, sometimes even more if you're bouncing off of the corners of the screen.\n[29:16.240,29:47.720]  Now, one very popular or very famous approach that showed this was presented by deepmind Google deepmind several years ago, where they showed that you could train A Q value network and you can see the input on the left hand side is simply the raw pixels coming from the screen all the way to the actions of a controller on the right hand side. And you could train this one network for a variety of different tasks all across the atari breakout ecosystem of games.\n[29:47.720,30:10.160]  And for each of these tasks, the really fascinating thing that they showed was for this very simple algorithm which really relies on random choice of selection of actions and then, you know, learning from, you know, actions that don't do very well, that you discourage them and trying to do actions that did perform well more frequently, very simple algorithm, but what they found was even with that type of algorithm.\n[30:10.160,30:38.340]  They were able to surpass human level performance on over half of the game. There were some games that you can see here were still below human level performance, but as we'll see, this was really like such an exciting advance because of the simplicity of the algorithm and how you clean the formulation of the training was you only needed a very little amount of prior knowledge to impose onto this neural network for it to be able to learn how to play these games. You never had to teach any of the rules of the game.\n[30:38.340,30:45.800]  You only had to let it explore its environment, play the game many, many times against itself, and learn directly from that data.\n[30:47.140,31:32.620]  Now there are several very important downsides of que learning and hopefully these are going to motivate the second part of today's lecture, which we'll talk about. But the first one that I want to really convey to everyone here is that you learning is naturally applicable to discrete action spaces, right? Because you can think of this output space that we're providing as kind of like one number per action that could be taken. Now if we have a continuous action space, we have to think about clever ways to work around that. In fact, there are now more recently there are some solutions to achieve que learning and continuous action spaces. But for the most part, queue learning is very well suited for discrete action spaces. And we'll talk about ways of overcoming that with other approaches a bit later.\n[31:32.620,32:5.240]  And the second component here is that the policy that we're learning, right, the q function is giving rise to that policy, which is the thing that we're actually using to determine what action to take. Given any state that policy is determined by, you know, deterministically optimizing that q function, we simply look at the results from the q function and apply our, or we, we look at the results of the q function and we pick the action that has the best or the highest q value.\n[32:5.240,32:41.600]  That is very dangerous in many cases because of the fact that it's always going to pick the best value for a given state. There's no stochasticity in that pipeline, so you can very frequently get caught in situations where you keep repeating the same actions and you don't learn to explore potentially different options that you may be thinking of. So to address these very important challenges, that's hopefully going to motivate now the next part of today's lecture, which is going to be focused on policy learning, which is a different class of reinforcement learning algorithms that are different than queue learning algorithms.\n[32:41.600,33:2.100]  And like I said, those are called policy gradient algorithms and policy gradient algorithms. The main difference is that instead of trying to infer the policy from the q function, we're just going to build a neural network that will directly learn that policy function from the data. So it kind of skips one step and we'll see how we can train those networks.\n[33:2.860,33:22.500]  So before we get there, let me just revisit one more time. The q function illustration that we are looking at, right q function, we are trying to build a neural network outputs these q values, one value per action, and we determine the policy by looking over this state of q values, picking the value that has the highest.\n[33:22.500,34:7.240]  And looking at its corresponding action now with policy networks, the idea that we want to keep here is that instead of predicting the key values themselves, let's directly try to optimize this policy function. Here we're calling the policy function pi of s, right? So pi is the policy, s is our state. So it's a function that takes as input only the state and it's going to directly output the action. So the outputs here give us the desired action that we should take in any given state that we find ourselves in that represents not only the best action that we should take, but let's denote this as basically the probability that selecting that action would result in a very desirable outcome.\n[34:7.240,34:26.940]  For our network, so not necessarily the value of that that action, but rather the probability that selecting that action would be the highest value, right? So you don't care exactly about what is the numerical value that selecting this action takes or gives rise to rather, but rather.\n[34:27.220,34:43.000]  What is the likelihood that selecting this action will give you the best performing value that you could expect? Exact value itself doesn't matter. You only care about if selecting this action is going to give you, with high likelihood, the best one.\n[34:43.260,34:50.120]  So we can see that if these predicted probabilities here, right in this example of atari.\n[34:50.460,35:28.860]  Going left has the probability of being the highest value action with 90% staying in the center has a probability of 10%. Going right is 0%. So ideally what our neural networks should do in this case is 90% of the time in this situation go to the left 10% of the time it could still try staying at where it is, but never it should go to the right. Now note that this now is a probability distribution. This is very different than A Q function. A que function has actually no eh structure, right? The q values themselves can take any real number.\n[35:28.860,35:53.540]  Right. But here the policy network has a very formulated output. All of the numbers here in the output have to sum to one because this is a probability distribution, right? And that gives it a very rigorous version of how we can train this model that makes it a bit easier to train than hue functions as well.\n[35:53.660,36:54.140]  One other very important advantage of having an output that is a probability distribution is actually going to tie back to this other issue of q functions and q neural networks that we saw before and that is the fact that q functions are naturally suited towards discrete action spaces. Now when we're looking at this policy network we're puttingting a distributions, right? And remember those those distributions can also take continuous forms. In fact, we've seen this in the last two lectures. In the generative lecture we saw how ves could be used to predict gaussian distributions over their latent space. In the last lecture we also saw how we could learn to predict uncertainties which are continuous probability distributions using data. And just like that, we could also use this same formulation to move beyond discrete action spaces like you can see here, which are one possible action, a probability associated to one possible action.\n[36:54.140,37:24.580]  In a discrete set of possible actions, now we may have a space which is not what action should I take, go left, right or say center, but rather how quickly should I move and in what direction should I move right? That is a continuous variable as opposed to a discrete variable. And you could say that now the answer should look like this, moving very fast to the right versus very slow to the, excuse me, very fast to the left versus very slow to the left has this continuous spectrum that we may want to model.\n[37:25.060,37:58.200]  Now, when we plot this entire distribution of taking an action, giving a state, you can see basically a very simple illustration of that right here. This, this distribution has most of its mass over, sorry, it has all of its mass over the entire real number line. First of all, it has most of its mass right in the optimal action space that we want to take. So if we want to determine the best action to take, we would simply take the mode of this distribution, the highest point. That would be the speed at which we should move and the direction that we should move in.\n[37:58.220,38:8.280]  If we wanted to also, you know, try out different things and explore our space, we could sample from this distribution and still obtain some stochasticity.\n[38:9.380,39:9.860]  Now let's look at an example of how we can actually model these continuous distributions and actually we've already seen some examples of this in the previous two lectures like I mentioned, but let's take a look specifically in the context of reinforcement learning and policy gradient learning. So instead of predicting this probability of taking an action, giving all possible states, which in this case there is now an infinite number of, because we're in the continuous domain, we can't simply predict a single probability for every possible action because there's an infinite number of them. So instead, what if we parameterized our action space by distribution, right? So let's take for example, the gaussian distribution to parameterize a gaussian distribution. We only need two outputs, right, we need a mean and a variance. Given a mean and a variance we can actually have a probability mass and we can compute a probability over any possible action that we may want to take just from those two numbers. So for example, in this image here we may want to output a gou.\n[39:9.860,39:44.720]  That looks like this right? Its mean is centered at, let's see, negative 0.8 indicating that we should move basically left with a speed of 0.8 meters per second for example. And again we can see that because this is a probability distribution because of the format of policy networks, right, we're enforcing that this is a probability distribution. That means that the integral now of this, of this outputs right by definition of it being a gaussian, must also integrate to one.\n[39:47.640,40:7.620]  Okay, great. So now let's maybe take a look at how policy gradient networks can be trained and, you know, step through that process as well as we look at a very concrete example. And maybe let's start by just revisiting this reinforcement learning loop that we started this class with now.\n[40:7.740,40:19.740]  Let's specifically consider the example of training an autonomous vehicles, since I think that this is a particularly very intuitive example that we can walk through the agent. Here is the vehicle, right?\n[40:19.880,40:36.720]  The state could be obtained through many sensors that could be mounted on the vehicle itself. So, for example, autonomous vehicles are typically equipped with sensors like cameras, lidars, radars etc, all of these are giving observational inputs to the to the vehicle.\n[40:36.720,40:52.700]  The action that we could take is a steering wheel angle. This is not a discrete variable. This is a continuous variable. It's actually an angle that could take any real number. And finally, the reward in this very simplistic example is the distance that we travel before we crash.\n[40:53.440,41:22.680]  Okay, so now let's take a look at how we could train a policy gradient neural network to solve this task of self driving cars as a concrete example. So we start by initializing our agent right. Remember that we have no training data, right? So we have to think about actually reinforcement learning is almost like a data acquisition plus learning pipeline combined together. So the first part of that data acquisition pipeline is first to initialize our agent to go out and collect some data.\n[41:24.380,41:26.640]  So we start our.\n[41:26.640,41:50.540]  Vehicle, our agent. And in the beginning, of course, it knows nothing about driving. It's never been exposed to any of these rules of the environment or the observation before. So it runs its policy, which right now is untrained entirely until it terminates, right until it goes outside of some bounds that we define. We measure basically the reward as the distance that it traveled before it terminated.\n[41:50.540,42:16.640]  And we record all of the states, all of the actions and the final reward that it obtained until that termination, right? This becomes our mini data set that we'll use for the first round of training. Let's take those data sets. And now we'll do one step of training. The first step of training that we'll do is to take me to take the later half of our.\n[42:17.160,42:46.620]  Of our trajectory that our agent ran and decreased the probability of actions that resulted in low rewards. Now, because the vehicle we know the vehicle terminated, we can assume that all of the actions that occurred in the later half of this trajectory were probably not very good actions because they came very close to termination. So let's decrease the probability of all of those things happening again in the future, and we'll take all of the things that happen in the beginning half of our training episode.\n[42:46.620,43:22.340]  And we will increase their probabilities. Now, again, there's no reason why there shouldn't necessarily be a good action that we took in the first half of this trajectory and a bad action in the later half. But it's simply because actions that are in the later half were closer to a failure and closer determination that we can assume, for example, that these were probably suboptimal actions. But it's very possible that these are noisy rewards as well, because it's such a sparse signal, it's very possible that you had some good actions at the end and you were actually trying to recover your car, but you were just too late.\n[43:24.080,43:53.520]  Now repeat this process again. Re-initialize the agent one more time and run it until completion. Now the agent goes a bit farther right because you've decreased the probabilities at the ends, increased the probabilities at the future, and you keep repeating this over and over again until you notice that the agent learns to perform better and better every time until it finally converges. And at the end the agent is able to basically follow lanes, usually swerving a bit side to side while it does that.\n[43:53.520,44:15.880]  Without crashing. And this is actually really fascinating because this is a self driving car that we never taught anything about. What a Lane marker means or what are the rules of the road, anything about that, right? This was a car that learned entirely just by going out, crashing a lot and, you know, trying to figure out what to do to not keep doing that in the future.\n[44:15.880,44:43.600]  And the remaining question is actually how we can update, you know, that policy as part of this algorithm that I'm showing you on the right and the left hand side, right? Like how can we basically formulate that same algorithm? And specifically the update equations, steps four and five right here. These are the two really important steps of how we can use those two steps to train our policy and decrease the probability of bad events while promoting these likelihoods of all these good events.\n[44:44.740,45:4.620]  So let's assume the let's look at the loss function. First of all, the loss function for a policy gradient neural network looks like this. And then we'll start by dissecting it to understand why this works the way it does. So here we can see that the loss consists of two terms. The first term is this term in green.\n[45:4.620,45:21.200]  Just called the log likelihood of selecting a particular action the second term is something that all of you are very familiar with already. This is simply the return at a specific time, so that's the expected return on rewards that you would get after this time point.\n[45:21.200,45:44.580]  Now, let's assume that we got a lot of reward for a particular action that had a high log probability or high probability. If we got a lot of reward for a particular action that had high probability, that means that we want to increase that probability even further. So we do it even more or even more likelihood, we sampled that action again into the future.\n[45:44.960,46:17.320]  On the other hand, if we selected or let's say if we obtained a reward that was very low for an action that had high likelihood, we want the inverse effect. We never want to sample that action again in the future because it resulted in a low reward, right? And you'll notice that this loss function right here, by including this negative, we're going to minimize the likelihood of achieving any action that had low rewards in this trajectory now in our simplified example on.\n[46:17.320,46:33.740]  The car example, all the things that had low rewards were exactly those actions that came closest to the termination part of the of the vehicle. All the things that had high rewards were the things that came in the beginning. That's just the assumption that we make when defining our reward structure.\n[46:34.000,47:9.460]  Now we can plug this into the the loss of gradient descent algorithm to train our neural network. When we see, you know, this policy gradient algorithm which you can see highlighted here. This gradient is exactly of the policy part of the neural network. That's the probability of selecting an action, even a specific state. And if you remember before when we defined, you know, what does it mean to be a policy function? That's exactly what it means, right? Given a particular state that you find yourself in, what is the probability of selecting a particular action with the highest likelihood.\n[47:9.460,47:17.320]  And that's, you know, exactly where this method gets its name from this policy gradient piece here that you can see here.\n[47:17.640,47:35.060]  Now, I want to take maybe just a very brief second towards the end of the class here just to talk about, you know, some of the challenges and keeping in line with the first lecture today, some of the challenges of deploying these types of algorithms in the context of the real world, right?\n[47:35.060,47:49.140]  What do you think when you look at this training algorithm that you can see here? What do you think are the shortcomings of this training algorithm and which step, I guess, specifically if we wanted to deploy this approach into reality?\n[47:52.780,48:40.100]  Yeah, exactly. So it's step two, right? If you wanted to do this in reality, right, that essentially means that you want to go out, collect your car, crashing it a bunch of times just to learn how to not crash it, right? And that's, you know, that's simply not feasible. Right? Number one, it's also, you know, very dangerous. Number two, so there are ways around this, right? The number one way around this is that people try to train these types of models in simulation, right? Simulation is very safe because you know we're not going to actually be damaging anything real. It's still very inefficient because we have to run these algorithms a bunch of times and crash them a bunch of times. Just learn not to crash, but at least now at least from a safety point of view.\n[48:40.100,48:41.880]  It's much safer.\n[48:41.880,49:13.720]  But, you know, the problem is that modern simulation engines for reinforcement learning and generally, very broadly speaking, modern simators for vision specifically, do not at all capture reality very accurately. In fact, there's a very famous notion called the simoral gap, which is a gap that exists when you train algorithms in simulation, and they don't extend to a lot of the phenomena that we see and the patterns that we see in reality.\n[49:13.720,50:14.080]  And one really cool result that I want to just highlight here is that when we're training reinforcement learning algorithms, we ultimately want them to be, you know, not operating in simulation. We want them to be in reality. And as part of our lab here at MIT, we've been developing this very, very cool brand new photo, realistic simulation engine that goes beyond basically the paradigm of how simulators work today, which is basically defining a model of their environment and trying to, you know, synthesize that that model. Essentially these simulators are like glorified game engines, right? They all look very game like when you look at them. But one thing that we've done is taken a data driven approach using real data of the real world. Can we build up synthetic environments that are super photo realistic and look like this, right? So this is a cool result that we created here at MIT developing this photo realistic simulation engine. This is actually an autonomous agent, not a real car driving through.\n[50:14.080,50:47.760]  Our virtual simulator and a bunch of different types of different scenarios. So this simulator is called vista, allows us to basically use real data that we do collect in the real world, but then re-simulate those same real roads. So for example, let's say you take your car, you drive out on mass, have you collect data of mass have you can now drop a virtual agent into that same simulated environment, observing new viewpoints of what that scene might have looked like from different types of perturbations or, or types of angles that it might be exposed to.\n[50:47.760,51:26.620]  And that allows us to train these agents now entirely using reinforcement learning, no human labels, but importantly allowed them to be transferred into reality because there's no SIM to real gap anymore. So in fact, we did exactly this. We placed agents into our simulator, we trained them using the exact algorithms that you learned about in today's lecture, these policy gradient algorithms and all of the training was done entirely in simulation. Then we took these policies and we deployed them on board our full scale autonomous vehicle. This is now in the real world, no longer in simulation, and on the left hand side you can see.\n[51:26.780,52:12.900]  Basically this car driving through this environment completely autonomous in the real world, no transfer learning is is done here. There is no augmentation of data from real world data. This is entirely trained using simulation and this represented actually the first time ever that reinforcement learning was used to train a policy end to end. We're an autonomous vehicle that could be deployed in reality. So that was something really cool that uh we we created here at MIT. But now that we covered, you know, all of these foundations of reinforcement learning and policy learning, I want to touch on some other maybe very exciting applications that we're seeing. And one very popular application that a lot of people will tell you about and talk about is the game of go.\n[52:12.900,52:46.140]  So here reinforcement learning agents could be actually tried to put against the test against you know, grand master level go players and you know at the time achieved incredibly impressive results. So for those of you who are not familiar with the game of go go game of go is played on a nineteen by nineteen board. The rough objective of go is to claim basically more board pieces than your opponent, right? And through the grid of sorry through the grid that you can see here this nineteen by nineteen grid.\n[52:46.140,53:11.860]  And while the game itself, the the logical rules, are actually quite simple, the number of possible action spaces and possible states that this board could be placed into is greater than the number of atoms in the universe. So this game, even though the rules are very simple in their logical definitions, is an extraordinarily complex game for an artificial algorithm to try and master.\n[53:11.860,53:33.000]  So the objective here was to build a reinforcement learning algorithm to master the game of go, not only beating, you know, these gold standard softwareares, but also what was at the time like an amazing result was to beat the grand master level players. So the number one player in the world of go was a human human champion, obviously.\n[53:33.000,54:17.460]  So Google deepmind Rose to this challenge they created a couple years ago developing this solution, which is very much based in the exact same algorithms that you learned about in today's lecture, combining both the value part of this network with residual layers, which we'll cover in the next lecture tomorrow. And using reinforcement learning pipeline, they were able to defeat the grand champion human players and the idea that its core was actually very simple, the first step is that you train a neural network to basically watch human level experts. So this is not using reinforcement learning, using supervised learning, using the techniques that we covered in lectures one, two and three.\n[54:17.460,54:41.000]  And from this first step, the goal is to build like a policy that would imitate some of the rough patterns that a human type of player or a human grandmaster would take based on a given board, state the type of actions that they might execute. But then given this pre trained model, essentially you could use it to bootstrap and reinforcement learning algorithm that would play against itself.\n[54:41.000,55:41.320]  In order to learn how to improve even beyond the human levels, right. So it would take its human understandings, try to imitate the humans first of all, but then from that imitation they would pin these two neural networks against themselves, play a game against themselves and the winners would be receiving a reward. The losers would try to negate all of the actions that they may have acquired from their human counterparts and try to actually learn new types of rules and new types of actions basically that might be very beneficial to achieving superhuman performance. And one of the very important auxiliary tricks that brought this idea to be possible was the usage of this second network, this auxiliary network which took as input the state of the board and tried to predict, you know, what are all of the different possible board states that might emerge from this particular state and what would their values be? What would their potential returns and their outcomes be? So this network was an auxiliary.\n[55:41.320,56:18.300]  Network that was almost hallucinating, right? Different board states that it could take from this particular state and using those predicted values to guide its planning of, you know, what action should it take into the future? And finally, very much more recently, they extended this algorithm and showed that they could not even use the human grand masters in the beginning to imitate from in the beginning. And bootstrap these algorithms. What if they just started entirely from scratch and just had two neural networks never trained before they start pinning themselves against each other and you could actually see that you could without any human supervision at all.\n[56:18.300,56:33.400]  Have a neural network learn to not only outperform the solution that outperform the humans, but also outperform the solution that was created, which was bootstrapped by humans as well.\n[56:34.300,57:11.940]  So with that, I'll summarize very quickly what we've learned today and and conclude for the day. So we've talked a lot about really the foundational algorithms underlying reinforcement learning. We saw two different types of reinforcement learning approaches of how we can optimize these solutions. First being q, learning, where we're trying to actually estimate, given a state, you know, what is the value that we might expect for any possible action in the second way was to take a much more end to end approach and say how, given the state that we see ourselves in, what is the likelihood that I should take any given action to maximize the potential that I I have in this particular state.\n[57:11.940,57:29.740]  And I hope that all of this was very exciting to you today. We have a very exciting lab and kick off for the competition and the deadline for these competitions will be well. It was originally set to be thursday, which is tomorrow at eleven PM. Thank you.\n", "ErrorMsg": "", "ResultDetail": [{"FinalSentence": "Hi everyone, welcome back. Today, I think that these two lectures today are really exciting because they start to move beyond. You know, a lot of what we've talked about in the class so far, which is focusing a lot on really static data sets and specifically in today. In this lecture right now I'm going to start to talk about how we can learn about this very long standing field of how we can specifically marry two topics. The first topic being reinforcement learning.", "SliceSentence": "Hi everyone welcome back Today I think that these two lectures today are really exciting because they start to move beyond You know a lot of what we've talked about in the class so far which is focusing a lot on really static data sets and specifically in today In this lecture right now I'm going to start to talk about how we can learn about this very long standing field of how we can specifically marry two topics The first topic being reinforcement learning", "StartMs": 8940, "EndMs": 36480, "WordsNum": 85, "Words": [{"Word": "Hi", "OffsetStartMs": 100, "OffsetEndMs": 450}, {"Word": "everyone", "OffsetStartMs": 450, "OffsetEndMs": 705}, {"Word": "welcome", "OffsetStartMs": 705, "OffsetEndMs": 975}, {"Word": "back", "OffsetStartMs": 975, "OffsetEndMs": 1340}, {"Word": "Today", "OffsetStartMs": 2140, "OffsetEndMs": 2540}, {"Word": "I", "OffsetStartMs": 2770, "OffsetEndMs": 3170}, {"Word": "think", "OffsetStartMs": 3190, "OffsetEndMs": 3495}, {"Word": "that", "OffsetStartMs": 3495, "OffsetEndMs": 3800}, {"Word": "these", "OffsetStartMs": 4000, "OffsetEndMs": 4320}, {"Word": "two", "OffsetStartMs": 4320, "OffsetEndMs": 4515}, {"Word": "lectures", "OffsetStartMs": 4515, "OffsetEndMs": 4905}, {"Word": "today", "OffsetStartMs": 4905, "OffsetEndMs": 5145}, {"Word": "are", "OffsetStartMs": 5145, "OffsetEndMs": 5355}, {"Word": "really", "OffsetStartMs": 5355, "OffsetEndMs": 5595}, {"Word": "exciting", "OffsetStartMs": 5595, "OffsetEndMs": 5955}, {"Word": "because", "OffsetStartMs": 5955, "OffsetEndMs": 6240}, {"Word": "they", "OffsetStartMs": 6240, "OffsetEndMs": 6530}, {"Word": "start", "OffsetStartMs": 6760, "OffsetEndMs": 7065}, {"Word": "to", "OffsetStartMs": 7065, "OffsetEndMs": 7230}, {"Word": "move", "OffsetStartMs": 7230, "OffsetEndMs": 7455}, {"Word": "beyond", "OffsetStartMs": 7455, "OffsetEndMs": 7820}, {"Word": "You", "OffsetStartMs": 7930, "OffsetEndMs": 8190}, {"Word": "know", "OffsetStartMs": 8190, "OffsetEndMs": 8340}, {"Word": "a", "OffsetStartMs": 8340, "OffsetEndMs": 8505}, {"Word": "lot", "OffsetStartMs": 8505, "OffsetEndMs": 8670}, {"Word": "of", "OffsetStartMs": 8670, "OffsetEndMs": 8850}, {"Word": "what", "OffsetStartMs": 8850, "OffsetEndMs": 9030}, {"Word": "we've", "OffsetStartMs": 9030, "OffsetEndMs": 9315}, {"Word": "talked", "OffsetStartMs": 9315, "OffsetEndMs": 9525}, {"Word": "about", "OffsetStartMs": 9525, "OffsetEndMs": 9735}, {"Word": "in", "OffsetStartMs": 9735, "OffsetEndMs": 9870}, {"Word": "the", "OffsetStartMs": 9870, "OffsetEndMs": 10020}, {"Word": "class", "OffsetStartMs": 10020, "OffsetEndMs": 10245}, {"Word": "so", "OffsetStartMs": 10245, "OffsetEndMs": 10515}, {"Word": "far", "OffsetStartMs": 10515, "OffsetEndMs": 10850}, {"Word": "which", "OffsetStartMs": 11200, "OffsetEndMs": 11475}, {"Word": "is", "OffsetStartMs": 11475, "OffsetEndMs": 11640}, {"Word": "focusing", "OffsetStartMs": 11640, "OffsetEndMs": 11925}, {"Word": "a", "OffsetStartMs": 11925, "OffsetEndMs": 12180}, {"Word": "lot", "OffsetStartMs": 12180, "OffsetEndMs": 12330}, {"Word": "on", "OffsetStartMs": 12330, "OffsetEndMs": 12600}, {"Word": "really", "OffsetStartMs": 12600, "OffsetEndMs": 12960}, {"Word": "static", "OffsetStartMs": 12960, "OffsetEndMs": 13370}, {"Word": "data", "OffsetStartMs": 13510, "OffsetEndMs": 13860}, {"Word": "sets", "OffsetStartMs": 13860, "OffsetEndMs": 14145}, {"Word": "and", "OffsetStartMs": 14145, "OffsetEndMs": 14445}, {"Word": "specifically", "OffsetStartMs": 14445, "OffsetEndMs": 14810}, {"Word": "in", "OffsetStartMs": 14830, "OffsetEndMs": 15135}, {"Word": "today", "OffsetStartMs": 15135, "OffsetEndMs": 15440}, {"Word": "In", "OffsetStartMs": 15460, "OffsetEndMs": 15735}, {"Word": "this", "OffsetStartMs": 15735, "OffsetEndMs": 15915}, {"Word": "lecture", "OffsetStartMs": 15915, "OffsetEndMs": 16215}, {"Word": "right", "OffsetStartMs": 16215, "OffsetEndMs": 16545}, {"Word": "now", "OffsetStartMs": 16545, "OffsetEndMs": 16880}, {"Word": "I'm", "OffsetStartMs": 17350, "OffsetEndMs": 17670}, {"Word": "going", "OffsetStartMs": 17670, "OffsetEndMs": 17790}, {"Word": "to", "OffsetStartMs": 17790, "OffsetEndMs": 17940}, {"Word": "start", "OffsetStartMs": 17940, "OffsetEndMs": 18090}, {"Word": "to", "OffsetStartMs": 18090, "OffsetEndMs": 18240}, {"Word": "talk", "OffsetStartMs": 18240, "OffsetEndMs": 18435}, {"Word": "about", "OffsetStartMs": 18435, "OffsetEndMs": 18660}, {"Word": "how", "OffsetStartMs": 18660, "OffsetEndMs": 18810}, {"Word": "we", "OffsetStartMs": 18810, "OffsetEndMs": 18930}, {"Word": "can", "OffsetStartMs": 18930, "OffsetEndMs": 19080}, {"Word": "learn", "OffsetStartMs": 19080, "OffsetEndMs": 19305}, {"Word": "about", "OffsetStartMs": 19305, "OffsetEndMs": 19530}, {"Word": "this", "OffsetStartMs": 19530, "OffsetEndMs": 19710}, {"Word": "very", "OffsetStartMs": 19710, "OffsetEndMs": 20000}, {"Word": "long", "OffsetStartMs": 20050, "OffsetEndMs": 20450}, {"Word": "standing", "OffsetStartMs": 20530, "OffsetEndMs": 20930}, {"Word": "field", "OffsetStartMs": 21100, "OffsetEndMs": 21450}, {"Word": "of", "OffsetStartMs": 21450, "OffsetEndMs": 21660}, {"Word": "how", "OffsetStartMs": 21660, "OffsetEndMs": 21795}, {"Word": "we", "OffsetStartMs": 21795, "OffsetEndMs": 21930}, {"Word": "can", "OffsetStartMs": 21930, "OffsetEndMs": 22095}, {"Word": "specifically", "OffsetStartMs": 22095, "OffsetEndMs": 22400}, {"Word": "marry", "OffsetStartMs": 22570, "OffsetEndMs": 22970}, {"Word": "two", "OffsetStartMs": 23380, "OffsetEndMs": 23780}, {"Word": "topics", "OffsetStartMs": 23800, "OffsetEndMs": 24200}, {"Word": "The", "OffsetStartMs": 24370, "OffsetEndMs": 24630}, {"Word": "first", "OffsetStartMs": 24630, "OffsetEndMs": 24810}, {"Word": "topic", "OffsetStartMs": 24810, "OffsetEndMs": 25130}, {"Word": "being", "OffsetStartMs": 25150, "OffsetEndMs": 25550}, {"Word": "reinforcement", "OffsetStartMs": 25810, "OffsetEndMs": 26610}, {"Word": "learning", "OffsetStartMs": 26610, "OffsetEndMs": 26900}], "SpeechSpeed": 16.8}, {"FinalSentence": "Which has existed for many, many decades, together with a lot of the very recent advances in deep learning, which you've already started learning about as part of this course.", "SliceSentence": "Which has existed for many many decades together with a lot of the very recent advances in deep learning which you've already started learning about as part of this course", "StartMs": 36480, "EndMs": 46480, "WordsNum": 30, "Words": [{"Word": "Which", "OffsetStartMs": 0, "OffsetEndMs": 290}, {"Word": "has", "OffsetStartMs": 370, "OffsetEndMs": 705}, {"Word": "existed", "OffsetStartMs": 705, "OffsetEndMs": 1095}, {"Word": "for", "OffsetStartMs": 1095, "OffsetEndMs": 1260}, {"Word": "many", "OffsetStartMs": 1260, "OffsetEndMs": 1485}, {"Word": "many", "OffsetStartMs": 1485, "OffsetEndMs": 1755}, {"Word": "decades", "OffsetStartMs": 1755, "OffsetEndMs": 2090}, {"Word": "together", "OffsetStartMs": 2500, "OffsetEndMs": 2895}, {"Word": "with", "OffsetStartMs": 2895, "OffsetEndMs": 3225}, {"Word": "a", "OffsetStartMs": 3225, "OffsetEndMs": 3420}, {"Word": "lot", "OffsetStartMs": 3420, "OffsetEndMs": 3555}, {"Word": "of", "OffsetStartMs": 3555, "OffsetEndMs": 3705}, {"Word": "the", "OffsetStartMs": 3705, "OffsetEndMs": 3840}, {"Word": "very", "OffsetStartMs": 3840, "OffsetEndMs": 4035}, {"Word": "recent", "OffsetStartMs": 4035, "OffsetEndMs": 4370}, {"Word": "advances", "OffsetStartMs": 4450, "OffsetEndMs": 5150}, {"Word": "in", "OffsetStartMs": 5410, "OffsetEndMs": 5775}, {"Word": "deep", "OffsetStartMs": 5775, "OffsetEndMs": 6045}, {"Word": "learning", "OffsetStartMs": 6045, "OffsetEndMs": 6300}, {"Word": "which", "OffsetStartMs": 6300, "OffsetEndMs": 6525}, {"Word": "you've", "OffsetStartMs": 6525, "OffsetEndMs": 6780}, {"Word": "already", "OffsetStartMs": 6780, "OffsetEndMs": 7020}, {"Word": "started", "OffsetStartMs": 7020, "OffsetEndMs": 7320}, {"Word": "learning", "OffsetStartMs": 7320, "OffsetEndMs": 7650}, {"Word": "about", "OffsetStartMs": 7650, "OffsetEndMs": 7950}, {"Word": "as", "OffsetStartMs": 7950, "OffsetEndMs": 8205}, {"Word": "part", "OffsetStartMs": 8205, "OffsetEndMs": 8415}, {"Word": "of", "OffsetStartMs": 8415, "OffsetEndMs": 8565}, {"Word": "this", "OffsetStartMs": 8565, "OffsetEndMs": 8790}, {"Word": "course", "OffsetStartMs": 8790, "OffsetEndMs": 9140}], "SpeechSpeed": 17.1}, {"FinalSentence": "Now this marriage of these two fields is actually really fascinating to me, particularly because like I said, it moves away from this whole paradigm of ah, or really this whole paradigm that we've been exposed to in the class thus far. And that paradigm is really how we can build a deep learning model using some data set. But that data set is typically fixed in in our world, right? We collect, we go out and go collect that data set, we deploy it on our machine learning or deep learning algorithm and then we can evaluate on a brand new data set.", "SliceSentence": "Now this marriage of these two fields is actually really fascinating to me particularly because like I said it moves away from this whole paradigm of ah or really this whole paradigm that we've been exposed to in the class thus far And that paradigm is really how we can build a deep learning model using some data set But that data set is typically fixed in in our world right We collect we go out and go collect that data set we deploy it on our machine learning or deep learning algorithm and then we can evaluate on a brand new data set", "StartMs": 46840, "EndMs": 79260, "WordsNum": 104, "Words": [{"Word": "Now", "OffsetStartMs": 100, "OffsetEndMs": 500}, {"Word": "this", "OffsetStartMs": 640, "OffsetEndMs": 1040}, {"Word": "marriage", "OffsetStartMs": 1180, "OffsetEndMs": 1580}, {"Word": "of", "OffsetStartMs": 1720, "OffsetEndMs": 2010}, {"Word": "these", "OffsetStartMs": 2010, "OffsetEndMs": 2250}, {"Word": "two", "OffsetStartMs": 2250, "OffsetEndMs": 2505}, {"Word": "fields", "OffsetStartMs": 2505, "OffsetEndMs": 2810}, {"Word": "is", "OffsetStartMs": 2860, "OffsetEndMs": 3225}, {"Word": "actually", "OffsetStartMs": 3225, "OffsetEndMs": 3450}, {"Word": "really", "OffsetStartMs": 3450, "OffsetEndMs": 3710}, {"Word": "fascinating", "OffsetStartMs": 3880, "OffsetEndMs": 4260}, {"Word": "to", "OffsetStartMs": 4260, "OffsetEndMs": 4500}, {"Word": "me", "OffsetStartMs": 4500, "OffsetEndMs": 4760}, {"Word": "particularly", "OffsetStartMs": 4840, "OffsetEndMs": 5240}, {"Word": "because", "OffsetStartMs": 5620, "OffsetEndMs": 6020}, {"Word": "like", "OffsetStartMs": 6160, "OffsetEndMs": 6420}, {"Word": "I", "OffsetStartMs": 6420, "OffsetEndMs": 6570}, {"Word": "said", "OffsetStartMs": 6570, "OffsetEndMs": 6765}, {"Word": "it", "OffsetStartMs": 6765, "OffsetEndMs": 6990}, {"Word": "moves", "OffsetStartMs": 6990, "OffsetEndMs": 7275}, {"Word": "away", "OffsetStartMs": 7275, "OffsetEndMs": 7560}, {"Word": "from", "OffsetStartMs": 7560, "OffsetEndMs": 7755}, {"Word": "this", "OffsetStartMs": 7755, "OffsetEndMs": 7905}, {"Word": "whole", "OffsetStartMs": 7905, "OffsetEndMs": 8085}, {"Word": "paradigm", "OffsetStartMs": 8085, "OffsetEndMs": 8840}, {"Word": "of", "OffsetStartMs": 9010, "OffsetEndMs": 9410}, {"Word": "ah", "OffsetStartMs": 10000, "OffsetEndMs": 10305}, {"Word": "or", "OffsetStartMs": 10305, "OffsetEndMs": 10485}, {"Word": "really", "OffsetStartMs": 10485, "OffsetEndMs": 10760}, {"Word": "this", "OffsetStartMs": 10780, "OffsetEndMs": 11055}, {"Word": "whole", "OffsetStartMs": 11055, "OffsetEndMs": 11220}, {"Word": "paradigm", "OffsetStartMs": 11220, "OffsetEndMs": 11595}, {"Word": "that", "OffsetStartMs": 11595, "OffsetEndMs": 11715}, {"Word": "we've", "OffsetStartMs": 11715, "OffsetEndMs": 11955}, {"Word": "been", "OffsetStartMs": 11955, "OffsetEndMs": 12200}, {"Word": "exposed", "OffsetStartMs": 12250, "OffsetEndMs": 12630}, {"Word": "to", "OffsetStartMs": 12630, "OffsetEndMs": 12960}, {"Word": "in", "OffsetStartMs": 12960, "OffsetEndMs": 13185}, {"Word": "the", "OffsetStartMs": 13185, "OffsetEndMs": 13335}, {"Word": "class", "OffsetStartMs": 13335, "OffsetEndMs": 13610}, {"Word": "thus", "OffsetStartMs": 13750, "OffsetEndMs": 14085}, {"Word": "far", "OffsetStartMs": 14085, "OffsetEndMs": 14295}, {"Word": "And", "OffsetStartMs": 14295, "OffsetEndMs": 14430}, {"Word": "that", "OffsetStartMs": 14430, "OffsetEndMs": 14595}, {"Word": "paradigm", "OffsetStartMs": 14595, "OffsetEndMs": 15320}, {"Word": "is", "OffsetStartMs": 15430, "OffsetEndMs": 15810}, {"Word": "really", "OffsetStartMs": 15810, "OffsetEndMs": 16140}, {"Word": "how", "OffsetStartMs": 16140, "OffsetEndMs": 16380}, {"Word": "we", "OffsetStartMs": 16380, "OffsetEndMs": 16560}, {"Word": "can", "OffsetStartMs": 16560, "OffsetEndMs": 16800}, {"Word": "build", "OffsetStartMs": 16800, "OffsetEndMs": 17150}, {"Word": "a", "OffsetStartMs": 17350, "OffsetEndMs": 17655}, {"Word": "deep", "OffsetStartMs": 17655, "OffsetEndMs": 17865}, {"Word": "learning", "OffsetStartMs": 17865, "OffsetEndMs": 18135}, {"Word": "model", "OffsetStartMs": 18135, "OffsetEndMs": 18500}, {"Word": "using", "OffsetStartMs": 19210, "OffsetEndMs": 19590}, {"Word": "some", "OffsetStartMs": 19590, "OffsetEndMs": 19860}, {"Word": "data", "OffsetStartMs": 19860, "OffsetEndMs": 20100}, {"Word": "set", "OffsetStartMs": 20100, "OffsetEndMs": 20340}, {"Word": "But", "OffsetStartMs": 20340, "OffsetEndMs": 20475}, {"Word": "that", "OffsetStartMs": 20475, "OffsetEndMs": 20640}, {"Word": "data", "OffsetStartMs": 20640, "OffsetEndMs": 20910}, {"Word": "set", "OffsetStartMs": 20910, "OffsetEndMs": 21120}, {"Word": "is", "OffsetStartMs": 21120, "OffsetEndMs": 21300}, {"Word": "typically", "OffsetStartMs": 21300, "OffsetEndMs": 21620}, {"Word": "fixed", "OffsetStartMs": 21820, "OffsetEndMs": 22220}, {"Word": "in", "OffsetStartMs": 22540, "OffsetEndMs": 22905}, {"Word": "in", "OffsetStartMs": 22905, "OffsetEndMs": 23270}, {"Word": "our", "OffsetStartMs": 23350, "OffsetEndMs": 23670}, {"Word": "world", "OffsetStartMs": 23670, "OffsetEndMs": 23985}, {"Word": "right", "OffsetStartMs": 23985, "OffsetEndMs": 24285}, {"Word": "We", "OffsetStartMs": 24285, "OffsetEndMs": 24525}, {"Word": "collect", "OffsetStartMs": 24525, "OffsetEndMs": 24810}, {"Word": "we", "OffsetStartMs": 24810, "OffsetEndMs": 25020}, {"Word": "go", "OffsetStartMs": 25020, "OffsetEndMs": 25140}, {"Word": "out", "OffsetStartMs": 25140, "OffsetEndMs": 25260}, {"Word": "and", "OffsetStartMs": 25260, "OffsetEndMs": 25395}, {"Word": "go", "OffsetStartMs": 25395, "OffsetEndMs": 25670}, {"Word": "collect", "OffsetStartMs": 25690, "OffsetEndMs": 25980}, {"Word": "that", "OffsetStartMs": 25980, "OffsetEndMs": 26160}, {"Word": "data", "OffsetStartMs": 26160, "OffsetEndMs": 26400}, {"Word": "set", "OffsetStartMs": 26400, "OffsetEndMs": 26750}, {"Word": "we", "OffsetStartMs": 26920, "OffsetEndMs": 27255}, {"Word": "deploy", "OffsetStartMs": 27255, "OffsetEndMs": 27465}, {"Word": "it", "OffsetStartMs": 27465, "OffsetEndMs": 27585}, {"Word": "on", "OffsetStartMs": 27585, "OffsetEndMs": 27690}, {"Word": "our", "OffsetStartMs": 27690, "OffsetEndMs": 27885}, {"Word": "machine", "OffsetStartMs": 27885, "OffsetEndMs": 28110}, {"Word": "learning", "OffsetStartMs": 28110, "OffsetEndMs": 28320}, {"Word": "or", "OffsetStartMs": 28320, "OffsetEndMs": 28515}, {"Word": "deep", "OffsetStartMs": 28515, "OffsetEndMs": 28680}, {"Word": "learning", "OffsetStartMs": 28680, "OffsetEndMs": 28970}, {"Word": "algorithm", "OffsetStartMs": 29020, "OffsetEndMs": 29570}, {"Word": "and", "OffsetStartMs": 29680, "OffsetEndMs": 29940}, {"Word": "then", "OffsetStartMs": 29940, "OffsetEndMs": 30045}, {"Word": "we", "OffsetStartMs": 30045, "OffsetEndMs": 30165}, {"Word": "can", "OffsetStartMs": 30165, "OffsetEndMs": 30345}, {"Word": "evaluate", "OffsetStartMs": 30345, "OffsetEndMs": 30650}, {"Word": "on", "OffsetStartMs": 30730, "OffsetEndMs": 30990}, {"Word": "a", "OffsetStartMs": 30990, "OffsetEndMs": 31110}, {"Word": "brand", "OffsetStartMs": 31110, "OffsetEndMs": 31275}, {"Word": "new", "OffsetStartMs": 31275, "OffsetEndMs": 31455}, {"Word": "data", "OffsetStartMs": 31455, "OffsetEndMs": 31680}, {"Word": "set", "OffsetStartMs": 31680, "OffsetEndMs": 32030}], "SpeechSpeed": 16.7}, {"FinalSentence": "But that is very different than the way things work in the real world. In the real world, you have your deep learning model actually deployed together with the data together, out into reality, exploring, interacting with its environment and trying out a whole bunch of different actions and different things in that environment in order to be able to learn how to best perform any particular task that may need to accomplish. And typically we want to be able to do this without explicit human supervision, right. This is the key motivation of reinforcement learning. You're going to try and learn through reinforcement, making mistakes in your world and then collecting data on those mistakes to learn how to improve.", "SliceSentence": "But that is very different than the way things work in the real world In the real world you have your deep learning model actually deployed together with the data together out into reality exploring interacting with its environment and trying out a whole bunch of different actions and different things in that environment in order to be able to learn how to best perform any particular task that may need to accomplish And typically we want to be able to do this without explicit human supervision right This is the key motivation of reinforcement learning You're going to try and learn through reinforcement making mistakes in your world and then collecting data on those mistakes to learn how to improve", "StartMs": 79260, "EndMs": 118940, "WordsNum": 121, "Words": [{"Word": "But", "OffsetStartMs": 70, "OffsetEndMs": 345}, {"Word": "that", "OffsetStartMs": 345, "OffsetEndMs": 495}, {"Word": "is", "OffsetStartMs": 495, "OffsetEndMs": 645}, {"Word": "very", "OffsetStartMs": 645, "OffsetEndMs": 855}, {"Word": "different", "OffsetStartMs": 855, "OffsetEndMs": 1190}, {"Word": "than", "OffsetStartMs": 1270, "OffsetEndMs": 1605}, {"Word": "the", "OffsetStartMs": 1605, "OffsetEndMs": 1785}, {"Word": "way", "OffsetStartMs": 1785, "OffsetEndMs": 1950}, {"Word": "things", "OffsetStartMs": 1950, "OffsetEndMs": 2220}, {"Word": "work", "OffsetStartMs": 2220, "OffsetEndMs": 2570}, {"Word": "in", "OffsetStartMs": 2710, "OffsetEndMs": 3000}, {"Word": "the", "OffsetStartMs": 3000, "OffsetEndMs": 3135}, {"Word": "real", "OffsetStartMs": 3135, "OffsetEndMs": 3285}, {"Word": "world", "OffsetStartMs": 3285, "OffsetEndMs": 3570}, {"Word": "In", "OffsetStartMs": 3570, "OffsetEndMs": 3795}, {"Word": "the", "OffsetStartMs": 3795, "OffsetEndMs": 3915}, {"Word": "real", "OffsetStartMs": 3915, "OffsetEndMs": 4095}, {"Word": "world", "OffsetStartMs": 4095, "OffsetEndMs": 4400}, {"Word": "you", "OffsetStartMs": 4690, "OffsetEndMs": 4995}, {"Word": "have", "OffsetStartMs": 4995, "OffsetEndMs": 5250}, {"Word": "your", "OffsetStartMs": 5250, "OffsetEndMs": 5490}, {"Word": "deep", "OffsetStartMs": 5490, "OffsetEndMs": 5685}, {"Word": "learning", "OffsetStartMs": 5685, "OffsetEndMs": 5955}, {"Word": "model", "OffsetStartMs": 5955, "OffsetEndMs": 6320}, {"Word": "actually", "OffsetStartMs": 6490, "OffsetEndMs": 6870}, {"Word": "deployed", "OffsetStartMs": 6870, "OffsetEndMs": 7395}, {"Word": "together", "OffsetStartMs": 7395, "OffsetEndMs": 7785}, {"Word": "with", "OffsetStartMs": 7785, "OffsetEndMs": 8115}, {"Word": "the", "OffsetStartMs": 8115, "OffsetEndMs": 8325}, {"Word": "data", "OffsetStartMs": 8325, "OffsetEndMs": 8600}, {"Word": "together", "OffsetStartMs": 8680, "OffsetEndMs": 9000}, {"Word": "out", "OffsetStartMs": 9000, "OffsetEndMs": 9240}, {"Word": "into", "OffsetStartMs": 9240, "OffsetEndMs": 9560}, {"Word": "reality", "OffsetStartMs": 9610, "OffsetEndMs": 10010}, {"Word": "exploring", "OffsetStartMs": 11020, "OffsetEndMs": 11480}, {"Word": "interacting", "OffsetStartMs": 11860, "OffsetEndMs": 12480}, {"Word": "with", "OffsetStartMs": 12480, "OffsetEndMs": 12735}, {"Word": "its", "OffsetStartMs": 12735, "OffsetEndMs": 13035}, {"Word": "environment", "OffsetStartMs": 13035, "OffsetEndMs": 13430}, {"Word": "and", "OffsetStartMs": 13570, "OffsetEndMs": 13875}, {"Word": "trying", "OffsetStartMs": 13875, "OffsetEndMs": 14100}, {"Word": "out", "OffsetStartMs": 14100, "OffsetEndMs": 14325}, {"Word": "a", "OffsetStartMs": 14325, "OffsetEndMs": 14490}, {"Word": "whole", "OffsetStartMs": 14490, "OffsetEndMs": 14640}, {"Word": "bunch", "OffsetStartMs": 14640, "OffsetEndMs": 14820}, {"Word": "of", "OffsetStartMs": 14820, "OffsetEndMs": 14985}, {"Word": "different", "OffsetStartMs": 14985, "OffsetEndMs": 15260}, {"Word": "actions", "OffsetStartMs": 15280, "OffsetEndMs": 15680}, {"Word": "and", "OffsetStartMs": 15760, "OffsetEndMs": 16065}, {"Word": "different", "OffsetStartMs": 16065, "OffsetEndMs": 16335}, {"Word": "things", "OffsetStartMs": 16335, "OffsetEndMs": 16695}, {"Word": "in", "OffsetStartMs": 16695, "OffsetEndMs": 16950}, {"Word": "that", "OffsetStartMs": 16950, "OffsetEndMs": 17145}, {"Word": "environment", "OffsetStartMs": 17145, "OffsetEndMs": 17480}, {"Word": "in", "OffsetStartMs": 17710, "OffsetEndMs": 18000}, {"Word": "order", "OffsetStartMs": 18000, "OffsetEndMs": 18255}, {"Word": "to", "OffsetStartMs": 18255, "OffsetEndMs": 18480}, {"Word": "be", "OffsetStartMs": 18480, "OffsetEndMs": 18585}, {"Word": "able", "OffsetStartMs": 18585, "OffsetEndMs": 18780}, {"Word": "to", "OffsetStartMs": 18780, "OffsetEndMs": 19005}, {"Word": "learn", "OffsetStartMs": 19005, "OffsetEndMs": 19280}, {"Word": "how", "OffsetStartMs": 19480, "OffsetEndMs": 19800}, {"Word": "to", "OffsetStartMs": 19800, "OffsetEndMs": 19965}, {"Word": "best", "OffsetStartMs": 19965, "OffsetEndMs": 20205}, {"Word": "perform", "OffsetStartMs": 20205, "OffsetEndMs": 20505}, {"Word": "any", "OffsetStartMs": 20505, "OffsetEndMs": 20805}, {"Word": "particular", "OffsetStartMs": 20805, "OffsetEndMs": 21200}, {"Word": "task", "OffsetStartMs": 21220, "OffsetEndMs": 21615}, {"Word": "that", "OffsetStartMs": 21615, "OffsetEndMs": 22010}, {"Word": "may", "OffsetStartMs": 22030, "OffsetEndMs": 22430}, {"Word": "need", "OffsetStartMs": 23290, "OffsetEndMs": 23565}, {"Word": "to", "OffsetStartMs": 23565, "OffsetEndMs": 23745}, {"Word": "accomplish", "OffsetStartMs": 23745, "OffsetEndMs": 24050}, {"Word": "And", "OffsetStartMs": 24070, "OffsetEndMs": 24435}, {"Word": "typically", "OffsetStartMs": 24435, "OffsetEndMs": 24800}, {"Word": "we", "OffsetStartMs": 25030, "OffsetEndMs": 25305}, {"Word": "want", "OffsetStartMs": 25305, "OffsetEndMs": 25500}, {"Word": "to", "OffsetStartMs": 25500, "OffsetEndMs": 25695}, {"Word": "be", "OffsetStartMs": 25695, "OffsetEndMs": 25815}, {"Word": "able", "OffsetStartMs": 25815, "OffsetEndMs": 25980}, {"Word": "to", "OffsetStartMs": 25980, "OffsetEndMs": 26160}, {"Word": "do", "OffsetStartMs": 26160, "OffsetEndMs": 26280}, {"Word": "this", "OffsetStartMs": 26280, "OffsetEndMs": 26460}, {"Word": "without", "OffsetStartMs": 26460, "OffsetEndMs": 26780}, {"Word": "explicit", "OffsetStartMs": 27100, "OffsetEndMs": 27585}, {"Word": "human", "OffsetStartMs": 27585, "OffsetEndMs": 27890}, {"Word": "supervision", "OffsetStartMs": 28030, "OffsetEndMs": 28490}, {"Word": "right", "OffsetStartMs": 28630, "OffsetEndMs": 28950}, {"Word": "This", "OffsetStartMs": 28950, "OffsetEndMs": 29145}, {"Word": "is", "OffsetStartMs": 29145, "OffsetEndMs": 29280}, {"Word": "the", "OffsetStartMs": 29280, "OffsetEndMs": 29445}, {"Word": "key", "OffsetStartMs": 29445, "OffsetEndMs": 29750}, {"Word": "motivation", "OffsetStartMs": 30280, "OffsetEndMs": 30885}, {"Word": "of", "OffsetStartMs": 30885, "OffsetEndMs": 31155}, {"Word": "reinforcement", "OffsetStartMs": 31155, "OffsetEndMs": 31770}, {"Word": "learning", "OffsetStartMs": 31770, "OffsetEndMs": 31980}, {"Word": "You're", "OffsetStartMs": 31980, "OffsetEndMs": 32280}, {"Word": "going", "OffsetStartMs": 32280, "OffsetEndMs": 32415}, {"Word": "to", "OffsetStartMs": 32415, "OffsetEndMs": 32595}, {"Word": "try", "OffsetStartMs": 32595, "OffsetEndMs": 32715}, {"Word": "and", "OffsetStartMs": 32715, "OffsetEndMs": 32850}, {"Word": "learn", "OffsetStartMs": 32850, "OffsetEndMs": 33120}, {"Word": "through", "OffsetStartMs": 33120, "OffsetEndMs": 33390}, {"Word": "reinforcement", "OffsetStartMs": 33390, "OffsetEndMs": 34170}, {"Word": "making", "OffsetStartMs": 34170, "OffsetEndMs": 34550}, {"Word": "mistakes", "OffsetStartMs": 34690, "OffsetEndMs": 35090}, {"Word": "in", "OffsetStartMs": 35260, "OffsetEndMs": 35550}, {"Word": "your", "OffsetStartMs": 35550, "OffsetEndMs": 35745}, {"Word": "world", "OffsetStartMs": 35745, "OffsetEndMs": 36050}, {"Word": "and", "OffsetStartMs": 36100, "OffsetEndMs": 36360}, {"Word": "then", "OffsetStartMs": 36360, "OffsetEndMs": 36570}, {"Word": "collecting", "OffsetStartMs": 36570, "OffsetEndMs": 36975}, {"Word": "data", "OffsetStartMs": 36975, "OffsetEndMs": 37170}, {"Word": "on", "OffsetStartMs": 37170, "OffsetEndMs": 37365}, {"Word": "those", "OffsetStartMs": 37365, "OffsetEndMs": 37640}, {"Word": "mistakes", "OffsetStartMs": 37660, "OffsetEndMs": 38060}, {"Word": "to", "OffsetStartMs": 38110, "OffsetEndMs": 38355}, {"Word": "learn", "OffsetStartMs": 38355, "OffsetEndMs": 38505}, {"Word": "how", "OffsetStartMs": 38505, "OffsetEndMs": 38715}, {"Word": "to", "OffsetStartMs": 38715, "OffsetEndMs": 38925}, {"Word": "improve", "OffsetStartMs": 38925, "OffsetEndMs": 39230}], "SpeechSpeed": 17.8}, {"FinalSentence": "Now, this is obviously a huge field in or a huge topic in the field of robotics and autonomy. You can think of self driving cars and robot manipulation, but also very recently we've started seeing incredible advances of deep reinforcement learning, specifically also on the side of game play and strategy making as well. So one really cool thing is that now you can even imagine right this.", "SliceSentence": "Now this is obviously a huge field in or a huge topic in the field of robotics and autonomy You can think of self driving cars and robot manipulation but also very recently we've started seeing incredible advances of deep reinforcement learning specifically also on the side of game play and strategy making as well So one really cool thing is that now you can even imagine right this", "StartMs": 119440, "EndMs": 145740, "WordsNum": 69, "Words": [{"Word": "Now", "OffsetStartMs": 160, "OffsetEndMs": 560}, {"Word": "this", "OffsetStartMs": 850, "OffsetEndMs": 1185}, {"Word": "is", "OffsetStartMs": 1185, "OffsetEndMs": 1520}, {"Word": "obviously", "OffsetStartMs": 1570, "OffsetEndMs": 1905}, {"Word": "a", "OffsetStartMs": 1905, "OffsetEndMs": 2240}, {"Word": "huge", "OffsetStartMs": 2650, "OffsetEndMs": 3015}, {"Word": "field", "OffsetStartMs": 3015, "OffsetEndMs": 3380}, {"Word": "in", "OffsetStartMs": 3640, "OffsetEndMs": 4035}, {"Word": "or", "OffsetStartMs": 4035, "OffsetEndMs": 4290}, {"Word": "a", "OffsetStartMs": 4290, "OffsetEndMs": 4425}, {"Word": "huge", "OffsetStartMs": 4425, "OffsetEndMs": 4650}, {"Word": "topic", "OffsetStartMs": 4650, "OffsetEndMs": 4995}, {"Word": "in", "OffsetStartMs": 4995, "OffsetEndMs": 5250}, {"Word": "the", "OffsetStartMs": 5250, "OffsetEndMs": 5400}, {"Word": "field", "OffsetStartMs": 5400, "OffsetEndMs": 5625}, {"Word": "of", "OffsetStartMs": 5625, "OffsetEndMs": 5960}, {"Word": "robotics", "OffsetStartMs": 6130, "OffsetEndMs": 6615}, {"Word": "and", "OffsetStartMs": 6615, "OffsetEndMs": 6795}, {"Word": "autonomy", "OffsetStartMs": 6795, "OffsetEndMs": 7260}, {"Word": "You", "OffsetStartMs": 7260, "OffsetEndMs": 7395}, {"Word": "can", "OffsetStartMs": 7395, "OffsetEndMs": 7545}, {"Word": "think", "OffsetStartMs": 7545, "OffsetEndMs": 7680}, {"Word": "of", "OffsetStartMs": 7680, "OffsetEndMs": 7845}, {"Word": "self", "OffsetStartMs": 7845, "OffsetEndMs": 8055}, {"Word": "driving", "OffsetStartMs": 8055, "OffsetEndMs": 8325}, {"Word": "cars", "OffsetStartMs": 8325, "OffsetEndMs": 8655}, {"Word": "and", "OffsetStartMs": 8655, "OffsetEndMs": 8970}, {"Word": "robot", "OffsetStartMs": 8970, "OffsetEndMs": 9210}, {"Word": "manipulation", "OffsetStartMs": 9210, "OffsetEndMs": 9830}, {"Word": "but", "OffsetStartMs": 10210, "OffsetEndMs": 10605}, {"Word": "also", "OffsetStartMs": 10605, "OffsetEndMs": 11000}, {"Word": "very", "OffsetStartMs": 11140, "OffsetEndMs": 11460}, {"Word": "recently", "OffsetStartMs": 11460, "OffsetEndMs": 11780}, {"Word": "we've", "OffsetStartMs": 12010, "OffsetEndMs": 12345}, {"Word": "started", "OffsetStartMs": 12345, "OffsetEndMs": 12540}, {"Word": "seeing", "OffsetStartMs": 12540, "OffsetEndMs": 12870}, {"Word": "incredible", "OffsetStartMs": 12870, "OffsetEndMs": 13250}, {"Word": "advances", "OffsetStartMs": 13270, "OffsetEndMs": 13800}, {"Word": "of", "OffsetStartMs": 13800, "OffsetEndMs": 13950}, {"Word": "deep", "OffsetStartMs": 13950, "OffsetEndMs": 14130}, {"Word": "reinforcement", "OffsetStartMs": 14130, "OffsetEndMs": 14760}, {"Word": "learning", "OffsetStartMs": 14760, "OffsetEndMs": 15015}, {"Word": "specifically", "OffsetStartMs": 15015, "OffsetEndMs": 15410}, {"Word": "also", "OffsetStartMs": 16360, "OffsetEndMs": 16710}, {"Word": "on", "OffsetStartMs": 16710, "OffsetEndMs": 17060}, {"Word": "the", "OffsetStartMs": 17170, "OffsetEndMs": 17475}, {"Word": "side", "OffsetStartMs": 17475, "OffsetEndMs": 17745}, {"Word": "of", "OffsetStartMs": 17745, "OffsetEndMs": 18075}, {"Word": "game", "OffsetStartMs": 18075, "OffsetEndMs": 18375}, {"Word": "play", "OffsetStartMs": 18375, "OffsetEndMs": 18645}, {"Word": "and", "OffsetStartMs": 18645, "OffsetEndMs": 18945}, {"Word": "strategy", "OffsetStartMs": 18945, "OffsetEndMs": 19310}, {"Word": "making", "OffsetStartMs": 19330, "OffsetEndMs": 19730}, {"Word": "as", "OffsetStartMs": 19780, "OffsetEndMs": 20100}, {"Word": "well", "OffsetStartMs": 20100, "OffsetEndMs": 20420}, {"Word": "So", "OffsetStartMs": 21040, "OffsetEndMs": 21440}, {"Word": "one", "OffsetStartMs": 21640, "OffsetEndMs": 21930}, {"Word": "really", "OffsetStartMs": 21930, "OffsetEndMs": 22155}, {"Word": "cool", "OffsetStartMs": 22155, "OffsetEndMs": 22380}, {"Word": "thing", "OffsetStartMs": 22380, "OffsetEndMs": 22530}, {"Word": "is", "OffsetStartMs": 22530, "OffsetEndMs": 22665}, {"Word": "that", "OffsetStartMs": 22665, "OffsetEndMs": 22830}, {"Word": "now", "OffsetStartMs": 22830, "OffsetEndMs": 23010}, {"Word": "you", "OffsetStartMs": 23010, "OffsetEndMs": 23160}, {"Word": "can", "OffsetStartMs": 23160, "OffsetEndMs": 23265}, {"Word": "even", "OffsetStartMs": 23265, "OffsetEndMs": 23505}, {"Word": "imagine", "OffsetStartMs": 23505, "OffsetEndMs": 23900}, {"Word": "right", "OffsetStartMs": 24190, "OffsetEndMs": 24510}, {"Word": "this", "OffsetStartMs": 24510, "OffsetEndMs": 24830}], "SpeechSpeed": 14.6}, {"FinalSentence": "This combination of robotics, together with gameplay right now, training robots to play against us in the real world, and I'll just play this very short video on starcraft and deepmind.", "SliceSentence": "This combination of robotics together with gameplay right now training robots to play against us in the real world and I'll just play this very short video on starcraft and deepmind", "StartMs": 146060, "EndMs": 158460, "WordsNum": 31, "Words": [{"Word": "This", "OffsetStartMs": 100, "OffsetEndMs": 500}, {"Word": "combination", "OffsetStartMs": 670, "OffsetEndMs": 1070}, {"Word": "of", "OffsetStartMs": 1510, "OffsetEndMs": 1910}, {"Word": "robotics", "OffsetStartMs": 2170, "OffsetEndMs": 2750}, {"Word": "together", "OffsetStartMs": 3100, "OffsetEndMs": 3500}, {"Word": "with", "OffsetStartMs": 3520, "OffsetEndMs": 3840}, {"Word": "gameplay", "OffsetStartMs": 3840, "OffsetEndMs": 4350}, {"Word": "right", "OffsetStartMs": 4350, "OffsetEndMs": 4670}, {"Word": "now", "OffsetStartMs": 4780, "OffsetEndMs": 5130}, {"Word": "training", "OffsetStartMs": 5130, "OffsetEndMs": 5430}, {"Word": "robots", "OffsetStartMs": 5430, "OffsetEndMs": 5880}, {"Word": "to", "OffsetStartMs": 5880, "OffsetEndMs": 6105}, {"Word": "play", "OffsetStartMs": 6105, "OffsetEndMs": 6345}, {"Word": "against", "OffsetStartMs": 6345, "OffsetEndMs": 6645}, {"Word": "us", "OffsetStartMs": 6645, "OffsetEndMs": 6870}, {"Word": "in", "OffsetStartMs": 6870, "OffsetEndMs": 7020}, {"Word": "the", "OffsetStartMs": 7020, "OffsetEndMs": 7125}, {"Word": "real", "OffsetStartMs": 7125, "OffsetEndMs": 7275}, {"Word": "world", "OffsetStartMs": 7275, "OffsetEndMs": 7580}, {"Word": "and", "OffsetStartMs": 7810, "OffsetEndMs": 8040}, {"Word": "I'll", "OffsetStartMs": 8040, "OffsetEndMs": 8205}, {"Word": "just", "OffsetStartMs": 8205, "OffsetEndMs": 8355}, {"Word": "play", "OffsetStartMs": 8355, "OffsetEndMs": 8535}, {"Word": "this", "OffsetStartMs": 8535, "OffsetEndMs": 8715}, {"Word": "very", "OffsetStartMs": 8715, "OffsetEndMs": 8925}, {"Word": "short", "OffsetStartMs": 8925, "OffsetEndMs": 9120}, {"Word": "video", "OffsetStartMs": 9120, "OffsetEndMs": 9360}, {"Word": "on", "OffsetStartMs": 9360, "OffsetEndMs": 9645}, {"Word": "starcraft", "OffsetStartMs": 9645, "OffsetEndMs": 10250}, {"Word": "and", "OffsetStartMs": 10450, "OffsetEndMs": 10740}, {"Word": "deepmind", "OffsetStartMs": 10740, "OffsetEndMs": 11210}], "SpeechSpeed": 14.6}, {"FinalSentence": "Perfect information and to display in real time. It also requires long term planning and the ability to choose what action to take from millions and millions of possibilities. I'm hoping for a five zero not to lose any games, but I think the realistic goal would be four and one in my favor. I think he looks more confident and Taylor was quite nervous before. The room was much more tense this time. Really didn't know what to expect. He's been playing starra pretty much since he five, I wasn't expecting AI to be that good. Everything that he did was proper, it was calculated and it was done well. I thought I'm learning something. I would consider myself a good player, right? But I lost every single one of my games.", "SliceSentence": "Perfect information and to display in real time It also requires long term planning and the ability to choose what action to take from millions and millions of possibilities I'm hoping for a five zero not to lose any games but I think the realistic goal would be four and one in my favor I think he looks more confident and Taylor was quite nervous before The room was much more tense this time Really didn't know what to expect He's been playing starra pretty much since he five I wasn't expecting AI to be that good Everything that he did was proper it was calculated and it was done well I thought I'm learning something I would consider myself a good player right But I lost every single one of my games", "StartMs": 161800, "EndMs": 222280, "WordsNum": 133, "Words": [{"Word": "Perfect", "OffsetStartMs": 70, "OffsetEndMs": 470}, {"Word": "information", "OffsetStartMs": 730, "OffsetEndMs": 1130}, {"Word": "and", "OffsetStartMs": 1210, "OffsetEndMs": 1515}, {"Word": "to", "OffsetStartMs": 1515, "OffsetEndMs": 1785}, {"Word": "display", "OffsetStartMs": 1785, "OffsetEndMs": 2025}, {"Word": "in", "OffsetStartMs": 2025, "OffsetEndMs": 2190}, {"Word": "real", "OffsetStartMs": 2190, "OffsetEndMs": 2430}, {"Word": "time", "OffsetStartMs": 2430, "OffsetEndMs": 2780}, {"Word": "It", "OffsetStartMs": 3310, "OffsetEndMs": 3705}, {"Word": "also", "OffsetStartMs": 3705, "OffsetEndMs": 4035}, {"Word": "requires", "OffsetStartMs": 4035, "OffsetEndMs": 4370}, {"Word": "long", "OffsetStartMs": 4450, "OffsetEndMs": 4785}, {"Word": "term", "OffsetStartMs": 4785, "OffsetEndMs": 5055}, {"Word": "planning", "OffsetStartMs": 5055, "OffsetEndMs": 5385}, {"Word": "and", "OffsetStartMs": 5385, "OffsetEndMs": 5685}, {"Word": "the", "OffsetStartMs": 5685, "OffsetEndMs": 5880}, {"Word": "ability", "OffsetStartMs": 5880, "OffsetEndMs": 6150}, {"Word": "to", "OffsetStartMs": 6150, "OffsetEndMs": 6450}, {"Word": "choose", "OffsetStartMs": 6450, "OffsetEndMs": 6720}, {"Word": "what", "OffsetStartMs": 6720, "OffsetEndMs": 6945}, {"Word": "action", "OffsetStartMs": 6945, "OffsetEndMs": 7200}, {"Word": "to", "OffsetStartMs": 7200, "OffsetEndMs": 7440}, {"Word": "take", "OffsetStartMs": 7440, "OffsetEndMs": 7605}, {"Word": "from", "OffsetStartMs": 7605, "OffsetEndMs": 7845}, {"Word": "millions", "OffsetStartMs": 7845, "OffsetEndMs": 8180}, {"Word": "and", "OffsetStartMs": 8260, "OffsetEndMs": 8580}, {"Word": "millions", "OffsetStartMs": 8580, "OffsetEndMs": 8880}, {"Word": "of", "OffsetStartMs": 8880, "OffsetEndMs": 9150}, {"Word": "possibilities", "OffsetStartMs": 9150, "OffsetEndMs": 9440}, {"Word": "I'm", "OffsetStartMs": 10630, "OffsetEndMs": 10995}, {"Word": "hoping", "OffsetStartMs": 10995, "OffsetEndMs": 11220}, {"Word": "for", "OffsetStartMs": 11220, "OffsetEndMs": 11475}, {"Word": "a", "OffsetStartMs": 11475, "OffsetEndMs": 11625}, {"Word": "five", "OffsetStartMs": 11625, "OffsetEndMs": 11865}, {"Word": "zero", "OffsetStartMs": 11865, "OffsetEndMs": 12165}, {"Word": "not", "OffsetStartMs": 12165, "OffsetEndMs": 12375}, {"Word": "to", "OffsetStartMs": 12375, "OffsetEndMs": 12495}, {"Word": "lose", "OffsetStartMs": 12495, "OffsetEndMs": 12630}, {"Word": "any", "OffsetStartMs": 12630, "OffsetEndMs": 12840}, {"Word": "games", "OffsetStartMs": 12840, "OffsetEndMs": 13080}, {"Word": "but", "OffsetStartMs": 13080, "OffsetEndMs": 13260}, {"Word": "I", "OffsetStartMs": 13260, "OffsetEndMs": 13365}, {"Word": "think", "OffsetStartMs": 13365, "OffsetEndMs": 13470}, {"Word": "the", "OffsetStartMs": 13470, "OffsetEndMs": 13605}, {"Word": "realistic", "OffsetStartMs": 13605, "OffsetEndMs": 14145}, {"Word": "goal", "OffsetStartMs": 14145, "OffsetEndMs": 14325}, {"Word": "would", "OffsetStartMs": 14325, "OffsetEndMs": 14520}, {"Word": "be", "OffsetStartMs": 14520, "OffsetEndMs": 14700}, {"Word": "four", "OffsetStartMs": 14700, "OffsetEndMs": 14880}, {"Word": "and", "OffsetStartMs": 14880, "OffsetEndMs": 15045}, {"Word": "one", "OffsetStartMs": 15045, "OffsetEndMs": 15225}, {"Word": "in", "OffsetStartMs": 15225, "OffsetEndMs": 15390}, {"Word": "my", "OffsetStartMs": 15390, "OffsetEndMs": 15540}, {"Word": "favor", "OffsetStartMs": 15540, "OffsetEndMs": 15830}, {"Word": "I", "OffsetStartMs": 18100, "OffsetEndMs": 18360}, {"Word": "think", "OffsetStartMs": 18360, "OffsetEndMs": 18480}, {"Word": "he", "OffsetStartMs": 18480, "OffsetEndMs": 18600}, {"Word": "looks", "OffsetStartMs": 18600, "OffsetEndMs": 18735}, {"Word": "more", "OffsetStartMs": 18735, "OffsetEndMs": 18960}, {"Word": "confident", "OffsetStartMs": 18960, "OffsetEndMs": 19310}, {"Word": "and", "OffsetStartMs": 19450, "OffsetEndMs": 19850}, {"Word": "Taylor", "OffsetStartMs": 20260, "OffsetEndMs": 20565}, {"Word": "was", "OffsetStartMs": 20565, "OffsetEndMs": 20745}, {"Word": "quite", "OffsetStartMs": 20745, "OffsetEndMs": 20910}, {"Word": "nervous", "OffsetStartMs": 20910, "OffsetEndMs": 21165}, {"Word": "before", "OffsetStartMs": 21165, "OffsetEndMs": 21530}, {"Word": "The", "OffsetStartMs": 26170, "OffsetEndMs": 26430}, {"Word": "room", "OffsetStartMs": 26430, "OffsetEndMs": 26565}, {"Word": "was", "OffsetStartMs": 26565, "OffsetEndMs": 26700}, {"Word": "much", "OffsetStartMs": 26700, "OffsetEndMs": 26850}, {"Word": "more", "OffsetStartMs": 26850, "OffsetEndMs": 27015}, {"Word": "tense", "OffsetStartMs": 27015, "OffsetEndMs": 27255}, {"Word": "this", "OffsetStartMs": 27255, "OffsetEndMs": 27480}, {"Word": "time", "OffsetStartMs": 27480, "OffsetEndMs": 27770}, {"Word": "Really", "OffsetStartMs": 29590, "OffsetEndMs": 29895}, {"Word": "didn't", "OffsetStartMs": 29895, "OffsetEndMs": 30195}, {"Word": "know", "OffsetStartMs": 30195, "OffsetEndMs": 30375}, {"Word": "what", "OffsetStartMs": 30375, "OffsetEndMs": 30555}, {"Word": "to", "OffsetStartMs": 30555, "OffsetEndMs": 30750}, {"Word": "expect", "OffsetStartMs": 30750, "OffsetEndMs": 31070}, {"Word": "He's", "OffsetStartMs": 31570, "OffsetEndMs": 32010}, {"Word": "been", "OffsetStartMs": 32010, "OffsetEndMs": 32220}, {"Word": "playing", "OffsetStartMs": 32220, "OffsetEndMs": 32490}, {"Word": "starra", "OffsetStartMs": 32490, "OffsetEndMs": 32970}, {"Word": "pretty", "OffsetStartMs": 32970, "OffsetEndMs": 33210}, {"Word": "much", "OffsetStartMs": 33210, "OffsetEndMs": 33420}, {"Word": "since", "OffsetStartMs": 33420, "OffsetEndMs": 33615}, {"Word": "he", "OffsetStartMs": 33615, "OffsetEndMs": 33870}, {"Word": "five", "OffsetStartMs": 33870, "OffsetEndMs": 34160}, {"Word": "I", "OffsetStartMs": 39370, "OffsetEndMs": 39645}, {"Word": "wasn't", "OffsetStartMs": 39645, "OffsetEndMs": 40035}, {"Word": "expecting", "OffsetStartMs": 40035, "OffsetEndMs": 40430}, {"Word": "AI", "OffsetStartMs": 40660, "OffsetEndMs": 40950}, {"Word": "to", "OffsetStartMs": 40950, "OffsetEndMs": 41100}, {"Word": "be", "OffsetStartMs": 41100, "OffsetEndMs": 41280}, {"Word": "that", "OffsetStartMs": 41280, "OffsetEndMs": 41520}, {"Word": "good", "OffsetStartMs": 41520, "OffsetEndMs": 41840}, {"Word": "Everything", "OffsetStartMs": 44230, "OffsetEndMs": 44505}, {"Word": "that", "OffsetStartMs": 44505, "OffsetEndMs": 44655}, {"Word": "he", "OffsetStartMs": 44655, "OffsetEndMs": 44790}, {"Word": "did", "OffsetStartMs": 44790, "OffsetEndMs": 44925}, {"Word": "was", "OffsetStartMs": 44925, "OffsetEndMs": 45135}, {"Word": "proper", "OffsetStartMs": 45135, "OffsetEndMs": 45470}, {"Word": "it", "OffsetStartMs": 45490, "OffsetEndMs": 45750}, {"Word": "was", "OffsetStartMs": 45750, "OffsetEndMs": 46010}, {"Word": "calculated", "OffsetStartMs": 46150, "OffsetEndMs": 46740}, {"Word": "and", "OffsetStartMs": 46740, "OffsetEndMs": 46935}, {"Word": "it", "OffsetStartMs": 46935, "OffsetEndMs": 47055}, {"Word": "was", "OffsetStartMs": 47055, "OffsetEndMs": 47205}, {"Word": "done", "OffsetStartMs": 47205, "OffsetEndMs": 47385}, {"Word": "well", "OffsetStartMs": 47385, "OffsetEndMs": 47690}, {"Word": "I", "OffsetStartMs": 48520, "OffsetEndMs": 48840}, {"Word": "thought", "OffsetStartMs": 48840, "OffsetEndMs": 49020}, {"Word": "I'm", "OffsetStartMs": 49020, "OffsetEndMs": 49260}, {"Word": "learning", "OffsetStartMs": 49260, "OffsetEndMs": 49520}, {"Word": "something", "OffsetStartMs": 49540, "OffsetEndMs": 49940}, {"Word": "I", "OffsetStartMs": 55000, "OffsetEndMs": 55260}, {"Word": "would", "OffsetStartMs": 55260, "OffsetEndMs": 55485}, {"Word": "consider", "OffsetStartMs": 55485, "OffsetEndMs": 55815}, {"Word": "myself", "OffsetStartMs": 55815, "OffsetEndMs": 56055}, {"Word": "a", "OffsetStartMs": 56055, "OffsetEndMs": 56220}, {"Word": "good", "OffsetStartMs": 56220, "OffsetEndMs": 56445}, {"Word": "player", "OffsetStartMs": 56445, "OffsetEndMs": 56745}, {"Word": "right", "OffsetStartMs": 56745, "OffsetEndMs": 57110}, {"Word": "But", "OffsetStartMs": 57400, "OffsetEndMs": 57690}, {"Word": "I", "OffsetStartMs": 57690, "OffsetEndMs": 57855}, {"Word": "lost", "OffsetStartMs": 57855, "OffsetEndMs": 58050}, {"Word": "every", "OffsetStartMs": 58050, "OffsetEndMs": 58320}, {"Word": "single", "OffsetStartMs": 58320, "OffsetEndMs": 58575}, {"Word": "one", "OffsetStartMs": 58575, "OffsetEndMs": 58740}, {"Word": "of", "OffsetStartMs": 58740, "OffsetEndMs": 58890}, {"Word": "my", "OffsetStartMs": 58890, "OffsetEndMs": 59115}, {"Word": "games", "OffsetStartMs": 59115, "OffsetEndMs": 59450}], "SpeechSpeed": 11.7}, {"FinalSentence": "Where away had won.", "SliceSentence": "Where away had won", "StartMs": 222280, "EndMs": 227600, "WordsNum": 4, "Words": [{"Word": "Where", "OffsetStartMs": 3460, "OffsetEndMs": 3810}, {"Word": "away", "OffsetStartMs": 3810, "OffsetEndMs": 4080}, {"Word": "had", "OffsetStartMs": 4080, "OffsetEndMs": 4320}, {"Word": "won", "OffsetStartMs": 4320, "OffsetEndMs": 4640}], "SpeechSpeed": 3.4}, {"FinalSentence": "So let's take maybe a start and take a step back, first of all, and think about how reinforcement learning fits into this whole paradigm of all of the different topics that you've been exposed to in this class so far. So as a whole, I think that we've really covered two different types of learning in this course to date. Right up until now we've really started focusing in the beginning part of the lectures, firstly on what we call supervised learning. Supervised learning is in this domain where we're given data in the form of x's, our inputs and our labels y, and our goal here is to learn a function or a neural network that can learn to predict y given our inputs X.", "SliceSentence": "So let's take maybe a start and take a step back first of all and think about how reinforcement learning fits into this whole paradigm of all of the different topics that you've been exposed to in this class so far So as a whole I think that we've really covered two different types of learning in this course to date Right up until now we've really started focusing in the beginning part of the lectures firstly on what we call supervised learning Supervised learning is in this domain where we're given data in the form of x's our inputs and our labels y and our goal here is to learn a function or a neural network that can learn to predict y given our inputs X", "StartMs": 228500, "EndMs": 268460, "WordsNum": 127, "Words": [{"Word": "So", "OffsetStartMs": 190, "OffsetEndMs": 590}, {"Word": "let's", "OffsetStartMs": 610, "OffsetEndMs": 975}, {"Word": "take", "OffsetStartMs": 975, "OffsetEndMs": 1185}, {"Word": "maybe", "OffsetStartMs": 1185, "OffsetEndMs": 1395}, {"Word": "a", "OffsetStartMs": 1395, "OffsetEndMs": 1590}, {"Word": "start", "OffsetStartMs": 1590, "OffsetEndMs": 1800}, {"Word": "and", "OffsetStartMs": 1800, "OffsetEndMs": 2010}, {"Word": "take", "OffsetStartMs": 2010, "OffsetEndMs": 2190}, {"Word": "a", "OffsetStartMs": 2190, "OffsetEndMs": 2325}, {"Word": "step", "OffsetStartMs": 2325, "OffsetEndMs": 2520}, {"Word": "back", "OffsetStartMs": 2520, "OffsetEndMs": 2840}, {"Word": "first", "OffsetStartMs": 3040, "OffsetEndMs": 3375}, {"Word": "of", "OffsetStartMs": 3375, "OffsetEndMs": 3555}, {"Word": "all", "OffsetStartMs": 3555, "OffsetEndMs": 3765}, {"Word": "and", "OffsetStartMs": 3765, "OffsetEndMs": 4130}, {"Word": "think", "OffsetStartMs": 4210, "OffsetEndMs": 4530}, {"Word": "about", "OffsetStartMs": 4530, "OffsetEndMs": 4740}, {"Word": "how", "OffsetStartMs": 4740, "OffsetEndMs": 4950}, {"Word": "reinforcement", "OffsetStartMs": 4950, "OffsetEndMs": 5655}, {"Word": "learning", "OffsetStartMs": 5655, "OffsetEndMs": 5960}, {"Word": "fits", "OffsetStartMs": 6430, "OffsetEndMs": 6750}, {"Word": "into", "OffsetStartMs": 6750, "OffsetEndMs": 7035}, {"Word": "this", "OffsetStartMs": 7035, "OffsetEndMs": 7275}, {"Word": "whole", "OffsetStartMs": 7275, "OffsetEndMs": 7455}, {"Word": "paradigm", "OffsetStartMs": 7455, "OffsetEndMs": 7965}, {"Word": "of", "OffsetStartMs": 7965, "OffsetEndMs": 8085}, {"Word": "all", "OffsetStartMs": 8085, "OffsetEndMs": 8220}, {"Word": "of", "OffsetStartMs": 8220, "OffsetEndMs": 8340}, {"Word": "the", "OffsetStartMs": 8340, "OffsetEndMs": 8460}, {"Word": "different", "OffsetStartMs": 8460, "OffsetEndMs": 8670}, {"Word": "topics", "OffsetStartMs": 8670, "OffsetEndMs": 9020}, {"Word": "that", "OffsetStartMs": 9100, "OffsetEndMs": 9375}, {"Word": "you've", "OffsetStartMs": 9375, "OffsetEndMs": 9570}, {"Word": "been", "OffsetStartMs": 9570, "OffsetEndMs": 9765}, {"Word": "exposed", "OffsetStartMs": 9765, "OffsetEndMs": 10095}, {"Word": "to", "OffsetStartMs": 10095, "OffsetEndMs": 10305}, {"Word": "in", "OffsetStartMs": 10305, "OffsetEndMs": 10410}, {"Word": "this", "OffsetStartMs": 10410, "OffsetEndMs": 10590}, {"Word": "class", "OffsetStartMs": 10590, "OffsetEndMs": 10910}, {"Word": "so", "OffsetStartMs": 11050, "OffsetEndMs": 11370}, {"Word": "far", "OffsetStartMs": 11370, "OffsetEndMs": 11640}, {"Word": "So", "OffsetStartMs": 11640, "OffsetEndMs": 11990}, {"Word": "as", "OffsetStartMs": 12580, "OffsetEndMs": 12855}, {"Word": "a", "OffsetStartMs": 12855, "OffsetEndMs": 12990}, {"Word": "whole", "OffsetStartMs": 12990, "OffsetEndMs": 13245}, {"Word": "I", "OffsetStartMs": 13245, "OffsetEndMs": 13515}, {"Word": "think", "OffsetStartMs": 13515, "OffsetEndMs": 13680}, {"Word": "that", "OffsetStartMs": 13680, "OffsetEndMs": 13830}, {"Word": "we've", "OffsetStartMs": 13830, "OffsetEndMs": 14025}, {"Word": "really", "OffsetStartMs": 14025, "OffsetEndMs": 14220}, {"Word": "covered", "OffsetStartMs": 14220, "OffsetEndMs": 14570}, {"Word": "two", "OffsetStartMs": 14650, "OffsetEndMs": 14940}, {"Word": "different", "OffsetStartMs": 14940, "OffsetEndMs": 15195}, {"Word": "types", "OffsetStartMs": 15195, "OffsetEndMs": 15510}, {"Word": "of", "OffsetStartMs": 15510, "OffsetEndMs": 15765}, {"Word": "learning", "OffsetStartMs": 15765, "OffsetEndMs": 16070}, {"Word": "in", "OffsetStartMs": 16180, "OffsetEndMs": 16455}, {"Word": "this", "OffsetStartMs": 16455, "OffsetEndMs": 16680}, {"Word": "course", "OffsetStartMs": 16680, "OffsetEndMs": 17030}, {"Word": "to", "OffsetStartMs": 17140, "OffsetEndMs": 17400}, {"Word": "date", "OffsetStartMs": 17400, "OffsetEndMs": 17660}, {"Word": "Right", "OffsetStartMs": 17740, "OffsetEndMs": 18030}, {"Word": "up", "OffsetStartMs": 18030, "OffsetEndMs": 18270}, {"Word": "until", "OffsetStartMs": 18270, "OffsetEndMs": 18510}, {"Word": "now", "OffsetStartMs": 18510, "OffsetEndMs": 18720}, {"Word": "we've", "OffsetStartMs": 18720, "OffsetEndMs": 19020}, {"Word": "really", "OffsetStartMs": 19020, "OffsetEndMs": 19275}, {"Word": "started", "OffsetStartMs": 19275, "OffsetEndMs": 19605}, {"Word": "focusing", "OffsetStartMs": 19605, "OffsetEndMs": 19940}, {"Word": "in", "OffsetStartMs": 20110, "OffsetEndMs": 20370}, {"Word": "the", "OffsetStartMs": 20370, "OffsetEndMs": 20550}, {"Word": "beginning", "OffsetStartMs": 20550, "OffsetEndMs": 20820}, {"Word": "part", "OffsetStartMs": 20820, "OffsetEndMs": 21015}, {"Word": "of", "OffsetStartMs": 21015, "OffsetEndMs": 21120}, {"Word": "the", "OffsetStartMs": 21120, "OffsetEndMs": 21225}, {"Word": "lectures", "OffsetStartMs": 21225, "OffsetEndMs": 21660}, {"Word": "firstly", "OffsetStartMs": 21660, "OffsetEndMs": 22280}, {"Word": "on", "OffsetStartMs": 22360, "OffsetEndMs": 22620}, {"Word": "what", "OffsetStartMs": 22620, "OffsetEndMs": 22755}, {"Word": "we", "OffsetStartMs": 22755, "OffsetEndMs": 22920}, {"Word": "call", "OffsetStartMs": 22920, "OffsetEndMs": 23210}, {"Word": "supervised", "OffsetStartMs": 23380, "OffsetEndMs": 23790}, {"Word": "learning", "OffsetStartMs": 23790, "OffsetEndMs": 24170}, {"Word": "Supervised", "OffsetStartMs": 25360, "OffsetEndMs": 25740}, {"Word": "learning", "OffsetStartMs": 25740, "OffsetEndMs": 26090}, {"Word": "is", "OffsetStartMs": 26230, "OffsetEndMs": 26610}, {"Word": "in", "OffsetStartMs": 26610, "OffsetEndMs": 26865}, {"Word": "this", "OffsetStartMs": 26865, "OffsetEndMs": 27045}, {"Word": "domain", "OffsetStartMs": 27045, "OffsetEndMs": 27350}, {"Word": "where", "OffsetStartMs": 27490, "OffsetEndMs": 27795}, {"Word": "we're", "OffsetStartMs": 27795, "OffsetEndMs": 28155}, {"Word": "given", "OffsetStartMs": 28155, "OffsetEndMs": 28460}, {"Word": "data", "OffsetStartMs": 28570, "OffsetEndMs": 28970}, {"Word": "in", "OffsetStartMs": 29020, "OffsetEndMs": 29295}, {"Word": "the", "OffsetStartMs": 29295, "OffsetEndMs": 29445}, {"Word": "form", "OffsetStartMs": 29445, "OffsetEndMs": 29625}, {"Word": "of", "OffsetStartMs": 29625, "OffsetEndMs": 29930}, {"Word": "x's", "OffsetStartMs": 30100, "OffsetEndMs": 30735}, {"Word": "our", "OffsetStartMs": 30735, "OffsetEndMs": 31010}, {"Word": "inputs", "OffsetStartMs": 31030, "OffsetEndMs": 31550}, {"Word": "and", "OffsetStartMs": 31720, "OffsetEndMs": 31980}, {"Word": "our", "OffsetStartMs": 31980, "OffsetEndMs": 32145}, {"Word": "labels", "OffsetStartMs": 32145, "OffsetEndMs": 32660}, {"Word": "y", "OffsetStartMs": 32770, "OffsetEndMs": 33170}, {"Word": "and", "OffsetStartMs": 33550, "OffsetEndMs": 33810}, {"Word": "our", "OffsetStartMs": 33810, "OffsetEndMs": 33960}, {"Word": "goal", "OffsetStartMs": 33960, "OffsetEndMs": 34170}, {"Word": "here", "OffsetStartMs": 34170, "OffsetEndMs": 34380}, {"Word": "is", "OffsetStartMs": 34380, "OffsetEndMs": 34590}, {"Word": "to", "OffsetStartMs": 34590, "OffsetEndMs": 34785}, {"Word": "learn", "OffsetStartMs": 34785, "OffsetEndMs": 34995}, {"Word": "a", "OffsetStartMs": 34995, "OffsetEndMs": 35205}, {"Word": "function", "OffsetStartMs": 35205, "OffsetEndMs": 35480}, {"Word": "or", "OffsetStartMs": 35500, "OffsetEndMs": 35760}, {"Word": "a", "OffsetStartMs": 35760, "OffsetEndMs": 35880}, {"Word": "neural", "OffsetStartMs": 35880, "OffsetEndMs": 36120}, {"Word": "network", "OffsetStartMs": 36120, "OffsetEndMs": 36380}, {"Word": "that", "OffsetStartMs": 36610, "OffsetEndMs": 36885}, {"Word": "can", "OffsetStartMs": 36885, "OffsetEndMs": 37035}, {"Word": "learn", "OffsetStartMs": 37035, "OffsetEndMs": 37230}, {"Word": "to", "OffsetStartMs": 37230, "OffsetEndMs": 37410}, {"Word": "predict", "OffsetStartMs": 37410, "OffsetEndMs": 37650}, {"Word": "y", "OffsetStartMs": 37650, "OffsetEndMs": 38030}, {"Word": "given", "OffsetStartMs": 38110, "OffsetEndMs": 38415}, {"Word": "our", "OffsetStartMs": 38415, "OffsetEndMs": 38700}, {"Word": "inputs", "OffsetStartMs": 38700, "OffsetEndMs": 39045}, {"Word": "X", "OffsetStartMs": 39045, "OffsetEndMs": 39320}], "SpeechSpeed": 16.6}, {"FinalSentence": "So, for example, if you consider this example of an Apple observing a bunch of images of apples, we want to detect, you know, in the future if we see a new image of an Apple, to detect that this is indeed an Apple.", "SliceSentence": "So for example if you consider this example of an Apple observing a bunch of images of apples we want to detect you know in the future if we see a new image of an Apple to detect that this is indeed an Apple", "StartMs": 268460, "EndMs": 280680, "WordsNum": 44, "Words": [{"Word": "So", "OffsetStartMs": 0, "OffsetEndMs": 150}, {"Word": "for", "OffsetStartMs": 150, "OffsetEndMs": 315}, {"Word": "example", "OffsetStartMs": 315, "OffsetEndMs": 620}, {"Word": "if", "OffsetStartMs": 1150, "OffsetEndMs": 1550}, {"Word": "you", "OffsetStartMs": 1750, "OffsetEndMs": 2100}, {"Word": "consider", "OffsetStartMs": 2100, "OffsetEndMs": 2355}, {"Word": "this", "OffsetStartMs": 2355, "OffsetEndMs": 2595}, {"Word": "example", "OffsetStartMs": 2595, "OffsetEndMs": 2850}, {"Word": "of", "OffsetStartMs": 2850, "OffsetEndMs": 3015}, {"Word": "an", "OffsetStartMs": 3015, "OffsetEndMs": 3120}, {"Word": "Apple", "OffsetStartMs": 3120, "OffsetEndMs": 3380}, {"Word": "observing", "OffsetStartMs": 3880, "OffsetEndMs": 4185}, {"Word": "a", "OffsetStartMs": 4185, "OffsetEndMs": 4365}, {"Word": "bunch", "OffsetStartMs": 4365, "OffsetEndMs": 4545}, {"Word": "of", "OffsetStartMs": 4545, "OffsetEndMs": 4725}, {"Word": "images", "OffsetStartMs": 4725, "OffsetEndMs": 5000}, {"Word": "of", "OffsetStartMs": 5020, "OffsetEndMs": 5295}, {"Word": "apples", "OffsetStartMs": 5295, "OffsetEndMs": 5570}, {"Word": "we", "OffsetStartMs": 5800, "OffsetEndMs": 6075}, {"Word": "want", "OffsetStartMs": 6075, "OffsetEndMs": 6240}, {"Word": "to", "OffsetStartMs": 6240, "OffsetEndMs": 6465}, {"Word": "detect", "OffsetStartMs": 6465, "OffsetEndMs": 6795}, {"Word": "you", "OffsetStartMs": 6795, "OffsetEndMs": 7050}, {"Word": "know", "OffsetStartMs": 7050, "OffsetEndMs": 7185}, {"Word": "in", "OffsetStartMs": 7185, "OffsetEndMs": 7320}, {"Word": "the", "OffsetStartMs": 7320, "OffsetEndMs": 7440}, {"Word": "future", "OffsetStartMs": 7440, "OffsetEndMs": 7620}, {"Word": "if", "OffsetStartMs": 7620, "OffsetEndMs": 7800}, {"Word": "we", "OffsetStartMs": 7800, "OffsetEndMs": 7935}, {"Word": "see", "OffsetStartMs": 7935, "OffsetEndMs": 8040}, {"Word": "a", "OffsetStartMs": 8040, "OffsetEndMs": 8130}, {"Word": "new", "OffsetStartMs": 8130, "OffsetEndMs": 8265}, {"Word": "image", "OffsetStartMs": 8265, "OffsetEndMs": 8460}, {"Word": "of", "OffsetStartMs": 8460, "OffsetEndMs": 8625}, {"Word": "an", "OffsetStartMs": 8625, "OffsetEndMs": 8715}, {"Word": "Apple", "OffsetStartMs": 8715, "OffsetEndMs": 8960}, {"Word": "to", "OffsetStartMs": 9070, "OffsetEndMs": 9405}, {"Word": "detect", "OffsetStartMs": 9405, "OffsetEndMs": 9645}, {"Word": "that", "OffsetStartMs": 9645, "OffsetEndMs": 9900}, {"Word": "this", "OffsetStartMs": 9900, "OffsetEndMs": 10125}, {"Word": "is", "OffsetStartMs": 10125, "OffsetEndMs": 10335}, {"Word": "indeed", "OffsetStartMs": 10335, "OffsetEndMs": 10560}, {"Word": "an", "OffsetStartMs": 10560, "OffsetEndMs": 10695}, {"Word": "Apple", "OffsetStartMs": 10695, "OffsetEndMs": 10940}], "SpeechSpeed": 16.9}, {"FinalSentence": "Now, the second class of learning approaches that we've discovered yesterday in yesterday's lecture was that of unsupervised learning. And in these algorithms you have only access to the data. There's no notion of labels, right? This is what we learned about yesterday in these types of algorithms. You're not trying to predict a label, but you're trying to uncover some of the underlying structure. What we were calling basically these latent variables, these hidden features in your data. So for example, in this Apple example, right using unsupervised learning. The analogous example would basically be to build a model that could understand and cluster certain certain parts of these images together. And maybe it doesn't have to understand that necessarily this is an image of an Apple. But it needs to understand that, you know, this image of the red Apple is similar. It has the same latent features and same semantic meaning as this black and white outline sketch of the Apple.", "SliceSentence": "Now the second class of learning approaches that we've discovered yesterday in yesterday's lecture was that of unsupervised learning And in these algorithms you have only access to the data There's no notion of labels right This is what we learned about yesterday in these types of algorithms You're not trying to predict a label but you're trying to uncover some of the underlying structure What we were calling basically these latent variables these hidden features in your data So for example in this Apple example right using unsupervised learning The analogous example would basically be to build a model that could understand and cluster certain certain parts of these images together And maybe it doesn't have to understand that necessarily this is an image of an Apple But it needs to understand that you know this image of the red Apple is similar It has the same latent features and same semantic meaning as this black and white outline sketch of the Apple", "StartMs": 280680, "EndMs": 336340, "WordsNum": 164, "Words": [{"Word": "Now", "OffsetStartMs": 70, "OffsetEndMs": 360}, {"Word": "the", "OffsetStartMs": 360, "OffsetEndMs": 525}, {"Word": "second", "OffsetStartMs": 525, "OffsetEndMs": 800}, {"Word": "class", "OffsetStartMs": 850, "OffsetEndMs": 1245}, {"Word": "of", "OffsetStartMs": 1245, "OffsetEndMs": 1640}, {"Word": "learning", "OffsetStartMs": 2020, "OffsetEndMs": 2420}, {"Word": "approaches", "OffsetStartMs": 2440, "OffsetEndMs": 2840}, {"Word": "that", "OffsetStartMs": 2950, "OffsetEndMs": 3225}, {"Word": "we've", "OffsetStartMs": 3225, "OffsetEndMs": 3620}, {"Word": "discovered", "OffsetStartMs": 3640, "OffsetEndMs": 4040}, {"Word": "yesterday", "OffsetStartMs": 4240, "OffsetEndMs": 4640}, {"Word": "in", "OffsetStartMs": 4840, "OffsetEndMs": 5115}, {"Word": "yesterday's", "OffsetStartMs": 5115, "OffsetEndMs": 5610}, {"Word": "lecture", "OffsetStartMs": 5610, "OffsetEndMs": 5850}, {"Word": "was", "OffsetStartMs": 5850, "OffsetEndMs": 6135}, {"Word": "that", "OffsetStartMs": 6135, "OffsetEndMs": 6345}, {"Word": "of", "OffsetStartMs": 6345, "OffsetEndMs": 6570}, {"Word": "unsupervised", "OffsetStartMs": 6570, "OffsetEndMs": 7290}, {"Word": "learning", "OffsetStartMs": 7290, "OffsetEndMs": 7530}, {"Word": "And", "OffsetStartMs": 7530, "OffsetEndMs": 7850}, {"Word": "in", "OffsetStartMs": 7870, "OffsetEndMs": 8160}, {"Word": "these", "OffsetStartMs": 8160, "OffsetEndMs": 8450}, {"Word": "algorithms", "OffsetStartMs": 8530, "OffsetEndMs": 9015}, {"Word": "you", "OffsetStartMs": 9015, "OffsetEndMs": 9225}, {"Word": "have", "OffsetStartMs": 9225, "OffsetEndMs": 9500}, {"Word": "only", "OffsetStartMs": 9760, "OffsetEndMs": 10160}, {"Word": "access", "OffsetStartMs": 10570, "OffsetEndMs": 10970}, {"Word": "to", "OffsetStartMs": 11050, "OffsetEndMs": 11310}, {"Word": "the", "OffsetStartMs": 11310, "OffsetEndMs": 11445}, {"Word": "data", "OffsetStartMs": 11445, "OffsetEndMs": 11720}, {"Word": "There's", "OffsetStartMs": 11740, "OffsetEndMs": 12150}, {"Word": "no", "OffsetStartMs": 12150, "OffsetEndMs": 12375}, {"Word": "notion", "OffsetStartMs": 12375, "OffsetEndMs": 12680}, {"Word": "of", "OffsetStartMs": 12760, "OffsetEndMs": 13080}, {"Word": "labels", "OffsetStartMs": 13080, "OffsetEndMs": 13500}, {"Word": "right", "OffsetStartMs": 13500, "OffsetEndMs": 13710}, {"Word": "This", "OffsetStartMs": 13710, "OffsetEndMs": 13860}, {"Word": "is", "OffsetStartMs": 13860, "OffsetEndMs": 13980}, {"Word": "what", "OffsetStartMs": 13980, "OffsetEndMs": 14100}, {"Word": "we", "OffsetStartMs": 14100, "OffsetEndMs": 14220}, {"Word": "learned", "OffsetStartMs": 14220, "OffsetEndMs": 14400}, {"Word": "about", "OffsetStartMs": 14400, "OffsetEndMs": 14720}, {"Word": "yesterday", "OffsetStartMs": 14740, "OffsetEndMs": 15140}, {"Word": "in", "OffsetStartMs": 16180, "OffsetEndMs": 16485}, {"Word": "these", "OffsetStartMs": 16485, "OffsetEndMs": 16755}, {"Word": "types", "OffsetStartMs": 16755, "OffsetEndMs": 17025}, {"Word": "of", "OffsetStartMs": 17025, "OffsetEndMs": 17295}, {"Word": "algorithms", "OffsetStartMs": 17295, "OffsetEndMs": 17670}, {"Word": "You're", "OffsetStartMs": 17670, "OffsetEndMs": 17865}, {"Word": "not", "OffsetStartMs": 17865, "OffsetEndMs": 18000}, {"Word": "trying", "OffsetStartMs": 18000, "OffsetEndMs": 18270}, {"Word": "to", "OffsetStartMs": 18270, "OffsetEndMs": 18540}, {"Word": "predict", "OffsetStartMs": 18540, "OffsetEndMs": 18810}, {"Word": "a", "OffsetStartMs": 18810, "OffsetEndMs": 19035}, {"Word": "label", "OffsetStartMs": 19035, "OffsetEndMs": 19310}, {"Word": "but", "OffsetStartMs": 19480, "OffsetEndMs": 19770}, {"Word": "you're", "OffsetStartMs": 19770, "OffsetEndMs": 19965}, {"Word": "trying", "OffsetStartMs": 19965, "OffsetEndMs": 20160}, {"Word": "to", "OffsetStartMs": 20160, "OffsetEndMs": 20445}, {"Word": "uncover", "OffsetStartMs": 20445, "OffsetEndMs": 21210}, {"Word": "some", "OffsetStartMs": 21210, "OffsetEndMs": 21465}, {"Word": "of", "OffsetStartMs": 21465, "OffsetEndMs": 21615}, {"Word": "the", "OffsetStartMs": 21615, "OffsetEndMs": 21750}, {"Word": "underlying", "OffsetStartMs": 21750, "OffsetEndMs": 22010}, {"Word": "structure", "OffsetStartMs": 22300, "OffsetEndMs": 22700}, {"Word": "What", "OffsetStartMs": 22780, "OffsetEndMs": 23070}, {"Word": "we", "OffsetStartMs": 23070, "OffsetEndMs": 23220}, {"Word": "were", "OffsetStartMs": 23220, "OffsetEndMs": 23355}, {"Word": "calling", "OffsetStartMs": 23355, "OffsetEndMs": 23565}, {"Word": "basically", "OffsetStartMs": 23565, "OffsetEndMs": 23900}, {"Word": "these", "OffsetStartMs": 23950, "OffsetEndMs": 24270}, {"Word": "latent", "OffsetStartMs": 24270, "OffsetEndMs": 24675}, {"Word": "variables", "OffsetStartMs": 24675, "OffsetEndMs": 25125}, {"Word": "these", "OffsetStartMs": 25125, "OffsetEndMs": 25350}, {"Word": "hidden", "OffsetStartMs": 25350, "OffsetEndMs": 25620}, {"Word": "features", "OffsetStartMs": 25620, "OffsetEndMs": 25970}, {"Word": "in", "OffsetStartMs": 26260, "OffsetEndMs": 26550}, {"Word": "your", "OffsetStartMs": 26550, "OffsetEndMs": 26730}, {"Word": "data", "OffsetStartMs": 26730, "OffsetEndMs": 27020}, {"Word": "So", "OffsetStartMs": 27070, "OffsetEndMs": 27345}, {"Word": "for", "OffsetStartMs": 27345, "OffsetEndMs": 27510}, {"Word": "example", "OffsetStartMs": 27510, "OffsetEndMs": 27720}, {"Word": "in", "OffsetStartMs": 27720, "OffsetEndMs": 27900}, {"Word": "this", "OffsetStartMs": 27900, "OffsetEndMs": 28035}, {"Word": "Apple", "OffsetStartMs": 28035, "OffsetEndMs": 28310}, {"Word": "example", "OffsetStartMs": 28690, "OffsetEndMs": 29070}, {"Word": "right", "OffsetStartMs": 29070, "OffsetEndMs": 29450}, {"Word": "using", "OffsetStartMs": 29650, "OffsetEndMs": 30000}, {"Word": "unsupervised", "OffsetStartMs": 30000, "OffsetEndMs": 30765}, {"Word": "learning", "OffsetStartMs": 30765, "OffsetEndMs": 31100}, {"Word": "The", "OffsetStartMs": 31330, "OffsetEndMs": 31695}, {"Word": "analogous", "OffsetStartMs": 31695, "OffsetEndMs": 32420}, {"Word": "example", "OffsetStartMs": 32500, "OffsetEndMs": 32900}, {"Word": "would", "OffsetStartMs": 33040, "OffsetEndMs": 33330}, {"Word": "basically", "OffsetStartMs": 33330, "OffsetEndMs": 33620}, {"Word": "be", "OffsetStartMs": 33790, "OffsetEndMs": 34190}, {"Word": "to", "OffsetStartMs": 34330, "OffsetEndMs": 34605}, {"Word": "build", "OffsetStartMs": 34605, "OffsetEndMs": 34770}, {"Word": "a", "OffsetStartMs": 34770, "OffsetEndMs": 34920}, {"Word": "model", "OffsetStartMs": 34920, "OffsetEndMs": 35180}, {"Word": "that", "OffsetStartMs": 35320, "OffsetEndMs": 35640}, {"Word": "could", "OffsetStartMs": 35640, "OffsetEndMs": 35960}, {"Word": "understand", "OffsetStartMs": 36160, "OffsetEndMs": 36560}, {"Word": "and", "OffsetStartMs": 36880, "OffsetEndMs": 37245}, {"Word": "cluster", "OffsetStartMs": 37245, "OffsetEndMs": 37640}, {"Word": "certain", "OffsetStartMs": 37810, "OffsetEndMs": 38210}, {"Word": "certain", "OffsetStartMs": 38620, "OffsetEndMs": 39000}, {"Word": "parts", "OffsetStartMs": 39000, "OffsetEndMs": 39360}, {"Word": "of", "OffsetStartMs": 39360, "OffsetEndMs": 39720}, {"Word": "these", "OffsetStartMs": 39720, "OffsetEndMs": 40020}, {"Word": "images", "OffsetStartMs": 40020, "OffsetEndMs": 40340}, {"Word": "together", "OffsetStartMs": 40540, "OffsetEndMs": 40875}, {"Word": "And", "OffsetStartMs": 40875, "OffsetEndMs": 41070}, {"Word": "maybe", "OffsetStartMs": 41070, "OffsetEndMs": 41250}, {"Word": "it", "OffsetStartMs": 41250, "OffsetEndMs": 41430}, {"Word": "doesn't", "OffsetStartMs": 41430, "OffsetEndMs": 41805}, {"Word": "have", "OffsetStartMs": 41805, "OffsetEndMs": 42060}, {"Word": "to", "OffsetStartMs": 42060, "OffsetEndMs": 42315}, {"Word": "understand", "OffsetStartMs": 42315, "OffsetEndMs": 42585}, {"Word": "that", "OffsetStartMs": 42585, "OffsetEndMs": 42890}, {"Word": "necessarily", "OffsetStartMs": 42910, "OffsetEndMs": 43245}, {"Word": "this", "OffsetStartMs": 43245, "OffsetEndMs": 43455}, {"Word": "is", "OffsetStartMs": 43455, "OffsetEndMs": 43605}, {"Word": "an", "OffsetStartMs": 43605, "OffsetEndMs": 43740}, {"Word": "image", "OffsetStartMs": 43740, "OffsetEndMs": 43950}, {"Word": "of", "OffsetStartMs": 43950, "OffsetEndMs": 44160}, {"Word": "an", "OffsetStartMs": 44160, "OffsetEndMs": 44295}, {"Word": "Apple", "OffsetStartMs": 44295, "OffsetEndMs": 44570}, {"Word": "But", "OffsetStartMs": 45010, "OffsetEndMs": 45270}, {"Word": "it", "OffsetStartMs": 45270, "OffsetEndMs": 45390}, {"Word": "needs", "OffsetStartMs": 45390, "OffsetEndMs": 45555}, {"Word": "to", "OffsetStartMs": 45555, "OffsetEndMs": 45840}, {"Word": "understand", "OffsetStartMs": 45840, "OffsetEndMs": 46140}, {"Word": "that", "OffsetStartMs": 46140, "OffsetEndMs": 46350}, {"Word": "you", "OffsetStartMs": 46350, "OffsetEndMs": 46485}, {"Word": "know", "OffsetStartMs": 46485, "OffsetEndMs": 46605}, {"Word": "this", "OffsetStartMs": 46605, "OffsetEndMs": 46880}, {"Word": "image", "OffsetStartMs": 47200, "OffsetEndMs": 47520}, {"Word": "of", "OffsetStartMs": 47520, "OffsetEndMs": 47715}, {"Word": "the", "OffsetStartMs": 47715, "OffsetEndMs": 47850}, {"Word": "red", "OffsetStartMs": 47850, "OffsetEndMs": 47985}, {"Word": "Apple", "OffsetStartMs": 47985, "OffsetEndMs": 48260}, {"Word": "is", "OffsetStartMs": 48340, "OffsetEndMs": 48675}, {"Word": "similar", "OffsetStartMs": 48675, "OffsetEndMs": 48960}, {"Word": "It", "OffsetStartMs": 48960, "OffsetEndMs": 49155}, {"Word": "has", "OffsetStartMs": 49155, "OffsetEndMs": 49305}, {"Word": "the", "OffsetStartMs": 49305, "OffsetEndMs": 49485}, {"Word": "same", "OffsetStartMs": 49485, "OffsetEndMs": 49760}, {"Word": "latent", "OffsetStartMs": 49780, "OffsetEndMs": 50235}, {"Word": "features", "OffsetStartMs": 50235, "OffsetEndMs": 50490}, {"Word": "and", "OffsetStartMs": 50490, "OffsetEndMs": 50745}, {"Word": "same", "OffsetStartMs": 50745, "OffsetEndMs": 50940}, {"Word": "semantic", "OffsetStartMs": 50940, "OffsetEndMs": 51495}, {"Word": "meaning", "OffsetStartMs": 51495, "OffsetEndMs": 51800}, {"Word": "as", "OffsetStartMs": 52090, "OffsetEndMs": 52440}, {"Word": "this", "OffsetStartMs": 52440, "OffsetEndMs": 52790}, {"Word": "black", "OffsetStartMs": 52810, "OffsetEndMs": 53100}, {"Word": "and", "OffsetStartMs": 53100, "OffsetEndMs": 53265}, {"Word": "white", "OffsetStartMs": 53265, "OffsetEndMs": 53540}, {"Word": "outline", "OffsetStartMs": 53620, "OffsetEndMs": 54195}, {"Word": "sketch", "OffsetStartMs": 54195, "OffsetEndMs": 54540}, {"Word": "of", "OffsetStartMs": 54540, "OffsetEndMs": 54765}, {"Word": "the", "OffsetStartMs": 54765, "OffsetEndMs": 54900}, {"Word": "Apple", "OffsetStartMs": 54900, "OffsetEndMs": 55160}], "SpeechSpeed": 17.4}, {"FinalSentence": "Now, in today's lecture we're going to talk about yet another type of learning algorithms, right in reinforcement learning. We're going to be only given data in the form of what are called state action pairs. Right now states are observations, right. This is what the agent, let's call it, the neural network is going to observe. It's what it sees. The actions are the behaviors that this agent takes in those particular states. So the goal of reinforcement learning is to build an agent that can learn how to maximize what are called rewards. This is the third component that is specific to reinforcement learning and you want to maximize all of those rewards over many, many time steps in the future.", "SliceSentence": "Now in today's lecture we're going to talk about yet another type of learning algorithms right in reinforcement learning We're going to be only given data in the form of what are called state action pairs Right now states are observations right This is what the agent let's call it the neural network is going to observe It's what it sees The actions are the behaviors that this agent takes in those particular states So the goal of reinforcement learning is to build an agent that can learn how to maximize what are called rewards This is the third component that is specific to reinforcement learning and you want to maximize all of those rewards over many many time steps in the future", "StartMs": 337560, "EndMs": 380960, "WordsNum": 123, "Words": [{"Word": "Now", "OffsetStartMs": 100, "OffsetEndMs": 480}, {"Word": "in", "OffsetStartMs": 480, "OffsetEndMs": 750}, {"Word": "today's", "OffsetStartMs": 750, "OffsetEndMs": 1365}, {"Word": "lecture", "OffsetStartMs": 1365, "OffsetEndMs": 1760}, {"Word": "we're", "OffsetStartMs": 1810, "OffsetEndMs": 2100}, {"Word": "going", "OffsetStartMs": 2100, "OffsetEndMs": 2220}, {"Word": "to", "OffsetStartMs": 2220, "OffsetEndMs": 2385}, {"Word": "talk", "OffsetStartMs": 2385, "OffsetEndMs": 2580}, {"Word": "about", "OffsetStartMs": 2580, "OffsetEndMs": 2820}, {"Word": "yet", "OffsetStartMs": 2820, "OffsetEndMs": 3105}, {"Word": "another", "OffsetStartMs": 3105, "OffsetEndMs": 3470}, {"Word": "type", "OffsetStartMs": 3670, "OffsetEndMs": 4070}, {"Word": "of", "OffsetStartMs": 4150, "OffsetEndMs": 4470}, {"Word": "learning", "OffsetStartMs": 4470, "OffsetEndMs": 4790}, {"Word": "algorithms", "OffsetStartMs": 4930, "OffsetEndMs": 5400}, {"Word": "right", "OffsetStartMs": 5400, "OffsetEndMs": 5730}, {"Word": "in", "OffsetStartMs": 5730, "OffsetEndMs": 6090}, {"Word": "reinforcement", "OffsetStartMs": 6090, "OffsetEndMs": 6885}, {"Word": "learning", "OffsetStartMs": 6885, "OffsetEndMs": 7160}, {"Word": "We're", "OffsetStartMs": 7210, "OffsetEndMs": 7575}, {"Word": "going", "OffsetStartMs": 7575, "OffsetEndMs": 7770}, {"Word": "to", "OffsetStartMs": 7770, "OffsetEndMs": 7935}, {"Word": "be", "OffsetStartMs": 7935, "OffsetEndMs": 8055}, {"Word": "only", "OffsetStartMs": 8055, "OffsetEndMs": 8325}, {"Word": "given", "OffsetStartMs": 8325, "OffsetEndMs": 8720}, {"Word": "data", "OffsetStartMs": 9010, "OffsetEndMs": 9410}, {"Word": "in", "OffsetStartMs": 9460, "OffsetEndMs": 9720}, {"Word": "the", "OffsetStartMs": 9720, "OffsetEndMs": 9870}, {"Word": "form", "OffsetStartMs": 9870, "OffsetEndMs": 10050}, {"Word": "of", "OffsetStartMs": 10050, "OffsetEndMs": 10215}, {"Word": "what", "OffsetStartMs": 10215, "OffsetEndMs": 10350}, {"Word": "are", "OffsetStartMs": 10350, "OffsetEndMs": 10500}, {"Word": "called", "OffsetStartMs": 10500, "OffsetEndMs": 10790}, {"Word": "state", "OffsetStartMs": 10840, "OffsetEndMs": 11205}, {"Word": "action", "OffsetStartMs": 11205, "OffsetEndMs": 11570}, {"Word": "pairs", "OffsetStartMs": 11770, "OffsetEndMs": 12230}, {"Word": "Right", "OffsetStartMs": 12700, "OffsetEndMs": 13095}, {"Word": "now", "OffsetStartMs": 13095, "OffsetEndMs": 13455}, {"Word": "states", "OffsetStartMs": 13455, "OffsetEndMs": 13820}, {"Word": "are", "OffsetStartMs": 14140, "OffsetEndMs": 14540}, {"Word": "observations", "OffsetStartMs": 14590, "OffsetEndMs": 15110}, {"Word": "right", "OffsetStartMs": 15550, "OffsetEndMs": 15855}, {"Word": "This", "OffsetStartMs": 15855, "OffsetEndMs": 16050}, {"Word": "is", "OffsetStartMs": 16050, "OffsetEndMs": 16230}, {"Word": "what", "OffsetStartMs": 16230, "OffsetEndMs": 16425}, {"Word": "the", "OffsetStartMs": 16425, "OffsetEndMs": 16730}, {"Word": "agent", "OffsetStartMs": 17020, "OffsetEndMs": 17420}, {"Word": "let's", "OffsetStartMs": 17650, "OffsetEndMs": 18030}, {"Word": "call", "OffsetStartMs": 18030, "OffsetEndMs": 18165}, {"Word": "it", "OffsetStartMs": 18165, "OffsetEndMs": 18315}, {"Word": "the", "OffsetStartMs": 18315, "OffsetEndMs": 18480}, {"Word": "neural", "OffsetStartMs": 18480, "OffsetEndMs": 18735}, {"Word": "network", "OffsetStartMs": 18735, "OffsetEndMs": 19005}, {"Word": "is", "OffsetStartMs": 19005, "OffsetEndMs": 19290}, {"Word": "going", "OffsetStartMs": 19290, "OffsetEndMs": 19500}, {"Word": "to", "OffsetStartMs": 19500, "OffsetEndMs": 19815}, {"Word": "observe", "OffsetStartMs": 19815, "OffsetEndMs": 20115}, {"Word": "It's", "OffsetStartMs": 20115, "OffsetEndMs": 20400}, {"Word": "what", "OffsetStartMs": 20400, "OffsetEndMs": 20520}, {"Word": "it", "OffsetStartMs": 20520, "OffsetEndMs": 20700}, {"Word": "sees", "OffsetStartMs": 20700, "OffsetEndMs": 21020}, {"Word": "The", "OffsetStartMs": 21700, "OffsetEndMs": 21945}, {"Word": "actions", "OffsetStartMs": 21945, "OffsetEndMs": 22190}, {"Word": "are", "OffsetStartMs": 22360, "OffsetEndMs": 22635}, {"Word": "the", "OffsetStartMs": 22635, "OffsetEndMs": 22845}, {"Word": "behaviors", "OffsetStartMs": 22845, "OffsetEndMs": 23370}, {"Word": "that", "OffsetStartMs": 23370, "OffsetEndMs": 23610}, {"Word": "this", "OffsetStartMs": 23610, "OffsetEndMs": 23805}, {"Word": "agent", "OffsetStartMs": 23805, "OffsetEndMs": 24110}, {"Word": "takes", "OffsetStartMs": 24250, "OffsetEndMs": 24650}, {"Word": "in", "OffsetStartMs": 25180, "OffsetEndMs": 25580}, {"Word": "those", "OffsetStartMs": 25840, "OffsetEndMs": 26240}, {"Word": "particular", "OffsetStartMs": 26440, "OffsetEndMs": 26840}, {"Word": "states", "OffsetStartMs": 27100, "OffsetEndMs": 27500}, {"Word": "So", "OffsetStartMs": 27880, "OffsetEndMs": 28155}, {"Word": "the", "OffsetStartMs": 28155, "OffsetEndMs": 28305}, {"Word": "goal", "OffsetStartMs": 28305, "OffsetEndMs": 28575}, {"Word": "of", "OffsetStartMs": 28575, "OffsetEndMs": 28875}, {"Word": "reinforcement", "OffsetStartMs": 28875, "OffsetEndMs": 29460}, {"Word": "learning", "OffsetStartMs": 29460, "OffsetEndMs": 29625}, {"Word": "is", "OffsetStartMs": 29625, "OffsetEndMs": 29850}, {"Word": "to", "OffsetStartMs": 29850, "OffsetEndMs": 30060}, {"Word": "build", "OffsetStartMs": 30060, "OffsetEndMs": 30255}, {"Word": "an", "OffsetStartMs": 30255, "OffsetEndMs": 30435}, {"Word": "agent", "OffsetStartMs": 30435, "OffsetEndMs": 30710}, {"Word": "that", "OffsetStartMs": 30820, "OffsetEndMs": 31125}, {"Word": "can", "OffsetStartMs": 31125, "OffsetEndMs": 31350}, {"Word": "learn", "OffsetStartMs": 31350, "OffsetEndMs": 31650}, {"Word": "how", "OffsetStartMs": 31650, "OffsetEndMs": 31935}, {"Word": "to", "OffsetStartMs": 31935, "OffsetEndMs": 32100}, {"Word": "maximize", "OffsetStartMs": 32100, "OffsetEndMs": 32655}, {"Word": "what", "OffsetStartMs": 32655, "OffsetEndMs": 32850}, {"Word": "are", "OffsetStartMs": 32850, "OffsetEndMs": 33000}, {"Word": "called", "OffsetStartMs": 33000, "OffsetEndMs": 33290}, {"Word": "rewards", "OffsetStartMs": 33430, "OffsetEndMs": 33980}, {"Word": "This", "OffsetStartMs": 34240, "OffsetEndMs": 34500}, {"Word": "is", "OffsetStartMs": 34500, "OffsetEndMs": 34650}, {"Word": "the", "OffsetStartMs": 34650, "OffsetEndMs": 34815}, {"Word": "third", "OffsetStartMs": 34815, "OffsetEndMs": 35090}, {"Word": "component", "OffsetStartMs": 35140, "OffsetEndMs": 35505}, {"Word": "that", "OffsetStartMs": 35505, "OffsetEndMs": 35715}, {"Word": "is", "OffsetStartMs": 35715, "OffsetEndMs": 35865}, {"Word": "specific", "OffsetStartMs": 35865, "OffsetEndMs": 36170}, {"Word": "to", "OffsetStartMs": 36550, "OffsetEndMs": 36810}, {"Word": "reinforcement", "OffsetStartMs": 36810, "OffsetEndMs": 37440}, {"Word": "learning", "OffsetStartMs": 37440, "OffsetEndMs": 37730}, {"Word": "and", "OffsetStartMs": 37990, "OffsetEndMs": 38265}, {"Word": "you", "OffsetStartMs": 38265, "OffsetEndMs": 38400}, {"Word": "want", "OffsetStartMs": 38400, "OffsetEndMs": 38595}, {"Word": "to", "OffsetStartMs": 38595, "OffsetEndMs": 38805}, {"Word": "maximize", "OffsetStartMs": 38805, "OffsetEndMs": 39420}, {"Word": "all", "OffsetStartMs": 39420, "OffsetEndMs": 39660}, {"Word": "of", "OffsetStartMs": 39660, "OffsetEndMs": 39825}, {"Word": "those", "OffsetStartMs": 39825, "OffsetEndMs": 40005}, {"Word": "rewards", "OffsetStartMs": 40005, "OffsetEndMs": 40425}, {"Word": "over", "OffsetStartMs": 40425, "OffsetEndMs": 40800}, {"Word": "many", "OffsetStartMs": 40800, "OffsetEndMs": 41100}, {"Word": "many", "OffsetStartMs": 41100, "OffsetEndMs": 41370}, {"Word": "time", "OffsetStartMs": 41370, "OffsetEndMs": 41670}, {"Word": "steps", "OffsetStartMs": 41670, "OffsetEndMs": 42020}, {"Word": "in", "OffsetStartMs": 42040, "OffsetEndMs": 42345}, {"Word": "the", "OffsetStartMs": 42345, "OffsetEndMs": 42510}, {"Word": "future", "OffsetStartMs": 42510, "OffsetEndMs": 42770}], "SpeechSpeed": 15.9}, {"FinalSentence": "So again, in this Apple example, we might now see that the agent doesn't necessarily learn that, okay, this is an Apple or it looks like these other apples. Now it has to learn to, let's say, eat the Apple, take an action, eat that Apple, because it has learned that eating that Apple makes it live longer or survive because it doesn't starve.", "SliceSentence": "So again in this Apple example we might now see that the agent doesn't necessarily learn that okay this is an Apple or it looks like these other apples Now it has to learn to let's say eat the Apple take an action eat that Apple because it has learned that eating that Apple makes it live longer or survive because it doesn't starve", "StartMs": 380960, "EndMs": 399060, "WordsNum": 64, "Words": [{"Word": "So", "OffsetStartMs": 0, "OffsetEndMs": 330}, {"Word": "again", "OffsetStartMs": 330, "OffsetEndMs": 615}, {"Word": "in", "OffsetStartMs": 615, "OffsetEndMs": 825}, {"Word": "this", "OffsetStartMs": 825, "OffsetEndMs": 990}, {"Word": "Apple", "OffsetStartMs": 990, "OffsetEndMs": 1280}, {"Word": "example", "OffsetStartMs": 1360, "OffsetEndMs": 1760}, {"Word": "we", "OffsetStartMs": 2200, "OffsetEndMs": 2475}, {"Word": "might", "OffsetStartMs": 2475, "OffsetEndMs": 2655}, {"Word": "now", "OffsetStartMs": 2655, "OffsetEndMs": 2910}, {"Word": "see", "OffsetStartMs": 2910, "OffsetEndMs": 3150}, {"Word": "that", "OffsetStartMs": 3150, "OffsetEndMs": 3315}, {"Word": "the", "OffsetStartMs": 3315, "OffsetEndMs": 3450}, {"Word": "agent", "OffsetStartMs": 3450, "OffsetEndMs": 3710}, {"Word": "doesn't", "OffsetStartMs": 4030, "OffsetEndMs": 4545}, {"Word": "necessarily", "OffsetStartMs": 4545, "OffsetEndMs": 4875}, {"Word": "learn", "OffsetStartMs": 4875, "OffsetEndMs": 5145}, {"Word": "that", "OffsetStartMs": 5145, "OffsetEndMs": 5370}, {"Word": "okay", "OffsetStartMs": 5370, "OffsetEndMs": 5550}, {"Word": "this", "OffsetStartMs": 5550, "OffsetEndMs": 5670}, {"Word": "is", "OffsetStartMs": 5670, "OffsetEndMs": 5790}, {"Word": "an", "OffsetStartMs": 5790, "OffsetEndMs": 5895}, {"Word": "Apple", "OffsetStartMs": 5895, "OffsetEndMs": 6140}, {"Word": "or", "OffsetStartMs": 6190, "OffsetEndMs": 6450}, {"Word": "it", "OffsetStartMs": 6450, "OffsetEndMs": 6570}, {"Word": "looks", "OffsetStartMs": 6570, "OffsetEndMs": 6735}, {"Word": "like", "OffsetStartMs": 6735, "OffsetEndMs": 6930}, {"Word": "these", "OffsetStartMs": 6930, "OffsetEndMs": 7080}, {"Word": "other", "OffsetStartMs": 7080, "OffsetEndMs": 7260}, {"Word": "apples", "OffsetStartMs": 7260, "OffsetEndMs": 7580}, {"Word": "Now", "OffsetStartMs": 7870, "OffsetEndMs": 8160}, {"Word": "it", "OffsetStartMs": 8160, "OffsetEndMs": 8310}, {"Word": "has", "OffsetStartMs": 8310, "OffsetEndMs": 8475}, {"Word": "to", "OffsetStartMs": 8475, "OffsetEndMs": 8655}, {"Word": "learn", "OffsetStartMs": 8655, "OffsetEndMs": 8930}, {"Word": "to", "OffsetStartMs": 9010, "OffsetEndMs": 9390}, {"Word": "let's", "OffsetStartMs": 9390, "OffsetEndMs": 9690}, {"Word": "say", "OffsetStartMs": 9690, "OffsetEndMs": 9825}, {"Word": "eat", "OffsetStartMs": 9825, "OffsetEndMs": 10035}, {"Word": "the", "OffsetStartMs": 10035, "OffsetEndMs": 10200}, {"Word": "Apple", "OffsetStartMs": 10200, "OffsetEndMs": 10460}, {"Word": "take", "OffsetStartMs": 10600, "OffsetEndMs": 10860}, {"Word": "an", "OffsetStartMs": 10860, "OffsetEndMs": 10980}, {"Word": "action", "OffsetStartMs": 10980, "OffsetEndMs": 11235}, {"Word": "eat", "OffsetStartMs": 11235, "OffsetEndMs": 11535}, {"Word": "that", "OffsetStartMs": 11535, "OffsetEndMs": 11715}, {"Word": "Apple", "OffsetStartMs": 11715, "OffsetEndMs": 11990}, {"Word": "because", "OffsetStartMs": 12040, "OffsetEndMs": 12360}, {"Word": "it", "OffsetStartMs": 12360, "OffsetEndMs": 12555}, {"Word": "has", "OffsetStartMs": 12555, "OffsetEndMs": 12750}, {"Word": "learned", "OffsetStartMs": 12750, "OffsetEndMs": 13005}, {"Word": "that", "OffsetStartMs": 13005, "OffsetEndMs": 13245}, {"Word": "eating", "OffsetStartMs": 13245, "OffsetEndMs": 13470}, {"Word": "that", "OffsetStartMs": 13470, "OffsetEndMs": 13665}, {"Word": "Apple", "OffsetStartMs": 13665, "OffsetEndMs": 13890}, {"Word": "makes", "OffsetStartMs": 13890, "OffsetEndMs": 14115}, {"Word": "it", "OffsetStartMs": 14115, "OffsetEndMs": 14265}, {"Word": "live", "OffsetStartMs": 14265, "OffsetEndMs": 14445}, {"Word": "longer", "OffsetStartMs": 14445, "OffsetEndMs": 14750}, {"Word": "or", "OffsetStartMs": 14800, "OffsetEndMs": 15180}, {"Word": "survive", "OffsetStartMs": 15180, "OffsetEndMs": 15510}, {"Word": "because", "OffsetStartMs": 15510, "OffsetEndMs": 15735}, {"Word": "it", "OffsetStartMs": 15735, "OffsetEndMs": 16010}, {"Word": "doesn't", "OffsetStartMs": 16180, "OffsetEndMs": 16605}, {"Word": "starve", "OffsetStartMs": 16605, "OffsetEndMs": 17090}], "SpeechSpeed": 18.3}, {"FinalSentence": "So in today, right, like I said, we're going to be focusing exclusively on this third type of learning paradigm, which is reinforcement learning. And before we go any further, I just want to start by building up some very key terminology and like, basically background for all of you so that we're all on the same page when we start discussing some of the more complex components of today's lecture.", "SliceSentence": "So in today right like I said we're going to be focusing exclusively on this third type of learning paradigm which is reinforcement learning And before we go any further I just want to start by building up some very key terminology and like basically background for all of you so that we're all on the same page when we start discussing some of the more complex components of today's lecture", "StartMs": 399460, "EndMs": 422640, "WordsNum": 71, "Words": [{"Word": "So", "OffsetStartMs": 160, "OffsetEndMs": 495}, {"Word": "in", "OffsetStartMs": 495, "OffsetEndMs": 720}, {"Word": "today", "OffsetStartMs": 720, "OffsetEndMs": 1010}, {"Word": "right", "OffsetStartMs": 1120, "OffsetEndMs": 1470}, {"Word": "like", "OffsetStartMs": 1470, "OffsetEndMs": 1680}, {"Word": "I", "OffsetStartMs": 1680, "OffsetEndMs": 1830}, {"Word": "said", "OffsetStartMs": 1830, "OffsetEndMs": 2040}, {"Word": "we're", "OffsetStartMs": 2040, "OffsetEndMs": 2250}, {"Word": "going", "OffsetStartMs": 2250, "OffsetEndMs": 2355}, {"Word": "to", "OffsetStartMs": 2355, "OffsetEndMs": 2460}, {"Word": "be", "OffsetStartMs": 2460, "OffsetEndMs": 2565}, {"Word": "focusing", "OffsetStartMs": 2565, "OffsetEndMs": 2840}, {"Word": "exclusively", "OffsetStartMs": 3160, "OffsetEndMs": 3900}, {"Word": "on", "OffsetStartMs": 3900, "OffsetEndMs": 4185}, {"Word": "this", "OffsetStartMs": 4185, "OffsetEndMs": 4455}, {"Word": "third", "OffsetStartMs": 4455, "OffsetEndMs": 4740}, {"Word": "type", "OffsetStartMs": 4740, "OffsetEndMs": 5055}, {"Word": "of", "OffsetStartMs": 5055, "OffsetEndMs": 5325}, {"Word": "learning", "OffsetStartMs": 5325, "OffsetEndMs": 5610}, {"Word": "paradigm", "OffsetStartMs": 5610, "OffsetEndMs": 6380}, {"Word": "which", "OffsetStartMs": 6460, "OffsetEndMs": 6765}, {"Word": "is", "OffsetStartMs": 6765, "OffsetEndMs": 7050}, {"Word": "reinforcement", "OffsetStartMs": 7050, "OffsetEndMs": 7785}, {"Word": "learning", "OffsetStartMs": 7785, "OffsetEndMs": 8060}, {"Word": "And", "OffsetStartMs": 8410, "OffsetEndMs": 8670}, {"Word": "before", "OffsetStartMs": 8670, "OffsetEndMs": 8865}, {"Word": "we", "OffsetStartMs": 8865, "OffsetEndMs": 9045}, {"Word": "go", "OffsetStartMs": 9045, "OffsetEndMs": 9150}, {"Word": "any", "OffsetStartMs": 9150, "OffsetEndMs": 9330}, {"Word": "further", "OffsetStartMs": 9330, "OffsetEndMs": 9650}, {"Word": "I", "OffsetStartMs": 9730, "OffsetEndMs": 10005}, {"Word": "just", "OffsetStartMs": 10005, "OffsetEndMs": 10140}, {"Word": "want", "OffsetStartMs": 10140, "OffsetEndMs": 10260}, {"Word": "to", "OffsetStartMs": 10260, "OffsetEndMs": 10425}, {"Word": "start", "OffsetStartMs": 10425, "OffsetEndMs": 10665}, {"Word": "by", "OffsetStartMs": 10665, "OffsetEndMs": 10905}, {"Word": "building", "OffsetStartMs": 10905, "OffsetEndMs": 11160}, {"Word": "up", "OffsetStartMs": 11160, "OffsetEndMs": 11415}, {"Word": "some", "OffsetStartMs": 11415, "OffsetEndMs": 11625}, {"Word": "very", "OffsetStartMs": 11625, "OffsetEndMs": 11925}, {"Word": "key", "OffsetStartMs": 11925, "OffsetEndMs": 12320}, {"Word": "terminology", "OffsetStartMs": 12400, "OffsetEndMs": 13340}, {"Word": "and", "OffsetStartMs": 13540, "OffsetEndMs": 13940}, {"Word": "like", "OffsetStartMs": 14290, "OffsetEndMs": 14610}, {"Word": "basically", "OffsetStartMs": 14610, "OffsetEndMs": 14930}, {"Word": "background", "OffsetStartMs": 15790, "OffsetEndMs": 16190}, {"Word": "for", "OffsetStartMs": 16390, "OffsetEndMs": 16650}, {"Word": "all", "OffsetStartMs": 16650, "OffsetEndMs": 16800}, {"Word": "of", "OffsetStartMs": 16800, "OffsetEndMs": 16965}, {"Word": "you", "OffsetStartMs": 16965, "OffsetEndMs": 17175}, {"Word": "so", "OffsetStartMs": 17175, "OffsetEndMs": 17355}, {"Word": "that", "OffsetStartMs": 17355, "OffsetEndMs": 17475}, {"Word": "we're", "OffsetStartMs": 17475, "OffsetEndMs": 17640}, {"Word": "all", "OffsetStartMs": 17640, "OffsetEndMs": 17760}, {"Word": "on", "OffsetStartMs": 17760, "OffsetEndMs": 17940}, {"Word": "the", "OffsetStartMs": 17940, "OffsetEndMs": 18090}, {"Word": "same", "OffsetStartMs": 18090, "OffsetEndMs": 18285}, {"Word": "page", "OffsetStartMs": 18285, "OffsetEndMs": 18615}, {"Word": "when", "OffsetStartMs": 18615, "OffsetEndMs": 18870}, {"Word": "we", "OffsetStartMs": 18870, "OffsetEndMs": 19020}, {"Word": "start", "OffsetStartMs": 19020, "OffsetEndMs": 19275}, {"Word": "discussing", "OffsetStartMs": 19275, "OffsetEndMs": 19605}, {"Word": "some", "OffsetStartMs": 19605, "OffsetEndMs": 19830}, {"Word": "of", "OffsetStartMs": 19830, "OffsetEndMs": 19950}, {"Word": "the", "OffsetStartMs": 19950, "OffsetEndMs": 20055}, {"Word": "more", "OffsetStartMs": 20055, "OffsetEndMs": 20300}, {"Word": "complex", "OffsetStartMs": 20320, "OffsetEndMs": 20720}, {"Word": "components", "OffsetStartMs": 21070, "OffsetEndMs": 21470}, {"Word": "of", "OffsetStartMs": 21490, "OffsetEndMs": 21780}, {"Word": "today's", "OffsetStartMs": 21780, "OffsetEndMs": 22155}, {"Word": "lecture", "OffsetStartMs": 22155, "OffsetEndMs": 22430}], "SpeechSpeed": 16.9}, {"FinalSentence": "So let's start by building up, you know, some of this terminology. The first main piece of terminology is that of an agent. An agent is a being basically that can take actions. For example, you can think of an agent as a machine, right? That is, let's say an autonomous drone that is making a delivery. Or for example, in a game, it could be super Mario that's navigating inside of your video video game.", "SliceSentence": "So let's start by building up you know some of this terminology The first main piece of terminology is that of an agent An agent is a being basically that can take actions For example you can think of an agent as a machine right That is let's say an autonomous drone that is making a delivery Or for example in a game it could be super Mario that's navigating inside of your video video game", "StartMs": 422640, "EndMs": 451500, "WordsNum": 76, "Words": [{"Word": "So", "OffsetStartMs": 280, "OffsetEndMs": 660}, {"Word": "let's", "OffsetStartMs": 660, "OffsetEndMs": 1035}, {"Word": "start", "OffsetStartMs": 1035, "OffsetEndMs": 1245}, {"Word": "by", "OffsetStartMs": 1245, "OffsetEndMs": 1580}, {"Word": "building", "OffsetStartMs": 1690, "OffsetEndMs": 2055}, {"Word": "up", "OffsetStartMs": 2055, "OffsetEndMs": 2420}, {"Word": "you", "OffsetStartMs": 2560, "OffsetEndMs": 2805}, {"Word": "know", "OffsetStartMs": 2805, "OffsetEndMs": 3015}, {"Word": "some", "OffsetStartMs": 3015, "OffsetEndMs": 3255}, {"Word": "of", "OffsetStartMs": 3255, "OffsetEndMs": 3390}, {"Word": "this", "OffsetStartMs": 3390, "OffsetEndMs": 3645}, {"Word": "terminology", "OffsetStartMs": 3645, "OffsetEndMs": 4350}, {"Word": "The", "OffsetStartMs": 4350, "OffsetEndMs": 4500}, {"Word": "first", "OffsetStartMs": 4500, "OffsetEndMs": 4790}, {"Word": "main", "OffsetStartMs": 4840, "OffsetEndMs": 5220}, {"Word": "piece", "OffsetStartMs": 5220, "OffsetEndMs": 5490}, {"Word": "of", "OffsetStartMs": 5490, "OffsetEndMs": 5670}, {"Word": "terminology", "OffsetStartMs": 5670, "OffsetEndMs": 6345}, {"Word": "is", "OffsetStartMs": 6345, "OffsetEndMs": 6555}, {"Word": "that", "OffsetStartMs": 6555, "OffsetEndMs": 6750}, {"Word": "of", "OffsetStartMs": 6750, "OffsetEndMs": 6960}, {"Word": "an", "OffsetStartMs": 6960, "OffsetEndMs": 7155}, {"Word": "agent", "OffsetStartMs": 7155, "OffsetEndMs": 7430}, {"Word": "An", "OffsetStartMs": 8020, "OffsetEndMs": 8295}, {"Word": "agent", "OffsetStartMs": 8295, "OffsetEndMs": 8570}, {"Word": "is", "OffsetStartMs": 8650, "OffsetEndMs": 9050}, {"Word": "a", "OffsetStartMs": 9730, "OffsetEndMs": 10130}, {"Word": "being", "OffsetStartMs": 11050, "OffsetEndMs": 11450}, {"Word": "basically", "OffsetStartMs": 11530, "OffsetEndMs": 11930}, {"Word": "that", "OffsetStartMs": 12220, "OffsetEndMs": 12525}, {"Word": "can", "OffsetStartMs": 12525, "OffsetEndMs": 12705}, {"Word": "take", "OffsetStartMs": 12705, "OffsetEndMs": 12885}, {"Word": "actions", "OffsetStartMs": 12885, "OffsetEndMs": 13190}, {"Word": "For", "OffsetStartMs": 13690, "OffsetEndMs": 13980}, {"Word": "example", "OffsetStartMs": 13980, "OffsetEndMs": 14270}, {"Word": "you", "OffsetStartMs": 14290, "OffsetEndMs": 14550}, {"Word": "can", "OffsetStartMs": 14550, "OffsetEndMs": 14685}, {"Word": "think", "OffsetStartMs": 14685, "OffsetEndMs": 14835}, {"Word": "of", "OffsetStartMs": 14835, "OffsetEndMs": 15090}, {"Word": "an", "OffsetStartMs": 15090, "OffsetEndMs": 15360}, {"Word": "agent", "OffsetStartMs": 15360, "OffsetEndMs": 15650}, {"Word": "as", "OffsetStartMs": 16240, "OffsetEndMs": 16640}, {"Word": "a", "OffsetStartMs": 16840, "OffsetEndMs": 17240}, {"Word": "machine", "OffsetStartMs": 17440, "OffsetEndMs": 17840}, {"Word": "right", "OffsetStartMs": 18040, "OffsetEndMs": 18435}, {"Word": "That", "OffsetStartMs": 18435, "OffsetEndMs": 18780}, {"Word": "is", "OffsetStartMs": 18780, "OffsetEndMs": 19095}, {"Word": "let's", "OffsetStartMs": 19095, "OffsetEndMs": 19395}, {"Word": "say", "OffsetStartMs": 19395, "OffsetEndMs": 19575}, {"Word": "an", "OffsetStartMs": 19575, "OffsetEndMs": 19770}, {"Word": "autonomous", "OffsetStartMs": 19770, "OffsetEndMs": 20355}, {"Word": "drone", "OffsetStartMs": 20355, "OffsetEndMs": 20720}, {"Word": "that", "OffsetStartMs": 20950, "OffsetEndMs": 21345}, {"Word": "is", "OffsetStartMs": 21345, "OffsetEndMs": 21645}, {"Word": "making", "OffsetStartMs": 21645, "OffsetEndMs": 21855}, {"Word": "a", "OffsetStartMs": 21855, "OffsetEndMs": 22095}, {"Word": "delivery", "OffsetStartMs": 22095, "OffsetEndMs": 22430}, {"Word": "Or", "OffsetStartMs": 22480, "OffsetEndMs": 22785}, {"Word": "for", "OffsetStartMs": 22785, "OffsetEndMs": 22995}, {"Word": "example", "OffsetStartMs": 22995, "OffsetEndMs": 23280}, {"Word": "in", "OffsetStartMs": 23280, "OffsetEndMs": 23505}, {"Word": "a", "OffsetStartMs": 23505, "OffsetEndMs": 23610}, {"Word": "game", "OffsetStartMs": 23610, "OffsetEndMs": 23790}, {"Word": "it", "OffsetStartMs": 23790, "OffsetEndMs": 23985}, {"Word": "could", "OffsetStartMs": 23985, "OffsetEndMs": 24120}, {"Word": "be", "OffsetStartMs": 24120, "OffsetEndMs": 24270}, {"Word": "super", "OffsetStartMs": 24270, "OffsetEndMs": 24480}, {"Word": "Mario", "OffsetStartMs": 24480, "OffsetEndMs": 24975}, {"Word": "that's", "OffsetStartMs": 24975, "OffsetEndMs": 25430}, {"Word": "navigating", "OffsetStartMs": 25780, "OffsetEndMs": 26475}, {"Word": "inside", "OffsetStartMs": 26475, "OffsetEndMs": 26730}, {"Word": "of", "OffsetStartMs": 26730, "OffsetEndMs": 26850}, {"Word": "your", "OffsetStartMs": 26850, "OffsetEndMs": 26985}, {"Word": "video", "OffsetStartMs": 26985, "OffsetEndMs": 27225}, {"Word": "video", "OffsetStartMs": 27225, "OffsetEndMs": 27525}, {"Word": "game", "OffsetStartMs": 27525, "OffsetEndMs": 27860}], "SpeechSpeed": 13.5}, {"FinalSentence": "The algorithm itself, it's important to remember that the algorithm is the agent, right? We're trying to build an agent that can do these tasks, and the algorithm is that agent. So in life, for example, all of you are agents in life.", "SliceSentence": "The algorithm itself it's important to remember that the algorithm is the agent right We're trying to build an agent that can do these tasks and the algorithm is that agent So in life for example all of you are agents in life", "StartMs": 451500, "EndMs": 465160, "WordsNum": 43, "Words": [{"Word": "The", "OffsetStartMs": 0, "OffsetEndMs": 285}, {"Word": "algorithm", "OffsetStartMs": 285, "OffsetEndMs": 810}, {"Word": "itself", "OffsetStartMs": 810, "OffsetEndMs": 1190}, {"Word": "it's", "OffsetStartMs": 1510, "OffsetEndMs": 1905}, {"Word": "important", "OffsetStartMs": 1905, "OffsetEndMs": 2115}, {"Word": "to", "OffsetStartMs": 2115, "OffsetEndMs": 2265}, {"Word": "remember", "OffsetStartMs": 2265, "OffsetEndMs": 2430}, {"Word": "that", "OffsetStartMs": 2430, "OffsetEndMs": 2625}, {"Word": "the", "OffsetStartMs": 2625, "OffsetEndMs": 2880}, {"Word": "algorithm", "OffsetStartMs": 2880, "OffsetEndMs": 3285}, {"Word": "is", "OffsetStartMs": 3285, "OffsetEndMs": 3555}, {"Word": "the", "OffsetStartMs": 3555, "OffsetEndMs": 3795}, {"Word": "agent", "OffsetStartMs": 3795, "OffsetEndMs": 4070}, {"Word": "right", "OffsetStartMs": 4330, "OffsetEndMs": 4680}, {"Word": "We're", "OffsetStartMs": 4680, "OffsetEndMs": 4980}, {"Word": "trying", "OffsetStartMs": 4980, "OffsetEndMs": 5145}, {"Word": "to", "OffsetStartMs": 5145, "OffsetEndMs": 5325}, {"Word": "build", "OffsetStartMs": 5325, "OffsetEndMs": 5535}, {"Word": "an", "OffsetStartMs": 5535, "OffsetEndMs": 5730}, {"Word": "agent", "OffsetStartMs": 5730, "OffsetEndMs": 5990}, {"Word": "that", "OffsetStartMs": 6040, "OffsetEndMs": 6315}, {"Word": "can", "OffsetStartMs": 6315, "OffsetEndMs": 6465}, {"Word": "do", "OffsetStartMs": 6465, "OffsetEndMs": 6630}, {"Word": "these", "OffsetStartMs": 6630, "OffsetEndMs": 6855}, {"Word": "tasks", "OffsetStartMs": 6855, "OffsetEndMs": 7170}, {"Word": "and", "OffsetStartMs": 7170, "OffsetEndMs": 7425}, {"Word": "the", "OffsetStartMs": 7425, "OffsetEndMs": 7635}, {"Word": "algorithm", "OffsetStartMs": 7635, "OffsetEndMs": 7935}, {"Word": "is", "OffsetStartMs": 7935, "OffsetEndMs": 8070}, {"Word": "that", "OffsetStartMs": 8070, "OffsetEndMs": 8235}, {"Word": "agent", "OffsetStartMs": 8235, "OffsetEndMs": 8510}, {"Word": "So", "OffsetStartMs": 8920, "OffsetEndMs": 9180}, {"Word": "in", "OffsetStartMs": 9180, "OffsetEndMs": 9330}, {"Word": "life", "OffsetStartMs": 9330, "OffsetEndMs": 9620}, {"Word": "for", "OffsetStartMs": 9670, "OffsetEndMs": 9975}, {"Word": "example", "OffsetStartMs": 9975, "OffsetEndMs": 10275}, {"Word": "all", "OffsetStartMs": 10275, "OffsetEndMs": 10560}, {"Word": "of", "OffsetStartMs": 10560, "OffsetEndMs": 10710}, {"Word": "you", "OffsetStartMs": 10710, "OffsetEndMs": 10965}, {"Word": "are", "OffsetStartMs": 10965, "OffsetEndMs": 11325}, {"Word": "agents", "OffsetStartMs": 11325, "OffsetEndMs": 11690}, {"Word": "in", "OffsetStartMs": 11980, "OffsetEndMs": 12270}, {"Word": "life", "OffsetStartMs": 12270, "OffsetEndMs": 12560}], "SpeechSpeed": 16.5}, {"FinalSentence": "The environment is the other kind of contrary approach or the contrary perspective to the agent. The environment is simply the world where that agent lives and where it operates, right where it exists and it moves around in.", "SliceSentence": "The environment is the other kind of contrary approach or the contrary perspective to the agent The environment is simply the world where that agent lives and where it operates right where it exists and it moves around in", "StartMs": 465320, "EndMs": 479760, "WordsNum": 39, "Words": [{"Word": "The", "OffsetStartMs": 100, "OffsetEndMs": 420}, {"Word": "environment", "OffsetStartMs": 420, "OffsetEndMs": 740}, {"Word": "is", "OffsetStartMs": 820, "OffsetEndMs": 1110}, {"Word": "the", "OffsetStartMs": 1110, "OffsetEndMs": 1230}, {"Word": "other", "OffsetStartMs": 1230, "OffsetEndMs": 1460}, {"Word": "kind", "OffsetStartMs": 1540, "OffsetEndMs": 1800}, {"Word": "of", "OffsetStartMs": 1800, "OffsetEndMs": 2060}, {"Word": "contrary", "OffsetStartMs": 2200, "OffsetEndMs": 2805}, {"Word": "approach", "OffsetStartMs": 2805, "OffsetEndMs": 3200}, {"Word": "or", "OffsetStartMs": 3280, "OffsetEndMs": 3555}, {"Word": "the", "OffsetStartMs": 3555, "OffsetEndMs": 3705}, {"Word": "contrary", "OffsetStartMs": 3705, "OffsetEndMs": 4220}, {"Word": "perspective", "OffsetStartMs": 4600, "OffsetEndMs": 5000}, {"Word": "to", "OffsetStartMs": 5170, "OffsetEndMs": 5415}, {"Word": "the", "OffsetStartMs": 5415, "OffsetEndMs": 5520}, {"Word": "agent", "OffsetStartMs": 5520, "OffsetEndMs": 5780}, {"Word": "The", "OffsetStartMs": 6130, "OffsetEndMs": 6435}, {"Word": "environment", "OffsetStartMs": 6435, "OffsetEndMs": 6740}, {"Word": "is", "OffsetStartMs": 6880, "OffsetEndMs": 7245}, {"Word": "simply", "OffsetStartMs": 7245, "OffsetEndMs": 7590}, {"Word": "the", "OffsetStartMs": 7590, "OffsetEndMs": 7845}, {"Word": "world", "OffsetStartMs": 7845, "OffsetEndMs": 8120}, {"Word": "where", "OffsetStartMs": 8230, "OffsetEndMs": 8550}, {"Word": "that", "OffsetStartMs": 8550, "OffsetEndMs": 8760}, {"Word": "agent", "OffsetStartMs": 8760, "OffsetEndMs": 9050}, {"Word": "lives", "OffsetStartMs": 9130, "OffsetEndMs": 9480}, {"Word": "and", "OffsetStartMs": 9480, "OffsetEndMs": 9780}, {"Word": "where", "OffsetStartMs": 9780, "OffsetEndMs": 9990}, {"Word": "it", "OffsetStartMs": 9990, "OffsetEndMs": 10110}, {"Word": "operates", "OffsetStartMs": 10110, "OffsetEndMs": 10580}, {"Word": "right", "OffsetStartMs": 10750, "OffsetEndMs": 11150}, {"Word": "where", "OffsetStartMs": 11290, "OffsetEndMs": 11565}, {"Word": "it", "OffsetStartMs": 11565, "OffsetEndMs": 11835}, {"Word": "exists", "OffsetStartMs": 11835, "OffsetEndMs": 12225}, {"Word": "and", "OffsetStartMs": 12225, "OffsetEndMs": 12480}, {"Word": "it", "OffsetStartMs": 12480, "OffsetEndMs": 12645}, {"Word": "moves", "OffsetStartMs": 12645, "OffsetEndMs": 12930}, {"Word": "around", "OffsetStartMs": 12930, "OffsetEndMs": 13245}, {"Word": "in", "OffsetStartMs": 13245, "OffsetEndMs": 13580}], "SpeechSpeed": 15.3}, {"FinalSentence": "The agent can send commands to that environment in the form of what are called actions. You can take actions in that environment and let's call for notation purposes. Let's say the possible set of all actions that it could take is let's say a set of capital a right now. It should be noted that agents at any point in time could choose amongst this, let's say list of possible actions. But of course in some situations your action space does not necessarily need to be a finite space. Maybe you could take actions in a continuous space. For example, when you're driving a car, you're taking actions on a continuous angle space of what angle you want to steer that car. It's not necessarily just going right or left or straight, you may steer at any continuous degree.", "SliceSentence": "The agent can send commands to that environment in the form of what are called actions You can take actions in that environment and let's call for notation purposes Let's say the possible set of all actions that it could take is let's say a set of capital a right now It should be noted that agents at any point in time could choose amongst this let's say list of possible actions But of course in some situations your action space does not necessarily need to be a finite space Maybe you could take actions in a continuous space For example when you're driving a car you're taking actions on a continuous angle space of what angle you want to steer that car It's not necessarily just going right or left or straight you may steer at any continuous degree", "StartMs": 479880, "EndMs": 525480, "WordsNum": 140, "Words": [{"Word": "The", "OffsetStartMs": 70, "OffsetEndMs": 315}, {"Word": "agent", "OffsetStartMs": 315, "OffsetEndMs": 555}, {"Word": "can", "OffsetStartMs": 555, "OffsetEndMs": 930}, {"Word": "send", "OffsetStartMs": 930, "OffsetEndMs": 1260}, {"Word": "commands", "OffsetStartMs": 1260, "OffsetEndMs": 1850}, {"Word": "to", "OffsetStartMs": 1900, "OffsetEndMs": 2160}, {"Word": "that", "OffsetStartMs": 2160, "OffsetEndMs": 2370}, {"Word": "environment", "OffsetStartMs": 2370, "OffsetEndMs": 2715}, {"Word": "in", "OffsetStartMs": 2715, "OffsetEndMs": 2970}, {"Word": "the", "OffsetStartMs": 2970, "OffsetEndMs": 3105}, {"Word": "form", "OffsetStartMs": 3105, "OffsetEndMs": 3270}, {"Word": "of", "OffsetStartMs": 3270, "OffsetEndMs": 3405}, {"Word": "what", "OffsetStartMs": 3405, "OffsetEndMs": 3510}, {"Word": "are", "OffsetStartMs": 3510, "OffsetEndMs": 3645}, {"Word": "called", "OffsetStartMs": 3645, "OffsetEndMs": 3825}, {"Word": "actions", "OffsetStartMs": 3825, "OffsetEndMs": 4130}, {"Word": "You", "OffsetStartMs": 4750, "OffsetEndMs": 4995}, {"Word": "can", "OffsetStartMs": 4995, "OffsetEndMs": 5145}, {"Word": "take", "OffsetStartMs": 5145, "OffsetEndMs": 5355}, {"Word": "actions", "OffsetStartMs": 5355, "OffsetEndMs": 5660}, {"Word": "in", "OffsetStartMs": 5710, "OffsetEndMs": 5985}, {"Word": "that", "OffsetStartMs": 5985, "OffsetEndMs": 6195}, {"Word": "environment", "OffsetStartMs": 6195, "OffsetEndMs": 6530}, {"Word": "and", "OffsetStartMs": 7000, "OffsetEndMs": 7400}, {"Word": "let's", "OffsetStartMs": 7420, "OffsetEndMs": 7905}, {"Word": "call", "OffsetStartMs": 7905, "OffsetEndMs": 8205}, {"Word": "for", "OffsetStartMs": 8205, "OffsetEndMs": 8540}, {"Word": "notation", "OffsetStartMs": 8920, "OffsetEndMs": 9495}, {"Word": "purposes", "OffsetStartMs": 9495, "OffsetEndMs": 9860}, {"Word": "Let's", "OffsetStartMs": 9940, "OffsetEndMs": 10305}, {"Word": "say", "OffsetStartMs": 10305, "OffsetEndMs": 10515}, {"Word": "the", "OffsetStartMs": 10515, "OffsetEndMs": 10880}, {"Word": "possible", "OffsetStartMs": 11410, "OffsetEndMs": 11810}, {"Word": "set", "OffsetStartMs": 12010, "OffsetEndMs": 12345}, {"Word": "of", "OffsetStartMs": 12345, "OffsetEndMs": 12570}, {"Word": "all", "OffsetStartMs": 12570, "OffsetEndMs": 12810}, {"Word": "actions", "OffsetStartMs": 12810, "OffsetEndMs": 13160}, {"Word": "that", "OffsetStartMs": 13240, "OffsetEndMs": 13500}, {"Word": "it", "OffsetStartMs": 13500, "OffsetEndMs": 13635}, {"Word": "could", "OffsetStartMs": 13635, "OffsetEndMs": 13800}, {"Word": "take", "OffsetStartMs": 13800, "OffsetEndMs": 14090}, {"Word": "is", "OffsetStartMs": 14350, "OffsetEndMs": 14730}, {"Word": "let's", "OffsetStartMs": 14730, "OffsetEndMs": 15030}, {"Word": "say", "OffsetStartMs": 15030, "OffsetEndMs": 15120}, {"Word": "a", "OffsetStartMs": 15120, "OffsetEndMs": 15285}, {"Word": "set", "OffsetStartMs": 15285, "OffsetEndMs": 15480}, {"Word": "of", "OffsetStartMs": 15480, "OffsetEndMs": 15705}, {"Word": "capital", "OffsetStartMs": 15705, "OffsetEndMs": 16020}, {"Word": "a", "OffsetStartMs": 16020, "OffsetEndMs": 16400}, {"Word": "right", "OffsetStartMs": 16570, "OffsetEndMs": 16970}, {"Word": "now", "OffsetStartMs": 17800, "OffsetEndMs": 18075}, {"Word": "It", "OffsetStartMs": 18075, "OffsetEndMs": 18225}, {"Word": "should", "OffsetStartMs": 18225, "OffsetEndMs": 18345}, {"Word": "be", "OffsetStartMs": 18345, "OffsetEndMs": 18465}, {"Word": "noted", "OffsetStartMs": 18465, "OffsetEndMs": 18705}, {"Word": "that", "OffsetStartMs": 18705, "OffsetEndMs": 19070}, {"Word": "agents", "OffsetStartMs": 19180, "OffsetEndMs": 19580}, {"Word": "at", "OffsetStartMs": 20230, "OffsetEndMs": 20505}, {"Word": "any", "OffsetStartMs": 20505, "OffsetEndMs": 20715}, {"Word": "point", "OffsetStartMs": 20715, "OffsetEndMs": 20940}, {"Word": "in", "OffsetStartMs": 20940, "OffsetEndMs": 21105}, {"Word": "time", "OffsetStartMs": 21105, "OffsetEndMs": 21380}, {"Word": "could", "OffsetStartMs": 21550, "OffsetEndMs": 21900}, {"Word": "choose", "OffsetStartMs": 21900, "OffsetEndMs": 22250}, {"Word": "amongst", "OffsetStartMs": 22360, "OffsetEndMs": 22760}, {"Word": "this", "OffsetStartMs": 23050, "OffsetEndMs": 23450}, {"Word": "let's", "OffsetStartMs": 23470, "OffsetEndMs": 23820}, {"Word": "say", "OffsetStartMs": 23820, "OffsetEndMs": 23955}, {"Word": "list", "OffsetStartMs": 23955, "OffsetEndMs": 24225}, {"Word": "of", "OffsetStartMs": 24225, "OffsetEndMs": 24480}, {"Word": "possible", "OffsetStartMs": 24480, "OffsetEndMs": 24770}, {"Word": "actions", "OffsetStartMs": 24820, "OffsetEndMs": 25220}, {"Word": "But", "OffsetStartMs": 25450, "OffsetEndMs": 25695}, {"Word": "of", "OffsetStartMs": 25695, "OffsetEndMs": 25815}, {"Word": "course", "OffsetStartMs": 25815, "OffsetEndMs": 25980}, {"Word": "in", "OffsetStartMs": 25980, "OffsetEndMs": 26160}, {"Word": "some", "OffsetStartMs": 26160, "OffsetEndMs": 26340}, {"Word": "situations", "OffsetStartMs": 26340, "OffsetEndMs": 26630}, {"Word": "your", "OffsetStartMs": 27160, "OffsetEndMs": 27435}, {"Word": "action", "OffsetStartMs": 27435, "OffsetEndMs": 27710}, {"Word": "space", "OffsetStartMs": 27850, "OffsetEndMs": 28215}, {"Word": "does", "OffsetStartMs": 28215, "OffsetEndMs": 28470}, {"Word": "not", "OffsetStartMs": 28470, "OffsetEndMs": 28760}, {"Word": "necessarily", "OffsetStartMs": 28780, "OffsetEndMs": 29145}, {"Word": "need", "OffsetStartMs": 29145, "OffsetEndMs": 29385}, {"Word": "to", "OffsetStartMs": 29385, "OffsetEndMs": 29505}, {"Word": "be", "OffsetStartMs": 29505, "OffsetEndMs": 29625}, {"Word": "a", "OffsetStartMs": 29625, "OffsetEndMs": 29805}, {"Word": "finite", "OffsetStartMs": 29805, "OffsetEndMs": 30290}, {"Word": "space", "OffsetStartMs": 30460, "OffsetEndMs": 30860}, {"Word": "Maybe", "OffsetStartMs": 30910, "OffsetEndMs": 31215}, {"Word": "you", "OffsetStartMs": 31215, "OffsetEndMs": 31395}, {"Word": "could", "OffsetStartMs": 31395, "OffsetEndMs": 31545}, {"Word": "take", "OffsetStartMs": 31545, "OffsetEndMs": 31710}, {"Word": "actions", "OffsetStartMs": 31710, "OffsetEndMs": 31995}, {"Word": "in", "OffsetStartMs": 31995, "OffsetEndMs": 32235}, {"Word": "a", "OffsetStartMs": 32235, "OffsetEndMs": 32430}, {"Word": "continuous", "OffsetStartMs": 32430, "OffsetEndMs": 32760}, {"Word": "space", "OffsetStartMs": 32760, "OffsetEndMs": 33105}, {"Word": "For", "OffsetStartMs": 33105, "OffsetEndMs": 33375}, {"Word": "example", "OffsetStartMs": 33375, "OffsetEndMs": 33630}, {"Word": "when", "OffsetStartMs": 33630, "OffsetEndMs": 33825}, {"Word": "you're", "OffsetStartMs": 33825, "OffsetEndMs": 33990}, {"Word": "driving", "OffsetStartMs": 33990, "OffsetEndMs": 34140}, {"Word": "a", "OffsetStartMs": 34140, "OffsetEndMs": 34335}, {"Word": "car", "OffsetStartMs": 34335, "OffsetEndMs": 34610}, {"Word": "you're", "OffsetStartMs": 34930, "OffsetEndMs": 35490}, {"Word": "taking", "OffsetStartMs": 35490, "OffsetEndMs": 35805}, {"Word": "actions", "OffsetStartMs": 35805, "OffsetEndMs": 36140}, {"Word": "on", "OffsetStartMs": 36190, "OffsetEndMs": 36450}, {"Word": "a", "OffsetStartMs": 36450, "OffsetEndMs": 36660}, {"Word": "continuous", "OffsetStartMs": 36660, "OffsetEndMs": 37010}, {"Word": "angle", "OffsetStartMs": 37450, "OffsetEndMs": 37850}, {"Word": "space", "OffsetStartMs": 37930, "OffsetEndMs": 38250}, {"Word": "of", "OffsetStartMs": 38250, "OffsetEndMs": 38460}, {"Word": "what", "OffsetStartMs": 38460, "OffsetEndMs": 38640}, {"Word": "angle", "OffsetStartMs": 38640, "OffsetEndMs": 38925}, {"Word": "you", "OffsetStartMs": 38925, "OffsetEndMs": 39180}, {"Word": "want", "OffsetStartMs": 39180, "OffsetEndMs": 39345}, {"Word": "to", "OffsetStartMs": 39345, "OffsetEndMs": 39555}, {"Word": "steer", "OffsetStartMs": 39555, "OffsetEndMs": 39795}, {"Word": "that", "OffsetStartMs": 39795, "OffsetEndMs": 39990}, {"Word": "car", "OffsetStartMs": 39990, "OffsetEndMs": 40215}, {"Word": "It's", "OffsetStartMs": 40215, "OffsetEndMs": 40440}, {"Word": "not", "OffsetStartMs": 40440, "OffsetEndMs": 40700}, {"Word": "necessarily", "OffsetStartMs": 40720, "OffsetEndMs": 41070}, {"Word": "just", "OffsetStartMs": 41070, "OffsetEndMs": 41295}, {"Word": "going", "OffsetStartMs": 41295, "OffsetEndMs": 41475}, {"Word": "right", "OffsetStartMs": 41475, "OffsetEndMs": 41685}, {"Word": "or", "OffsetStartMs": 41685, "OffsetEndMs": 41880}, {"Word": "left", "OffsetStartMs": 41880, "OffsetEndMs": 42090}, {"Word": "or", "OffsetStartMs": 42090, "OffsetEndMs": 42345}, {"Word": "straight", "OffsetStartMs": 42345, "OffsetEndMs": 42680}, {"Word": "you", "OffsetStartMs": 42940, "OffsetEndMs": 43200}, {"Word": "may", "OffsetStartMs": 43200, "OffsetEndMs": 43460}, {"Word": "steer", "OffsetStartMs": 43600, "OffsetEndMs": 43875}, {"Word": "at", "OffsetStartMs": 43875, "OffsetEndMs": 43980}, {"Word": "any", "OffsetStartMs": 43980, "OffsetEndMs": 44240}, {"Word": "continuous", "OffsetStartMs": 44290, "OffsetEndMs": 44690}, {"Word": "degree", "OffsetStartMs": 44770, "OffsetEndMs": 45170}], "SpeechSpeed": 16.6}, {"FinalSentence": "Observations is essentially how the environment responds back to the agent, right? The environment can tell the agent you know what it should be seeing based on those actions that it just took, and it responds in the form of what is called a state. A state is simply a concrete and immediate situation that the agent finds itself in at that particular moment.", "SliceSentence": "Observations is essentially how the environment responds back to the agent right The environment can tell the agent you know what it should be seeing based on those actions that it just took and it responds in the form of what is called a state A state is simply a concrete and immediate situation that the agent finds itself in at that particular moment", "StartMs": 526740, "EndMs": 549940, "WordsNum": 64, "Words": [{"Word": "Observations", "OffsetStartMs": 340, "OffsetEndMs": 825}, {"Word": "is", "OffsetStartMs": 825, "OffsetEndMs": 1200}, {"Word": "essentially", "OffsetStartMs": 1200, "OffsetEndMs": 1575}, {"Word": "how", "OffsetStartMs": 1575, "OffsetEndMs": 1920}, {"Word": "the", "OffsetStartMs": 1920, "OffsetEndMs": 2175}, {"Word": "environment", "OffsetStartMs": 2175, "OffsetEndMs": 2480}, {"Word": "responds", "OffsetStartMs": 2680, "OffsetEndMs": 3120}, {"Word": "back", "OffsetStartMs": 3120, "OffsetEndMs": 3410}, {"Word": "to", "OffsetStartMs": 3580, "OffsetEndMs": 3825}, {"Word": "the", "OffsetStartMs": 3825, "OffsetEndMs": 3945}, {"Word": "agent", "OffsetStartMs": 3945, "OffsetEndMs": 4220}, {"Word": "right", "OffsetStartMs": 4660, "OffsetEndMs": 4995}, {"Word": "The", "OffsetStartMs": 4995, "OffsetEndMs": 5250}, {"Word": "environment", "OffsetStartMs": 5250, "OffsetEndMs": 5570}, {"Word": "can", "OffsetStartMs": 5830, "OffsetEndMs": 6230}, {"Word": "tell", "OffsetStartMs": 6430, "OffsetEndMs": 6735}, {"Word": "the", "OffsetStartMs": 6735, "OffsetEndMs": 6885}, {"Word": "agent", "OffsetStartMs": 6885, "OffsetEndMs": 7130}, {"Word": "you", "OffsetStartMs": 7450, "OffsetEndMs": 7695}, {"Word": "know", "OffsetStartMs": 7695, "OffsetEndMs": 7815}, {"Word": "what", "OffsetStartMs": 7815, "OffsetEndMs": 7950}, {"Word": "it", "OffsetStartMs": 7950, "OffsetEndMs": 8205}, {"Word": "should", "OffsetStartMs": 8205, "OffsetEndMs": 8550}, {"Word": "be", "OffsetStartMs": 8550, "OffsetEndMs": 8835}, {"Word": "seeing", "OffsetStartMs": 8835, "OffsetEndMs": 9135}, {"Word": "based", "OffsetStartMs": 9135, "OffsetEndMs": 9435}, {"Word": "on", "OffsetStartMs": 9435, "OffsetEndMs": 9645}, {"Word": "those", "OffsetStartMs": 9645, "OffsetEndMs": 9810}, {"Word": "actions", "OffsetStartMs": 9810, "OffsetEndMs": 10100}, {"Word": "that", "OffsetStartMs": 10210, "OffsetEndMs": 10470}, {"Word": "it", "OffsetStartMs": 10470, "OffsetEndMs": 10605}, {"Word": "just", "OffsetStartMs": 10605, "OffsetEndMs": 10815}, {"Word": "took", "OffsetStartMs": 10815, "OffsetEndMs": 11150}, {"Word": "and", "OffsetStartMs": 11560, "OffsetEndMs": 11895}, {"Word": "it", "OffsetStartMs": 11895, "OffsetEndMs": 12225}, {"Word": "responds", "OffsetStartMs": 12225, "OffsetEndMs": 12795}, {"Word": "in", "OffsetStartMs": 12795, "OffsetEndMs": 12975}, {"Word": "the", "OffsetStartMs": 12975, "OffsetEndMs": 13140}, {"Word": "form", "OffsetStartMs": 13140, "OffsetEndMs": 13430}, {"Word": "of", "OffsetStartMs": 13930, "OffsetEndMs": 14330}, {"Word": "what", "OffsetStartMs": 14380, "OffsetEndMs": 14640}, {"Word": "is", "OffsetStartMs": 14640, "OffsetEndMs": 14790}, {"Word": "called", "OffsetStartMs": 14790, "OffsetEndMs": 14985}, {"Word": "a", "OffsetStartMs": 14985, "OffsetEndMs": 15210}, {"Word": "state", "OffsetStartMs": 15210, "OffsetEndMs": 15525}, {"Word": "A", "OffsetStartMs": 15525, "OffsetEndMs": 15825}, {"Word": "state", "OffsetStartMs": 15825, "OffsetEndMs": 16020}, {"Word": "is", "OffsetStartMs": 16020, "OffsetEndMs": 16185}, {"Word": "simply", "OffsetStartMs": 16185, "OffsetEndMs": 16395}, {"Word": "a", "OffsetStartMs": 16395, "OffsetEndMs": 16730}, {"Word": "concrete", "OffsetStartMs": 16870, "OffsetEndMs": 17205}, {"Word": "and", "OffsetStartMs": 17205, "OffsetEndMs": 17540}, {"Word": "immediate", "OffsetStartMs": 17560, "OffsetEndMs": 17960}, {"Word": "situation", "OffsetStartMs": 18310, "OffsetEndMs": 18710}, {"Word": "that", "OffsetStartMs": 19120, "OffsetEndMs": 19410}, {"Word": "the", "OffsetStartMs": 19410, "OffsetEndMs": 19560}, {"Word": "agent", "OffsetStartMs": 19560, "OffsetEndMs": 19820}, {"Word": "finds", "OffsetStartMs": 19870, "OffsetEndMs": 20270}, {"Word": "itself", "OffsetStartMs": 20290, "OffsetEndMs": 20625}, {"Word": "in", "OffsetStartMs": 20625, "OffsetEndMs": 20895}, {"Word": "at", "OffsetStartMs": 20895, "OffsetEndMs": 21105}, {"Word": "that", "OffsetStartMs": 21105, "OffsetEndMs": 21380}, {"Word": "particular", "OffsetStartMs": 21430, "OffsetEndMs": 21810}, {"Word": "moment", "OffsetStartMs": 21810, "OffsetEndMs": 22190}], "SpeechSpeed": 15.3}, {"FinalSentence": "Now it's important to remember that unlike other types of learning that we've covered in this course, reinforcement learning is a bit unique because it has one more component here in addition to these other components, which is called the reward. Now the reward is a feedback by which we measure, or we can try to measure the success of a particular agent in its environment. So, for example, in a video game, when Mario grabs a coin, for example, he wins points, right? So from a given state, an agent can send out any form of actions to take some decisions, and those actions may or may not result in rewards being collected and accumulated over time.", "SliceSentence": "Now it's important to remember that unlike other types of learning that we've covered in this course reinforcement learning is a bit unique because it has one more component here in addition to these other components which is called the reward Now the reward is a feedback by which we measure or we can try to measure the success of a particular agent in its environment So for example in a video game when Mario grabs a coin for example he wins points right So from a given state an agent can send out any form of actions to take some decisions and those actions may or may not result in rewards being collected and accumulated over time", "StartMs": 550440, "EndMs": 593560, "WordsNum": 118, "Words": [{"Word": "Now", "OffsetStartMs": 130, "OffsetEndMs": 530}, {"Word": "it's", "OffsetStartMs": 760, "OffsetEndMs": 1155}, {"Word": "important", "OffsetStartMs": 1155, "OffsetEndMs": 1365}, {"Word": "to", "OffsetStartMs": 1365, "OffsetEndMs": 1545}, {"Word": "remember", "OffsetStartMs": 1545, "OffsetEndMs": 1800}, {"Word": "that", "OffsetStartMs": 1800, "OffsetEndMs": 2180}, {"Word": "unlike", "OffsetStartMs": 2620, "OffsetEndMs": 2940}, {"Word": "other", "OffsetStartMs": 2940, "OffsetEndMs": 3260}, {"Word": "types", "OffsetStartMs": 3400, "OffsetEndMs": 3720}, {"Word": "of", "OffsetStartMs": 3720, "OffsetEndMs": 3945}, {"Word": "learning", "OffsetStartMs": 3945, "OffsetEndMs": 4250}, {"Word": "that", "OffsetStartMs": 4360, "OffsetEndMs": 4635}, {"Word": "we've", "OffsetStartMs": 4635, "OffsetEndMs": 4890}, {"Word": "covered", "OffsetStartMs": 4890, "OffsetEndMs": 5150}, {"Word": "in", "OffsetStartMs": 5230, "OffsetEndMs": 5625}, {"Word": "this", "OffsetStartMs": 5625, "OffsetEndMs": 5985}, {"Word": "course", "OffsetStartMs": 5985, "OffsetEndMs": 6350}, {"Word": "reinforcement", "OffsetStartMs": 6700, "OffsetEndMs": 7395}, {"Word": "learning", "OffsetStartMs": 7395, "OffsetEndMs": 7560}, {"Word": "is", "OffsetStartMs": 7560, "OffsetEndMs": 7710}, {"Word": "a", "OffsetStartMs": 7710, "OffsetEndMs": 7830}, {"Word": "bit", "OffsetStartMs": 7830, "OffsetEndMs": 7965}, {"Word": "unique", "OffsetStartMs": 7965, "OffsetEndMs": 8240}, {"Word": "because", "OffsetStartMs": 8500, "OffsetEndMs": 8760}, {"Word": "it", "OffsetStartMs": 8760, "OffsetEndMs": 8895}, {"Word": "has", "OffsetStartMs": 8895, "OffsetEndMs": 9150}, {"Word": "one", "OffsetStartMs": 9150, "OffsetEndMs": 9435}, {"Word": "more", "OffsetStartMs": 9435, "OffsetEndMs": 9735}, {"Word": "component", "OffsetStartMs": 9735, "OffsetEndMs": 10125}, {"Word": "here", "OffsetStartMs": 10125, "OffsetEndMs": 10520}, {"Word": "in", "OffsetStartMs": 10720, "OffsetEndMs": 11040}, {"Word": "addition", "OffsetStartMs": 11040, "OffsetEndMs": 11360}, {"Word": "to", "OffsetStartMs": 11410, "OffsetEndMs": 11670}, {"Word": "these", "OffsetStartMs": 11670, "OffsetEndMs": 11820}, {"Word": "other", "OffsetStartMs": 11820, "OffsetEndMs": 12110}, {"Word": "components", "OffsetStartMs": 12130, "OffsetEndMs": 12530}, {"Word": "which", "OffsetStartMs": 13450, "OffsetEndMs": 13725}, {"Word": "is", "OffsetStartMs": 13725, "OffsetEndMs": 13905}, {"Word": "called", "OffsetStartMs": 13905, "OffsetEndMs": 14145}, {"Word": "the", "OffsetStartMs": 14145, "OffsetEndMs": 14400}, {"Word": "reward", "OffsetStartMs": 14400, "OffsetEndMs": 14720}, {"Word": "Now", "OffsetStartMs": 14830, "OffsetEndMs": 15120}, {"Word": "the", "OffsetStartMs": 15120, "OffsetEndMs": 15330}, {"Word": "reward", "OffsetStartMs": 15330, "OffsetEndMs": 15650}, {"Word": "is", "OffsetStartMs": 16000, "OffsetEndMs": 16380}, {"Word": "a", "OffsetStartMs": 16380, "OffsetEndMs": 16725}, {"Word": "feedback", "OffsetStartMs": 16725, "OffsetEndMs": 17090}, {"Word": "by", "OffsetStartMs": 17560, "OffsetEndMs": 17850}, {"Word": "which", "OffsetStartMs": 17850, "OffsetEndMs": 18090}, {"Word": "we", "OffsetStartMs": 18090, "OffsetEndMs": 18345}, {"Word": "measure", "OffsetStartMs": 18345, "OffsetEndMs": 18650}, {"Word": "or", "OffsetStartMs": 18820, "OffsetEndMs": 19095}, {"Word": "we", "OffsetStartMs": 19095, "OffsetEndMs": 19260}, {"Word": "can", "OffsetStartMs": 19260, "OffsetEndMs": 19470}, {"Word": "try", "OffsetStartMs": 19470, "OffsetEndMs": 19710}, {"Word": "to", "OffsetStartMs": 19710, "OffsetEndMs": 19890}, {"Word": "measure", "OffsetStartMs": 19890, "OffsetEndMs": 20150}, {"Word": "the", "OffsetStartMs": 20500, "OffsetEndMs": 20790}, {"Word": "success", "OffsetStartMs": 20790, "OffsetEndMs": 21080}, {"Word": "of", "OffsetStartMs": 21700, "OffsetEndMs": 21975}, {"Word": "a", "OffsetStartMs": 21975, "OffsetEndMs": 22200}, {"Word": "particular", "OffsetStartMs": 22200, "OffsetEndMs": 22545}, {"Word": "agent", "OffsetStartMs": 22545, "OffsetEndMs": 22940}, {"Word": "in", "OffsetStartMs": 23110, "OffsetEndMs": 23370}, {"Word": "its", "OffsetStartMs": 23370, "OffsetEndMs": 23595}, {"Word": "environment", "OffsetStartMs": 23595, "OffsetEndMs": 23960}, {"Word": "So", "OffsetStartMs": 24190, "OffsetEndMs": 24465}, {"Word": "for", "OffsetStartMs": 24465, "OffsetEndMs": 24660}, {"Word": "example", "OffsetStartMs": 24660, "OffsetEndMs": 24930}, {"Word": "in", "OffsetStartMs": 24930, "OffsetEndMs": 25140}, {"Word": "a", "OffsetStartMs": 25140, "OffsetEndMs": 25245}, {"Word": "video", "OffsetStartMs": 25245, "OffsetEndMs": 25440}, {"Word": "game", "OffsetStartMs": 25440, "OffsetEndMs": 25790}, {"Word": "when", "OffsetStartMs": 26140, "OffsetEndMs": 26535}, {"Word": "Mario", "OffsetStartMs": 26535, "OffsetEndMs": 27075}, {"Word": "grabs", "OffsetStartMs": 27075, "OffsetEndMs": 27345}, {"Word": "a", "OffsetStartMs": 27345, "OffsetEndMs": 27480}, {"Word": "coin", "OffsetStartMs": 27480, "OffsetEndMs": 27930}, {"Word": "for", "OffsetStartMs": 27930, "OffsetEndMs": 28215}, {"Word": "example", "OffsetStartMs": 28215, "OffsetEndMs": 28520}, {"Word": "he", "OffsetStartMs": 28990, "OffsetEndMs": 29355}, {"Word": "wins", "OffsetStartMs": 29355, "OffsetEndMs": 29670}, {"Word": "points", "OffsetStartMs": 29670, "OffsetEndMs": 29940}, {"Word": "right", "OffsetStartMs": 29940, "OffsetEndMs": 30150}, {"Word": "So", "OffsetStartMs": 30150, "OffsetEndMs": 30315}, {"Word": "from", "OffsetStartMs": 30315, "OffsetEndMs": 30450}, {"Word": "a", "OffsetStartMs": 30450, "OffsetEndMs": 30570}, {"Word": "given", "OffsetStartMs": 30570, "OffsetEndMs": 30825}, {"Word": "state", "OffsetStartMs": 30825, "OffsetEndMs": 31220}, {"Word": "an", "OffsetStartMs": 31390, "OffsetEndMs": 31665}, {"Word": "agent", "OffsetStartMs": 31665, "OffsetEndMs": 31940}, {"Word": "can", "OffsetStartMs": 32020, "OffsetEndMs": 32355}, {"Word": "send", "OffsetStartMs": 32355, "OffsetEndMs": 32565}, {"Word": "out", "OffsetStartMs": 32565, "OffsetEndMs": 32840}, {"Word": "any", "OffsetStartMs": 33160, "OffsetEndMs": 33510}, {"Word": "form", "OffsetStartMs": 33510, "OffsetEndMs": 33780}, {"Word": "of", "OffsetStartMs": 33780, "OffsetEndMs": 33975}, {"Word": "actions", "OffsetStartMs": 33975, "OffsetEndMs": 34250}, {"Word": "to", "OffsetStartMs": 34600, "OffsetEndMs": 35000}, {"Word": "take", "OffsetStartMs": 35350, "OffsetEndMs": 35655}, {"Word": "some", "OffsetStartMs": 35655, "OffsetEndMs": 35960}, {"Word": "decisions", "OffsetStartMs": 36250, "OffsetEndMs": 36630}, {"Word": "and", "OffsetStartMs": 36630, "OffsetEndMs": 36960}, {"Word": "those", "OffsetStartMs": 36960, "OffsetEndMs": 37230}, {"Word": "actions", "OffsetStartMs": 37230, "OffsetEndMs": 37550}, {"Word": "may", "OffsetStartMs": 37750, "OffsetEndMs": 38085}, {"Word": "or", "OffsetStartMs": 38085, "OffsetEndMs": 38310}, {"Word": "may", "OffsetStartMs": 38310, "OffsetEndMs": 38505}, {"Word": "not", "OffsetStartMs": 38505, "OffsetEndMs": 38810}, {"Word": "result", "OffsetStartMs": 39100, "OffsetEndMs": 39500}, {"Word": "in", "OffsetStartMs": 39730, "OffsetEndMs": 40020}, {"Word": "rewards", "OffsetStartMs": 40020, "OffsetEndMs": 40410}, {"Word": "being", "OffsetStartMs": 40410, "OffsetEndMs": 40770}, {"Word": "collected", "OffsetStartMs": 40770, "OffsetEndMs": 41150}, {"Word": "and", "OffsetStartMs": 41230, "OffsetEndMs": 41475}, {"Word": "accumulated", "OffsetStartMs": 41475, "OffsetEndMs": 42045}, {"Word": "over", "OffsetStartMs": 42045, "OffsetEndMs": 42300}, {"Word": "time", "OffsetStartMs": 42300, "OffsetEndMs": 42650}], "SpeechSpeed": 14.8}, {"FinalSentence": "Now, it's also very important to remember that not all actions result in immediate rewards. You may take some actions that will result in a reward in a delayed fashion, maybe in a few time steps down the future, maybe in life, maybe years, you may take an action today that results in a reward many some time from now. And, but essentially all of these try to effectively evaluate some way of measuring the success of a particular action that an agent takes.", "SliceSentence": "Now it's also very important to remember that not all actions result in immediate rewards You may take some actions that will result in a reward in a delayed fashion maybe in a few time steps down the future maybe in life maybe years you may take an action today that results in a reward many some time from now And but essentially all of these try to effectively evaluate some way of measuring the success of a particular action that an agent takes", "StartMs": 593560, "EndMs": 623160, "WordsNum": 84, "Words": [{"Word": "Now", "OffsetStartMs": 70, "OffsetEndMs": 470}, {"Word": "it's", "OffsetStartMs": 550, "OffsetEndMs": 975}, {"Word": "also", "OffsetStartMs": 975, "OffsetEndMs": 1170}, {"Word": "very", "OffsetStartMs": 1170, "OffsetEndMs": 1350}, {"Word": "important", "OffsetStartMs": 1350, "OffsetEndMs": 1575}, {"Word": "to", "OffsetStartMs": 1575, "OffsetEndMs": 1755}, {"Word": "remember", "OffsetStartMs": 1755, "OffsetEndMs": 1980}, {"Word": "that", "OffsetStartMs": 1980, "OffsetEndMs": 2235}, {"Word": "not", "OffsetStartMs": 2235, "OffsetEndMs": 2445}, {"Word": "all", "OffsetStartMs": 2445, "OffsetEndMs": 2655}, {"Word": "actions", "OffsetStartMs": 2655, "OffsetEndMs": 2960}, {"Word": "result", "OffsetStartMs": 3460, "OffsetEndMs": 3795}, {"Word": "in", "OffsetStartMs": 3795, "OffsetEndMs": 4110}, {"Word": "immediate", "OffsetStartMs": 4110, "OffsetEndMs": 4470}, {"Word": "rewards", "OffsetStartMs": 4470, "OffsetEndMs": 4935}, {"Word": "You", "OffsetStartMs": 4935, "OffsetEndMs": 5145}, {"Word": "may", "OffsetStartMs": 5145, "OffsetEndMs": 5295}, {"Word": "take", "OffsetStartMs": 5295, "OffsetEndMs": 5520}, {"Word": "some", "OffsetStartMs": 5520, "OffsetEndMs": 5715}, {"Word": "actions", "OffsetStartMs": 5715, "OffsetEndMs": 5990}, {"Word": "that", "OffsetStartMs": 6100, "OffsetEndMs": 6480}, {"Word": "will", "OffsetStartMs": 6480, "OffsetEndMs": 6825}, {"Word": "result", "OffsetStartMs": 6825, "OffsetEndMs": 7095}, {"Word": "in", "OffsetStartMs": 7095, "OffsetEndMs": 7245}, {"Word": "a", "OffsetStartMs": 7245, "OffsetEndMs": 7425}, {"Word": "reward", "OffsetStartMs": 7425, "OffsetEndMs": 7760}, {"Word": "in", "OffsetStartMs": 8290, "OffsetEndMs": 8535}, {"Word": "a", "OffsetStartMs": 8535, "OffsetEndMs": 8715}, {"Word": "delayed", "OffsetStartMs": 8715, "OffsetEndMs": 9000}, {"Word": "fashion", "OffsetStartMs": 9000, "OffsetEndMs": 9350}, {"Word": "maybe", "OffsetStartMs": 9430, "OffsetEndMs": 9735}, {"Word": "in", "OffsetStartMs": 9735, "OffsetEndMs": 9870}, {"Word": "a", "OffsetStartMs": 9870, "OffsetEndMs": 9990}, {"Word": "few", "OffsetStartMs": 9990, "OffsetEndMs": 10170}, {"Word": "time", "OffsetStartMs": 10170, "OffsetEndMs": 10410}, {"Word": "steps", "OffsetStartMs": 10410, "OffsetEndMs": 10695}, {"Word": "down", "OffsetStartMs": 10695, "OffsetEndMs": 10890}, {"Word": "the", "OffsetStartMs": 10890, "OffsetEndMs": 11010}, {"Word": "future", "OffsetStartMs": 11010, "OffsetEndMs": 11265}, {"Word": "maybe", "OffsetStartMs": 11265, "OffsetEndMs": 11610}, {"Word": "in", "OffsetStartMs": 11610, "OffsetEndMs": 11850}, {"Word": "life", "OffsetStartMs": 11850, "OffsetEndMs": 12090}, {"Word": "maybe", "OffsetStartMs": 12090, "OffsetEndMs": 12405}, {"Word": "years", "OffsetStartMs": 12405, "OffsetEndMs": 12770}, {"Word": "you", "OffsetStartMs": 13180, "OffsetEndMs": 13425}, {"Word": "may", "OffsetStartMs": 13425, "OffsetEndMs": 13560}, {"Word": "take", "OffsetStartMs": 13560, "OffsetEndMs": 13710}, {"Word": "an", "OffsetStartMs": 13710, "OffsetEndMs": 13815}, {"Word": "action", "OffsetStartMs": 13815, "OffsetEndMs": 14025}, {"Word": "today", "OffsetStartMs": 14025, "OffsetEndMs": 14355}, {"Word": "that", "OffsetStartMs": 14355, "OffsetEndMs": 14685}, {"Word": "results", "OffsetStartMs": 14685, "OffsetEndMs": 14970}, {"Word": "in", "OffsetStartMs": 14970, "OffsetEndMs": 15195}, {"Word": "a", "OffsetStartMs": 15195, "OffsetEndMs": 15435}, {"Word": "reward", "OffsetStartMs": 15435, "OffsetEndMs": 15770}, {"Word": "many", "OffsetStartMs": 15910, "OffsetEndMs": 16310}, {"Word": "some", "OffsetStartMs": 17380, "OffsetEndMs": 17700}, {"Word": "time", "OffsetStartMs": 17700, "OffsetEndMs": 17985}, {"Word": "from", "OffsetStartMs": 17985, "OffsetEndMs": 18240}, {"Word": "now", "OffsetStartMs": 18240, "OffsetEndMs": 18530}, {"Word": "And", "OffsetStartMs": 18970, "OffsetEndMs": 19290}, {"Word": "but", "OffsetStartMs": 19290, "OffsetEndMs": 19545}, {"Word": "essentially", "OffsetStartMs": 19545, "OffsetEndMs": 19880}, {"Word": "all", "OffsetStartMs": 19960, "OffsetEndMs": 20250}, {"Word": "of", "OffsetStartMs": 20250, "OffsetEndMs": 20430}, {"Word": "these", "OffsetStartMs": 20430, "OffsetEndMs": 20720}, {"Word": "try", "OffsetStartMs": 20920, "OffsetEndMs": 21240}, {"Word": "to", "OffsetStartMs": 21240, "OffsetEndMs": 21480}, {"Word": "effectively", "OffsetStartMs": 21480, "OffsetEndMs": 21800}, {"Word": "evaluate", "OffsetStartMs": 21970, "OffsetEndMs": 22370}, {"Word": "some", "OffsetStartMs": 22540, "OffsetEndMs": 22875}, {"Word": "way", "OffsetStartMs": 22875, "OffsetEndMs": 23210}, {"Word": "of", "OffsetStartMs": 23740, "OffsetEndMs": 24140}, {"Word": "measuring", "OffsetStartMs": 24820, "OffsetEndMs": 25365}, {"Word": "the", "OffsetStartMs": 25365, "OffsetEndMs": 25515}, {"Word": "success", "OffsetStartMs": 25515, "OffsetEndMs": 25790}, {"Word": "of", "OffsetStartMs": 26290, "OffsetEndMs": 26640}, {"Word": "a", "OffsetStartMs": 26640, "OffsetEndMs": 26940}, {"Word": "particular", "OffsetStartMs": 26940, "OffsetEndMs": 27240}, {"Word": "action", "OffsetStartMs": 27240, "OffsetEndMs": 27590}, {"Word": "that", "OffsetStartMs": 27820, "OffsetEndMs": 28110}, {"Word": "an", "OffsetStartMs": 28110, "OffsetEndMs": 28260}, {"Word": "agent", "OffsetStartMs": 28260, "OffsetEndMs": 28520}, {"Word": "takes", "OffsetStartMs": 28570, "OffsetEndMs": 28970}], "SpeechSpeed": 15.2}, {"FinalSentence": "So, for example, when we look at the total rewards that an agent accumulates over the course of its lifetime, we can simply sum up all of the rewards that an agent gets after a certain time t right? So this capital r of t is the sum of all rewards from that point on into the future into infinity.", "SliceSentence": "So for example when we look at the total rewards that an agent accumulates over the course of its lifetime we can simply sum up all of the rewards that an agent gets after a certain time t right So this capital r of t is the sum of all rewards from that point on into the future into infinity", "StartMs": 623160, "EndMs": 643080, "WordsNum": 60, "Words": [{"Word": "So", "OffsetStartMs": 10, "OffsetEndMs": 300}, {"Word": "for", "OffsetStartMs": 300, "OffsetEndMs": 480}, {"Word": "example", "OffsetStartMs": 480, "OffsetEndMs": 720}, {"Word": "when", "OffsetStartMs": 720, "OffsetEndMs": 930}, {"Word": "we", "OffsetStartMs": 930, "OffsetEndMs": 1065}, {"Word": "look", "OffsetStartMs": 1065, "OffsetEndMs": 1215}, {"Word": "at", "OffsetStartMs": 1215, "OffsetEndMs": 1410}, {"Word": "the", "OffsetStartMs": 1410, "OffsetEndMs": 1730}, {"Word": "total", "OffsetStartMs": 1900, "OffsetEndMs": 2265}, {"Word": "rewards", "OffsetStartMs": 2265, "OffsetEndMs": 2780}, {"Word": "that", "OffsetStartMs": 2890, "OffsetEndMs": 3180}, {"Word": "an", "OffsetStartMs": 3180, "OffsetEndMs": 3315}, {"Word": "agent", "OffsetStartMs": 3315, "OffsetEndMs": 3540}, {"Word": "accumulates", "OffsetStartMs": 3540, "OffsetEndMs": 4200}, {"Word": "over", "OffsetStartMs": 4200, "OffsetEndMs": 4410}, {"Word": "the", "OffsetStartMs": 4410, "OffsetEndMs": 4620}, {"Word": "course", "OffsetStartMs": 4620, "OffsetEndMs": 4815}, {"Word": "of", "OffsetStartMs": 4815, "OffsetEndMs": 4950}, {"Word": "its", "OffsetStartMs": 4950, "OffsetEndMs": 5180}, {"Word": "lifetime", "OffsetStartMs": 5260, "OffsetEndMs": 5660}, {"Word": "we", "OffsetStartMs": 5800, "OffsetEndMs": 6090}, {"Word": "can", "OffsetStartMs": 6090, "OffsetEndMs": 6285}, {"Word": "simply", "OffsetStartMs": 6285, "OffsetEndMs": 6590}, {"Word": "sum", "OffsetStartMs": 6610, "OffsetEndMs": 6900}, {"Word": "up", "OffsetStartMs": 6900, "OffsetEndMs": 7190}, {"Word": "all", "OffsetStartMs": 7300, "OffsetEndMs": 7620}, {"Word": "of", "OffsetStartMs": 7620, "OffsetEndMs": 7830}, {"Word": "the", "OffsetStartMs": 7830, "OffsetEndMs": 7965}, {"Word": "rewards", "OffsetStartMs": 7965, "OffsetEndMs": 8330}, {"Word": "that", "OffsetStartMs": 8920, "OffsetEndMs": 9210}, {"Word": "an", "OffsetStartMs": 9210, "OffsetEndMs": 9360}, {"Word": "agent", "OffsetStartMs": 9360, "OffsetEndMs": 9620}, {"Word": "gets", "OffsetStartMs": 9730, "OffsetEndMs": 10130}, {"Word": "after", "OffsetStartMs": 10240, "OffsetEndMs": 10635}, {"Word": "a", "OffsetStartMs": 10635, "OffsetEndMs": 10905}, {"Word": "certain", "OffsetStartMs": 10905, "OffsetEndMs": 11145}, {"Word": "time", "OffsetStartMs": 11145, "OffsetEndMs": 11490}, {"Word": "t", "OffsetStartMs": 11490, "OffsetEndMs": 11870}, {"Word": "right", "OffsetStartMs": 12070, "OffsetEndMs": 12390}, {"Word": "So", "OffsetStartMs": 12390, "OffsetEndMs": 12570}, {"Word": "this", "OffsetStartMs": 12570, "OffsetEndMs": 12750}, {"Word": "capital", "OffsetStartMs": 12750, "OffsetEndMs": 13050}, {"Word": "r", "OffsetStartMs": 13050, "OffsetEndMs": 13350}, {"Word": "of", "OffsetStartMs": 13350, "OffsetEndMs": 13590}, {"Word": "t", "OffsetStartMs": 13590, "OffsetEndMs": 13910}, {"Word": "is", "OffsetStartMs": 14050, "OffsetEndMs": 14415}, {"Word": "the", "OffsetStartMs": 14415, "OffsetEndMs": 14670}, {"Word": "sum", "OffsetStartMs": 14670, "OffsetEndMs": 14880}, {"Word": "of", "OffsetStartMs": 14880, "OffsetEndMs": 15075}, {"Word": "all", "OffsetStartMs": 15075, "OffsetEndMs": 15225}, {"Word": "rewards", "OffsetStartMs": 15225, "OffsetEndMs": 15650}, {"Word": "from", "OffsetStartMs": 15880, "OffsetEndMs": 16155}, {"Word": "that", "OffsetStartMs": 16155, "OffsetEndMs": 16365}, {"Word": "point", "OffsetStartMs": 16365, "OffsetEndMs": 16700}, {"Word": "on", "OffsetStartMs": 16720, "OffsetEndMs": 17100}, {"Word": "into", "OffsetStartMs": 17100, "OffsetEndMs": 17415}, {"Word": "the", "OffsetStartMs": 17415, "OffsetEndMs": 17625}, {"Word": "future", "OffsetStartMs": 17625, "OffsetEndMs": 17900}, {"Word": "into", "OffsetStartMs": 18040, "OffsetEndMs": 18360}, {"Word": "infinity", "OffsetStartMs": 18360, "OffsetEndMs": 19070}], "SpeechSpeed": 14.7}, {"FinalSentence": "And that can be expanded to look exactly like this. It's rewarded time t plus the word time t plus one, plus t plus two, and so on and so forth. Often it's actually very useful for all of us to consider not only the sum of all of these rewards, but instead what's called the discounted sum. So you can see here I've added this gamma factor in front of all of the rewards. And that discounting factor is essentially multiplied by every future reward that the agent sees and it's discovered by the agent. And the reason that we want to do this is actually this dampening factor is designed to make future rewards essentially worth less than rewards that we might see at this instant, at this moment right now.", "SliceSentence": "And that can be expanded to look exactly like this It's rewarded time t plus the word time t plus one plus t plus two and so on and so forth Often it's actually very useful for all of us to consider not only the sum of all of these rewards but instead what's called the discounted sum So you can see here I've added this gamma factor in front of all of the rewards And that discounting factor is essentially multiplied by every future reward that the agent sees and it's discovered by the agent And the reason that we want to do this is actually this dampening factor is designed to make future rewards essentially worth less than rewards that we might see at this instant at this moment right now", "StartMs": 643480, "EndMs": 688000, "WordsNum": 133, "Words": [{"Word": "And", "OffsetStartMs": 100, "OffsetEndMs": 345}, {"Word": "that", "OffsetStartMs": 345, "OffsetEndMs": 465}, {"Word": "can", "OffsetStartMs": 465, "OffsetEndMs": 600}, {"Word": "be", "OffsetStartMs": 600, "OffsetEndMs": 795}, {"Word": "expanded", "OffsetStartMs": 795, "OffsetEndMs": 1130}, {"Word": "to", "OffsetStartMs": 1240, "OffsetEndMs": 1560}, {"Word": "look", "OffsetStartMs": 1560, "OffsetEndMs": 1880}, {"Word": "exactly", "OffsetStartMs": 1900, "OffsetEndMs": 2300}, {"Word": "like", "OffsetStartMs": 2470, "OffsetEndMs": 2790}, {"Word": "this", "OffsetStartMs": 2790, "OffsetEndMs": 3060}, {"Word": "It's", "OffsetStartMs": 3060, "OffsetEndMs": 3390}, {"Word": "rewarded", "OffsetStartMs": 3390, "OffsetEndMs": 3780}, {"Word": "time", "OffsetStartMs": 3780, "OffsetEndMs": 4005}, {"Word": "t", "OffsetStartMs": 4005, "OffsetEndMs": 4340}, {"Word": "plus", "OffsetStartMs": 4360, "OffsetEndMs": 4650}, {"Word": "the", "OffsetStartMs": 4650, "OffsetEndMs": 4830}, {"Word": "word", "OffsetStartMs": 4830, "OffsetEndMs": 5055}, {"Word": "time", "OffsetStartMs": 5055, "OffsetEndMs": 5280}, {"Word": "t", "OffsetStartMs": 5280, "OffsetEndMs": 5430}, {"Word": "plus", "OffsetStartMs": 5430, "OffsetEndMs": 5595}, {"Word": "one", "OffsetStartMs": 5595, "OffsetEndMs": 5880}, {"Word": "plus", "OffsetStartMs": 5880, "OffsetEndMs": 6165}, {"Word": "t", "OffsetStartMs": 6165, "OffsetEndMs": 6330}, {"Word": "plus", "OffsetStartMs": 6330, "OffsetEndMs": 6510}, {"Word": "two", "OffsetStartMs": 6510, "OffsetEndMs": 6830}, {"Word": "and", "OffsetStartMs": 7060, "OffsetEndMs": 7350}, {"Word": "so", "OffsetStartMs": 7350, "OffsetEndMs": 7485}, {"Word": "on", "OffsetStartMs": 7485, "OffsetEndMs": 7560}, {"Word": "and", "OffsetStartMs": 7560, "OffsetEndMs": 7665}, {"Word": "so", "OffsetStartMs": 7665, "OffsetEndMs": 7845}, {"Word": "forth", "OffsetStartMs": 7845, "OffsetEndMs": 8150}, {"Word": "Often", "OffsetStartMs": 8980, "OffsetEndMs": 9360}, {"Word": "it's", "OffsetStartMs": 9360, "OffsetEndMs": 9825}, {"Word": "actually", "OffsetStartMs": 9825, "OffsetEndMs": 10095}, {"Word": "very", "OffsetStartMs": 10095, "OffsetEndMs": 10335}, {"Word": "useful", "OffsetStartMs": 10335, "OffsetEndMs": 10670}, {"Word": "for", "OffsetStartMs": 10810, "OffsetEndMs": 11055}, {"Word": "all", "OffsetStartMs": 11055, "OffsetEndMs": 11175}, {"Word": "of", "OffsetStartMs": 11175, "OffsetEndMs": 11295}, {"Word": "us", "OffsetStartMs": 11295, "OffsetEndMs": 11445}, {"Word": "to", "OffsetStartMs": 11445, "OffsetEndMs": 11715}, {"Word": "consider", "OffsetStartMs": 11715, "OffsetEndMs": 12080}, {"Word": "not", "OffsetStartMs": 12190, "OffsetEndMs": 12510}, {"Word": "only", "OffsetStartMs": 12510, "OffsetEndMs": 12830}, {"Word": "the", "OffsetStartMs": 12940, "OffsetEndMs": 13275}, {"Word": "sum", "OffsetStartMs": 13275, "OffsetEndMs": 13610}, {"Word": "of", "OffsetStartMs": 13690, "OffsetEndMs": 13950}, {"Word": "all", "OffsetStartMs": 13950, "OffsetEndMs": 14085}, {"Word": "of", "OffsetStartMs": 14085, "OffsetEndMs": 14235}, {"Word": "these", "OffsetStartMs": 14235, "OffsetEndMs": 14415}, {"Word": "rewards", "OffsetStartMs": 14415, "OffsetEndMs": 14870}, {"Word": "but", "OffsetStartMs": 14950, "OffsetEndMs": 15300}, {"Word": "instead", "OffsetStartMs": 15300, "OffsetEndMs": 15555}, {"Word": "what's", "OffsetStartMs": 15555, "OffsetEndMs": 15855}, {"Word": "called", "OffsetStartMs": 15855, "OffsetEndMs": 16050}, {"Word": "the", "OffsetStartMs": 16050, "OffsetEndMs": 16275}, {"Word": "discounted", "OffsetStartMs": 16275, "OffsetEndMs": 17010}, {"Word": "sum", "OffsetStartMs": 17010, "OffsetEndMs": 17295}, {"Word": "So", "OffsetStartMs": 17295, "OffsetEndMs": 17490}, {"Word": "you", "OffsetStartMs": 17490, "OffsetEndMs": 17565}, {"Word": "can", "OffsetStartMs": 17565, "OffsetEndMs": 17715}, {"Word": "see", "OffsetStartMs": 17715, "OffsetEndMs": 17910}, {"Word": "here", "OffsetStartMs": 17910, "OffsetEndMs": 18200}, {"Word": "I've", "OffsetStartMs": 18460, "OffsetEndMs": 18810}, {"Word": "added", "OffsetStartMs": 18810, "OffsetEndMs": 19035}, {"Word": "this", "OffsetStartMs": 19035, "OffsetEndMs": 19395}, {"Word": "gamma", "OffsetStartMs": 19395, "OffsetEndMs": 19860}, {"Word": "factor", "OffsetStartMs": 19860, "OffsetEndMs": 20150}, {"Word": "in", "OffsetStartMs": 20230, "OffsetEndMs": 20535}, {"Word": "front", "OffsetStartMs": 20535, "OffsetEndMs": 20745}, {"Word": "of", "OffsetStartMs": 20745, "OffsetEndMs": 20925}, {"Word": "all", "OffsetStartMs": 20925, "OffsetEndMs": 21075}, {"Word": "of", "OffsetStartMs": 21075, "OffsetEndMs": 21240}, {"Word": "the", "OffsetStartMs": 21240, "OffsetEndMs": 21375}, {"Word": "rewards", "OffsetStartMs": 21375, "OffsetEndMs": 21770}, {"Word": "And", "OffsetStartMs": 22180, "OffsetEndMs": 22580}, {"Word": "that", "OffsetStartMs": 23020, "OffsetEndMs": 23340}, {"Word": "discounting", "OffsetStartMs": 23340, "OffsetEndMs": 24000}, {"Word": "factor", "OffsetStartMs": 24000, "OffsetEndMs": 24255}, {"Word": "is", "OffsetStartMs": 24255, "OffsetEndMs": 24540}, {"Word": "essentially", "OffsetStartMs": 24540, "OffsetEndMs": 24860}, {"Word": "multiplied", "OffsetStartMs": 24880, "OffsetEndMs": 25640}, {"Word": "by", "OffsetStartMs": 25660, "OffsetEndMs": 25965}, {"Word": "every", "OffsetStartMs": 25965, "OffsetEndMs": 26270}, {"Word": "future", "OffsetStartMs": 26380, "OffsetEndMs": 26780}, {"Word": "reward", "OffsetStartMs": 26950, "OffsetEndMs": 27315}, {"Word": "that", "OffsetStartMs": 27315, "OffsetEndMs": 27615}, {"Word": "the", "OffsetStartMs": 27615, "OffsetEndMs": 27950}, {"Word": "agent", "OffsetStartMs": 28150, "OffsetEndMs": 28550}, {"Word": "sees", "OffsetStartMs": 28900, "OffsetEndMs": 29300}, {"Word": "and", "OffsetStartMs": 29680, "OffsetEndMs": 29910}, {"Word": "it's", "OffsetStartMs": 29910, "OffsetEndMs": 30150}, {"Word": "discovered", "OffsetStartMs": 30150, "OffsetEndMs": 30420}, {"Word": "by", "OffsetStartMs": 30420, "OffsetEndMs": 30645}, {"Word": "the", "OffsetStartMs": 30645, "OffsetEndMs": 30765}, {"Word": "agent", "OffsetStartMs": 30765, "OffsetEndMs": 31010}, {"Word": "And", "OffsetStartMs": 31030, "OffsetEndMs": 31290}, {"Word": "the", "OffsetStartMs": 31290, "OffsetEndMs": 31410}, {"Word": "reason", "OffsetStartMs": 31410, "OffsetEndMs": 31670}, {"Word": "that", "OffsetStartMs": 31960, "OffsetEndMs": 32220}, {"Word": "we", "OffsetStartMs": 32220, "OffsetEndMs": 32340}, {"Word": "want", "OffsetStartMs": 32340, "OffsetEndMs": 32490}, {"Word": "to", "OffsetStartMs": 32490, "OffsetEndMs": 32640}, {"Word": "do", "OffsetStartMs": 32640, "OffsetEndMs": 32775}, {"Word": "this", "OffsetStartMs": 32775, "OffsetEndMs": 33000}, {"Word": "is", "OffsetStartMs": 33000, "OffsetEndMs": 33330}, {"Word": "actually", "OffsetStartMs": 33330, "OffsetEndMs": 33710}, {"Word": "this", "OffsetStartMs": 34060, "OffsetEndMs": 34425}, {"Word": "dampening", "OffsetStartMs": 34425, "OffsetEndMs": 35025}, {"Word": "factor", "OffsetStartMs": 35025, "OffsetEndMs": 35265}, {"Word": "is", "OffsetStartMs": 35265, "OffsetEndMs": 35610}, {"Word": "designed", "OffsetStartMs": 35610, "OffsetEndMs": 35990}, {"Word": "to", "OffsetStartMs": 36460, "OffsetEndMs": 36720}, {"Word": "make", "OffsetStartMs": 36720, "OffsetEndMs": 36945}, {"Word": "future", "OffsetStartMs": 36945, "OffsetEndMs": 37310}, {"Word": "rewards", "OffsetStartMs": 37390, "OffsetEndMs": 37970}, {"Word": "essentially", "OffsetStartMs": 38170, "OffsetEndMs": 38570}, {"Word": "worth", "OffsetStartMs": 38770, "OffsetEndMs": 39170}, {"Word": "less", "OffsetStartMs": 39190, "OffsetEndMs": 39590}, {"Word": "than", "OffsetStartMs": 40090, "OffsetEndMs": 40425}, {"Word": "rewards", "OffsetStartMs": 40425, "OffsetEndMs": 40860}, {"Word": "that", "OffsetStartMs": 40860, "OffsetEndMs": 41070}, {"Word": "we", "OffsetStartMs": 41070, "OffsetEndMs": 41220}, {"Word": "might", "OffsetStartMs": 41220, "OffsetEndMs": 41460}, {"Word": "see", "OffsetStartMs": 41460, "OffsetEndMs": 41700}, {"Word": "at", "OffsetStartMs": 41700, "OffsetEndMs": 41880}, {"Word": "this", "OffsetStartMs": 41880, "OffsetEndMs": 42170}, {"Word": "instant", "OffsetStartMs": 42400, "OffsetEndMs": 42800}, {"Word": "at", "OffsetStartMs": 42880, "OffsetEndMs": 43155}, {"Word": "this", "OffsetStartMs": 43155, "OffsetEndMs": 43350}, {"Word": "moment", "OffsetStartMs": 43350, "OffsetEndMs": 43635}, {"Word": "right", "OffsetStartMs": 43635, "OffsetEndMs": 43905}, {"Word": "now", "OffsetStartMs": 43905, "OffsetEndMs": 44210}], "SpeechSpeed": 15.7}, {"FinalSentence": "Now, you can think of this as basically enforcing some kind of short term.", "SliceSentence": "Now you can think of this as basically enforcing some kind of short term", "StartMs": 688000, "EndMs": 693740, "WordsNum": 14, "Words": [{"Word": "Now", "OffsetStartMs": 10, "OffsetEndMs": 240}, {"Word": "you", "OffsetStartMs": 240, "OffsetEndMs": 330}, {"Word": "can", "OffsetStartMs": 330, "OffsetEndMs": 465}, {"Word": "think", "OffsetStartMs": 465, "OffsetEndMs": 600}, {"Word": "of", "OffsetStartMs": 600, "OffsetEndMs": 735}, {"Word": "this", "OffsetStartMs": 735, "OffsetEndMs": 870}, {"Word": "as", "OffsetStartMs": 870, "OffsetEndMs": 1050}, {"Word": "basically", "OffsetStartMs": 1050, "OffsetEndMs": 1335}, {"Word": "enforcing", "OffsetStartMs": 1335, "OffsetEndMs": 1935}, {"Word": "some", "OffsetStartMs": 1935, "OffsetEndMs": 2190}, {"Word": "kind", "OffsetStartMs": 2190, "OffsetEndMs": 2445}, {"Word": "of", "OffsetStartMs": 2445, "OffsetEndMs": 2670}, {"Word": "short", "OffsetStartMs": 2670, "OffsetEndMs": 2955}, {"Word": "term", "OffsetStartMs": 2955, "OffsetEndMs": 3320}], "SpeechSpeed": 12.5}, {"FinalSentence": "Greiness in the algorithm, right. So for example, if I offered you a reward of five dollars today or a reward of five dollars and ten years from now, I think all of you would prefer that five dollars today simply because we have that same discounting factor applied to this. To this processing. We have that factor that that five dollars is not worth as much to us if it's given to us ten years in the future. And that's exactly how this is captured here as well. Mathematically, this discounting factor is like multiply, like I said, multiply that every single.", "SliceSentence": "Greiness in the algorithm right So for example if I offered you a reward of five dollars today or a reward of five dollars and ten years from now I think all of you would prefer that five dollars today simply because we have that same discounting factor applied to this To this processing We have that factor that that five dollars is not worth as much to us if it's given to us ten years in the future And that's exactly how this is captured here as well Mathematically this discounting factor is like multiply like I said multiply that every single", "StartMs": 693820, "EndMs": 725400, "WordsNum": 103, "Words": [{"Word": "Greiness", "OffsetStartMs": 370, "OffsetEndMs": 1065}, {"Word": "in", "OffsetStartMs": 1065, "OffsetEndMs": 1350}, {"Word": "the", "OffsetStartMs": 1350, "OffsetEndMs": 1590}, {"Word": "algorithm", "OffsetStartMs": 1590, "OffsetEndMs": 2010}, {"Word": "right", "OffsetStartMs": 2010, "OffsetEndMs": 2250}, {"Word": "So", "OffsetStartMs": 2250, "OffsetEndMs": 2505}, {"Word": "for", "OffsetStartMs": 2505, "OffsetEndMs": 2745}, {"Word": "example", "OffsetStartMs": 2745, "OffsetEndMs": 2970}, {"Word": "if", "OffsetStartMs": 2970, "OffsetEndMs": 3150}, {"Word": "I", "OffsetStartMs": 3150, "OffsetEndMs": 3285}, {"Word": "offered", "OffsetStartMs": 3285, "OffsetEndMs": 3525}, {"Word": "you", "OffsetStartMs": 3525, "OffsetEndMs": 3890}, {"Word": "a", "OffsetStartMs": 3970, "OffsetEndMs": 4320}, {"Word": "reward", "OffsetStartMs": 4320, "OffsetEndMs": 4575}, {"Word": "of", "OffsetStartMs": 4575, "OffsetEndMs": 4755}, {"Word": "five", "OffsetStartMs": 4755, "OffsetEndMs": 4950}, {"Word": "dollars", "OffsetStartMs": 4950, "OffsetEndMs": 5270}, {"Word": "today", "OffsetStartMs": 5320, "OffsetEndMs": 5720}, {"Word": "or", "OffsetStartMs": 5890, "OffsetEndMs": 6255}, {"Word": "a", "OffsetStartMs": 6255, "OffsetEndMs": 6525}, {"Word": "reward", "OffsetStartMs": 6525, "OffsetEndMs": 6720}, {"Word": "of", "OffsetStartMs": 6720, "OffsetEndMs": 6870}, {"Word": "five", "OffsetStartMs": 6870, "OffsetEndMs": 7035}, {"Word": "dollars", "OffsetStartMs": 7035, "OffsetEndMs": 7340}, {"Word": "and", "OffsetStartMs": 7390, "OffsetEndMs": 7790}, {"Word": "ten", "OffsetStartMs": 7870, "OffsetEndMs": 8145}, {"Word": "years", "OffsetStartMs": 8145, "OffsetEndMs": 8355}, {"Word": "from", "OffsetStartMs": 8355, "OffsetEndMs": 8565}, {"Word": "now", "OffsetStartMs": 8565, "OffsetEndMs": 8840}, {"Word": "I", "OffsetStartMs": 9070, "OffsetEndMs": 9315}, {"Word": "think", "OffsetStartMs": 9315, "OffsetEndMs": 9450}, {"Word": "all", "OffsetStartMs": 9450, "OffsetEndMs": 9615}, {"Word": "of", "OffsetStartMs": 9615, "OffsetEndMs": 9765}, {"Word": "you", "OffsetStartMs": 9765, "OffsetEndMs": 9945}, {"Word": "would", "OffsetStartMs": 9945, "OffsetEndMs": 10140}, {"Word": "prefer", "OffsetStartMs": 10140, "OffsetEndMs": 10430}, {"Word": "that", "OffsetStartMs": 10540, "OffsetEndMs": 10830}, {"Word": "five", "OffsetStartMs": 10830, "OffsetEndMs": 11010}, {"Word": "dollars", "OffsetStartMs": 11010, "OffsetEndMs": 11265}, {"Word": "today", "OffsetStartMs": 11265, "OffsetEndMs": 11630}, {"Word": "simply", "OffsetStartMs": 12070, "OffsetEndMs": 12470}, {"Word": "because", "OffsetStartMs": 12520, "OffsetEndMs": 12920}, {"Word": "we", "OffsetStartMs": 13030, "OffsetEndMs": 13290}, {"Word": "have", "OffsetStartMs": 13290, "OffsetEndMs": 13440}, {"Word": "that", "OffsetStartMs": 13440, "OffsetEndMs": 13665}, {"Word": "same", "OffsetStartMs": 13665, "OffsetEndMs": 13950}, {"Word": "discounting", "OffsetStartMs": 13950, "OffsetEndMs": 14520}, {"Word": "factor", "OffsetStartMs": 14520, "OffsetEndMs": 14810}, {"Word": "applied", "OffsetStartMs": 14920, "OffsetEndMs": 15320}, {"Word": "to", "OffsetStartMs": 15610, "OffsetEndMs": 15870}, {"Word": "this", "OffsetStartMs": 15870, "OffsetEndMs": 16130}, {"Word": "To", "OffsetStartMs": 16270, "OffsetEndMs": 16515}, {"Word": "this", "OffsetStartMs": 16515, "OffsetEndMs": 16665}, {"Word": "processing", "OffsetStartMs": 16665, "OffsetEndMs": 16970}, {"Word": "We", "OffsetStartMs": 17350, "OffsetEndMs": 17655}, {"Word": "have", "OffsetStartMs": 17655, "OffsetEndMs": 17850}, {"Word": "that", "OffsetStartMs": 17850, "OffsetEndMs": 18105}, {"Word": "factor", "OffsetStartMs": 18105, "OffsetEndMs": 18435}, {"Word": "that", "OffsetStartMs": 18435, "OffsetEndMs": 18675}, {"Word": "that", "OffsetStartMs": 18675, "OffsetEndMs": 18840}, {"Word": "five", "OffsetStartMs": 18840, "OffsetEndMs": 19035}, {"Word": "dollars", "OffsetStartMs": 19035, "OffsetEndMs": 19305}, {"Word": "is", "OffsetStartMs": 19305, "OffsetEndMs": 19545}, {"Word": "not", "OffsetStartMs": 19545, "OffsetEndMs": 19755}, {"Word": "worth", "OffsetStartMs": 19755, "OffsetEndMs": 19995}, {"Word": "as", "OffsetStartMs": 19995, "OffsetEndMs": 20235}, {"Word": "much", "OffsetStartMs": 20235, "OffsetEndMs": 20505}, {"Word": "to", "OffsetStartMs": 20505, "OffsetEndMs": 20685}, {"Word": "us", "OffsetStartMs": 20685, "OffsetEndMs": 20930}, {"Word": "if", "OffsetStartMs": 21070, "OffsetEndMs": 21330}, {"Word": "it's", "OffsetStartMs": 21330, "OffsetEndMs": 21540}, {"Word": "given", "OffsetStartMs": 21540, "OffsetEndMs": 21720}, {"Word": "to", "OffsetStartMs": 21720, "OffsetEndMs": 21870}, {"Word": "us", "OffsetStartMs": 21870, "OffsetEndMs": 22020}, {"Word": "ten", "OffsetStartMs": 22020, "OffsetEndMs": 22230}, {"Word": "years", "OffsetStartMs": 22230, "OffsetEndMs": 22515}, {"Word": "in", "OffsetStartMs": 22515, "OffsetEndMs": 22770}, {"Word": "the", "OffsetStartMs": 22770, "OffsetEndMs": 22890}, {"Word": "future", "OffsetStartMs": 22890, "OffsetEndMs": 23100}, {"Word": "And", "OffsetStartMs": 23100, "OffsetEndMs": 23325}, {"Word": "that's", "OffsetStartMs": 23325, "OffsetEndMs": 23580}, {"Word": "exactly", "OffsetStartMs": 23580, "OffsetEndMs": 23870}, {"Word": "how", "OffsetStartMs": 23950, "OffsetEndMs": 24225}, {"Word": "this", "OffsetStartMs": 24225, "OffsetEndMs": 24390}, {"Word": "is", "OffsetStartMs": 24390, "OffsetEndMs": 24585}, {"Word": "captured", "OffsetStartMs": 24585, "OffsetEndMs": 24870}, {"Word": "here", "OffsetStartMs": 24870, "OffsetEndMs": 25125}, {"Word": "as", "OffsetStartMs": 25125, "OffsetEndMs": 25275}, {"Word": "well", "OffsetStartMs": 25275, "OffsetEndMs": 25550}, {"Word": "Mathematically", "OffsetStartMs": 25690, "OffsetEndMs": 26330}, {"Word": "this", "OffsetStartMs": 26710, "OffsetEndMs": 27000}, {"Word": "discounting", "OffsetStartMs": 27000, "OffsetEndMs": 27525}, {"Word": "factor", "OffsetStartMs": 27525, "OffsetEndMs": 27750}, {"Word": "is", "OffsetStartMs": 27750, "OffsetEndMs": 28100}, {"Word": "like", "OffsetStartMs": 28150, "OffsetEndMs": 28550}, {"Word": "multiply", "OffsetStartMs": 28570, "OffsetEndMs": 29160}, {"Word": "like", "OffsetStartMs": 29160, "OffsetEndMs": 29310}, {"Word": "I", "OffsetStartMs": 29310, "OffsetEndMs": 29445}, {"Word": "said", "OffsetStartMs": 29445, "OffsetEndMs": 29625}, {"Word": "multiply", "OffsetStartMs": 29625, "OffsetEndMs": 30105}, {"Word": "that", "OffsetStartMs": 30105, "OffsetEndMs": 30285}, {"Word": "every", "OffsetStartMs": 30285, "OffsetEndMs": 30540}, {"Word": "single", "OffsetStartMs": 30540, "OffsetEndMs": 30920}], "SpeechSpeed": 17.4}, {"FinalSentence": "Future award exponentially. And it's important to understand that also. Typically this discounting factor is, you know, between zero and one, there are some exceptional cases where maybe you want some strange behaviors and have a discounting factor greater than one, but in general that's not something we're going to be talking about today.", "SliceSentence": "Future award exponentially And it's important to understand that also Typically this discounting factor is you know between zero and one there are some exceptional cases where maybe you want some strange behaviors and have a discounting factor greater than one but in general that's not something we're going to be talking about today", "StartMs": 725400, "EndMs": 744380, "WordsNum": 54, "Words": [{"Word": "Future", "OffsetStartMs": 0, "OffsetEndMs": 380}, {"Word": "award", "OffsetStartMs": 400, "OffsetEndMs": 800}, {"Word": "exponentially", "OffsetStartMs": 1000, "OffsetEndMs": 2000}, {"Word": "And", "OffsetStartMs": 2860, "OffsetEndMs": 3260}, {"Word": "it's", "OffsetStartMs": 3580, "OffsetEndMs": 3990}, {"Word": "important", "OffsetStartMs": 3990, "OffsetEndMs": 4245}, {"Word": "to", "OffsetStartMs": 4245, "OffsetEndMs": 4575}, {"Word": "understand", "OffsetStartMs": 4575, "OffsetEndMs": 4875}, {"Word": "that", "OffsetStartMs": 4875, "OffsetEndMs": 5145}, {"Word": "also", "OffsetStartMs": 5145, "OffsetEndMs": 5445}, {"Word": "Typically", "OffsetStartMs": 5445, "OffsetEndMs": 5780}, {"Word": "this", "OffsetStartMs": 5920, "OffsetEndMs": 6240}, {"Word": "discounting", "OffsetStartMs": 6240, "OffsetEndMs": 6810}, {"Word": "factor", "OffsetStartMs": 6810, "OffsetEndMs": 7100}, {"Word": "is", "OffsetStartMs": 7120, "OffsetEndMs": 7520}, {"Word": "you", "OffsetStartMs": 7750, "OffsetEndMs": 7980}, {"Word": "know", "OffsetStartMs": 7980, "OffsetEndMs": 8210}, {"Word": "between", "OffsetStartMs": 8260, "OffsetEndMs": 8580}, {"Word": "zero", "OffsetStartMs": 8580, "OffsetEndMs": 8790}, {"Word": "and", "OffsetStartMs": 8790, "OffsetEndMs": 8985}, {"Word": "one", "OffsetStartMs": 8985, "OffsetEndMs": 9270}, {"Word": "there", "OffsetStartMs": 9270, "OffsetEndMs": 9495}, {"Word": "are", "OffsetStartMs": 9495, "OffsetEndMs": 9645}, {"Word": "some", "OffsetStartMs": 9645, "OffsetEndMs": 9870}, {"Word": "exceptional", "OffsetStartMs": 9870, "OffsetEndMs": 10305}, {"Word": "cases", "OffsetStartMs": 10305, "OffsetEndMs": 10560}, {"Word": "where", "OffsetStartMs": 10560, "OffsetEndMs": 10800}, {"Word": "maybe", "OffsetStartMs": 10800, "OffsetEndMs": 10965}, {"Word": "you", "OffsetStartMs": 10965, "OffsetEndMs": 11130}, {"Word": "want", "OffsetStartMs": 11130, "OffsetEndMs": 11325}, {"Word": "some", "OffsetStartMs": 11325, "OffsetEndMs": 11660}, {"Word": "strange", "OffsetStartMs": 11710, "OffsetEndMs": 12090}, {"Word": "behaviors", "OffsetStartMs": 12090, "OffsetEndMs": 12585}, {"Word": "and", "OffsetStartMs": 12585, "OffsetEndMs": 12795}, {"Word": "have", "OffsetStartMs": 12795, "OffsetEndMs": 12960}, {"Word": "a", "OffsetStartMs": 12960, "OffsetEndMs": 13080}, {"Word": "discounting", "OffsetStartMs": 13080, "OffsetEndMs": 13575}, {"Word": "factor", "OffsetStartMs": 13575, "OffsetEndMs": 13830}, {"Word": "greater", "OffsetStartMs": 13830, "OffsetEndMs": 14145}, {"Word": "than", "OffsetStartMs": 14145, "OffsetEndMs": 14355}, {"Word": "one", "OffsetStartMs": 14355, "OffsetEndMs": 14550}, {"Word": "but", "OffsetStartMs": 14550, "OffsetEndMs": 14715}, {"Word": "in", "OffsetStartMs": 14715, "OffsetEndMs": 14850}, {"Word": "general", "OffsetStartMs": 14850, "OffsetEndMs": 15140}, {"Word": "that's", "OffsetStartMs": 15490, "OffsetEndMs": 16010}, {"Word": "not", "OffsetStartMs": 16030, "OffsetEndMs": 16320}, {"Word": "something", "OffsetStartMs": 16320, "OffsetEndMs": 16560}, {"Word": "we're", "OffsetStartMs": 16560, "OffsetEndMs": 16800}, {"Word": "going", "OffsetStartMs": 16800, "OffsetEndMs": 16905}, {"Word": "to", "OffsetStartMs": 16905, "OffsetEndMs": 17025}, {"Word": "be", "OffsetStartMs": 17025, "OffsetEndMs": 17130}, {"Word": "talking", "OffsetStartMs": 17130, "OffsetEndMs": 17340}, {"Word": "about", "OffsetStartMs": 17340, "OffsetEndMs": 17580}, {"Word": "today", "OffsetStartMs": 17580, "OffsetEndMs": 17870}], "SpeechSpeed": 17.6}, {"FinalSentence": "Now finally, it's very important in reinforcement learning, this special function called the q function, which ties in a lot of these different components that I've just shared with you altogether. Now let's look at what this q function is, right? So we already covered this r of t function right? R of t is the discounted sum of rewards from time t all the way into the future time infinity.", "SliceSentence": "Now finally it's very important in reinforcement learning this special function called the q function which ties in a lot of these different components that I've just shared with you altogether Now let's look at what this q function is right So we already covered this r of t function right R of t is the discounted sum of rewards from time t all the way into the future time infinity", "StartMs": 744380, "EndMs": 770400, "WordsNum": 71, "Words": [{"Word": "Now", "OffsetStartMs": 0, "OffsetEndMs": 315}, {"Word": "finally", "OffsetStartMs": 315, "OffsetEndMs": 675}, {"Word": "it's", "OffsetStartMs": 675, "OffsetEndMs": 1160}, {"Word": "very", "OffsetStartMs": 1180, "OffsetEndMs": 1560}, {"Word": "important", "OffsetStartMs": 1560, "OffsetEndMs": 1940}, {"Word": "in", "OffsetStartMs": 1990, "OffsetEndMs": 2390}, {"Word": "reinforcement", "OffsetStartMs": 2470, "OffsetEndMs": 3165}, {"Word": "learning", "OffsetStartMs": 3165, "OffsetEndMs": 3440}, {"Word": "this", "OffsetStartMs": 3790, "OffsetEndMs": 4190}, {"Word": "special", "OffsetStartMs": 4360, "OffsetEndMs": 4740}, {"Word": "function", "OffsetStartMs": 4740, "OffsetEndMs": 5120}, {"Word": "called", "OffsetStartMs": 5920, "OffsetEndMs": 6255}, {"Word": "the", "OffsetStartMs": 6255, "OffsetEndMs": 6480}, {"Word": "q", "OffsetStartMs": 6480, "OffsetEndMs": 6660}, {"Word": "function", "OffsetStartMs": 6660, "OffsetEndMs": 6950}, {"Word": "which", "OffsetStartMs": 7090, "OffsetEndMs": 7455}, {"Word": "ties", "OffsetStartMs": 7455, "OffsetEndMs": 7800}, {"Word": "in", "OffsetStartMs": 7800, "OffsetEndMs": 8055}, {"Word": "a", "OffsetStartMs": 8055, "OffsetEndMs": 8235}, {"Word": "lot", "OffsetStartMs": 8235, "OffsetEndMs": 8400}, {"Word": "of", "OffsetStartMs": 8400, "OffsetEndMs": 8565}, {"Word": "these", "OffsetStartMs": 8565, "OffsetEndMs": 8730}, {"Word": "different", "OffsetStartMs": 8730, "OffsetEndMs": 9020}, {"Word": "components", "OffsetStartMs": 9070, "OffsetEndMs": 9470}, {"Word": "that", "OffsetStartMs": 9520, "OffsetEndMs": 9780}, {"Word": "I've", "OffsetStartMs": 9780, "OffsetEndMs": 9975}, {"Word": "just", "OffsetStartMs": 9975, "OffsetEndMs": 10110}, {"Word": "shared", "OffsetStartMs": 10110, "OffsetEndMs": 10320}, {"Word": "with", "OffsetStartMs": 10320, "OffsetEndMs": 10515}, {"Word": "you", "OffsetStartMs": 10515, "OffsetEndMs": 10790}, {"Word": "altogether", "OffsetStartMs": 11050, "OffsetEndMs": 11450}, {"Word": "Now", "OffsetStartMs": 12190, "OffsetEndMs": 12585}, {"Word": "let's", "OffsetStartMs": 12585, "OffsetEndMs": 12960}, {"Word": "look", "OffsetStartMs": 12960, "OffsetEndMs": 13095}, {"Word": "at", "OffsetStartMs": 13095, "OffsetEndMs": 13335}, {"Word": "what", "OffsetStartMs": 13335, "OffsetEndMs": 13605}, {"Word": "this", "OffsetStartMs": 13605, "OffsetEndMs": 13815}, {"Word": "q", "OffsetStartMs": 13815, "OffsetEndMs": 13995}, {"Word": "function", "OffsetStartMs": 13995, "OffsetEndMs": 14270}, {"Word": "is", "OffsetStartMs": 14500, "OffsetEndMs": 14850}, {"Word": "right", "OffsetStartMs": 14850, "OffsetEndMs": 15105}, {"Word": "So", "OffsetStartMs": 15105, "OffsetEndMs": 15315}, {"Word": "we", "OffsetStartMs": 15315, "OffsetEndMs": 15570}, {"Word": "already", "OffsetStartMs": 15570, "OffsetEndMs": 15840}, {"Word": "covered", "OffsetStartMs": 15840, "OffsetEndMs": 16155}, {"Word": "this", "OffsetStartMs": 16155, "OffsetEndMs": 16550}, {"Word": "r", "OffsetStartMs": 16750, "OffsetEndMs": 17055}, {"Word": "of", "OffsetStartMs": 17055, "OffsetEndMs": 17280}, {"Word": "t", "OffsetStartMs": 17280, "OffsetEndMs": 17600}, {"Word": "function", "OffsetStartMs": 17620, "OffsetEndMs": 18000}, {"Word": "right", "OffsetStartMs": 18000, "OffsetEndMs": 18270}, {"Word": "R", "OffsetStartMs": 18270, "OffsetEndMs": 18435}, {"Word": "of", "OffsetStartMs": 18435, "OffsetEndMs": 18600}, {"Word": "t", "OffsetStartMs": 18600, "OffsetEndMs": 18750}, {"Word": "is", "OffsetStartMs": 18750, "OffsetEndMs": 18930}, {"Word": "the", "OffsetStartMs": 18930, "OffsetEndMs": 19250}, {"Word": "discounted", "OffsetStartMs": 19540, "OffsetEndMs": 20310}, {"Word": "sum", "OffsetStartMs": 20310, "OffsetEndMs": 20625}, {"Word": "of", "OffsetStartMs": 20625, "OffsetEndMs": 20910}, {"Word": "rewards", "OffsetStartMs": 20910, "OffsetEndMs": 21350}, {"Word": "from", "OffsetStartMs": 21610, "OffsetEndMs": 21975}, {"Word": "time", "OffsetStartMs": 21975, "OffsetEndMs": 22290}, {"Word": "t", "OffsetStartMs": 22290, "OffsetEndMs": 22575}, {"Word": "all", "OffsetStartMs": 22575, "OffsetEndMs": 22800}, {"Word": "the", "OffsetStartMs": 22800, "OffsetEndMs": 22950}, {"Word": "way", "OffsetStartMs": 22950, "OffsetEndMs": 23175}, {"Word": "into", "OffsetStartMs": 23175, "OffsetEndMs": 23540}, {"Word": "the", "OffsetStartMs": 23740, "OffsetEndMs": 24015}, {"Word": "future", "OffsetStartMs": 24015, "OffsetEndMs": 24290}, {"Word": "time", "OffsetStartMs": 24760, "OffsetEndMs": 25050}, {"Word": "infinity", "OffsetStartMs": 25050, "OffsetEndMs": 25760}], "SpeechSpeed": 14.8}, {"FinalSentence": "But remember that this rf t right, it's discounted number one and number two, we're going to try and build A Q function that captures the the maximum or the best action that we could take that will maximize this reward. So let me say that one more time in a different way. The q function takes as input two different things. The first is the state that you're currently in and the second is a possible action that you could execute in this particular state. So here's of t is that stay at time T A of t is that action that you may want to take at time t, and the q function of these two pieces is going to denote or capture what the expected total return would be of that agent if it took that action in that particular state.", "SliceSentence": "But remember that this rf t right it's discounted number one and number two we're going to try and build A Q function that captures the the maximum or the best action that we could take that will maximize this reward So let me say that one more time in a different way The q function takes as input two different things The first is the state that you're currently in and the second is a possible action that you could execute in this particular state So here's of t is that stay at time T A of t is that action that you may want to take at time t and the q function of these two pieces is going to denote or capture what the expected total return would be of that agent if it took that action in that particular state", "StartMs": 770400, "EndMs": 822020, "WordsNum": 144, "Words": [{"Word": "But", "OffsetStartMs": 70, "OffsetEndMs": 405}, {"Word": "remember", "OffsetStartMs": 405, "OffsetEndMs": 740}, {"Word": "that", "OffsetStartMs": 1120, "OffsetEndMs": 1515}, {"Word": "this", "OffsetStartMs": 1515, "OffsetEndMs": 1910}, {"Word": "rf", "OffsetStartMs": 2350, "OffsetEndMs": 2820}, {"Word": "t", "OffsetStartMs": 2820, "OffsetEndMs": 3060}, {"Word": "right", "OffsetStartMs": 3060, "OffsetEndMs": 3315}, {"Word": "it's", "OffsetStartMs": 3315, "OffsetEndMs": 3570}, {"Word": "discounted", "OffsetStartMs": 3570, "OffsetEndMs": 4170}, {"Word": "number", "OffsetStartMs": 4170, "OffsetEndMs": 4425}, {"Word": "one", "OffsetStartMs": 4425, "OffsetEndMs": 4760}, {"Word": "and", "OffsetStartMs": 4900, "OffsetEndMs": 5160}, {"Word": "number", "OffsetStartMs": 5160, "OffsetEndMs": 5400}, {"Word": "two", "OffsetStartMs": 5400, "OffsetEndMs": 5780}, {"Word": "we're", "OffsetStartMs": 6760, "OffsetEndMs": 7050}, {"Word": "going", "OffsetStartMs": 7050, "OffsetEndMs": 7170}, {"Word": "to", "OffsetStartMs": 7170, "OffsetEndMs": 7335}, {"Word": "try", "OffsetStartMs": 7335, "OffsetEndMs": 7470}, {"Word": "and", "OffsetStartMs": 7470, "OffsetEndMs": 7620}, {"Word": "build", "OffsetStartMs": 7620, "OffsetEndMs": 7910}, {"Word": "A", "OffsetStartMs": 8500, "OffsetEndMs": 8900}, {"Word": "Q", "OffsetStartMs": 9280, "OffsetEndMs": 9680}, {"Word": "function", "OffsetStartMs": 10000, "OffsetEndMs": 10400}, {"Word": "that", "OffsetStartMs": 10900, "OffsetEndMs": 11295}, {"Word": "captures", "OffsetStartMs": 11295, "OffsetEndMs": 11960}, {"Word": "the", "OffsetStartMs": 12430, "OffsetEndMs": 12830}, {"Word": "the", "OffsetStartMs": 13180, "OffsetEndMs": 13515}, {"Word": "maximum", "OffsetStartMs": 13515, "OffsetEndMs": 13850}, {"Word": "or", "OffsetStartMs": 14050, "OffsetEndMs": 14340}, {"Word": "the", "OffsetStartMs": 14340, "OffsetEndMs": 14535}, {"Word": "best", "OffsetStartMs": 14535, "OffsetEndMs": 14820}, {"Word": "action", "OffsetStartMs": 14820, "OffsetEndMs": 15200}, {"Word": "that", "OffsetStartMs": 15280, "OffsetEndMs": 15555}, {"Word": "we", "OffsetStartMs": 15555, "OffsetEndMs": 15705}, {"Word": "could", "OffsetStartMs": 15705, "OffsetEndMs": 15885}, {"Word": "take", "OffsetStartMs": 15885, "OffsetEndMs": 16190}, {"Word": "that", "OffsetStartMs": 16390, "OffsetEndMs": 16695}, {"Word": "will", "OffsetStartMs": 16695, "OffsetEndMs": 16950}, {"Word": "maximize", "OffsetStartMs": 16950, "OffsetEndMs": 17690}, {"Word": "this", "OffsetStartMs": 17830, "OffsetEndMs": 18225}, {"Word": "reward", "OffsetStartMs": 18225, "OffsetEndMs": 18570}, {"Word": "So", "OffsetStartMs": 18570, "OffsetEndMs": 18795}, {"Word": "let", "OffsetStartMs": 18795, "OffsetEndMs": 18915}, {"Word": "me", "OffsetStartMs": 18915, "OffsetEndMs": 19050}, {"Word": "say", "OffsetStartMs": 19050, "OffsetEndMs": 19215}, {"Word": "that", "OffsetStartMs": 19215, "OffsetEndMs": 19350}, {"Word": "one", "OffsetStartMs": 19350, "OffsetEndMs": 19485}, {"Word": "more", "OffsetStartMs": 19485, "OffsetEndMs": 19665}, {"Word": "time", "OffsetStartMs": 19665, "OffsetEndMs": 19905}, {"Word": "in", "OffsetStartMs": 19905, "OffsetEndMs": 20085}, {"Word": "a", "OffsetStartMs": 20085, "OffsetEndMs": 20190}, {"Word": "different", "OffsetStartMs": 20190, "OffsetEndMs": 20385}, {"Word": "way", "OffsetStartMs": 20385, "OffsetEndMs": 20720}, {"Word": "The", "OffsetStartMs": 21130, "OffsetEndMs": 21420}, {"Word": "q", "OffsetStartMs": 21420, "OffsetEndMs": 21600}, {"Word": "function", "OffsetStartMs": 21600, "OffsetEndMs": 21890}, {"Word": "takes", "OffsetStartMs": 21940, "OffsetEndMs": 22230}, {"Word": "as", "OffsetStartMs": 22230, "OffsetEndMs": 22520}, {"Word": "input", "OffsetStartMs": 22600, "OffsetEndMs": 23000}, {"Word": "two", "OffsetStartMs": 23500, "OffsetEndMs": 23760}, {"Word": "different", "OffsetStartMs": 23760, "OffsetEndMs": 23970}, {"Word": "things", "OffsetStartMs": 23970, "OffsetEndMs": 24320}, {"Word": "The", "OffsetStartMs": 24460, "OffsetEndMs": 24720}, {"Word": "first", "OffsetStartMs": 24720, "OffsetEndMs": 24900}, {"Word": "is", "OffsetStartMs": 24900, "OffsetEndMs": 25110}, {"Word": "the", "OffsetStartMs": 25110, "OffsetEndMs": 25305}, {"Word": "state", "OffsetStartMs": 25305, "OffsetEndMs": 25530}, {"Word": "that", "OffsetStartMs": 25530, "OffsetEndMs": 25695}, {"Word": "you're", "OffsetStartMs": 25695, "OffsetEndMs": 25875}, {"Word": "currently", "OffsetStartMs": 25875, "OffsetEndMs": 26085}, {"Word": "in", "OffsetStartMs": 26085, "OffsetEndMs": 26450}, {"Word": "and", "OffsetStartMs": 26560, "OffsetEndMs": 26820}, {"Word": "the", "OffsetStartMs": 26820, "OffsetEndMs": 26955}, {"Word": "second", "OffsetStartMs": 26955, "OffsetEndMs": 27165}, {"Word": "is", "OffsetStartMs": 27165, "OffsetEndMs": 27495}, {"Word": "a", "OffsetStartMs": 27495, "OffsetEndMs": 27795}, {"Word": "possible", "OffsetStartMs": 27795, "OffsetEndMs": 28100}, {"Word": "action", "OffsetStartMs": 28150, "OffsetEndMs": 28550}, {"Word": "that", "OffsetStartMs": 28810, "OffsetEndMs": 29070}, {"Word": "you", "OffsetStartMs": 29070, "OffsetEndMs": 29190}, {"Word": "could", "OffsetStartMs": 29190, "OffsetEndMs": 29450}, {"Word": "execute", "OffsetStartMs": 29530, "OffsetEndMs": 29930}, {"Word": "in", "OffsetStartMs": 30070, "OffsetEndMs": 30405}, {"Word": "this", "OffsetStartMs": 30405, "OffsetEndMs": 30735}, {"Word": "particular", "OffsetStartMs": 30735, "OffsetEndMs": 31130}, {"Word": "state", "OffsetStartMs": 31300, "OffsetEndMs": 31700}, {"Word": "So", "OffsetStartMs": 32590, "OffsetEndMs": 32940}, {"Word": "here's", "OffsetStartMs": 32940, "OffsetEndMs": 33180}, {"Word": "of", "OffsetStartMs": 33180, "OffsetEndMs": 33375}, {"Word": "t", "OffsetStartMs": 33375, "OffsetEndMs": 33510}, {"Word": "is", "OffsetStartMs": 33510, "OffsetEndMs": 33630}, {"Word": "that", "OffsetStartMs": 33630, "OffsetEndMs": 33870}, {"Word": "stay", "OffsetStartMs": 33870, "OffsetEndMs": 34110}, {"Word": "at", "OffsetStartMs": 34110, "OffsetEndMs": 34275}, {"Word": "time", "OffsetStartMs": 34275, "OffsetEndMs": 34485}, {"Word": "T", "OffsetStartMs": 34485, "OffsetEndMs": 34820}, {"Word": "A", "OffsetStartMs": 34930, "OffsetEndMs": 35220}, {"Word": "of", "OffsetStartMs": 35220, "OffsetEndMs": 35430}, {"Word": "t", "OffsetStartMs": 35430, "OffsetEndMs": 35685}, {"Word": "is", "OffsetStartMs": 35685, "OffsetEndMs": 35880}, {"Word": "that", "OffsetStartMs": 35880, "OffsetEndMs": 36015}, {"Word": "action", "OffsetStartMs": 36015, "OffsetEndMs": 36270}, {"Word": "that", "OffsetStartMs": 36270, "OffsetEndMs": 36510}, {"Word": "you", "OffsetStartMs": 36510, "OffsetEndMs": 36660}, {"Word": "may", "OffsetStartMs": 36660, "OffsetEndMs": 36855}, {"Word": "want", "OffsetStartMs": 36855, "OffsetEndMs": 37035}, {"Word": "to", "OffsetStartMs": 37035, "OffsetEndMs": 37200}, {"Word": "take", "OffsetStartMs": 37200, "OffsetEndMs": 37455}, {"Word": "at", "OffsetStartMs": 37455, "OffsetEndMs": 37725}, {"Word": "time", "OffsetStartMs": 37725, "OffsetEndMs": 37995}, {"Word": "t", "OffsetStartMs": 37995, "OffsetEndMs": 38360}, {"Word": "and", "OffsetStartMs": 38590, "OffsetEndMs": 38850}, {"Word": "the", "OffsetStartMs": 38850, "OffsetEndMs": 39015}, {"Word": "q", "OffsetStartMs": 39015, "OffsetEndMs": 39210}, {"Word": "function", "OffsetStartMs": 39210, "OffsetEndMs": 39500}, {"Word": "of", "OffsetStartMs": 39520, "OffsetEndMs": 39825}, {"Word": "these", "OffsetStartMs": 39825, "OffsetEndMs": 40080}, {"Word": "two", "OffsetStartMs": 40080, "OffsetEndMs": 40430}, {"Word": "pieces", "OffsetStartMs": 40600, "OffsetEndMs": 41000}, {"Word": "is", "OffsetStartMs": 41080, "OffsetEndMs": 41400}, {"Word": "going", "OffsetStartMs": 41400, "OffsetEndMs": 41640}, {"Word": "to", "OffsetStartMs": 41640, "OffsetEndMs": 41850}, {"Word": "denote", "OffsetStartMs": 41850, "OffsetEndMs": 42290}, {"Word": "or", "OffsetStartMs": 42490, "OffsetEndMs": 42890}, {"Word": "capture", "OffsetStartMs": 42940, "OffsetEndMs": 43340}, {"Word": "what", "OffsetStartMs": 44080, "OffsetEndMs": 44370}, {"Word": "the", "OffsetStartMs": 44370, "OffsetEndMs": 44660}, {"Word": "expected", "OffsetStartMs": 44740, "OffsetEndMs": 45140}, {"Word": "total", "OffsetStartMs": 45190, "OffsetEndMs": 45590}, {"Word": "return", "OffsetStartMs": 45700, "OffsetEndMs": 46100}, {"Word": "would", "OffsetStartMs": 46450, "OffsetEndMs": 46755}, {"Word": "be", "OffsetStartMs": 46755, "OffsetEndMs": 46950}, {"Word": "of", "OffsetStartMs": 46950, "OffsetEndMs": 47100}, {"Word": "that", "OffsetStartMs": 47100, "OffsetEndMs": 47250}, {"Word": "agent", "OffsetStartMs": 47250, "OffsetEndMs": 47535}, {"Word": "if", "OffsetStartMs": 47535, "OffsetEndMs": 47790}, {"Word": "it", "OffsetStartMs": 47790, "OffsetEndMs": 47940}, {"Word": "took", "OffsetStartMs": 47940, "OffsetEndMs": 48120}, {"Word": "that", "OffsetStartMs": 48120, "OffsetEndMs": 48315}, {"Word": "action", "OffsetStartMs": 48315, "OffsetEndMs": 48620}, {"Word": "in", "OffsetStartMs": 48970, "OffsetEndMs": 49275}, {"Word": "that", "OffsetStartMs": 49275, "OffsetEndMs": 49580}, {"Word": "particular", "OffsetStartMs": 49630, "OffsetEndMs": 50030}, {"Word": "state", "OffsetStartMs": 50290, "OffsetEndMs": 50690}], "SpeechSpeed": 13.9}, {"FinalSentence": "Now, one thing that I think maybe we should all be asking ourselves now is this seems like a really powerful function, right? If you had access to this type of a function, this q function, I think you could actually perform a lot of tasks right off the BAT, right? So if you wanted to, for example, understand how to what actions to take in a particular state, and let's suppose I gave you this magical cue function, does anyone have any ideas of how you could transform that cue function to directly infer what action should be taken?", "SliceSentence": "Now one thing that I think maybe we should all be asking ourselves now is this seems like a really powerful function right If you had access to this type of a function this q function I think you could actually perform a lot of tasks right off the BAT right So if you wanted to for example understand how to what actions to take in a particular state and let's suppose I gave you this magical cue function does anyone have any ideas of how you could transform that cue function to directly infer what action should be taken", "StartMs": 822620, "EndMs": 855220, "WordsNum": 100, "Words": [{"Word": "Now", "OffsetStartMs": 160, "OffsetEndMs": 560}, {"Word": "one", "OffsetStartMs": 1240, "OffsetEndMs": 1545}, {"Word": "thing", "OffsetStartMs": 1545, "OffsetEndMs": 1815}, {"Word": "that", "OffsetStartMs": 1815, "OffsetEndMs": 2040}, {"Word": "I", "OffsetStartMs": 2040, "OffsetEndMs": 2190}, {"Word": "think", "OffsetStartMs": 2190, "OffsetEndMs": 2480}, {"Word": "maybe", "OffsetStartMs": 2650, "OffsetEndMs": 3050}, {"Word": "we", "OffsetStartMs": 3220, "OffsetEndMs": 3540}, {"Word": "should", "OffsetStartMs": 3540, "OffsetEndMs": 3705}, {"Word": "all", "OffsetStartMs": 3705, "OffsetEndMs": 3855}, {"Word": "be", "OffsetStartMs": 3855, "OffsetEndMs": 4065}, {"Word": "asking", "OffsetStartMs": 4065, "OffsetEndMs": 4370}, {"Word": "ourselves", "OffsetStartMs": 4450, "OffsetEndMs": 4785}, {"Word": "now", "OffsetStartMs": 4785, "OffsetEndMs": 5115}, {"Word": "is", "OffsetStartMs": 5115, "OffsetEndMs": 5510}, {"Word": "this", "OffsetStartMs": 6340, "OffsetEndMs": 6630}, {"Word": "seems", "OffsetStartMs": 6630, "OffsetEndMs": 6810}, {"Word": "like", "OffsetStartMs": 6810, "OffsetEndMs": 6960}, {"Word": "a", "OffsetStartMs": 6960, "OffsetEndMs": 7170}, {"Word": "really", "OffsetStartMs": 7170, "OffsetEndMs": 7470}, {"Word": "powerful", "OffsetStartMs": 7470, "OffsetEndMs": 7820}, {"Word": "function", "OffsetStartMs": 7840, "OffsetEndMs": 8235}, {"Word": "right", "OffsetStartMs": 8235, "OffsetEndMs": 8520}, {"Word": "If", "OffsetStartMs": 8520, "OffsetEndMs": 8700}, {"Word": "you", "OffsetStartMs": 8700, "OffsetEndMs": 8850}, {"Word": "had", "OffsetStartMs": 8850, "OffsetEndMs": 9110}, {"Word": "access", "OffsetStartMs": 9220, "OffsetEndMs": 9570}, {"Word": "to", "OffsetStartMs": 9570, "OffsetEndMs": 9795}, {"Word": "this", "OffsetStartMs": 9795, "OffsetEndMs": 10020}, {"Word": "type", "OffsetStartMs": 10020, "OffsetEndMs": 10260}, {"Word": "of", "OffsetStartMs": 10260, "OffsetEndMs": 10425}, {"Word": "a", "OffsetStartMs": 10425, "OffsetEndMs": 10560}, {"Word": "function", "OffsetStartMs": 10560, "OffsetEndMs": 10785}, {"Word": "this", "OffsetStartMs": 10785, "OffsetEndMs": 11085}, {"Word": "q", "OffsetStartMs": 11085, "OffsetEndMs": 11310}, {"Word": "function", "OffsetStartMs": 11310, "OffsetEndMs": 11600}, {"Word": "I", "OffsetStartMs": 11830, "OffsetEndMs": 12105}, {"Word": "think", "OffsetStartMs": 12105, "OffsetEndMs": 12255}, {"Word": "you", "OffsetStartMs": 12255, "OffsetEndMs": 12390}, {"Word": "could", "OffsetStartMs": 12390, "OffsetEndMs": 12615}, {"Word": "actually", "OffsetStartMs": 12615, "OffsetEndMs": 12980}, {"Word": "perform", "OffsetStartMs": 13090, "OffsetEndMs": 13380}, {"Word": "a", "OffsetStartMs": 13380, "OffsetEndMs": 13560}, {"Word": "lot", "OffsetStartMs": 13560, "OffsetEndMs": 13725}, {"Word": "of", "OffsetStartMs": 13725, "OffsetEndMs": 13890}, {"Word": "tasks", "OffsetStartMs": 13890, "OffsetEndMs": 14180}, {"Word": "right", "OffsetStartMs": 14290, "OffsetEndMs": 14565}, {"Word": "off", "OffsetStartMs": 14565, "OffsetEndMs": 14730}, {"Word": "the", "OffsetStartMs": 14730, "OffsetEndMs": 14865}, {"Word": "BAT", "OffsetStartMs": 14865, "OffsetEndMs": 15060}, {"Word": "right", "OffsetStartMs": 15060, "OffsetEndMs": 15300}, {"Word": "So", "OffsetStartMs": 15300, "OffsetEndMs": 15590}, {"Word": "if", "OffsetStartMs": 16000, "OffsetEndMs": 16320}, {"Word": "you", "OffsetStartMs": 16320, "OffsetEndMs": 16530}, {"Word": "wanted", "OffsetStartMs": 16530, "OffsetEndMs": 16820}, {"Word": "to", "OffsetStartMs": 16840, "OffsetEndMs": 17145}, {"Word": "for", "OffsetStartMs": 17145, "OffsetEndMs": 17340}, {"Word": "example", "OffsetStartMs": 17340, "OffsetEndMs": 17630}, {"Word": "understand", "OffsetStartMs": 17800, "OffsetEndMs": 18150}, {"Word": "how", "OffsetStartMs": 18150, "OffsetEndMs": 18465}, {"Word": "to", "OffsetStartMs": 18465, "OffsetEndMs": 18830}, {"Word": "what", "OffsetStartMs": 19210, "OffsetEndMs": 19500}, {"Word": "actions", "OffsetStartMs": 19500, "OffsetEndMs": 19790}, {"Word": "to", "OffsetStartMs": 19960, "OffsetEndMs": 20250}, {"Word": "take", "OffsetStartMs": 20250, "OffsetEndMs": 20540}, {"Word": "in", "OffsetStartMs": 20650, "OffsetEndMs": 20925}, {"Word": "a", "OffsetStartMs": 20925, "OffsetEndMs": 21165}, {"Word": "particular", "OffsetStartMs": 21165, "OffsetEndMs": 21530}, {"Word": "state", "OffsetStartMs": 21670, "OffsetEndMs": 22070}, {"Word": "and", "OffsetStartMs": 22420, "OffsetEndMs": 22665}, {"Word": "let's", "OffsetStartMs": 22665, "OffsetEndMs": 22875}, {"Word": "suppose", "OffsetStartMs": 22875, "OffsetEndMs": 23025}, {"Word": "I", "OffsetStartMs": 23025, "OffsetEndMs": 23190}, {"Word": "gave", "OffsetStartMs": 23190, "OffsetEndMs": 23385}, {"Word": "you", "OffsetStartMs": 23385, "OffsetEndMs": 23550}, {"Word": "this", "OffsetStartMs": 23550, "OffsetEndMs": 23715}, {"Word": "magical", "OffsetStartMs": 23715, "OffsetEndMs": 24210}, {"Word": "cue", "OffsetStartMs": 24210, "OffsetEndMs": 24420}, {"Word": "function", "OffsetStartMs": 24420, "OffsetEndMs": 24680}, {"Word": "does", "OffsetStartMs": 25120, "OffsetEndMs": 25455}, {"Word": "anyone", "OffsetStartMs": 25455, "OffsetEndMs": 25650}, {"Word": "have", "OffsetStartMs": 25650, "OffsetEndMs": 25770}, {"Word": "any", "OffsetStartMs": 25770, "OffsetEndMs": 25980}, {"Word": "ideas", "OffsetStartMs": 25980, "OffsetEndMs": 26235}, {"Word": "of", "OffsetStartMs": 26235, "OffsetEndMs": 26460}, {"Word": "how", "OffsetStartMs": 26460, "OffsetEndMs": 26670}, {"Word": "you", "OffsetStartMs": 26670, "OffsetEndMs": 26850}, {"Word": "could", "OffsetStartMs": 26850, "OffsetEndMs": 27140}, {"Word": "transform", "OffsetStartMs": 27160, "OffsetEndMs": 27465}, {"Word": "that", "OffsetStartMs": 27465, "OffsetEndMs": 27675}, {"Word": "cue", "OffsetStartMs": 27675, "OffsetEndMs": 27870}, {"Word": "function", "OffsetStartMs": 27870, "OffsetEndMs": 28130}, {"Word": "to", "OffsetStartMs": 28360, "OffsetEndMs": 28760}, {"Word": "directly", "OffsetStartMs": 28900, "OffsetEndMs": 29300}, {"Word": "infer", "OffsetStartMs": 29920, "OffsetEndMs": 30320}, {"Word": "what", "OffsetStartMs": 30400, "OffsetEndMs": 30675}, {"Word": "action", "OffsetStartMs": 30675, "OffsetEndMs": 30950}, {"Word": "should", "OffsetStartMs": 30970, "OffsetEndMs": 31215}, {"Word": "be", "OffsetStartMs": 31215, "OffsetEndMs": 31350}, {"Word": "taken", "OffsetStartMs": 31350, "OffsetEndMs": 31640}], "SpeechSpeed": 16.0}, {"FinalSentence": "Given a state, you can look at your possible action space and pick the one that gives you the highest q value. Exactly, so that's exactly right. So just to repeat that one more time, the q function tells us for any possible action, right? What is the expected reward for that action to be taken? So if we wanted to take a specific action given in a specific state, ultimately we need to, you know, figure out which action is the best action. The way we do that from A Q function is simply to pick the action that will maximize our future reward. And we can simply try out number one, if we have a discrete action space, we can simply try out all possible actions, compute their q value for every single possible actions based on the state that we currently find ourselves in, and then we pick the action that is going to result in the highest q value.", "SliceSentence": "Given a state you can look at your possible action space and pick the one that gives you the highest q value Exactly so that's exactly right So just to repeat that one more time the q function tells us for any possible action right What is the expected reward for that action to be taken So if we wanted to take a specific action given in a specific state ultimately we need to you know figure out which action is the best action The way we do that from A Q function is simply to pick the action that will maximize our future reward And we can simply try out number one if we have a discrete action space we can simply try out all possible actions compute their q value for every single possible actions based on the state that we currently find ourselves in and then we pick the action that is going to result in the highest q value", "StartMs": 857320, "EndMs": 908680, "WordsNum": 163, "Words": [{"Word": "Given", "OffsetStartMs": 70, "OffsetEndMs": 390}, {"Word": "a", "OffsetStartMs": 390, "OffsetEndMs": 630}, {"Word": "state", "OffsetStartMs": 630, "OffsetEndMs": 950}, {"Word": "you", "OffsetStartMs": 1000, "OffsetEndMs": 1275}, {"Word": "can", "OffsetStartMs": 1275, "OffsetEndMs": 1425}, {"Word": "look", "OffsetStartMs": 1425, "OffsetEndMs": 1575}, {"Word": "at", "OffsetStartMs": 1575, "OffsetEndMs": 1770}, {"Word": "your", "OffsetStartMs": 1770, "OffsetEndMs": 1995}, {"Word": "possible", "OffsetStartMs": 1995, "OffsetEndMs": 2295}, {"Word": "action", "OffsetStartMs": 2295, "OffsetEndMs": 2690}, {"Word": "space", "OffsetStartMs": 2770, "OffsetEndMs": 3105}, {"Word": "and", "OffsetStartMs": 3105, "OffsetEndMs": 3330}, {"Word": "pick", "OffsetStartMs": 3330, "OffsetEndMs": 3525}, {"Word": "the", "OffsetStartMs": 3525, "OffsetEndMs": 3690}, {"Word": "one", "OffsetStartMs": 3690, "OffsetEndMs": 3840}, {"Word": "that", "OffsetStartMs": 3840, "OffsetEndMs": 4005}, {"Word": "gives", "OffsetStartMs": 4005, "OffsetEndMs": 4170}, {"Word": "you", "OffsetStartMs": 4170, "OffsetEndMs": 4320}, {"Word": "the", "OffsetStartMs": 4320, "OffsetEndMs": 4440}, {"Word": "highest", "OffsetStartMs": 4440, "OffsetEndMs": 4665}, {"Word": "q", "OffsetStartMs": 4665, "OffsetEndMs": 4905}, {"Word": "value", "OffsetStartMs": 4905, "OffsetEndMs": 5180}, {"Word": "Exactly", "OffsetStartMs": 5590, "OffsetEndMs": 5990}, {"Word": "so", "OffsetStartMs": 6370, "OffsetEndMs": 6770}, {"Word": "that's", "OffsetStartMs": 6880, "OffsetEndMs": 7260}, {"Word": "exactly", "OffsetStartMs": 7260, "OffsetEndMs": 7500}, {"Word": "right", "OffsetStartMs": 7500, "OffsetEndMs": 7785}, {"Word": "So", "OffsetStartMs": 7785, "OffsetEndMs": 8120}, {"Word": "just", "OffsetStartMs": 8200, "OffsetEndMs": 8490}, {"Word": "to", "OffsetStartMs": 8490, "OffsetEndMs": 8715}, {"Word": "repeat", "OffsetStartMs": 8715, "OffsetEndMs": 8925}, {"Word": "that", "OffsetStartMs": 8925, "OffsetEndMs": 9075}, {"Word": "one", "OffsetStartMs": 9075, "OffsetEndMs": 9225}, {"Word": "more", "OffsetStartMs": 9225, "OffsetEndMs": 9405}, {"Word": "time", "OffsetStartMs": 9405, "OffsetEndMs": 9710}, {"Word": "the", "OffsetStartMs": 10210, "OffsetEndMs": 10485}, {"Word": "q", "OffsetStartMs": 10485, "OffsetEndMs": 10635}, {"Word": "function", "OffsetStartMs": 10635, "OffsetEndMs": 10890}, {"Word": "tells", "OffsetStartMs": 10890, "OffsetEndMs": 11160}, {"Word": "us", "OffsetStartMs": 11160, "OffsetEndMs": 11355}, {"Word": "for", "OffsetStartMs": 11355, "OffsetEndMs": 11505}, {"Word": "any", "OffsetStartMs": 11505, "OffsetEndMs": 11700}, {"Word": "possible", "OffsetStartMs": 11700, "OffsetEndMs": 12030}, {"Word": "action", "OffsetStartMs": 12030, "OffsetEndMs": 12410}, {"Word": "right", "OffsetStartMs": 12850, "OffsetEndMs": 13250}, {"Word": "What", "OffsetStartMs": 13720, "OffsetEndMs": 13980}, {"Word": "is", "OffsetStartMs": 13980, "OffsetEndMs": 14190}, {"Word": "the", "OffsetStartMs": 14190, "OffsetEndMs": 14540}, {"Word": "expected", "OffsetStartMs": 14590, "OffsetEndMs": 14990}, {"Word": "reward", "OffsetStartMs": 15280, "OffsetEndMs": 15680}, {"Word": "for", "OffsetStartMs": 15760, "OffsetEndMs": 16020}, {"Word": "that", "OffsetStartMs": 16020, "OffsetEndMs": 16155}, {"Word": "action", "OffsetStartMs": 16155, "OffsetEndMs": 16430}, {"Word": "to", "OffsetStartMs": 16630, "OffsetEndMs": 16875}, {"Word": "be", "OffsetStartMs": 16875, "OffsetEndMs": 16995}, {"Word": "taken", "OffsetStartMs": 16995, "OffsetEndMs": 17270}, {"Word": "So", "OffsetStartMs": 17290, "OffsetEndMs": 17535}, {"Word": "if", "OffsetStartMs": 17535, "OffsetEndMs": 17640}, {"Word": "we", "OffsetStartMs": 17640, "OffsetEndMs": 17760}, {"Word": "wanted", "OffsetStartMs": 17760, "OffsetEndMs": 17955}, {"Word": "to", "OffsetStartMs": 17955, "OffsetEndMs": 18290}, {"Word": "take", "OffsetStartMs": 18460, "OffsetEndMs": 18860}, {"Word": "a", "OffsetStartMs": 18880, "OffsetEndMs": 19260}, {"Word": "specific", "OffsetStartMs": 19260, "OffsetEndMs": 19605}, {"Word": "action", "OffsetStartMs": 19605, "OffsetEndMs": 19970}, {"Word": "given", "OffsetStartMs": 20080, "OffsetEndMs": 20385}, {"Word": "in", "OffsetStartMs": 20385, "OffsetEndMs": 20520}, {"Word": "a", "OffsetStartMs": 20520, "OffsetEndMs": 20640}, {"Word": "specific", "OffsetStartMs": 20640, "OffsetEndMs": 20930}, {"Word": "state", "OffsetStartMs": 21010, "OffsetEndMs": 21410}, {"Word": "ultimately", "OffsetStartMs": 22210, "OffsetEndMs": 22610}, {"Word": "we", "OffsetStartMs": 22780, "OffsetEndMs": 23085}, {"Word": "need", "OffsetStartMs": 23085, "OffsetEndMs": 23310}, {"Word": "to", "OffsetStartMs": 23310, "OffsetEndMs": 23630}, {"Word": "you", "OffsetStartMs": 23650, "OffsetEndMs": 23910}, {"Word": "know", "OffsetStartMs": 23910, "OffsetEndMs": 24135}, {"Word": "figure", "OffsetStartMs": 24135, "OffsetEndMs": 24420}, {"Word": "out", "OffsetStartMs": 24420, "OffsetEndMs": 24720}, {"Word": "which", "OffsetStartMs": 24720, "OffsetEndMs": 25020}, {"Word": "action", "OffsetStartMs": 25020, "OffsetEndMs": 25340}, {"Word": "is", "OffsetStartMs": 25600, "OffsetEndMs": 25890}, {"Word": "the", "OffsetStartMs": 25890, "OffsetEndMs": 26025}, {"Word": "best", "OffsetStartMs": 26025, "OffsetEndMs": 26190}, {"Word": "action", "OffsetStartMs": 26190, "OffsetEndMs": 26505}, {"Word": "The", "OffsetStartMs": 26505, "OffsetEndMs": 26745}, {"Word": "way", "OffsetStartMs": 26745, "OffsetEndMs": 26865}, {"Word": "we", "OffsetStartMs": 26865, "OffsetEndMs": 27000}, {"Word": "do", "OffsetStartMs": 27000, "OffsetEndMs": 27135}, {"Word": "that", "OffsetStartMs": 27135, "OffsetEndMs": 27360}, {"Word": "from", "OffsetStartMs": 27360, "OffsetEndMs": 27585}, {"Word": "A", "OffsetStartMs": 27585, "OffsetEndMs": 27860}, {"Word": "Q", "OffsetStartMs": 27880, "OffsetEndMs": 28170}, {"Word": "function", "OffsetStartMs": 28170, "OffsetEndMs": 28460}, {"Word": "is", "OffsetStartMs": 28900, "OffsetEndMs": 29300}, {"Word": "simply", "OffsetStartMs": 29380, "OffsetEndMs": 29780}, {"Word": "to", "OffsetStartMs": 29800, "OffsetEndMs": 30165}, {"Word": "pick", "OffsetStartMs": 30165, "OffsetEndMs": 30450}, {"Word": "the", "OffsetStartMs": 30450, "OffsetEndMs": 30615}, {"Word": "action", "OffsetStartMs": 30615, "OffsetEndMs": 30860}, {"Word": "that", "OffsetStartMs": 31120, "OffsetEndMs": 31395}, {"Word": "will", "OffsetStartMs": 31395, "OffsetEndMs": 31560}, {"Word": "maximize", "OffsetStartMs": 31560, "OffsetEndMs": 32240}, {"Word": "our", "OffsetStartMs": 32440, "OffsetEndMs": 32760}, {"Word": "future", "OffsetStartMs": 32760, "OffsetEndMs": 33080}, {"Word": "reward", "OffsetStartMs": 33160, "OffsetEndMs": 33560}, {"Word": "And", "OffsetStartMs": 33730, "OffsetEndMs": 33990}, {"Word": "we", "OffsetStartMs": 33990, "OffsetEndMs": 34125}, {"Word": "can", "OffsetStartMs": 34125, "OffsetEndMs": 34400}, {"Word": "simply", "OffsetStartMs": 34480, "OffsetEndMs": 34880}, {"Word": "try", "OffsetStartMs": 35800, "OffsetEndMs": 36090}, {"Word": "out", "OffsetStartMs": 36090, "OffsetEndMs": 36375}, {"Word": "number", "OffsetStartMs": 36375, "OffsetEndMs": 36690}, {"Word": "one", "OffsetStartMs": 36690, "OffsetEndMs": 36945}, {"Word": "if", "OffsetStartMs": 36945, "OffsetEndMs": 37185}, {"Word": "we", "OffsetStartMs": 37185, "OffsetEndMs": 37335}, {"Word": "have", "OffsetStartMs": 37335, "OffsetEndMs": 37425}, {"Word": "a", "OffsetStartMs": 37425, "OffsetEndMs": 37530}, {"Word": "discrete", "OffsetStartMs": 37530, "OffsetEndMs": 37965}, {"Word": "action", "OffsetStartMs": 37965, "OffsetEndMs": 38270}, {"Word": "space", "OffsetStartMs": 38350, "OffsetEndMs": 38700}, {"Word": "we", "OffsetStartMs": 38700, "OffsetEndMs": 38910}, {"Word": "can", "OffsetStartMs": 38910, "OffsetEndMs": 39075}, {"Word": "simply", "OffsetStartMs": 39075, "OffsetEndMs": 39375}, {"Word": "try", "OffsetStartMs": 39375, "OffsetEndMs": 39630}, {"Word": "out", "OffsetStartMs": 39630, "OffsetEndMs": 39765}, {"Word": "all", "OffsetStartMs": 39765, "OffsetEndMs": 39975}, {"Word": "possible", "OffsetStartMs": 39975, "OffsetEndMs": 40305}, {"Word": "actions", "OffsetStartMs": 40305, "OffsetEndMs": 40700}, {"Word": "compute", "OffsetStartMs": 41110, "OffsetEndMs": 41565}, {"Word": "their", "OffsetStartMs": 41565, "OffsetEndMs": 41805}, {"Word": "q", "OffsetStartMs": 41805, "OffsetEndMs": 42045}, {"Word": "value", "OffsetStartMs": 42045, "OffsetEndMs": 42350}, {"Word": "for", "OffsetStartMs": 42730, "OffsetEndMs": 43005}, {"Word": "every", "OffsetStartMs": 43005, "OffsetEndMs": 43260}, {"Word": "single", "OffsetStartMs": 43260, "OffsetEndMs": 43575}, {"Word": "possible", "OffsetStartMs": 43575, "OffsetEndMs": 43875}, {"Word": "actions", "OffsetStartMs": 43875, "OffsetEndMs": 44240}, {"Word": "based", "OffsetStartMs": 44290, "OffsetEndMs": 44580}, {"Word": "on", "OffsetStartMs": 44580, "OffsetEndMs": 44715}, {"Word": "the", "OffsetStartMs": 44715, "OffsetEndMs": 44835}, {"Word": "state", "OffsetStartMs": 44835, "OffsetEndMs": 45000}, {"Word": "that", "OffsetStartMs": 45000, "OffsetEndMs": 45150}, {"Word": "we", "OffsetStartMs": 45150, "OffsetEndMs": 45300}, {"Word": "currently", "OffsetStartMs": 45300, "OffsetEndMs": 45540}, {"Word": "find", "OffsetStartMs": 45540, "OffsetEndMs": 45870}, {"Word": "ourselves", "OffsetStartMs": 45870, "OffsetEndMs": 46170}, {"Word": "in", "OffsetStartMs": 46170, "OffsetEndMs": 46490}, {"Word": "and", "OffsetStartMs": 46630, "OffsetEndMs": 46875}, {"Word": "then", "OffsetStartMs": 46875, "OffsetEndMs": 46965}, {"Word": "we", "OffsetStartMs": 46965, "OffsetEndMs": 47115}, {"Word": "pick", "OffsetStartMs": 47115, "OffsetEndMs": 47340}, {"Word": "the", "OffsetStartMs": 47340, "OffsetEndMs": 47505}, {"Word": "action", "OffsetStartMs": 47505, "OffsetEndMs": 47750}, {"Word": "that", "OffsetStartMs": 48160, "OffsetEndMs": 48420}, {"Word": "is", "OffsetStartMs": 48420, "OffsetEndMs": 48585}, {"Word": "going", "OffsetStartMs": 48585, "OffsetEndMs": 48795}, {"Word": "to", "OffsetStartMs": 48795, "OffsetEndMs": 49100}, {"Word": "result", "OffsetStartMs": 49180, "OffsetEndMs": 49580}, {"Word": "in", "OffsetStartMs": 49630, "OffsetEndMs": 49905}, {"Word": "the", "OffsetStartMs": 49905, "OffsetEndMs": 50040}, {"Word": "highest", "OffsetStartMs": 50040, "OffsetEndMs": 50300}, {"Word": "q", "OffsetStartMs": 50320, "OffsetEndMs": 50580}, {"Word": "value", "OffsetStartMs": 50580, "OffsetEndMs": 50840}], "SpeechSpeed": 16.2}, {"FinalSentence": "If we have a continuous action space, maybe we do something a bit more intelligent, maybe following the gradients along this q value curve and maximizing it as part of an optimization procedure.", "SliceSentence": "If we have a continuous action space maybe we do something a bit more intelligent maybe following the gradients along this q value curve and maximizing it as part of an optimization procedure", "StartMs": 909620, "EndMs": 920620, "WordsNum": 33, "Words": [{"Word": "If", "OffsetStartMs": 70, "OffsetEndMs": 345}, {"Word": "we", "OffsetStartMs": 345, "OffsetEndMs": 465}, {"Word": "have", "OffsetStartMs": 465, "OffsetEndMs": 540}, {"Word": "a", "OffsetStartMs": 540, "OffsetEndMs": 705}, {"Word": "continuous", "OffsetStartMs": 705, "OffsetEndMs": 990}, {"Word": "action", "OffsetStartMs": 990, "OffsetEndMs": 1340}, {"Word": "space", "OffsetStartMs": 1390, "OffsetEndMs": 1785}, {"Word": "maybe", "OffsetStartMs": 1785, "OffsetEndMs": 2100}, {"Word": "we", "OffsetStartMs": 2100, "OffsetEndMs": 2295}, {"Word": "do", "OffsetStartMs": 2295, "OffsetEndMs": 2445}, {"Word": "something", "OffsetStartMs": 2445, "OffsetEndMs": 2640}, {"Word": "a", "OffsetStartMs": 2640, "OffsetEndMs": 2820}, {"Word": "bit", "OffsetStartMs": 2820, "OffsetEndMs": 2955}, {"Word": "more", "OffsetStartMs": 2955, "OffsetEndMs": 3180}, {"Word": "intelligent", "OffsetStartMs": 3180, "OffsetEndMs": 3530}, {"Word": "maybe", "OffsetStartMs": 3640, "OffsetEndMs": 4040}, {"Word": "following", "OffsetStartMs": 4210, "OffsetEndMs": 4605}, {"Word": "the", "OffsetStartMs": 4605, "OffsetEndMs": 4905}, {"Word": "gradients", "OffsetStartMs": 4905, "OffsetEndMs": 5390}, {"Word": "along", "OffsetStartMs": 5440, "OffsetEndMs": 5760}, {"Word": "this", "OffsetStartMs": 5760, "OffsetEndMs": 5985}, {"Word": "q", "OffsetStartMs": 5985, "OffsetEndMs": 6150}, {"Word": "value", "OffsetStartMs": 6150, "OffsetEndMs": 6405}, {"Word": "curve", "OffsetStartMs": 6405, "OffsetEndMs": 6800}, {"Word": "and", "OffsetStartMs": 7210, "OffsetEndMs": 7500}, {"Word": "maximizing", "OffsetStartMs": 7500, "OffsetEndMs": 8025}, {"Word": "it", "OffsetStartMs": 8025, "OffsetEndMs": 8220}, {"Word": "as", "OffsetStartMs": 8220, "OffsetEndMs": 8370}, {"Word": "part", "OffsetStartMs": 8370, "OffsetEndMs": 8535}, {"Word": "of", "OffsetStartMs": 8535, "OffsetEndMs": 8655}, {"Word": "an", "OffsetStartMs": 8655, "OffsetEndMs": 8835}, {"Word": "optimization", "OffsetStartMs": 8835, "OffsetEndMs": 9360}, {"Word": "procedure", "OffsetStartMs": 9360, "OffsetEndMs": 9740}], "SpeechSpeed": 17.4}, {"FinalSentence": "But generally in this lecture, what I want to focus on is actually how we can obtain this q function. To start with, I I kind of skipped a lot of steps in that last slide where I just said let's suppose I give you this magical q function, how can you determine what action to take? But in reality we're not given that q function. We have to learn that q function using deep learning. And that's what today's lecture is going to be talking about primarily is first of all, how can we construct and learn that q function from data.", "SliceSentence": "But generally in this lecture what I want to focus on is actually how we can obtain this q function To start with I I kind of skipped a lot of steps in that last slide where I just said let's suppose I give you this magical q function how can you determine what action to take But in reality we're not given that q function We have to learn that q function using deep learning And that's what today's lecture is going to be talking about primarily is first of all how can we construct and learn that q function from data", "StartMs": 920620, "EndMs": 948340, "WordsNum": 103, "Words": [{"Word": "But", "OffsetStartMs": 0, "OffsetEndMs": 380}, {"Word": "generally", "OffsetStartMs": 490, "OffsetEndMs": 890}, {"Word": "in", "OffsetStartMs": 1090, "OffsetEndMs": 1380}, {"Word": "this", "OffsetStartMs": 1380, "OffsetEndMs": 1605}, {"Word": "lecture", "OffsetStartMs": 1605, "OffsetEndMs": 1940}, {"Word": "what", "OffsetStartMs": 2170, "OffsetEndMs": 2415}, {"Word": "I", "OffsetStartMs": 2415, "OffsetEndMs": 2520}, {"Word": "want", "OffsetStartMs": 2520, "OffsetEndMs": 2670}, {"Word": "to", "OffsetStartMs": 2670, "OffsetEndMs": 2820}, {"Word": "focus", "OffsetStartMs": 2820, "OffsetEndMs": 3045}, {"Word": "on", "OffsetStartMs": 3045, "OffsetEndMs": 3410}, {"Word": "is", "OffsetStartMs": 3460, "OffsetEndMs": 3860}, {"Word": "actually", "OffsetStartMs": 4120, "OffsetEndMs": 4485}, {"Word": "how", "OffsetStartMs": 4485, "OffsetEndMs": 4785}, {"Word": "we", "OffsetStartMs": 4785, "OffsetEndMs": 4995}, {"Word": "can", "OffsetStartMs": 4995, "OffsetEndMs": 5115}, {"Word": "obtain", "OffsetStartMs": 5115, "OffsetEndMs": 5600}, {"Word": "this", "OffsetStartMs": 5740, "OffsetEndMs": 6090}, {"Word": "q", "OffsetStartMs": 6090, "OffsetEndMs": 6330}, {"Word": "function", "OffsetStartMs": 6330, "OffsetEndMs": 6600}, {"Word": "To", "OffsetStartMs": 6600, "OffsetEndMs": 6870}, {"Word": "start", "OffsetStartMs": 6870, "OffsetEndMs": 7065}, {"Word": "with", "OffsetStartMs": 7065, "OffsetEndMs": 7370}, {"Word": "I", "OffsetStartMs": 7420, "OffsetEndMs": 7820}, {"Word": "I", "OffsetStartMs": 7990, "OffsetEndMs": 8340}, {"Word": "kind", "OffsetStartMs": 8340, "OffsetEndMs": 8535}, {"Word": "of", "OffsetStartMs": 8535, "OffsetEndMs": 8685}, {"Word": "skipped", "OffsetStartMs": 8685, "OffsetEndMs": 8895}, {"Word": "a", "OffsetStartMs": 8895, "OffsetEndMs": 9030}, {"Word": "lot", "OffsetStartMs": 9030, "OffsetEndMs": 9180}, {"Word": "of", "OffsetStartMs": 9180, "OffsetEndMs": 9360}, {"Word": "steps", "OffsetStartMs": 9360, "OffsetEndMs": 9615}, {"Word": "in", "OffsetStartMs": 9615, "OffsetEndMs": 9840}, {"Word": "that", "OffsetStartMs": 9840, "OffsetEndMs": 9990}, {"Word": "last", "OffsetStartMs": 9990, "OffsetEndMs": 10245}, {"Word": "slide", "OffsetStartMs": 10245, "OffsetEndMs": 10545}, {"Word": "where", "OffsetStartMs": 10545, "OffsetEndMs": 10710}, {"Word": "I", "OffsetStartMs": 10710, "OffsetEndMs": 10815}, {"Word": "just", "OffsetStartMs": 10815, "OffsetEndMs": 10965}, {"Word": "said", "OffsetStartMs": 10965, "OffsetEndMs": 11115}, {"Word": "let's", "OffsetStartMs": 11115, "OffsetEndMs": 11400}, {"Word": "suppose", "OffsetStartMs": 11400, "OffsetEndMs": 11550}, {"Word": "I", "OffsetStartMs": 11550, "OffsetEndMs": 11730}, {"Word": "give", "OffsetStartMs": 11730, "OffsetEndMs": 11955}, {"Word": "you", "OffsetStartMs": 11955, "OffsetEndMs": 12150}, {"Word": "this", "OffsetStartMs": 12150, "OffsetEndMs": 12345}, {"Word": "magical", "OffsetStartMs": 12345, "OffsetEndMs": 12840}, {"Word": "q", "OffsetStartMs": 12840, "OffsetEndMs": 13005}, {"Word": "function", "OffsetStartMs": 13005, "OffsetEndMs": 13275}, {"Word": "how", "OffsetStartMs": 13275, "OffsetEndMs": 13560}, {"Word": "can", "OffsetStartMs": 13560, "OffsetEndMs": 13695}, {"Word": "you", "OffsetStartMs": 13695, "OffsetEndMs": 13890}, {"Word": "determine", "OffsetStartMs": 13890, "OffsetEndMs": 14175}, {"Word": "what", "OffsetStartMs": 14175, "OffsetEndMs": 14370}, {"Word": "action", "OffsetStartMs": 14370, "OffsetEndMs": 14610}, {"Word": "to", "OffsetStartMs": 14610, "OffsetEndMs": 14850}, {"Word": "take", "OffsetStartMs": 14850, "OffsetEndMs": 15110}, {"Word": "But", "OffsetStartMs": 15370, "OffsetEndMs": 15600}, {"Word": "in", "OffsetStartMs": 15600, "OffsetEndMs": 15705}, {"Word": "reality", "OffsetStartMs": 15705, "OffsetEndMs": 15980}, {"Word": "we're", "OffsetStartMs": 16060, "OffsetEndMs": 16380}, {"Word": "not", "OffsetStartMs": 16380, "OffsetEndMs": 16500}, {"Word": "given", "OffsetStartMs": 16500, "OffsetEndMs": 16695}, {"Word": "that", "OffsetStartMs": 16695, "OffsetEndMs": 16920}, {"Word": "q", "OffsetStartMs": 16920, "OffsetEndMs": 17115}, {"Word": "function", "OffsetStartMs": 17115, "OffsetEndMs": 17385}, {"Word": "We", "OffsetStartMs": 17385, "OffsetEndMs": 17625}, {"Word": "have", "OffsetStartMs": 17625, "OffsetEndMs": 17760}, {"Word": "to", "OffsetStartMs": 17760, "OffsetEndMs": 17925}, {"Word": "learn", "OffsetStartMs": 17925, "OffsetEndMs": 18120}, {"Word": "that", "OffsetStartMs": 18120, "OffsetEndMs": 18345}, {"Word": "q", "OffsetStartMs": 18345, "OffsetEndMs": 18525}, {"Word": "function", "OffsetStartMs": 18525, "OffsetEndMs": 18795}, {"Word": "using", "OffsetStartMs": 18795, "OffsetEndMs": 19185}, {"Word": "deep", "OffsetStartMs": 19185, "OffsetEndMs": 19485}, {"Word": "learning", "OffsetStartMs": 19485, "OffsetEndMs": 19790}, {"Word": "And", "OffsetStartMs": 20140, "OffsetEndMs": 20400}, {"Word": "that's", "OffsetStartMs": 20400, "OffsetEndMs": 20625}, {"Word": "what", "OffsetStartMs": 20625, "OffsetEndMs": 20775}, {"Word": "today's", "OffsetStartMs": 20775, "OffsetEndMs": 21105}, {"Word": "lecture", "OffsetStartMs": 21105, "OffsetEndMs": 21285}, {"Word": "is", "OffsetStartMs": 21285, "OffsetEndMs": 21480}, {"Word": "going", "OffsetStartMs": 21480, "OffsetEndMs": 21615}, {"Word": "to", "OffsetStartMs": 21615, "OffsetEndMs": 21720}, {"Word": "be", "OffsetStartMs": 21720, "OffsetEndMs": 21950}, {"Word": "talking", "OffsetStartMs": 22150, "OffsetEndMs": 22530}, {"Word": "about", "OffsetStartMs": 22530, "OffsetEndMs": 22830}, {"Word": "primarily", "OffsetStartMs": 22830, "OffsetEndMs": 23150}, {"Word": "is", "OffsetStartMs": 23230, "OffsetEndMs": 23520}, {"Word": "first", "OffsetStartMs": 23520, "OffsetEndMs": 23685}, {"Word": "of", "OffsetStartMs": 23685, "OffsetEndMs": 23775}, {"Word": "all", "OffsetStartMs": 23775, "OffsetEndMs": 23880}, {"Word": "how", "OffsetStartMs": 23880, "OffsetEndMs": 24075}, {"Word": "can", "OffsetStartMs": 24075, "OffsetEndMs": 24255}, {"Word": "we", "OffsetStartMs": 24255, "OffsetEndMs": 24530}, {"Word": "construct", "OffsetStartMs": 24580, "OffsetEndMs": 24980}, {"Word": "and", "OffsetStartMs": 25180, "OffsetEndMs": 25515}, {"Word": "learn", "OffsetStartMs": 25515, "OffsetEndMs": 25770}, {"Word": "that", "OffsetStartMs": 25770, "OffsetEndMs": 26010}, {"Word": "q", "OffsetStartMs": 26010, "OffsetEndMs": 26205}, {"Word": "function", "OffsetStartMs": 26205, "OffsetEndMs": 26475}, {"Word": "from", "OffsetStartMs": 26475, "OffsetEndMs": 26775}, {"Word": "data", "OffsetStartMs": 26775, "OffsetEndMs": 27080}], "SpeechSpeed": 18.8}, {"FinalSentence": "And then of course, the final step is use that q function to, you know, take some actions in the real world. And broadly speaking, there are two classes of reinforcement learning algorithms that we're going to briefly touch on as part of today's lecture. The first class is what's going to be called value learning, and that's exactly this process that we've just talked about. Value learning tries to estimate our q function, right? So to find that q function q given our state and our action, and then use that q function to, you know, optimize for the best action to take given a particular state that we find ourselves in.", "SliceSentence": "And then of course the final step is use that q function to you know take some actions in the real world And broadly speaking there are two classes of reinforcement learning algorithms that we're going to briefly touch on as part of today's lecture The first class is what's going to be called value learning and that's exactly this process that we've just talked about Value learning tries to estimate our q function right So to find that q function q given our state and our action and then use that q function to you know optimize for the best action to take given a particular state that we find ourselves in", "StartMs": 948340, "EndMs": 981700, "WordsNum": 113, "Words": [{"Word": "And", "OffsetStartMs": 0, "OffsetEndMs": 135}, {"Word": "then", "OffsetStartMs": 135, "OffsetEndMs": 270}, {"Word": "of", "OffsetStartMs": 270, "OffsetEndMs": 420}, {"Word": "course", "OffsetStartMs": 420, "OffsetEndMs": 630}, {"Word": "the", "OffsetStartMs": 630, "OffsetEndMs": 810}, {"Word": "final", "OffsetStartMs": 810, "OffsetEndMs": 1065}, {"Word": "step", "OffsetStartMs": 1065, "OffsetEndMs": 1350}, {"Word": "is", "OffsetStartMs": 1350, "OffsetEndMs": 1545}, {"Word": "use", "OffsetStartMs": 1545, "OffsetEndMs": 1740}, {"Word": "that", "OffsetStartMs": 1740, "OffsetEndMs": 1950}, {"Word": "q", "OffsetStartMs": 1950, "OffsetEndMs": 2160}, {"Word": "function", "OffsetStartMs": 2160, "OffsetEndMs": 2450}, {"Word": "to", "OffsetStartMs": 2620, "OffsetEndMs": 3020}, {"Word": "you", "OffsetStartMs": 3220, "OffsetEndMs": 3450}, {"Word": "know", "OffsetStartMs": 3450, "OffsetEndMs": 3630}, {"Word": "take", "OffsetStartMs": 3630, "OffsetEndMs": 3885}, {"Word": "some", "OffsetStartMs": 3885, "OffsetEndMs": 4050}, {"Word": "actions", "OffsetStartMs": 4050, "OffsetEndMs": 4310}, {"Word": "in", "OffsetStartMs": 4450, "OffsetEndMs": 4725}, {"Word": "the", "OffsetStartMs": 4725, "OffsetEndMs": 4860}, {"Word": "real", "OffsetStartMs": 4860, "OffsetEndMs": 5010}, {"Word": "world", "OffsetStartMs": 5010, "OffsetEndMs": 5300}, {"Word": "And", "OffsetStartMs": 5350, "OffsetEndMs": 5655}, {"Word": "broadly", "OffsetStartMs": 5655, "OffsetEndMs": 6090}, {"Word": "speaking", "OffsetStartMs": 6090, "OffsetEndMs": 6390}, {"Word": "there", "OffsetStartMs": 6390, "OffsetEndMs": 6615}, {"Word": "are", "OffsetStartMs": 6615, "OffsetEndMs": 6795}, {"Word": "two", "OffsetStartMs": 6795, "OffsetEndMs": 7050}, {"Word": "classes", "OffsetStartMs": 7050, "OffsetEndMs": 7370}, {"Word": "of", "OffsetStartMs": 7870, "OffsetEndMs": 8175}, {"Word": "reinforcement", "OffsetStartMs": 8175, "OffsetEndMs": 8775}, {"Word": "learning", "OffsetStartMs": 8775, "OffsetEndMs": 9050}, {"Word": "algorithms", "OffsetStartMs": 9070, "OffsetEndMs": 9465}, {"Word": "that", "OffsetStartMs": 9465, "OffsetEndMs": 9600}, {"Word": "we're", "OffsetStartMs": 9600, "OffsetEndMs": 9780}, {"Word": "going", "OffsetStartMs": 9780, "OffsetEndMs": 9885}, {"Word": "to", "OffsetStartMs": 9885, "OffsetEndMs": 10020}, {"Word": "briefly", "OffsetStartMs": 10020, "OffsetEndMs": 10260}, {"Word": "touch", "OffsetStartMs": 10260, "OffsetEndMs": 10530}, {"Word": "on", "OffsetStartMs": 10530, "OffsetEndMs": 10710}, {"Word": "as", "OffsetStartMs": 10710, "OffsetEndMs": 10875}, {"Word": "part", "OffsetStartMs": 10875, "OffsetEndMs": 10995}, {"Word": "of", "OffsetStartMs": 10995, "OffsetEndMs": 11130}, {"Word": "today's", "OffsetStartMs": 11130, "OffsetEndMs": 11490}, {"Word": "lecture", "OffsetStartMs": 11490, "OffsetEndMs": 11750}, {"Word": "The", "OffsetStartMs": 12160, "OffsetEndMs": 12435}, {"Word": "first", "OffsetStartMs": 12435, "OffsetEndMs": 12660}, {"Word": "class", "OffsetStartMs": 12660, "OffsetEndMs": 12945}, {"Word": "is", "OffsetStartMs": 12945, "OffsetEndMs": 13230}, {"Word": "what's", "OffsetStartMs": 13230, "OffsetEndMs": 13515}, {"Word": "going", "OffsetStartMs": 13515, "OffsetEndMs": 13635}, {"Word": "to", "OffsetStartMs": 13635, "OffsetEndMs": 13740}, {"Word": "be", "OffsetStartMs": 13740, "OffsetEndMs": 13845}, {"Word": "called", "OffsetStartMs": 13845, "OffsetEndMs": 14040}, {"Word": "value", "OffsetStartMs": 14040, "OffsetEndMs": 14340}, {"Word": "learning", "OffsetStartMs": 14340, "OffsetEndMs": 14700}, {"Word": "and", "OffsetStartMs": 14700, "OffsetEndMs": 14940}, {"Word": "that's", "OffsetStartMs": 14940, "OffsetEndMs": 15240}, {"Word": "exactly", "OffsetStartMs": 15240, "OffsetEndMs": 15525}, {"Word": "this", "OffsetStartMs": 15525, "OffsetEndMs": 15780}, {"Word": "process", "OffsetStartMs": 15780, "OffsetEndMs": 16065}, {"Word": "that", "OffsetStartMs": 16065, "OffsetEndMs": 16320}, {"Word": "we've", "OffsetStartMs": 16320, "OffsetEndMs": 16515}, {"Word": "just", "OffsetStartMs": 16515, "OffsetEndMs": 16680}, {"Word": "talked", "OffsetStartMs": 16680, "OffsetEndMs": 16935}, {"Word": "about", "OffsetStartMs": 16935, "OffsetEndMs": 17220}, {"Word": "Value", "OffsetStartMs": 17220, "OffsetEndMs": 17550}, {"Word": "learning", "OffsetStartMs": 17550, "OffsetEndMs": 17910}, {"Word": "tries", "OffsetStartMs": 17910, "OffsetEndMs": 18210}, {"Word": "to", "OffsetStartMs": 18210, "OffsetEndMs": 18530}, {"Word": "estimate", "OffsetStartMs": 18580, "OffsetEndMs": 18980}, {"Word": "our", "OffsetStartMs": 19180, "OffsetEndMs": 19515}, {"Word": "q", "OffsetStartMs": 19515, "OffsetEndMs": 19725}, {"Word": "function", "OffsetStartMs": 19725, "OffsetEndMs": 20000}, {"Word": "right", "OffsetStartMs": 20140, "OffsetEndMs": 20445}, {"Word": "So", "OffsetStartMs": 20445, "OffsetEndMs": 20655}, {"Word": "to", "OffsetStartMs": 20655, "OffsetEndMs": 20850}, {"Word": "find", "OffsetStartMs": 20850, "OffsetEndMs": 21140}, {"Word": "that", "OffsetStartMs": 21160, "OffsetEndMs": 21480}, {"Word": "q", "OffsetStartMs": 21480, "OffsetEndMs": 21690}, {"Word": "function", "OffsetStartMs": 21690, "OffsetEndMs": 21980}, {"Word": "q", "OffsetStartMs": 22090, "OffsetEndMs": 22490}, {"Word": "given", "OffsetStartMs": 22660, "OffsetEndMs": 22950}, {"Word": "our", "OffsetStartMs": 22950, "OffsetEndMs": 23175}, {"Word": "state", "OffsetStartMs": 23175, "OffsetEndMs": 23415}, {"Word": "and", "OffsetStartMs": 23415, "OffsetEndMs": 23565}, {"Word": "our", "OffsetStartMs": 23565, "OffsetEndMs": 23685}, {"Word": "action", "OffsetStartMs": 23685, "OffsetEndMs": 23960}, {"Word": "and", "OffsetStartMs": 24310, "OffsetEndMs": 24570}, {"Word": "then", "OffsetStartMs": 24570, "OffsetEndMs": 24720}, {"Word": "use", "OffsetStartMs": 24720, "OffsetEndMs": 24945}, {"Word": "that", "OffsetStartMs": 24945, "OffsetEndMs": 25230}, {"Word": "q", "OffsetStartMs": 25230, "OffsetEndMs": 25470}, {"Word": "function", "OffsetStartMs": 25470, "OffsetEndMs": 25760}, {"Word": "to", "OffsetStartMs": 25990, "OffsetEndMs": 26390}, {"Word": "you", "OffsetStartMs": 26560, "OffsetEndMs": 26805}, {"Word": "know", "OffsetStartMs": 26805, "OffsetEndMs": 27050}, {"Word": "optimize", "OffsetStartMs": 27310, "OffsetEndMs": 27765}, {"Word": "for", "OffsetStartMs": 27765, "OffsetEndMs": 28050}, {"Word": "the", "OffsetStartMs": 28050, "OffsetEndMs": 28260}, {"Word": "best", "OffsetStartMs": 28260, "OffsetEndMs": 28485}, {"Word": "action", "OffsetStartMs": 28485, "OffsetEndMs": 28820}, {"Word": "to", "OffsetStartMs": 28870, "OffsetEndMs": 29160}, {"Word": "take", "OffsetStartMs": 29160, "OffsetEndMs": 29450}, {"Word": "given", "OffsetStartMs": 29650, "OffsetEndMs": 30050}, {"Word": "a", "OffsetStartMs": 30520, "OffsetEndMs": 30870}, {"Word": "particular", "OffsetStartMs": 30870, "OffsetEndMs": 31220}, {"Word": "state", "OffsetStartMs": 31240, "OffsetEndMs": 31530}, {"Word": "that", "OffsetStartMs": 31530, "OffsetEndMs": 31665}, {"Word": "we", "OffsetStartMs": 31665, "OffsetEndMs": 31785}, {"Word": "find", "OffsetStartMs": 31785, "OffsetEndMs": 32025}, {"Word": "ourselves", "OffsetStartMs": 32025, "OffsetEndMs": 32295}, {"Word": "in", "OffsetStartMs": 32295, "OffsetEndMs": 32600}], "SpeechSpeed": 18.3}, {"FinalSentence": "The second class of algorithms, which we'll touch on right at the end of today's lecture, is kind of a different framing of this same approach. But instead of first optimizing the q function and finding A Q value and then using that q function to optimize our actions, what if we just try to directly optimize our policy, which is what action to take based on a particular state that we find ourselves in? If we do that, if we can obtain this function, right?", "SliceSentence": "The second class of algorithms which we'll touch on right at the end of today's lecture is kind of a different framing of this same approach But instead of first optimizing the q function and finding A Q value and then using that q function to optimize our actions what if we just try to directly optimize our policy which is what action to take based on a particular state that we find ourselves in If we do that if we can obtain this function right", "StartMs": 981700, "EndMs": 1009120, "WordsNum": 86, "Words": [{"Word": "The", "OffsetStartMs": 0, "OffsetEndMs": 225}, {"Word": "second", "OffsetStartMs": 225, "OffsetEndMs": 530}, {"Word": "class", "OffsetStartMs": 580, "OffsetEndMs": 900}, {"Word": "of", "OffsetStartMs": 900, "OffsetEndMs": 1185}, {"Word": "algorithms", "OffsetStartMs": 1185, "OffsetEndMs": 1545}, {"Word": "which", "OffsetStartMs": 1545, "OffsetEndMs": 1725}, {"Word": "we'll", "OffsetStartMs": 1725, "OffsetEndMs": 1935}, {"Word": "touch", "OffsetStartMs": 1935, "OffsetEndMs": 2055}, {"Word": "on", "OffsetStartMs": 2055, "OffsetEndMs": 2280}, {"Word": "right", "OffsetStartMs": 2280, "OffsetEndMs": 2505}, {"Word": "at", "OffsetStartMs": 2505, "OffsetEndMs": 2655}, {"Word": "the", "OffsetStartMs": 2655, "OffsetEndMs": 2775}, {"Word": "end", "OffsetStartMs": 2775, "OffsetEndMs": 2955}, {"Word": "of", "OffsetStartMs": 2955, "OffsetEndMs": 3180}, {"Word": "today's", "OffsetStartMs": 3180, "OffsetEndMs": 3525}, {"Word": "lecture", "OffsetStartMs": 3525, "OffsetEndMs": 3770}, {"Word": "is", "OffsetStartMs": 4150, "OffsetEndMs": 4455}, {"Word": "kind", "OffsetStartMs": 4455, "OffsetEndMs": 4650}, {"Word": "of", "OffsetStartMs": 4650, "OffsetEndMs": 4830}, {"Word": "a", "OffsetStartMs": 4830, "OffsetEndMs": 5100}, {"Word": "different", "OffsetStartMs": 5100, "OffsetEndMs": 5460}, {"Word": "framing", "OffsetStartMs": 5460, "OffsetEndMs": 6015}, {"Word": "of", "OffsetStartMs": 6015, "OffsetEndMs": 6285}, {"Word": "this", "OffsetStartMs": 6285, "OffsetEndMs": 6495}, {"Word": "same", "OffsetStartMs": 6495, "OffsetEndMs": 6780}, {"Word": "approach", "OffsetStartMs": 6780, "OffsetEndMs": 7155}, {"Word": "But", "OffsetStartMs": 7155, "OffsetEndMs": 7500}, {"Word": "instead", "OffsetStartMs": 7500, "OffsetEndMs": 7710}, {"Word": "of", "OffsetStartMs": 7710, "OffsetEndMs": 7970}, {"Word": "first", "OffsetStartMs": 8050, "OffsetEndMs": 8450}, {"Word": "optimizing", "OffsetStartMs": 8620, "OffsetEndMs": 9140}, {"Word": "the", "OffsetStartMs": 9550, "OffsetEndMs": 9870}, {"Word": "q", "OffsetStartMs": 9870, "OffsetEndMs": 10080}, {"Word": "function", "OffsetStartMs": 10080, "OffsetEndMs": 10370}, {"Word": "and", "OffsetStartMs": 10390, "OffsetEndMs": 10680}, {"Word": "finding", "OffsetStartMs": 10680, "OffsetEndMs": 10920}, {"Word": "A", "OffsetStartMs": 10920, "OffsetEndMs": 11160}, {"Word": "Q", "OffsetStartMs": 11160, "OffsetEndMs": 11310}, {"Word": "value", "OffsetStartMs": 11310, "OffsetEndMs": 11505}, {"Word": "and", "OffsetStartMs": 11505, "OffsetEndMs": 11685}, {"Word": "then", "OffsetStartMs": 11685, "OffsetEndMs": 11820}, {"Word": "using", "OffsetStartMs": 11820, "OffsetEndMs": 12060}, {"Word": "that", "OffsetStartMs": 12060, "OffsetEndMs": 12315}, {"Word": "q", "OffsetStartMs": 12315, "OffsetEndMs": 12510}, {"Word": "function", "OffsetStartMs": 12510, "OffsetEndMs": 12800}, {"Word": "to", "OffsetStartMs": 12880, "OffsetEndMs": 13280}, {"Word": "optimize", "OffsetStartMs": 13600, "OffsetEndMs": 13995}, {"Word": "our", "OffsetStartMs": 13995, "OffsetEndMs": 14205}, {"Word": "actions", "OffsetStartMs": 14205, "OffsetEndMs": 14510}, {"Word": "what", "OffsetStartMs": 14980, "OffsetEndMs": 15240}, {"Word": "if", "OffsetStartMs": 15240, "OffsetEndMs": 15390}, {"Word": "we", "OffsetStartMs": 15390, "OffsetEndMs": 15630}, {"Word": "just", "OffsetStartMs": 15630, "OffsetEndMs": 15960}, {"Word": "try", "OffsetStartMs": 15960, "OffsetEndMs": 16275}, {"Word": "to", "OffsetStartMs": 16275, "OffsetEndMs": 16605}, {"Word": "directly", "OffsetStartMs": 16605, "OffsetEndMs": 17000}, {"Word": "optimize", "OffsetStartMs": 17200, "OffsetEndMs": 17690}, {"Word": "our", "OffsetStartMs": 17740, "OffsetEndMs": 18075}, {"Word": "policy", "OffsetStartMs": 18075, "OffsetEndMs": 18410}, {"Word": "which", "OffsetStartMs": 18670, "OffsetEndMs": 18960}, {"Word": "is", "OffsetStartMs": 18960, "OffsetEndMs": 19250}, {"Word": "what", "OffsetStartMs": 19420, "OffsetEndMs": 19695}, {"Word": "action", "OffsetStartMs": 19695, "OffsetEndMs": 19970}, {"Word": "to", "OffsetStartMs": 19990, "OffsetEndMs": 20250}, {"Word": "take", "OffsetStartMs": 20250, "OffsetEndMs": 20510}, {"Word": "based", "OffsetStartMs": 20890, "OffsetEndMs": 21210}, {"Word": "on", "OffsetStartMs": 21210, "OffsetEndMs": 21390}, {"Word": "a", "OffsetStartMs": 21390, "OffsetEndMs": 21555}, {"Word": "particular", "OffsetStartMs": 21555, "OffsetEndMs": 21855}, {"Word": "state", "OffsetStartMs": 21855, "OffsetEndMs": 22140}, {"Word": "that", "OffsetStartMs": 22140, "OffsetEndMs": 22290}, {"Word": "we", "OffsetStartMs": 22290, "OffsetEndMs": 22410}, {"Word": "find", "OffsetStartMs": 22410, "OffsetEndMs": 22665}, {"Word": "ourselves", "OffsetStartMs": 22665, "OffsetEndMs": 22980}, {"Word": "in", "OffsetStartMs": 22980, "OffsetEndMs": 23300}, {"Word": "If", "OffsetStartMs": 23890, "OffsetEndMs": 24165}, {"Word": "we", "OffsetStartMs": 24165, "OffsetEndMs": 24315}, {"Word": "do", "OffsetStartMs": 24315, "OffsetEndMs": 24465}, {"Word": "that", "OffsetStartMs": 24465, "OffsetEndMs": 24740}, {"Word": "if", "OffsetStartMs": 24880, "OffsetEndMs": 25155}, {"Word": "we", "OffsetStartMs": 25155, "OffsetEndMs": 25305}, {"Word": "can", "OffsetStartMs": 25305, "OffsetEndMs": 25425}, {"Word": "obtain", "OffsetStartMs": 25425, "OffsetEndMs": 25740}, {"Word": "this", "OffsetStartMs": 25740, "OffsetEndMs": 25980}, {"Word": "function", "OffsetStartMs": 25980, "OffsetEndMs": 26300}, {"Word": "right", "OffsetStartMs": 26590, "OffsetEndMs": 26990}], "SpeechSpeed": 16.4}, {"FinalSentence": "Then we can directly sample from that policy distribution to obtain the optimal action. We'll talk more details about that later in the lecture, but first let's cover this first class of approaches, which is q learning approaches, and we'll build up that intuition and that knowledge onto the second part of policy learning. So maybe let's start by just digging a bit deeper into the q function specifically just to start to understand, you know, how we could estimate this in the beginning.", "SliceSentence": "Then we can directly sample from that policy distribution to obtain the optimal action We'll talk more details about that later in the lecture but first let's cover this first class of approaches which is q learning approaches and we'll build up that intuition and that knowledge onto the second part of policy learning So maybe let's start by just digging a bit deeper into the q function specifically just to start to understand you know how we could estimate this in the beginning", "StartMs": 1009120, "EndMs": 1036160, "WordsNum": 84, "Words": [{"Word": "Then", "OffsetStartMs": 0, "OffsetEndMs": 135}, {"Word": "we", "OffsetStartMs": 135, "OffsetEndMs": 270}, {"Word": "can", "OffsetStartMs": 270, "OffsetEndMs": 450}, {"Word": "directly", "OffsetStartMs": 450, "OffsetEndMs": 770}, {"Word": "sample", "OffsetStartMs": 790, "OffsetEndMs": 1190}, {"Word": "from", "OffsetStartMs": 1210, "OffsetEndMs": 1500}, {"Word": "that", "OffsetStartMs": 1500, "OffsetEndMs": 1725}, {"Word": "policy", "OffsetStartMs": 1725, "OffsetEndMs": 2060}, {"Word": "distribution", "OffsetStartMs": 2440, "OffsetEndMs": 2840}, {"Word": "to", "OffsetStartMs": 3280, "OffsetEndMs": 3510}, {"Word": "obtain", "OffsetStartMs": 3510, "OffsetEndMs": 3840}, {"Word": "the", "OffsetStartMs": 3840, "OffsetEndMs": 4080}, {"Word": "optimal", "OffsetStartMs": 4080, "OffsetEndMs": 4335}, {"Word": "action", "OffsetStartMs": 4335, "OffsetEndMs": 4580}, {"Word": "We'll", "OffsetStartMs": 4900, "OffsetEndMs": 5235}, {"Word": "talk", "OffsetStartMs": 5235, "OffsetEndMs": 5430}, {"Word": "more", "OffsetStartMs": 5430, "OffsetEndMs": 5745}, {"Word": "details", "OffsetStartMs": 5745, "OffsetEndMs": 6090}, {"Word": "about", "OffsetStartMs": 6090, "OffsetEndMs": 6345}, {"Word": "that", "OffsetStartMs": 6345, "OffsetEndMs": 6630}, {"Word": "later", "OffsetStartMs": 6630, "OffsetEndMs": 6915}, {"Word": "in", "OffsetStartMs": 6915, "OffsetEndMs": 7110}, {"Word": "the", "OffsetStartMs": 7110, "OffsetEndMs": 7260}, {"Word": "lecture", "OffsetStartMs": 7260, "OffsetEndMs": 7485}, {"Word": "but", "OffsetStartMs": 7485, "OffsetEndMs": 7755}, {"Word": "first", "OffsetStartMs": 7755, "OffsetEndMs": 7965}, {"Word": "let's", "OffsetStartMs": 7965, "OffsetEndMs": 8235}, {"Word": "cover", "OffsetStartMs": 8235, "OffsetEndMs": 8430}, {"Word": "this", "OffsetStartMs": 8430, "OffsetEndMs": 8685}, {"Word": "first", "OffsetStartMs": 8685, "OffsetEndMs": 8955}, {"Word": "class", "OffsetStartMs": 8955, "OffsetEndMs": 9255}, {"Word": "of", "OffsetStartMs": 9255, "OffsetEndMs": 9590}, {"Word": "approaches", "OffsetStartMs": 9880, "OffsetEndMs": 10280}, {"Word": "which", "OffsetStartMs": 10390, "OffsetEndMs": 10665}, {"Word": "is", "OffsetStartMs": 10665, "OffsetEndMs": 10860}, {"Word": "q", "OffsetStartMs": 10860, "OffsetEndMs": 11055}, {"Word": "learning", "OffsetStartMs": 11055, "OffsetEndMs": 11325}, {"Word": "approaches", "OffsetStartMs": 11325, "OffsetEndMs": 11720}, {"Word": "and", "OffsetStartMs": 12400, "OffsetEndMs": 12705}, {"Word": "we'll", "OffsetStartMs": 12705, "OffsetEndMs": 12960}, {"Word": "build", "OffsetStartMs": 12960, "OffsetEndMs": 13140}, {"Word": "up", "OffsetStartMs": 13140, "OffsetEndMs": 13460}, {"Word": "that", "OffsetStartMs": 13510, "OffsetEndMs": 13860}, {"Word": "intuition", "OffsetStartMs": 13860, "OffsetEndMs": 14385}, {"Word": "and", "OffsetStartMs": 14385, "OffsetEndMs": 14595}, {"Word": "that", "OffsetStartMs": 14595, "OffsetEndMs": 14760}, {"Word": "knowledge", "OffsetStartMs": 14760, "OffsetEndMs": 15050}, {"Word": "onto", "OffsetStartMs": 15220, "OffsetEndMs": 15620}, {"Word": "the", "OffsetStartMs": 15700, "OffsetEndMs": 15975}, {"Word": "second", "OffsetStartMs": 15975, "OffsetEndMs": 16200}, {"Word": "part", "OffsetStartMs": 16200, "OffsetEndMs": 16425}, {"Word": "of", "OffsetStartMs": 16425, "OffsetEndMs": 16590}, {"Word": "policy", "OffsetStartMs": 16590, "OffsetEndMs": 16860}, {"Word": "learning", "OffsetStartMs": 16860, "OffsetEndMs": 17240}, {"Word": "So", "OffsetStartMs": 17950, "OffsetEndMs": 18300}, {"Word": "maybe", "OffsetStartMs": 18300, "OffsetEndMs": 18570}, {"Word": "let's", "OffsetStartMs": 18570, "OffsetEndMs": 18855}, {"Word": "start", "OffsetStartMs": 18855, "OffsetEndMs": 19050}, {"Word": "by", "OffsetStartMs": 19050, "OffsetEndMs": 19260}, {"Word": "just", "OffsetStartMs": 19260, "OffsetEndMs": 19455}, {"Word": "digging", "OffsetStartMs": 19455, "OffsetEndMs": 19755}, {"Word": "a", "OffsetStartMs": 19755, "OffsetEndMs": 19890}, {"Word": "bit", "OffsetStartMs": 19890, "OffsetEndMs": 20100}, {"Word": "deeper", "OffsetStartMs": 20100, "OffsetEndMs": 20420}, {"Word": "into", "OffsetStartMs": 20560, "OffsetEndMs": 20960}, {"Word": "the", "OffsetStartMs": 21310, "OffsetEndMs": 21600}, {"Word": "q", "OffsetStartMs": 21600, "OffsetEndMs": 21780}, {"Word": "function", "OffsetStartMs": 21780, "OffsetEndMs": 22070}, {"Word": "specifically", "OffsetStartMs": 22240, "OffsetEndMs": 22640}, {"Word": "just", "OffsetStartMs": 23140, "OffsetEndMs": 23430}, {"Word": "to", "OffsetStartMs": 23430, "OffsetEndMs": 23625}, {"Word": "start", "OffsetStartMs": 23625, "OffsetEndMs": 23820}, {"Word": "to", "OffsetStartMs": 23820, "OffsetEndMs": 24075}, {"Word": "understand", "OffsetStartMs": 24075, "OffsetEndMs": 24330}, {"Word": "you", "OffsetStartMs": 24330, "OffsetEndMs": 24465}, {"Word": "know", "OffsetStartMs": 24465, "OffsetEndMs": 24600}, {"Word": "how", "OffsetStartMs": 24600, "OffsetEndMs": 24765}, {"Word": "we", "OffsetStartMs": 24765, "OffsetEndMs": 24915}, {"Word": "could", "OffsetStartMs": 24915, "OffsetEndMs": 25190}, {"Word": "estimate", "OffsetStartMs": 25390, "OffsetEndMs": 25680}, {"Word": "this", "OffsetStartMs": 25680, "OffsetEndMs": 25950}, {"Word": "in", "OffsetStartMs": 25950, "OffsetEndMs": 26205}, {"Word": "the", "OffsetStartMs": 26205, "OffsetEndMs": 26370}, {"Word": "beginning", "OffsetStartMs": 26370, "OffsetEndMs": 26660}], "SpeechSpeed": 17.9}, {"FinalSentence": "So first let me introduce this game. Maybe some of you recognize this. This is the game of called atari breakout. The the game here is essentially one where the agent is able to move left or right, this paddle on the bottom left or right. And the objective is to move it in a way that this ball that's coming down towards the bottom of the screen can be, you know, bounced off of your paddle, reflected back up, and essentially you want to break out, right, reflect that ball back up to the top of the screen towards the rainbow portion and keep breaking off. Every time you hit a pixel on the top of the screen, you break off that pixel. And the objective of the game is to basically eliminate all of those rainbow pixels, right? So you want to keep hitting that ball against the top of the screen until you remove all the pixels.", "SliceSentence": "So first let me introduce this game Maybe some of you recognize this This is the game of called atari breakout The the game here is essentially one where the agent is able to move left or right this paddle on the bottom left or right And the objective is to move it in a way that this ball that's coming down towards the bottom of the screen can be you know bounced off of your paddle reflected back up and essentially you want to break out right reflect that ball back up to the top of the screen towards the rainbow portion and keep breaking off Every time you hit a pixel on the top of the screen you break off that pixel And the objective of the game is to basically eliminate all of those rainbow pixels right So you want to keep hitting that ball against the top of the screen until you remove all the pixels", "StartMs": 1036160, "EndMs": 1081100, "WordsNum": 160, "Words": [{"Word": "So", "OffsetStartMs": 280, "OffsetEndMs": 540}, {"Word": "first", "OffsetStartMs": 540, "OffsetEndMs": 720}, {"Word": "let", "OffsetStartMs": 720, "OffsetEndMs": 885}, {"Word": "me", "OffsetStartMs": 885, "OffsetEndMs": 1095}, {"Word": "introduce", "OffsetStartMs": 1095, "OffsetEndMs": 1380}, {"Word": "this", "OffsetStartMs": 1380, "OffsetEndMs": 1605}, {"Word": "game", "OffsetStartMs": 1605, "OffsetEndMs": 1890}, {"Word": "Maybe", "OffsetStartMs": 1890, "OffsetEndMs": 2190}, {"Word": "some", "OffsetStartMs": 2190, "OffsetEndMs": 2370}, {"Word": "of", "OffsetStartMs": 2370, "OffsetEndMs": 2490}, {"Word": "you", "OffsetStartMs": 2490, "OffsetEndMs": 2625}, {"Word": "recognize", "OffsetStartMs": 2625, "OffsetEndMs": 2900}, {"Word": "this", "OffsetStartMs": 3070, "OffsetEndMs": 3330}, {"Word": "This", "OffsetStartMs": 3330, "OffsetEndMs": 3465}, {"Word": "is", "OffsetStartMs": 3465, "OffsetEndMs": 3600}, {"Word": "the", "OffsetStartMs": 3600, "OffsetEndMs": 3735}, {"Word": "game", "OffsetStartMs": 3735, "OffsetEndMs": 3915}, {"Word": "of", "OffsetStartMs": 3915, "OffsetEndMs": 4170}, {"Word": "called", "OffsetStartMs": 4170, "OffsetEndMs": 4520}, {"Word": "atari", "OffsetStartMs": 4570, "OffsetEndMs": 5115}, {"Word": "breakout", "OffsetStartMs": 5115, "OffsetEndMs": 5660}, {"Word": "The", "OffsetStartMs": 6850, "OffsetEndMs": 7215}, {"Word": "the", "OffsetStartMs": 7215, "OffsetEndMs": 7425}, {"Word": "game", "OffsetStartMs": 7425, "OffsetEndMs": 7620}, {"Word": "here", "OffsetStartMs": 7620, "OffsetEndMs": 7845}, {"Word": "is", "OffsetStartMs": 7845, "OffsetEndMs": 8055}, {"Word": "essentially", "OffsetStartMs": 8055, "OffsetEndMs": 8390}, {"Word": "one", "OffsetStartMs": 8650, "OffsetEndMs": 8985}, {"Word": "where", "OffsetStartMs": 8985, "OffsetEndMs": 9320}, {"Word": "the", "OffsetStartMs": 9580, "OffsetEndMs": 9840}, {"Word": "agent", "OffsetStartMs": 9840, "OffsetEndMs": 10100}, {"Word": "is", "OffsetStartMs": 10360, "OffsetEndMs": 10635}, {"Word": "able", "OffsetStartMs": 10635, "OffsetEndMs": 10860}, {"Word": "to", "OffsetStartMs": 10860, "OffsetEndMs": 11070}, {"Word": "move", "OffsetStartMs": 11070, "OffsetEndMs": 11295}, {"Word": "left", "OffsetStartMs": 11295, "OffsetEndMs": 11550}, {"Word": "or", "OffsetStartMs": 11550, "OffsetEndMs": 11715}, {"Word": "right", "OffsetStartMs": 11715, "OffsetEndMs": 11925}, {"Word": "this", "OffsetStartMs": 11925, "OffsetEndMs": 12180}, {"Word": "paddle", "OffsetStartMs": 12180, "OffsetEndMs": 12480}, {"Word": "on", "OffsetStartMs": 12480, "OffsetEndMs": 12600}, {"Word": "the", "OffsetStartMs": 12600, "OffsetEndMs": 12720}, {"Word": "bottom", "OffsetStartMs": 12720, "OffsetEndMs": 12980}, {"Word": "left", "OffsetStartMs": 13030, "OffsetEndMs": 13380}, {"Word": "or", "OffsetStartMs": 13380, "OffsetEndMs": 13620}, {"Word": "right", "OffsetStartMs": 13620, "OffsetEndMs": 13910}, {"Word": "And", "OffsetStartMs": 14080, "OffsetEndMs": 14430}, {"Word": "the", "OffsetStartMs": 14430, "OffsetEndMs": 14685}, {"Word": "objective", "OffsetStartMs": 14685, "OffsetEndMs": 14990}, {"Word": "is", "OffsetStartMs": 15010, "OffsetEndMs": 15375}, {"Word": "to", "OffsetStartMs": 15375, "OffsetEndMs": 15645}, {"Word": "move", "OffsetStartMs": 15645, "OffsetEndMs": 15840}, {"Word": "it", "OffsetStartMs": 15840, "OffsetEndMs": 16005}, {"Word": "in", "OffsetStartMs": 16005, "OffsetEndMs": 16125}, {"Word": "a", "OffsetStartMs": 16125, "OffsetEndMs": 16245}, {"Word": "way", "OffsetStartMs": 16245, "OffsetEndMs": 16520}, {"Word": "that", "OffsetStartMs": 16540, "OffsetEndMs": 16875}, {"Word": "this", "OffsetStartMs": 16875, "OffsetEndMs": 17130}, {"Word": "ball", "OffsetStartMs": 17130, "OffsetEndMs": 17450}, {"Word": "that's", "OffsetStartMs": 17500, "OffsetEndMs": 17985}, {"Word": "coming", "OffsetStartMs": 17985, "OffsetEndMs": 18320}, {"Word": "down", "OffsetStartMs": 18580, "OffsetEndMs": 18980}, {"Word": "towards", "OffsetStartMs": 19210, "OffsetEndMs": 19545}, {"Word": "the", "OffsetStartMs": 19545, "OffsetEndMs": 19740}, {"Word": "bottom", "OffsetStartMs": 19740, "OffsetEndMs": 19920}, {"Word": "of", "OffsetStartMs": 19920, "OffsetEndMs": 20115}, {"Word": "the", "OffsetStartMs": 20115, "OffsetEndMs": 20295}, {"Word": "screen", "OffsetStartMs": 20295, "OffsetEndMs": 20600}, {"Word": "can", "OffsetStartMs": 20800, "OffsetEndMs": 21075}, {"Word": "be", "OffsetStartMs": 21075, "OffsetEndMs": 21300}, {"Word": "you", "OffsetStartMs": 21300, "OffsetEndMs": 21495}, {"Word": "know", "OffsetStartMs": 21495, "OffsetEndMs": 21630}, {"Word": "bounced", "OffsetStartMs": 21630, "OffsetEndMs": 21945}, {"Word": "off", "OffsetStartMs": 21945, "OffsetEndMs": 22245}, {"Word": "of", "OffsetStartMs": 22245, "OffsetEndMs": 22410}, {"Word": "your", "OffsetStartMs": 22410, "OffsetEndMs": 22560}, {"Word": "paddle", "OffsetStartMs": 22560, "OffsetEndMs": 23000}, {"Word": "reflected", "OffsetStartMs": 23320, "OffsetEndMs": 23700}, {"Word": "back", "OffsetStartMs": 23700, "OffsetEndMs": 23985}, {"Word": "up", "OffsetStartMs": 23985, "OffsetEndMs": 24195}, {"Word": "and", "OffsetStartMs": 24195, "OffsetEndMs": 24435}, {"Word": "essentially", "OffsetStartMs": 24435, "OffsetEndMs": 24735}, {"Word": "you", "OffsetStartMs": 24735, "OffsetEndMs": 24975}, {"Word": "want", "OffsetStartMs": 24975, "OffsetEndMs": 25200}, {"Word": "to", "OffsetStartMs": 25200, "OffsetEndMs": 25550}, {"Word": "break", "OffsetStartMs": 25780, "OffsetEndMs": 26085}, {"Word": "out", "OffsetStartMs": 26085, "OffsetEndMs": 26390}, {"Word": "right", "OffsetStartMs": 26500, "OffsetEndMs": 26900}, {"Word": "reflect", "OffsetStartMs": 27130, "OffsetEndMs": 27435}, {"Word": "that", "OffsetStartMs": 27435, "OffsetEndMs": 27615}, {"Word": "ball", "OffsetStartMs": 27615, "OffsetEndMs": 27810}, {"Word": "back", "OffsetStartMs": 27810, "OffsetEndMs": 28035}, {"Word": "up", "OffsetStartMs": 28035, "OffsetEndMs": 28245}, {"Word": "to", "OffsetStartMs": 28245, "OffsetEndMs": 28380}, {"Word": "the", "OffsetStartMs": 28380, "OffsetEndMs": 28500}, {"Word": "top", "OffsetStartMs": 28500, "OffsetEndMs": 28665}, {"Word": "of", "OffsetStartMs": 28665, "OffsetEndMs": 28770}, {"Word": "the", "OffsetStartMs": 28770, "OffsetEndMs": 28905}, {"Word": "screen", "OffsetStartMs": 28905, "OffsetEndMs": 29130}, {"Word": "towards", "OffsetStartMs": 29130, "OffsetEndMs": 29355}, {"Word": "the", "OffsetStartMs": 29355, "OffsetEndMs": 29520}, {"Word": "rainbow", "OffsetStartMs": 29520, "OffsetEndMs": 29910}, {"Word": "portion", "OffsetStartMs": 29910, "OffsetEndMs": 30180}, {"Word": "and", "OffsetStartMs": 30180, "OffsetEndMs": 30480}, {"Word": "keep", "OffsetStartMs": 30480, "OffsetEndMs": 30720}, {"Word": "breaking", "OffsetStartMs": 30720, "OffsetEndMs": 31020}, {"Word": "off", "OffsetStartMs": 31020, "OffsetEndMs": 31320}, {"Word": "Every", "OffsetStartMs": 31320, "OffsetEndMs": 31560}, {"Word": "time", "OffsetStartMs": 31560, "OffsetEndMs": 31755}, {"Word": "you", "OffsetStartMs": 31755, "OffsetEndMs": 31905}, {"Word": "hit", "OffsetStartMs": 31905, "OffsetEndMs": 32115}, {"Word": "a", "OffsetStartMs": 32115, "OffsetEndMs": 32385}, {"Word": "pixel", "OffsetStartMs": 32385, "OffsetEndMs": 32760}, {"Word": "on", "OffsetStartMs": 32760, "OffsetEndMs": 32850}, {"Word": "the", "OffsetStartMs": 32850, "OffsetEndMs": 32970}, {"Word": "top", "OffsetStartMs": 32970, "OffsetEndMs": 33105}, {"Word": "of", "OffsetStartMs": 33105, "OffsetEndMs": 33225}, {"Word": "the", "OffsetStartMs": 33225, "OffsetEndMs": 33360}, {"Word": "screen", "OffsetStartMs": 33360, "OffsetEndMs": 33525}, {"Word": "you", "OffsetStartMs": 33525, "OffsetEndMs": 33690}, {"Word": "break", "OffsetStartMs": 33690, "OffsetEndMs": 33885}, {"Word": "off", "OffsetStartMs": 33885, "OffsetEndMs": 34095}, {"Word": "that", "OffsetStartMs": 34095, "OffsetEndMs": 34305}, {"Word": "pixel", "OffsetStartMs": 34305, "OffsetEndMs": 34820}, {"Word": "And", "OffsetStartMs": 34870, "OffsetEndMs": 35115}, {"Word": "the", "OffsetStartMs": 35115, "OffsetEndMs": 35250}, {"Word": "objective", "OffsetStartMs": 35250, "OffsetEndMs": 35490}, {"Word": "of", "OffsetStartMs": 35490, "OffsetEndMs": 35715}, {"Word": "the", "OffsetStartMs": 35715, "OffsetEndMs": 35835}, {"Word": "game", "OffsetStartMs": 35835, "OffsetEndMs": 35985}, {"Word": "is", "OffsetStartMs": 35985, "OffsetEndMs": 36165}, {"Word": "to", "OffsetStartMs": 36165, "OffsetEndMs": 36285}, {"Word": "basically", "OffsetStartMs": 36285, "OffsetEndMs": 36530}, {"Word": "eliminate", "OffsetStartMs": 37870, "OffsetEndMs": 38430}, {"Word": "all", "OffsetStartMs": 38430, "OffsetEndMs": 38670}, {"Word": "of", "OffsetStartMs": 38670, "OffsetEndMs": 38835}, {"Word": "those", "OffsetStartMs": 38835, "OffsetEndMs": 39015}, {"Word": "rainbow", "OffsetStartMs": 39015, "OffsetEndMs": 39420}, {"Word": "pixels", "OffsetStartMs": 39420, "OffsetEndMs": 39885}, {"Word": "right", "OffsetStartMs": 39885, "OffsetEndMs": 40140}, {"Word": "So", "OffsetStartMs": 40140, "OffsetEndMs": 40260}, {"Word": "you", "OffsetStartMs": 40260, "OffsetEndMs": 40335}, {"Word": "want", "OffsetStartMs": 40335, "OffsetEndMs": 40440}, {"Word": "to", "OffsetStartMs": 40440, "OffsetEndMs": 40575}, {"Word": "keep", "OffsetStartMs": 40575, "OffsetEndMs": 40740}, {"Word": "hitting", "OffsetStartMs": 40740, "OffsetEndMs": 40950}, {"Word": "that", "OffsetStartMs": 40950, "OffsetEndMs": 41145}, {"Word": "ball", "OffsetStartMs": 41145, "OffsetEndMs": 41355}, {"Word": "against", "OffsetStartMs": 41355, "OffsetEndMs": 41565}, {"Word": "the", "OffsetStartMs": 41565, "OffsetEndMs": 41700}, {"Word": "top", "OffsetStartMs": 41700, "OffsetEndMs": 41820}, {"Word": "of", "OffsetStartMs": 41820, "OffsetEndMs": 41910}, {"Word": "the", "OffsetStartMs": 41910, "OffsetEndMs": 42030}, {"Word": "screen", "OffsetStartMs": 42030, "OffsetEndMs": 42270}, {"Word": "until", "OffsetStartMs": 42270, "OffsetEndMs": 42510}, {"Word": "you", "OffsetStartMs": 42510, "OffsetEndMs": 42800}, {"Word": "remove", "OffsetStartMs": 42970, "OffsetEndMs": 43245}, {"Word": "all", "OffsetStartMs": 43245, "OffsetEndMs": 43410}, {"Word": "the", "OffsetStartMs": 43410, "OffsetEndMs": 43560}, {"Word": "pixels", "OffsetStartMs": 43560, "OffsetEndMs": 44000}], "SpeechSpeed": 18.1}, {"FinalSentence": "Now the q function tells us, you know, the expected total return or the total reward that we can expect based on a given state and action pair that we may find ourselves in this game. Now, the first point I want to make here is that sometimes even for us as humans to understand what the q value should be is sometimes quite unintuitive, right? So here's one example. Let's say we find these two state action pairs right here is a and b two different options that we can be presented with in this game.", "SliceSentence": "Now the q function tells us you know the expected total return or the total reward that we can expect based on a given state and action pair that we may find ourselves in this game Now the first point I want to make here is that sometimes even for us as humans to understand what the q value should be is sometimes quite unintuitive right So here's one example Let's say we find these two state action pairs right here is a and b two different options that we can be presented with in this game", "StartMs": 1081580, "EndMs": 1114060, "WordsNum": 97, "Words": [{"Word": "Now", "OffsetStartMs": 100, "OffsetEndMs": 480}, {"Word": "the", "OffsetStartMs": 480, "OffsetEndMs": 735}, {"Word": "q", "OffsetStartMs": 735, "OffsetEndMs": 900}, {"Word": "function", "OffsetStartMs": 900, "OffsetEndMs": 1190}, {"Word": "tells", "OffsetStartMs": 1510, "OffsetEndMs": 1845}, {"Word": "us", "OffsetStartMs": 1845, "OffsetEndMs": 2180}, {"Word": "you", "OffsetStartMs": 2590, "OffsetEndMs": 2835}, {"Word": "know", "OffsetStartMs": 2835, "OffsetEndMs": 3000}, {"Word": "the", "OffsetStartMs": 3000, "OffsetEndMs": 3315}, {"Word": "expected", "OffsetStartMs": 3315, "OffsetEndMs": 3710}, {"Word": "total", "OffsetStartMs": 3790, "OffsetEndMs": 4190}, {"Word": "return", "OffsetStartMs": 4510, "OffsetEndMs": 4910}, {"Word": "or", "OffsetStartMs": 4930, "OffsetEndMs": 5205}, {"Word": "the", "OffsetStartMs": 5205, "OffsetEndMs": 5370}, {"Word": "total", "OffsetStartMs": 5370, "OffsetEndMs": 5660}, {"Word": "reward", "OffsetStartMs": 6100, "OffsetEndMs": 6500}, {"Word": "that", "OffsetStartMs": 6790, "OffsetEndMs": 7065}, {"Word": "we", "OffsetStartMs": 7065, "OffsetEndMs": 7215}, {"Word": "can", "OffsetStartMs": 7215, "OffsetEndMs": 7470}, {"Word": "expect", "OffsetStartMs": 7470, "OffsetEndMs": 7850}, {"Word": "based", "OffsetStartMs": 7900, "OffsetEndMs": 8235}, {"Word": "on", "OffsetStartMs": 8235, "OffsetEndMs": 8430}, {"Word": "a", "OffsetStartMs": 8430, "OffsetEndMs": 8535}, {"Word": "given", "OffsetStartMs": 8535, "OffsetEndMs": 8780}, {"Word": "state", "OffsetStartMs": 8800, "OffsetEndMs": 9200}, {"Word": "and", "OffsetStartMs": 9340, "OffsetEndMs": 9660}, {"Word": "action", "OffsetStartMs": 9660, "OffsetEndMs": 9980}, {"Word": "pair", "OffsetStartMs": 10090, "OffsetEndMs": 10490}, {"Word": "that", "OffsetStartMs": 10660, "OffsetEndMs": 10920}, {"Word": "we", "OffsetStartMs": 10920, "OffsetEndMs": 11040}, {"Word": "may", "OffsetStartMs": 11040, "OffsetEndMs": 11190}, {"Word": "find", "OffsetStartMs": 11190, "OffsetEndMs": 11460}, {"Word": "ourselves", "OffsetStartMs": 11460, "OffsetEndMs": 11820}, {"Word": "in", "OffsetStartMs": 11820, "OffsetEndMs": 12075}, {"Word": "this", "OffsetStartMs": 12075, "OffsetEndMs": 12270}, {"Word": "game", "OffsetStartMs": 12270, "OffsetEndMs": 12590}, {"Word": "Now", "OffsetStartMs": 13270, "OffsetEndMs": 13635}, {"Word": "the", "OffsetStartMs": 13635, "OffsetEndMs": 13875}, {"Word": "first", "OffsetStartMs": 13875, "OffsetEndMs": 14055}, {"Word": "point", "OffsetStartMs": 14055, "OffsetEndMs": 14250}, {"Word": "I", "OffsetStartMs": 14250, "OffsetEndMs": 14385}, {"Word": "want", "OffsetStartMs": 14385, "OffsetEndMs": 14505}, {"Word": "to", "OffsetStartMs": 14505, "OffsetEndMs": 14625}, {"Word": "make", "OffsetStartMs": 14625, "OffsetEndMs": 14790}, {"Word": "here", "OffsetStartMs": 14790, "OffsetEndMs": 15060}, {"Word": "is", "OffsetStartMs": 15060, "OffsetEndMs": 15300}, {"Word": "that", "OffsetStartMs": 15300, "OffsetEndMs": 15525}, {"Word": "sometimes", "OffsetStartMs": 15525, "OffsetEndMs": 15860}, {"Word": "even", "OffsetStartMs": 16210, "OffsetEndMs": 16610}, {"Word": "for", "OffsetStartMs": 17230, "OffsetEndMs": 17475}, {"Word": "us", "OffsetStartMs": 17475, "OffsetEndMs": 17720}, {"Word": "as", "OffsetStartMs": 17740, "OffsetEndMs": 18060}, {"Word": "humans", "OffsetStartMs": 18060, "OffsetEndMs": 18380}, {"Word": "to", "OffsetStartMs": 18490, "OffsetEndMs": 18890}, {"Word": "understand", "OffsetStartMs": 19000, "OffsetEndMs": 19400}, {"Word": "what", "OffsetStartMs": 19510, "OffsetEndMs": 19830}, {"Word": "the", "OffsetStartMs": 19830, "OffsetEndMs": 20040}, {"Word": "q", "OffsetStartMs": 20040, "OffsetEndMs": 20205}, {"Word": "value", "OffsetStartMs": 20205, "OffsetEndMs": 20480}, {"Word": "should", "OffsetStartMs": 20500, "OffsetEndMs": 20790}, {"Word": "be", "OffsetStartMs": 20790, "OffsetEndMs": 21080}, {"Word": "is", "OffsetStartMs": 21220, "OffsetEndMs": 21620}, {"Word": "sometimes", "OffsetStartMs": 21640, "OffsetEndMs": 22040}, {"Word": "quite", "OffsetStartMs": 22090, "OffsetEndMs": 22395}, {"Word": "unintuitive", "OffsetStartMs": 22395, "OffsetEndMs": 23175}, {"Word": "right", "OffsetStartMs": 23175, "OffsetEndMs": 23490}, {"Word": "So", "OffsetStartMs": 23490, "OffsetEndMs": 23685}, {"Word": "here's", "OffsetStartMs": 23685, "OffsetEndMs": 23940}, {"Word": "one", "OffsetStartMs": 23940, "OffsetEndMs": 24135}, {"Word": "example", "OffsetStartMs": 24135, "OffsetEndMs": 24470}, {"Word": "Let's", "OffsetStartMs": 25000, "OffsetEndMs": 25335}, {"Word": "say", "OffsetStartMs": 25335, "OffsetEndMs": 25455}, {"Word": "we", "OffsetStartMs": 25455, "OffsetEndMs": 25650}, {"Word": "find", "OffsetStartMs": 25650, "OffsetEndMs": 25935}, {"Word": "these", "OffsetStartMs": 25935, "OffsetEndMs": 26280}, {"Word": "two", "OffsetStartMs": 26280, "OffsetEndMs": 26610}, {"Word": "state", "OffsetStartMs": 26610, "OffsetEndMs": 26865}, {"Word": "action", "OffsetStartMs": 26865, "OffsetEndMs": 27170}, {"Word": "pairs", "OffsetStartMs": 27400, "OffsetEndMs": 27855}, {"Word": "right", "OffsetStartMs": 27855, "OffsetEndMs": 28230}, {"Word": "here", "OffsetStartMs": 28230, "OffsetEndMs": 28470}, {"Word": "is", "OffsetStartMs": 28470, "OffsetEndMs": 28635}, {"Word": "a", "OffsetStartMs": 28635, "OffsetEndMs": 28890}, {"Word": "and", "OffsetStartMs": 28890, "OffsetEndMs": 29145}, {"Word": "b", "OffsetStartMs": 29145, "OffsetEndMs": 29445}, {"Word": "two", "OffsetStartMs": 29445, "OffsetEndMs": 29700}, {"Word": "different", "OffsetStartMs": 29700, "OffsetEndMs": 29880}, {"Word": "options", "OffsetStartMs": 29880, "OffsetEndMs": 30195}, {"Word": "that", "OffsetStartMs": 30195, "OffsetEndMs": 30450}, {"Word": "we", "OffsetStartMs": 30450, "OffsetEndMs": 30570}, {"Word": "can", "OffsetStartMs": 30570, "OffsetEndMs": 30675}, {"Word": "be", "OffsetStartMs": 30675, "OffsetEndMs": 30795}, {"Word": "presented", "OffsetStartMs": 30795, "OffsetEndMs": 31070}, {"Word": "with", "OffsetStartMs": 31090, "OffsetEndMs": 31365}, {"Word": "in", "OffsetStartMs": 31365, "OffsetEndMs": 31515}, {"Word": "this", "OffsetStartMs": 31515, "OffsetEndMs": 31695}, {"Word": "game", "OffsetStartMs": 31695, "OffsetEndMs": 32000}], "SpeechSpeed": 15.2}, {"FinalSentence": "A the ball is coming straight down towards us. That's our state. Our action is to do nothing and simply reflect that ball back up vertically up. The second situation. The state is basically that the ball is coming slightly at an angle. We're not quite underneath it yet and we need to move towards it and actually hit that ball in a way that you know will will make it and not Miss it hopefully right? So hopefully that ball doesn't pass below us and the game would be over. Can you imagine, you know which of these two options might have a higher q value for the network? Which one would result in a.", "SliceSentence": "A the ball is coming straight down towards us That's our state Our action is to do nothing and simply reflect that ball back up vertically up The second situation The state is basically that the ball is coming slightly at an angle We're not quite underneath it yet and we need to move towards it and actually hit that ball in a way that you know will will make it and not Miss it hopefully right So hopefully that ball doesn't pass below us and the game would be over Can you imagine you know which of these two options might have a higher q value for the network Which one would result in a", "StartMs": 1114060, "EndMs": 1151940, "WordsNum": 116, "Words": [{"Word": "A", "OffsetStartMs": 0, "OffsetEndMs": 380}, {"Word": "the", "OffsetStartMs": 700, "OffsetEndMs": 960}, {"Word": "ball", "OffsetStartMs": 960, "OffsetEndMs": 1095}, {"Word": "is", "OffsetStartMs": 1095, "OffsetEndMs": 1260}, {"Word": "coming", "OffsetStartMs": 1260, "OffsetEndMs": 1550}, {"Word": "straight", "OffsetStartMs": 1750, "OffsetEndMs": 2040}, {"Word": "down", "OffsetStartMs": 2040, "OffsetEndMs": 2265}, {"Word": "towards", "OffsetStartMs": 2265, "OffsetEndMs": 2505}, {"Word": "us", "OffsetStartMs": 2505, "OffsetEndMs": 2760}, {"Word": "That's", "OffsetStartMs": 2760, "OffsetEndMs": 3060}, {"Word": "our", "OffsetStartMs": 3060, "OffsetEndMs": 3255}, {"Word": "state", "OffsetStartMs": 3255, "OffsetEndMs": 3620}, {"Word": "Our", "OffsetStartMs": 3700, "OffsetEndMs": 3990}, {"Word": "action", "OffsetStartMs": 3990, "OffsetEndMs": 4280}, {"Word": "is", "OffsetStartMs": 4300, "OffsetEndMs": 4605}, {"Word": "to", "OffsetStartMs": 4605, "OffsetEndMs": 4755}, {"Word": "do", "OffsetStartMs": 4755, "OffsetEndMs": 4875}, {"Word": "nothing", "OffsetStartMs": 4875, "OffsetEndMs": 5150}, {"Word": "and", "OffsetStartMs": 5200, "OffsetEndMs": 5490}, {"Word": "simply", "OffsetStartMs": 5490, "OffsetEndMs": 5780}, {"Word": "reflect", "OffsetStartMs": 5860, "OffsetEndMs": 6165}, {"Word": "that", "OffsetStartMs": 6165, "OffsetEndMs": 6360}, {"Word": "ball", "OffsetStartMs": 6360, "OffsetEndMs": 6650}, {"Word": "back", "OffsetStartMs": 6670, "OffsetEndMs": 6975}, {"Word": "up", "OffsetStartMs": 6975, "OffsetEndMs": 7280}, {"Word": "vertically", "OffsetStartMs": 7990, "OffsetEndMs": 8490}, {"Word": "up", "OffsetStartMs": 8490, "OffsetEndMs": 8750}, {"Word": "The", "OffsetStartMs": 9130, "OffsetEndMs": 9405}, {"Word": "second", "OffsetStartMs": 9405, "OffsetEndMs": 9680}, {"Word": "situation", "OffsetStartMs": 10750, "OffsetEndMs": 11150}, {"Word": "The", "OffsetStartMs": 11920, "OffsetEndMs": 12270}, {"Word": "state", "OffsetStartMs": 12270, "OffsetEndMs": 12570}, {"Word": "is", "OffsetStartMs": 12570, "OffsetEndMs": 12810}, {"Word": "basically", "OffsetStartMs": 12810, "OffsetEndMs": 13100}, {"Word": "that", "OffsetStartMs": 13150, "OffsetEndMs": 13425}, {"Word": "the", "OffsetStartMs": 13425, "OffsetEndMs": 13560}, {"Word": "ball", "OffsetStartMs": 13560, "OffsetEndMs": 13710}, {"Word": "is", "OffsetStartMs": 13710, "OffsetEndMs": 13890}, {"Word": "coming", "OffsetStartMs": 13890, "OffsetEndMs": 14115}, {"Word": "slightly", "OffsetStartMs": 14115, "OffsetEndMs": 14385}, {"Word": "at", "OffsetStartMs": 14385, "OffsetEndMs": 14565}, {"Word": "an", "OffsetStartMs": 14565, "OffsetEndMs": 14700}, {"Word": "angle", "OffsetStartMs": 14700, "OffsetEndMs": 14990}, {"Word": "We're", "OffsetStartMs": 15130, "OffsetEndMs": 15510}, {"Word": "not", "OffsetStartMs": 15510, "OffsetEndMs": 15735}, {"Word": "quite", "OffsetStartMs": 15735, "OffsetEndMs": 16005}, {"Word": "underneath", "OffsetStartMs": 16005, "OffsetEndMs": 16310}, {"Word": "it", "OffsetStartMs": 16450, "OffsetEndMs": 16740}, {"Word": "yet", "OffsetStartMs": 16740, "OffsetEndMs": 16950}, {"Word": "and", "OffsetStartMs": 16950, "OffsetEndMs": 17115}, {"Word": "we", "OffsetStartMs": 17115, "OffsetEndMs": 17220}, {"Word": "need", "OffsetStartMs": 17220, "OffsetEndMs": 17385}, {"Word": "to", "OffsetStartMs": 17385, "OffsetEndMs": 17580}, {"Word": "move", "OffsetStartMs": 17580, "OffsetEndMs": 17850}, {"Word": "towards", "OffsetStartMs": 17850, "OffsetEndMs": 18165}, {"Word": "it", "OffsetStartMs": 18165, "OffsetEndMs": 18500}, {"Word": "and", "OffsetStartMs": 18730, "OffsetEndMs": 19130}, {"Word": "actually", "OffsetStartMs": 19330, "OffsetEndMs": 19730}, {"Word": "hit", "OffsetStartMs": 20380, "OffsetEndMs": 20670}, {"Word": "that", "OffsetStartMs": 20670, "OffsetEndMs": 20865}, {"Word": "ball", "OffsetStartMs": 20865, "OffsetEndMs": 21170}, {"Word": "in", "OffsetStartMs": 21400, "OffsetEndMs": 21660}, {"Word": "a", "OffsetStartMs": 21660, "OffsetEndMs": 21810}, {"Word": "way", "OffsetStartMs": 21810, "OffsetEndMs": 22020}, {"Word": "that", "OffsetStartMs": 22020, "OffsetEndMs": 22340}, {"Word": "you", "OffsetStartMs": 22510, "OffsetEndMs": 22755}, {"Word": "know", "OffsetStartMs": 22755, "OffsetEndMs": 23000}, {"Word": "will", "OffsetStartMs": 23020, "OffsetEndMs": 23420}, {"Word": "will", "OffsetStartMs": 23440, "OffsetEndMs": 23730}, {"Word": "make", "OffsetStartMs": 23730, "OffsetEndMs": 23925}, {"Word": "it", "OffsetStartMs": 23925, "OffsetEndMs": 24105}, {"Word": "and", "OffsetStartMs": 24105, "OffsetEndMs": 24380}, {"Word": "not", "OffsetStartMs": 24460, "OffsetEndMs": 24780}, {"Word": "Miss", "OffsetStartMs": 24780, "OffsetEndMs": 24975}, {"Word": "it", "OffsetStartMs": 24975, "OffsetEndMs": 25125}, {"Word": "hopefully", "OffsetStartMs": 25125, "OffsetEndMs": 25400}, {"Word": "right", "OffsetStartMs": 25450, "OffsetEndMs": 25770}, {"Word": "So", "OffsetStartMs": 25770, "OffsetEndMs": 25950}, {"Word": "hopefully", "OffsetStartMs": 25950, "OffsetEndMs": 26145}, {"Word": "that", "OffsetStartMs": 26145, "OffsetEndMs": 26340}, {"Word": "ball", "OffsetStartMs": 26340, "OffsetEndMs": 26490}, {"Word": "doesn't", "OffsetStartMs": 26490, "OffsetEndMs": 26790}, {"Word": "pass", "OffsetStartMs": 26790, "OffsetEndMs": 27015}, {"Word": "below", "OffsetStartMs": 27015, "OffsetEndMs": 27255}, {"Word": "us", "OffsetStartMs": 27255, "OffsetEndMs": 27450}, {"Word": "and", "OffsetStartMs": 27450, "OffsetEndMs": 27600}, {"Word": "the", "OffsetStartMs": 27600, "OffsetEndMs": 27720}, {"Word": "game", "OffsetStartMs": 27720, "OffsetEndMs": 27855}, {"Word": "would", "OffsetStartMs": 27855, "OffsetEndMs": 28020}, {"Word": "be", "OffsetStartMs": 28020, "OffsetEndMs": 28155}, {"Word": "over", "OffsetStartMs": 28155, "OffsetEndMs": 28400}, {"Word": "Can", "OffsetStartMs": 29290, "OffsetEndMs": 29550}, {"Word": "you", "OffsetStartMs": 29550, "OffsetEndMs": 29730}, {"Word": "imagine", "OffsetStartMs": 29730, "OffsetEndMs": 30050}, {"Word": "you", "OffsetStartMs": 30250, "OffsetEndMs": 30495}, {"Word": "know", "OffsetStartMs": 30495, "OffsetEndMs": 30675}, {"Word": "which", "OffsetStartMs": 30675, "OffsetEndMs": 30900}, {"Word": "of", "OffsetStartMs": 30900, "OffsetEndMs": 31080}, {"Word": "these", "OffsetStartMs": 31080, "OffsetEndMs": 31370}, {"Word": "two", "OffsetStartMs": 31390, "OffsetEndMs": 31790}, {"Word": "options", "OffsetStartMs": 32080, "OffsetEndMs": 32480}, {"Word": "might", "OffsetStartMs": 33070, "OffsetEndMs": 33390}, {"Word": "have", "OffsetStartMs": 33390, "OffsetEndMs": 33710}, {"Word": "a", "OffsetStartMs": 33760, "OffsetEndMs": 34080}, {"Word": "higher", "OffsetStartMs": 34080, "OffsetEndMs": 34395}, {"Word": "q", "OffsetStartMs": 34395, "OffsetEndMs": 34680}, {"Word": "value", "OffsetStartMs": 34680, "OffsetEndMs": 34970}, {"Word": "for", "OffsetStartMs": 35290, "OffsetEndMs": 35550}, {"Word": "the", "OffsetStartMs": 35550, "OffsetEndMs": 35670}, {"Word": "network", "OffsetStartMs": 35670, "OffsetEndMs": 35895}, {"Word": "Which", "OffsetStartMs": 35895, "OffsetEndMs": 36135}, {"Word": "one", "OffsetStartMs": 36135, "OffsetEndMs": 36300}, {"Word": "would", "OffsetStartMs": 36300, "OffsetEndMs": 36540}, {"Word": "result", "OffsetStartMs": 36540, "OffsetEndMs": 36810}, {"Word": "in", "OffsetStartMs": 36810, "OffsetEndMs": 36990}, {"Word": "a", "OffsetStartMs": 36990, "OffsetEndMs": 37250}], "SpeechSpeed": 15.6}, {"FinalSentence": "Rate of reward for the neural network or for the agent.", "SliceSentence": "Rate of reward for the neural network or for the agent", "StartMs": 1151940, "EndMs": 1155960, "WordsNum": 11, "Words": [{"Word": "Rate", "OffsetStartMs": 70, "OffsetEndMs": 330}, {"Word": "of", "OffsetStartMs": 330, "OffsetEndMs": 525}, {"Word": "reward", "OffsetStartMs": 525, "OffsetEndMs": 860}, {"Word": "for", "OffsetStartMs": 880, "OffsetEndMs": 1140}, {"Word": "the", "OffsetStartMs": 1140, "OffsetEndMs": 1260}, {"Word": "neural", "OffsetStartMs": 1260, "OffsetEndMs": 1470}, {"Word": "network", "OffsetStartMs": 1470, "OffsetEndMs": 1730}, {"Word": "or", "OffsetStartMs": 1990, "OffsetEndMs": 2265}, {"Word": "for", "OffsetStartMs": 2265, "OffsetEndMs": 2385}, {"Word": "the", "OffsetStartMs": 2385, "OffsetEndMs": 2490}, {"Word": "agent", "OffsetStartMs": 2490, "OffsetEndMs": 2750}], "SpeechSpeed": 13.4}, {"FinalSentence": "So how many people believe a would result in a higher return?", "SliceSentence": "So how many people believe a would result in a higher return", "StartMs": 1157160, "EndMs": 1163740, "WordsNum": 12, "Words": [{"Word": "So", "OffsetStartMs": 100, "OffsetEndMs": 360}, {"Word": "how", "OffsetStartMs": 360, "OffsetEndMs": 480}, {"Word": "many", "OffsetStartMs": 480, "OffsetEndMs": 615}, {"Word": "people", "OffsetStartMs": 615, "OffsetEndMs": 855}, {"Word": "believe", "OffsetStartMs": 855, "OffsetEndMs": 1125}, {"Word": "a", "OffsetStartMs": 1125, "OffsetEndMs": 1430}, {"Word": "would", "OffsetStartMs": 1450, "OffsetEndMs": 1800}, {"Word": "result", "OffsetStartMs": 1800, "OffsetEndMs": 2055}, {"Word": "in", "OffsetStartMs": 2055, "OffsetEndMs": 2220}, {"Word": "a", "OffsetStartMs": 2220, "OffsetEndMs": 2340}, {"Word": "higher", "OffsetStartMs": 2340, "OffsetEndMs": 2600}, {"Word": "return", "OffsetStartMs": 3850, "OffsetEndMs": 4250}], "SpeechSpeed": 9.1}, {"FinalSentence": "How about b?", "SliceSentence": "How about b", "StartMs": 1163860, "EndMs": 1165680, "WordsNum": 3, "Words": [{"Word": "How", "OffsetStartMs": 70, "OffsetEndMs": 330}, {"Word": "about", "OffsetStartMs": 330, "OffsetEndMs": 480}, {"Word": "b", "OffsetStartMs": 480, "OffsetEndMs": 770}], "SpeechSpeed": 6.0}, {"FinalSentence": "Okay, how about someone who picked b? Can you tell me why? B.", "SliceSentence": "Okay how about someone who picked b Can you tell me why B", "StartMs": 1166180, "EndMs": 1170620, "WordsNum": 13, "Words": [{"Word": "Okay", "OffsetStartMs": 220, "OffsetEndMs": 620}, {"Word": "how", "OffsetStartMs": 670, "OffsetEndMs": 930}, {"Word": "about", "OffsetStartMs": 930, "OffsetEndMs": 1080}, {"Word": "someone", "OffsetStartMs": 1080, "OffsetEndMs": 1290}, {"Word": "who", "OffsetStartMs": 1290, "OffsetEndMs": 1485}, {"Word": "picked", "OffsetStartMs": 1485, "OffsetEndMs": 1695}, {"Word": "b", "OffsetStartMs": 1695, "OffsetEndMs": 1995}, {"Word": "Can", "OffsetStartMs": 1995, "OffsetEndMs": 2250}, {"Word": "you", "OffsetStartMs": 2250, "OffsetEndMs": 2535}, {"Word": "tell", "OffsetStartMs": 2535, "OffsetEndMs": 2805}, {"Word": "me", "OffsetStartMs": 2805, "OffsetEndMs": 2955}, {"Word": "why", "OffsetStartMs": 2955, "OffsetEndMs": 3195}, {"Word": "B", "OffsetStartMs": 3195, "OffsetEndMs": 3560}], "SpeechSpeed": 12.8}, {"FinalSentence": "Agency, you're actually doing something.", "SliceSentence": "Agency you're actually doing something", "StartMs": 1172000, "EndMs": 1175600, "WordsNum": 5, "Words": [{"Word": "Agency", "OffsetStartMs": 160, "OffsetEndMs": 560}, {"Word": "you're", "OffsetStartMs": 1120, "OffsetEndMs": 1530}, {"Word": "actually", "OffsetStartMs": 1530, "OffsetEndMs": 1755}, {"Word": "doing", "OffsetStartMs": 1755, "OffsetEndMs": 2040}, {"Word": "something", "OffsetStartMs": 2040, "OffsetEndMs": 2420}], "SpeechSpeed": 10.6}, {"FinalSentence": "Okay, yeah about more for the for a you only have like the maximum you can take off is like one because after you reflect your automatically background more than exactly and actually there's a very interesting thing. So when I first saw this actually it's ah, it was very unintuitive for me. Y A is actually working much worse than b but in general with this very conservative action of b, your kind of exactly like you said, the two answers were implying is that a is a very conservative action. You're kind of only going up and down. It will achieve a good reward. It will solve the game, right? In fact it solves the game exactly like this right here. You can see in general this action is going to be quite conservative. It's just bouncing up, hitting one point at a time from the top and breaking off very slowly. The board that you can see here. But in general you see the part of the board that's being broken off is towards the center of the board, right? Not much on.", "SliceSentence": "Okay yeah about more for the for a you only have like the maximum you can take off is like one because after you reflect your automatically background more than exactly and actually there's a very interesting thing So when I first saw this actually it's ah it was very unintuitive for me Y A is actually working much worse than b but in general with this very conservative action of b your kind of exactly like you said the two answers were implying is that a is a very conservative action You're kind of only going up and down It will achieve a good reward It will solve the game right In fact it solves the game exactly like this right here You can see in general this action is going to be quite conservative It's just bouncing up hitting one point at a time from the top and breaking off very slowly The board that you can see here But in general you see the part of the board that's being broken off is towards the center of the board right Not much on", "StartMs": 1175600, "EndMs": 1236000, "WordsNum": 186, "Words": [{"Word": "Okay", "OffsetStartMs": 130, "OffsetEndMs": 530}, {"Word": "yeah", "OffsetStartMs": 730, "OffsetEndMs": 1130}, {"Word": "about", "OffsetStartMs": 1870, "OffsetEndMs": 2145}, {"Word": "more", "OffsetStartMs": 2145, "OffsetEndMs": 2420}, {"Word": "for", "OffsetStartMs": 3310, "OffsetEndMs": 3555}, {"Word": "the", "OffsetStartMs": 3555, "OffsetEndMs": 3800}, {"Word": "for", "OffsetStartMs": 4030, "OffsetEndMs": 4335}, {"Word": "a", "OffsetStartMs": 4335, "OffsetEndMs": 4620}, {"Word": "you", "OffsetStartMs": 4620, "OffsetEndMs": 4845}, {"Word": "only", "OffsetStartMs": 4845, "OffsetEndMs": 4980}, {"Word": "have", "OffsetStartMs": 4980, "OffsetEndMs": 5145}, {"Word": "like", "OffsetStartMs": 5145, "OffsetEndMs": 5420}, {"Word": "the", "OffsetStartMs": 5560, "OffsetEndMs": 5820}, {"Word": "maximum", "OffsetStartMs": 5820, "OffsetEndMs": 6045}, {"Word": "you", "OffsetStartMs": 6045, "OffsetEndMs": 6270}, {"Word": "can", "OffsetStartMs": 6270, "OffsetEndMs": 6405}, {"Word": "take", "OffsetStartMs": 6405, "OffsetEndMs": 6570}, {"Word": "off", "OffsetStartMs": 6570, "OffsetEndMs": 6735}, {"Word": "is", "OffsetStartMs": 6735, "OffsetEndMs": 6855}, {"Word": "like", "OffsetStartMs": 6855, "OffsetEndMs": 7035}, {"Word": "one", "OffsetStartMs": 7035, "OffsetEndMs": 7370}, {"Word": "because", "OffsetStartMs": 7420, "OffsetEndMs": 7785}, {"Word": "after", "OffsetStartMs": 7785, "OffsetEndMs": 8130}, {"Word": "you", "OffsetStartMs": 8130, "OffsetEndMs": 8475}, {"Word": "reflect", "OffsetStartMs": 8475, "OffsetEndMs": 8840}, {"Word": "your", "OffsetStartMs": 9310, "OffsetEndMs": 9645}, {"Word": "automatically", "OffsetStartMs": 9645, "OffsetEndMs": 9980}, {"Word": "background", "OffsetStartMs": 10150, "OffsetEndMs": 10550}, {"Word": "more", "OffsetStartMs": 13060, "OffsetEndMs": 13320}, {"Word": "than", "OffsetStartMs": 13320, "OffsetEndMs": 13580}, {"Word": "exactly", "OffsetStartMs": 14980, "OffsetEndMs": 15380}, {"Word": "and", "OffsetStartMs": 15490, "OffsetEndMs": 15885}, {"Word": "actually", "OffsetStartMs": 15885, "OffsetEndMs": 16200}, {"Word": "there's", "OffsetStartMs": 16200, "OffsetEndMs": 16485}, {"Word": "a", "OffsetStartMs": 16485, "OffsetEndMs": 16680}, {"Word": "very", "OffsetStartMs": 16680, "OffsetEndMs": 17030}, {"Word": "interesting", "OffsetStartMs": 17350, "OffsetEndMs": 17670}, {"Word": "thing", "OffsetStartMs": 17670, "OffsetEndMs": 17940}, {"Word": "So", "OffsetStartMs": 17940, "OffsetEndMs": 18290}, {"Word": "when", "OffsetStartMs": 18370, "OffsetEndMs": 18615}, {"Word": "I", "OffsetStartMs": 18615, "OffsetEndMs": 18750}, {"Word": "first", "OffsetStartMs": 18750, "OffsetEndMs": 18945}, {"Word": "saw", "OffsetStartMs": 18945, "OffsetEndMs": 19140}, {"Word": "this", "OffsetStartMs": 19140, "OffsetEndMs": 19430}, {"Word": "actually", "OffsetStartMs": 19510, "OffsetEndMs": 19875}, {"Word": "it's", "OffsetStartMs": 19875, "OffsetEndMs": 20295}, {"Word": "ah", "OffsetStartMs": 20295, "OffsetEndMs": 20570}, {"Word": "it", "OffsetStartMs": 21700, "OffsetEndMs": 21960}, {"Word": "was", "OffsetStartMs": 21960, "OffsetEndMs": 22110}, {"Word": "very", "OffsetStartMs": 22110, "OffsetEndMs": 22305}, {"Word": "unintuitive", "OffsetStartMs": 22305, "OffsetEndMs": 22920}, {"Word": "for", "OffsetStartMs": 22920, "OffsetEndMs": 23070}, {"Word": "me", "OffsetStartMs": 23070, "OffsetEndMs": 23295}, {"Word": "Y", "OffsetStartMs": 23295, "OffsetEndMs": 23610}, {"Word": "A", "OffsetStartMs": 23610, "OffsetEndMs": 23865}, {"Word": "is", "OffsetStartMs": 23865, "OffsetEndMs": 24170}, {"Word": "actually", "OffsetStartMs": 24190, "OffsetEndMs": 24555}, {"Word": "working", "OffsetStartMs": 24555, "OffsetEndMs": 24900}, {"Word": "much", "OffsetStartMs": 24900, "OffsetEndMs": 25215}, {"Word": "worse", "OffsetStartMs": 25215, "OffsetEndMs": 25530}, {"Word": "than", "OffsetStartMs": 25530, "OffsetEndMs": 25815}, {"Word": "b", "OffsetStartMs": 25815, "OffsetEndMs": 26040}, {"Word": "but", "OffsetStartMs": 26040, "OffsetEndMs": 26205}, {"Word": "in", "OffsetStartMs": 26205, "OffsetEndMs": 26340}, {"Word": "general", "OffsetStartMs": 26340, "OffsetEndMs": 26630}, {"Word": "with", "OffsetStartMs": 26740, "OffsetEndMs": 27000}, {"Word": "this", "OffsetStartMs": 27000, "OffsetEndMs": 27260}, {"Word": "very", "OffsetStartMs": 27340, "OffsetEndMs": 27740}, {"Word": "conservative", "OffsetStartMs": 27790, "OffsetEndMs": 28190}, {"Word": "action", "OffsetStartMs": 28240, "OffsetEndMs": 28640}, {"Word": "of", "OffsetStartMs": 29110, "OffsetEndMs": 29445}, {"Word": "b", "OffsetStartMs": 29445, "OffsetEndMs": 29775}, {"Word": "your", "OffsetStartMs": 29775, "OffsetEndMs": 30075}, {"Word": "kind", "OffsetStartMs": 30075, "OffsetEndMs": 30240}, {"Word": "of", "OffsetStartMs": 30240, "OffsetEndMs": 30405}, {"Word": "exactly", "OffsetStartMs": 30405, "OffsetEndMs": 30615}, {"Word": "like", "OffsetStartMs": 30615, "OffsetEndMs": 30795}, {"Word": "you", "OffsetStartMs": 30795, "OffsetEndMs": 30960}, {"Word": "said", "OffsetStartMs": 30960, "OffsetEndMs": 31250}, {"Word": "the", "OffsetStartMs": 31480, "OffsetEndMs": 31770}, {"Word": "two", "OffsetStartMs": 31770, "OffsetEndMs": 32060}, {"Word": "answers", "OffsetStartMs": 32200, "OffsetEndMs": 32600}, {"Word": "were", "OffsetStartMs": 32830, "OffsetEndMs": 33225}, {"Word": "implying", "OffsetStartMs": 33225, "OffsetEndMs": 33890}, {"Word": "is", "OffsetStartMs": 34240, "OffsetEndMs": 34515}, {"Word": "that", "OffsetStartMs": 34515, "OffsetEndMs": 34665}, {"Word": "a", "OffsetStartMs": 34665, "OffsetEndMs": 34815}, {"Word": "is", "OffsetStartMs": 34815, "OffsetEndMs": 34935}, {"Word": "a", "OffsetStartMs": 34935, "OffsetEndMs": 35025}, {"Word": "very", "OffsetStartMs": 35025, "OffsetEndMs": 35250}, {"Word": "conservative", "OffsetStartMs": 35250, "OffsetEndMs": 35565}, {"Word": "action", "OffsetStartMs": 35565, "OffsetEndMs": 35850}, {"Word": "You're", "OffsetStartMs": 35850, "OffsetEndMs": 36120}, {"Word": "kind", "OffsetStartMs": 36120, "OffsetEndMs": 36195}, {"Word": "of", "OffsetStartMs": 36195, "OffsetEndMs": 36315}, {"Word": "only", "OffsetStartMs": 36315, "OffsetEndMs": 36510}, {"Word": "going", "OffsetStartMs": 36510, "OffsetEndMs": 36705}, {"Word": "up", "OffsetStartMs": 36705, "OffsetEndMs": 36855}, {"Word": "and", "OffsetStartMs": 36855, "OffsetEndMs": 37020}, {"Word": "down", "OffsetStartMs": 37020, "OffsetEndMs": 37310}, {"Word": "It", "OffsetStartMs": 37810, "OffsetEndMs": 38070}, {"Word": "will", "OffsetStartMs": 38070, "OffsetEndMs": 38295}, {"Word": "achieve", "OffsetStartMs": 38295, "OffsetEndMs": 38535}, {"Word": "a", "OffsetStartMs": 38535, "OffsetEndMs": 38670}, {"Word": "good", "OffsetStartMs": 38670, "OffsetEndMs": 38850}, {"Word": "reward", "OffsetStartMs": 38850, "OffsetEndMs": 39075}, {"Word": "It", "OffsetStartMs": 39075, "OffsetEndMs": 39225}, {"Word": "will", "OffsetStartMs": 39225, "OffsetEndMs": 39375}, {"Word": "solve", "OffsetStartMs": 39375, "OffsetEndMs": 39615}, {"Word": "the", "OffsetStartMs": 39615, "OffsetEndMs": 39810}, {"Word": "game", "OffsetStartMs": 39810, "OffsetEndMs": 40070}, {"Word": "right", "OffsetStartMs": 40270, "OffsetEndMs": 40670}, {"Word": "In", "OffsetStartMs": 40750, "OffsetEndMs": 41010}, {"Word": "fact", "OffsetStartMs": 41010, "OffsetEndMs": 41160}, {"Word": "it", "OffsetStartMs": 41160, "OffsetEndMs": 41370}, {"Word": "solves", "OffsetStartMs": 41370, "OffsetEndMs": 41670}, {"Word": "the", "OffsetStartMs": 41670, "OffsetEndMs": 41790}, {"Word": "game", "OffsetStartMs": 41790, "OffsetEndMs": 42045}, {"Word": "exactly", "OffsetStartMs": 42045, "OffsetEndMs": 42405}, {"Word": "like", "OffsetStartMs": 42405, "OffsetEndMs": 42675}, {"Word": "this", "OffsetStartMs": 42675, "OffsetEndMs": 42915}, {"Word": "right", "OffsetStartMs": 42915, "OffsetEndMs": 43140}, {"Word": "here", "OffsetStartMs": 43140, "OffsetEndMs": 43290}, {"Word": "You", "OffsetStartMs": 43290, "OffsetEndMs": 43410}, {"Word": "can", "OffsetStartMs": 43410, "OffsetEndMs": 43560}, {"Word": "see", "OffsetStartMs": 43560, "OffsetEndMs": 43850}, {"Word": "in", "OffsetStartMs": 44110, "OffsetEndMs": 44400}, {"Word": "general", "OffsetStartMs": 44400, "OffsetEndMs": 44655}, {"Word": "this", "OffsetStartMs": 44655, "OffsetEndMs": 44955}, {"Word": "action", "OffsetStartMs": 44955, "OffsetEndMs": 45290}, {"Word": "is", "OffsetStartMs": 45460, "OffsetEndMs": 45780}, {"Word": "going", "OffsetStartMs": 45780, "OffsetEndMs": 45990}, {"Word": "to", "OffsetStartMs": 45990, "OffsetEndMs": 46125}, {"Word": "be", "OffsetStartMs": 46125, "OffsetEndMs": 46275}, {"Word": "quite", "OffsetStartMs": 46275, "OffsetEndMs": 46530}, {"Word": "conservative", "OffsetStartMs": 46530, "OffsetEndMs": 46830}, {"Word": "It's", "OffsetStartMs": 46830, "OffsetEndMs": 47100}, {"Word": "just", "OffsetStartMs": 47100, "OffsetEndMs": 47205}, {"Word": "bouncing", "OffsetStartMs": 47205, "OffsetEndMs": 47610}, {"Word": "up", "OffsetStartMs": 47610, "OffsetEndMs": 47870}, {"Word": "hitting", "OffsetStartMs": 48070, "OffsetEndMs": 48420}, {"Word": "one", "OffsetStartMs": 48420, "OffsetEndMs": 48705}, {"Word": "point", "OffsetStartMs": 48705, "OffsetEndMs": 48930}, {"Word": "at", "OffsetStartMs": 48930, "OffsetEndMs": 49065}, {"Word": "a", "OffsetStartMs": 49065, "OffsetEndMs": 49200}, {"Word": "time", "OffsetStartMs": 49200, "OffsetEndMs": 49490}, {"Word": "from", "OffsetStartMs": 49540, "OffsetEndMs": 49815}, {"Word": "the", "OffsetStartMs": 49815, "OffsetEndMs": 49965}, {"Word": "top", "OffsetStartMs": 49965, "OffsetEndMs": 50145}, {"Word": "and", "OffsetStartMs": 50145, "OffsetEndMs": 50340}, {"Word": "breaking", "OffsetStartMs": 50340, "OffsetEndMs": 50565}, {"Word": "off", "OffsetStartMs": 50565, "OffsetEndMs": 50835}, {"Word": "very", "OffsetStartMs": 50835, "OffsetEndMs": 51165}, {"Word": "slowly", "OffsetStartMs": 51165, "OffsetEndMs": 51560}, {"Word": "The", "OffsetStartMs": 52000, "OffsetEndMs": 52275}, {"Word": "board", "OffsetStartMs": 52275, "OffsetEndMs": 52485}, {"Word": "that", "OffsetStartMs": 52485, "OffsetEndMs": 52695}, {"Word": "you", "OffsetStartMs": 52695, "OffsetEndMs": 52845}, {"Word": "can", "OffsetStartMs": 52845, "OffsetEndMs": 53010}, {"Word": "see", "OffsetStartMs": 53010, "OffsetEndMs": 53190}, {"Word": "here", "OffsetStartMs": 53190, "OffsetEndMs": 53480}, {"Word": "But", "OffsetStartMs": 53860, "OffsetEndMs": 54260}, {"Word": "in", "OffsetStartMs": 54340, "OffsetEndMs": 54630}, {"Word": "general", "OffsetStartMs": 54630, "OffsetEndMs": 54885}, {"Word": "you", "OffsetStartMs": 54885, "OffsetEndMs": 55140}, {"Word": "see", "OffsetStartMs": 55140, "OffsetEndMs": 55320}, {"Word": "the", "OffsetStartMs": 55320, "OffsetEndMs": 55500}, {"Word": "part", "OffsetStartMs": 55500, "OffsetEndMs": 55665}, {"Word": "of", "OffsetStartMs": 55665, "OffsetEndMs": 55815}, {"Word": "the", "OffsetStartMs": 55815, "OffsetEndMs": 55950}, {"Word": "board", "OffsetStartMs": 55950, "OffsetEndMs": 56130}, {"Word": "that's", "OffsetStartMs": 56130, "OffsetEndMs": 56460}, {"Word": "being", "OffsetStartMs": 56460, "OffsetEndMs": 56625}, {"Word": "broken", "OffsetStartMs": 56625, "OffsetEndMs": 56865}, {"Word": "off", "OffsetStartMs": 56865, "OffsetEndMs": 57195}, {"Word": "is", "OffsetStartMs": 57195, "OffsetEndMs": 57510}, {"Word": "towards", "OffsetStartMs": 57510, "OffsetEndMs": 57750}, {"Word": "the", "OffsetStartMs": 57750, "OffsetEndMs": 57960}, {"Word": "center", "OffsetStartMs": 57960, "OffsetEndMs": 58250}, {"Word": "of", "OffsetStartMs": 58450, "OffsetEndMs": 58740}, {"Word": "the", "OffsetStartMs": 58740, "OffsetEndMs": 58890}, {"Word": "board", "OffsetStartMs": 58890, "OffsetEndMs": 59150}, {"Word": "right", "OffsetStartMs": 59290, "OffsetEndMs": 59655}, {"Word": "Not", "OffsetStartMs": 59655, "OffsetEndMs": 59940}, {"Word": "much", "OffsetStartMs": 59940, "OffsetEndMs": 60135}, {"Word": "on", "OffsetStartMs": 60135, "OffsetEndMs": 60360}], "SpeechSpeed": 15.8}, {"FinalSentence": "Edges of the board. If you look at b now with b, you're kind of having agency. Like one of the answers said you're coming towards the ball and what that implies is that you're sometimes going to actually hit the corner of your paddle and have a very extreme angle on your paddle and hit the sides of the board as well. And it turns out that the algorithm, the agent can actually learn that hitting the sides of the board can have some kind of unexpected consequences that look like this. So here you see it trying to enact that policy. It's targeting the sides of the board, but once it reaches a breakout on the side of the board, it found this hack in the solution where now it's breaking off a ton of points. So that was kind of a trick that this neural network learned. It was a way that it even moves away from the ball as it's coming down just so we could move back towards it, just to hit it on the corner and execute on those those corner parts of the board and break out a lot of pieces for free almost.", "SliceSentence": "Edges of the board If you look at b now with b you're kind of having agency Like one of the answers said you're coming towards the ball and what that implies is that you're sometimes going to actually hit the corner of your paddle and have a very extreme angle on your paddle and hit the sides of the board as well And it turns out that the algorithm the agent can actually learn that hitting the sides of the board can have some kind of unexpected consequences that look like this So here you see it trying to enact that policy It's targeting the sides of the board but once it reaches a breakout on the side of the board it found this hack in the solution where now it's breaking off a ton of points So that was kind of a trick that this neural network learned It was a way that it even moves away from the ball as it's coming down just so we could move back towards it just to hit it on the corner and execute on those those corner parts of the board and break out a lot of pieces for free almost", "StartMs": 1236000, "EndMs": 1292760, "WordsNum": 201, "Words": [{"Word": "Edges", "OffsetStartMs": 0, "OffsetEndMs": 315}, {"Word": "of", "OffsetStartMs": 315, "OffsetEndMs": 480}, {"Word": "the", "OffsetStartMs": 480, "OffsetEndMs": 630}, {"Word": "board", "OffsetStartMs": 630, "OffsetEndMs": 890}, {"Word": "If", "OffsetStartMs": 1270, "OffsetEndMs": 1545}, {"Word": "you", "OffsetStartMs": 1545, "OffsetEndMs": 1680}, {"Word": "look", "OffsetStartMs": 1680, "OffsetEndMs": 1815}, {"Word": "at", "OffsetStartMs": 1815, "OffsetEndMs": 2040}, {"Word": "b", "OffsetStartMs": 2040, "OffsetEndMs": 2390}, {"Word": "now", "OffsetStartMs": 2560, "OffsetEndMs": 2960}, {"Word": "with", "OffsetStartMs": 3340, "OffsetEndMs": 3660}, {"Word": "b", "OffsetStartMs": 3660, "OffsetEndMs": 3885}, {"Word": "you're", "OffsetStartMs": 3885, "OffsetEndMs": 4140}, {"Word": "kind", "OffsetStartMs": 4140, "OffsetEndMs": 4275}, {"Word": "of", "OffsetStartMs": 4275, "OffsetEndMs": 4550}, {"Word": "having", "OffsetStartMs": 4570, "OffsetEndMs": 4905}, {"Word": "agency", "OffsetStartMs": 4905, "OffsetEndMs": 5240}, {"Word": "Like", "OffsetStartMs": 5530, "OffsetEndMs": 5805}, {"Word": "one", "OffsetStartMs": 5805, "OffsetEndMs": 5925}, {"Word": "of", "OffsetStartMs": 5925, "OffsetEndMs": 6015}, {"Word": "the", "OffsetStartMs": 6015, "OffsetEndMs": 6105}, {"Word": "answers", "OffsetStartMs": 6105, "OffsetEndMs": 6350}, {"Word": "said", "OffsetStartMs": 6370, "OffsetEndMs": 6690}, {"Word": "you're", "OffsetStartMs": 6690, "OffsetEndMs": 6945}, {"Word": "coming", "OffsetStartMs": 6945, "OffsetEndMs": 7185}, {"Word": "towards", "OffsetStartMs": 7185, "OffsetEndMs": 7530}, {"Word": "the", "OffsetStartMs": 7530, "OffsetEndMs": 7740}, {"Word": "ball", "OffsetStartMs": 7740, "OffsetEndMs": 8000}, {"Word": "and", "OffsetStartMs": 8140, "OffsetEndMs": 8415}, {"Word": "what", "OffsetStartMs": 8415, "OffsetEndMs": 8565}, {"Word": "that", "OffsetStartMs": 8565, "OffsetEndMs": 8700}, {"Word": "implies", "OffsetStartMs": 8700, "OffsetEndMs": 9170}, {"Word": "is", "OffsetStartMs": 9520, "OffsetEndMs": 9795}, {"Word": "that", "OffsetStartMs": 9795, "OffsetEndMs": 9975}, {"Word": "you're", "OffsetStartMs": 9975, "OffsetEndMs": 10335}, {"Word": "sometimes", "OffsetStartMs": 10335, "OffsetEndMs": 10670}, {"Word": "going", "OffsetStartMs": 10840, "OffsetEndMs": 11115}, {"Word": "to", "OffsetStartMs": 11115, "OffsetEndMs": 11325}, {"Word": "actually", "OffsetStartMs": 11325, "OffsetEndMs": 11565}, {"Word": "hit", "OffsetStartMs": 11565, "OffsetEndMs": 11870}, {"Word": "the", "OffsetStartMs": 12040, "OffsetEndMs": 12360}, {"Word": "corner", "OffsetStartMs": 12360, "OffsetEndMs": 12630}, {"Word": "of", "OffsetStartMs": 12630, "OffsetEndMs": 12840}, {"Word": "your", "OffsetStartMs": 12840, "OffsetEndMs": 13020}, {"Word": "paddle", "OffsetStartMs": 13020, "OffsetEndMs": 13520}, {"Word": "and", "OffsetStartMs": 13540, "OffsetEndMs": 13800}, {"Word": "have", "OffsetStartMs": 13800, "OffsetEndMs": 13920}, {"Word": "a", "OffsetStartMs": 13920, "OffsetEndMs": 14055}, {"Word": "very", "OffsetStartMs": 14055, "OffsetEndMs": 14330}, {"Word": "extreme", "OffsetStartMs": 14440, "OffsetEndMs": 14775}, {"Word": "angle", "OffsetStartMs": 14775, "OffsetEndMs": 15110}, {"Word": "on", "OffsetStartMs": 15400, "OffsetEndMs": 15675}, {"Word": "your", "OffsetStartMs": 15675, "OffsetEndMs": 15855}, {"Word": "paddle", "OffsetStartMs": 15855, "OffsetEndMs": 16230}, {"Word": "and", "OffsetStartMs": 16230, "OffsetEndMs": 16425}, {"Word": "hit", "OffsetStartMs": 16425, "OffsetEndMs": 16590}, {"Word": "the", "OffsetStartMs": 16590, "OffsetEndMs": 16785}, {"Word": "sides", "OffsetStartMs": 16785, "OffsetEndMs": 17040}, {"Word": "of", "OffsetStartMs": 17040, "OffsetEndMs": 17265}, {"Word": "the", "OffsetStartMs": 17265, "OffsetEndMs": 17400}, {"Word": "board", "OffsetStartMs": 17400, "OffsetEndMs": 17580}, {"Word": "as", "OffsetStartMs": 17580, "OffsetEndMs": 17790}, {"Word": "well", "OffsetStartMs": 17790, "OffsetEndMs": 18080}, {"Word": "And", "OffsetStartMs": 18190, "OffsetEndMs": 18450}, {"Word": "it", "OffsetStartMs": 18450, "OffsetEndMs": 18600}, {"Word": "turns", "OffsetStartMs": 18600, "OffsetEndMs": 18810}, {"Word": "out", "OffsetStartMs": 18810, "OffsetEndMs": 19095}, {"Word": "that", "OffsetStartMs": 19095, "OffsetEndMs": 19410}, {"Word": "the", "OffsetStartMs": 19410, "OffsetEndMs": 19710}, {"Word": "algorithm", "OffsetStartMs": 19710, "OffsetEndMs": 20180}, {"Word": "the", "OffsetStartMs": 20260, "OffsetEndMs": 20520}, {"Word": "agent", "OffsetStartMs": 20520, "OffsetEndMs": 20780}, {"Word": "can", "OffsetStartMs": 20830, "OffsetEndMs": 21180}, {"Word": "actually", "OffsetStartMs": 21180, "OffsetEndMs": 21435}, {"Word": "learn", "OffsetStartMs": 21435, "OffsetEndMs": 21740}, {"Word": "that", "OffsetStartMs": 21940, "OffsetEndMs": 22335}, {"Word": "hitting", "OffsetStartMs": 22335, "OffsetEndMs": 22730}, {"Word": "the", "OffsetStartMs": 22900, "OffsetEndMs": 23190}, {"Word": "sides", "OffsetStartMs": 23190, "OffsetEndMs": 23370}, {"Word": "of", "OffsetStartMs": 23370, "OffsetEndMs": 23535}, {"Word": "the", "OffsetStartMs": 23535, "OffsetEndMs": 23670}, {"Word": "board", "OffsetStartMs": 23670, "OffsetEndMs": 23910}, {"Word": "can", "OffsetStartMs": 23910, "OffsetEndMs": 24150}, {"Word": "have", "OffsetStartMs": 24150, "OffsetEndMs": 24315}, {"Word": "some", "OffsetStartMs": 24315, "OffsetEndMs": 24620}, {"Word": "kind", "OffsetStartMs": 24670, "OffsetEndMs": 24930}, {"Word": "of", "OffsetStartMs": 24930, "OffsetEndMs": 25065}, {"Word": "unexpected", "OffsetStartMs": 25065, "OffsetEndMs": 25340}, {"Word": "consequences", "OffsetStartMs": 25660, "OffsetEndMs": 26060}, {"Word": "that", "OffsetStartMs": 26800, "OffsetEndMs": 27090}, {"Word": "look", "OffsetStartMs": 27090, "OffsetEndMs": 27255}, {"Word": "like", "OffsetStartMs": 27255, "OffsetEndMs": 27435}, {"Word": "this", "OffsetStartMs": 27435, "OffsetEndMs": 27740}, {"Word": "So", "OffsetStartMs": 27850, "OffsetEndMs": 28140}, {"Word": "here", "OffsetStartMs": 28140, "OffsetEndMs": 28305}, {"Word": "you", "OffsetStartMs": 28305, "OffsetEndMs": 28470}, {"Word": "see", "OffsetStartMs": 28470, "OffsetEndMs": 28605}, {"Word": "it", "OffsetStartMs": 28605, "OffsetEndMs": 28740}, {"Word": "trying", "OffsetStartMs": 28740, "OffsetEndMs": 28935}, {"Word": "to", "OffsetStartMs": 28935, "OffsetEndMs": 29085}, {"Word": "enact", "OffsetStartMs": 29085, "OffsetEndMs": 29355}, {"Word": "that", "OffsetStartMs": 29355, "OffsetEndMs": 29565}, {"Word": "policy", "OffsetStartMs": 29565, "OffsetEndMs": 29850}, {"Word": "It's", "OffsetStartMs": 29850, "OffsetEndMs": 30270}, {"Word": "targeting", "OffsetStartMs": 30270, "OffsetEndMs": 30735}, {"Word": "the", "OffsetStartMs": 30735, "OffsetEndMs": 30915}, {"Word": "sides", "OffsetStartMs": 30915, "OffsetEndMs": 31155}, {"Word": "of", "OffsetStartMs": 31155, "OffsetEndMs": 31365}, {"Word": "the", "OffsetStartMs": 31365, "OffsetEndMs": 31500}, {"Word": "board", "OffsetStartMs": 31500, "OffsetEndMs": 31760}, {"Word": "but", "OffsetStartMs": 32170, "OffsetEndMs": 32460}, {"Word": "once", "OffsetStartMs": 32460, "OffsetEndMs": 32655}, {"Word": "it", "OffsetStartMs": 32655, "OffsetEndMs": 32835}, {"Word": "reaches", "OffsetStartMs": 32835, "OffsetEndMs": 33285}, {"Word": "a", "OffsetStartMs": 33285, "OffsetEndMs": 33540}, {"Word": "breakout", "OffsetStartMs": 33540, "OffsetEndMs": 33930}, {"Word": "on", "OffsetStartMs": 33930, "OffsetEndMs": 34080}, {"Word": "the", "OffsetStartMs": 34080, "OffsetEndMs": 34200}, {"Word": "side", "OffsetStartMs": 34200, "OffsetEndMs": 34320}, {"Word": "of", "OffsetStartMs": 34320, "OffsetEndMs": 34410}, {"Word": "the", "OffsetStartMs": 34410, "OffsetEndMs": 34500}, {"Word": "board", "OffsetStartMs": 34500, "OffsetEndMs": 34760}, {"Word": "it", "OffsetStartMs": 34840, "OffsetEndMs": 35130}, {"Word": "found", "OffsetStartMs": 35130, "OffsetEndMs": 35325}, {"Word": "this", "OffsetStartMs": 35325, "OffsetEndMs": 35535}, {"Word": "hack", "OffsetStartMs": 35535, "OffsetEndMs": 35840}, {"Word": "in", "OffsetStartMs": 35890, "OffsetEndMs": 36165}, {"Word": "the", "OffsetStartMs": 36165, "OffsetEndMs": 36330}, {"Word": "solution", "OffsetStartMs": 36330, "OffsetEndMs": 36620}, {"Word": "where", "OffsetStartMs": 36700, "OffsetEndMs": 36960}, {"Word": "now", "OffsetStartMs": 36960, "OffsetEndMs": 37080}, {"Word": "it's", "OffsetStartMs": 37080, "OffsetEndMs": 37275}, {"Word": "breaking", "OffsetStartMs": 37275, "OffsetEndMs": 37470}, {"Word": "off", "OffsetStartMs": 37470, "OffsetEndMs": 37665}, {"Word": "a", "OffsetStartMs": 37665, "OffsetEndMs": 37830}, {"Word": "ton", "OffsetStartMs": 37830, "OffsetEndMs": 37980}, {"Word": "of", "OffsetStartMs": 37980, "OffsetEndMs": 38130}, {"Word": "points", "OffsetStartMs": 38130, "OffsetEndMs": 38420}, {"Word": "So", "OffsetStartMs": 38980, "OffsetEndMs": 39255}, {"Word": "that", "OffsetStartMs": 39255, "OffsetEndMs": 39405}, {"Word": "was", "OffsetStartMs": 39405, "OffsetEndMs": 39630}, {"Word": "kind", "OffsetStartMs": 39630, "OffsetEndMs": 39855}, {"Word": "of", "OffsetStartMs": 39855, "OffsetEndMs": 40080}, {"Word": "a", "OffsetStartMs": 40080, "OffsetEndMs": 40365}, {"Word": "trick", "OffsetStartMs": 40365, "OffsetEndMs": 40700}, {"Word": "that", "OffsetStartMs": 40720, "OffsetEndMs": 41055}, {"Word": "this", "OffsetStartMs": 41055, "OffsetEndMs": 41310}, {"Word": "neural", "OffsetStartMs": 41310, "OffsetEndMs": 41580}, {"Word": "network", "OffsetStartMs": 41580, "OffsetEndMs": 41840}, {"Word": "learned", "OffsetStartMs": 41860, "OffsetEndMs": 42260}, {"Word": "It", "OffsetStartMs": 42790, "OffsetEndMs": 43080}, {"Word": "was", "OffsetStartMs": 43080, "OffsetEndMs": 43245}, {"Word": "a", "OffsetStartMs": 43245, "OffsetEndMs": 43395}, {"Word": "way", "OffsetStartMs": 43395, "OffsetEndMs": 43590}, {"Word": "that", "OffsetStartMs": 43590, "OffsetEndMs": 43800}, {"Word": "it", "OffsetStartMs": 43800, "OffsetEndMs": 43965}, {"Word": "even", "OffsetStartMs": 43965, "OffsetEndMs": 44220}, {"Word": "moves", "OffsetStartMs": 44220, "OffsetEndMs": 44600}, {"Word": "away", "OffsetStartMs": 44650, "OffsetEndMs": 45050}, {"Word": "from", "OffsetStartMs": 45130, "OffsetEndMs": 45405}, {"Word": "the", "OffsetStartMs": 45405, "OffsetEndMs": 45555}, {"Word": "ball", "OffsetStartMs": 45555, "OffsetEndMs": 45830}, {"Word": "as", "OffsetStartMs": 45910, "OffsetEndMs": 46185}, {"Word": "it's", "OffsetStartMs": 46185, "OffsetEndMs": 46395}, {"Word": "coming", "OffsetStartMs": 46395, "OffsetEndMs": 46560}, {"Word": "down", "OffsetStartMs": 46560, "OffsetEndMs": 46800}, {"Word": "just", "OffsetStartMs": 46800, "OffsetEndMs": 47010}, {"Word": "so", "OffsetStartMs": 47010, "OffsetEndMs": 47160}, {"Word": "we", "OffsetStartMs": 47160, "OffsetEndMs": 47280}, {"Word": "could", "OffsetStartMs": 47280, "OffsetEndMs": 47430}, {"Word": "move", "OffsetStartMs": 47430, "OffsetEndMs": 47640}, {"Word": "back", "OffsetStartMs": 47640, "OffsetEndMs": 47910}, {"Word": "towards", "OffsetStartMs": 47910, "OffsetEndMs": 48165}, {"Word": "it", "OffsetStartMs": 48165, "OffsetEndMs": 48345}, {"Word": "just", "OffsetStartMs": 48345, "OffsetEndMs": 48510}, {"Word": "to", "OffsetStartMs": 48510, "OffsetEndMs": 48645}, {"Word": "hit", "OffsetStartMs": 48645, "OffsetEndMs": 48795}, {"Word": "it", "OffsetStartMs": 48795, "OffsetEndMs": 48990}, {"Word": "on", "OffsetStartMs": 48990, "OffsetEndMs": 49155}, {"Word": "the", "OffsetStartMs": 49155, "OffsetEndMs": 49320}, {"Word": "corner", "OffsetStartMs": 49320, "OffsetEndMs": 49610}, {"Word": "and", "OffsetStartMs": 49840, "OffsetEndMs": 50240}, {"Word": "execute", "OffsetStartMs": 50320, "OffsetEndMs": 50580}, {"Word": "on", "OffsetStartMs": 50580, "OffsetEndMs": 50715}, {"Word": "those", "OffsetStartMs": 50715, "OffsetEndMs": 50990}, {"Word": "those", "OffsetStartMs": 51130, "OffsetEndMs": 51495}, {"Word": "corner", "OffsetStartMs": 51495, "OffsetEndMs": 51860}, {"Word": "parts", "OffsetStartMs": 51880, "OffsetEndMs": 52185}, {"Word": "of", "OffsetStartMs": 52185, "OffsetEndMs": 52380}, {"Word": "the", "OffsetStartMs": 52380, "OffsetEndMs": 52515}, {"Word": "board", "OffsetStartMs": 52515, "OffsetEndMs": 52710}, {"Word": "and", "OffsetStartMs": 52710, "OffsetEndMs": 52965}, {"Word": "break", "OffsetStartMs": 52965, "OffsetEndMs": 53160}, {"Word": "out", "OffsetStartMs": 53160, "OffsetEndMs": 53340}, {"Word": "a", "OffsetStartMs": 53340, "OffsetEndMs": 53505}, {"Word": "lot", "OffsetStartMs": 53505, "OffsetEndMs": 53655}, {"Word": "of", "OffsetStartMs": 53655, "OffsetEndMs": 53930}, {"Word": "pieces", "OffsetStartMs": 54070, "OffsetEndMs": 54470}, {"Word": "for", "OffsetStartMs": 54640, "OffsetEndMs": 54960}, {"Word": "free", "OffsetStartMs": 54960, "OffsetEndMs": 55280}, {"Word": "almost", "OffsetStartMs": 55360, "OffsetEndMs": 55760}], "SpeechSpeed": 17.6}, {"FinalSentence": "So now that we can see that sometimes obtaining the q function can be a little bit unintuitive, but the key point here is that if we have the q function, we can directly use it to determine, you know, what is the best action that we can take in any given state that we find ourselves in? So now the question naturally is how can we train a neural network that can indeed learn this q function?", "SliceSentence": "So now that we can see that sometimes obtaining the q function can be a little bit unintuitive but the key point here is that if we have the q function we can directly use it to determine you know what is the best action that we can take in any given state that we find ourselves in So now the question naturally is how can we train a neural network that can indeed learn this q function", "StartMs": 1293460, "EndMs": 1317100, "WordsNum": 78, "Words": [{"Word": "So", "OffsetStartMs": 340, "OffsetEndMs": 600}, {"Word": "now", "OffsetStartMs": 600, "OffsetEndMs": 750}, {"Word": "that", "OffsetStartMs": 750, "OffsetEndMs": 960}, {"Word": "we", "OffsetStartMs": 960, "OffsetEndMs": 1140}, {"Word": "can", "OffsetStartMs": 1140, "OffsetEndMs": 1290}, {"Word": "see", "OffsetStartMs": 1290, "OffsetEndMs": 1455}, {"Word": "that", "OffsetStartMs": 1455, "OffsetEndMs": 1730}, {"Word": "sometimes", "OffsetStartMs": 1750, "OffsetEndMs": 2145}, {"Word": "obtaining", "OffsetStartMs": 2145, "OffsetEndMs": 2655}, {"Word": "the", "OffsetStartMs": 2655, "OffsetEndMs": 2865}, {"Word": "q", "OffsetStartMs": 2865, "OffsetEndMs": 3030}, {"Word": "function", "OffsetStartMs": 3030, "OffsetEndMs": 3320}, {"Word": "can", "OffsetStartMs": 3580, "OffsetEndMs": 3980}, {"Word": "be", "OffsetStartMs": 4150, "OffsetEndMs": 4470}, {"Word": "a", "OffsetStartMs": 4470, "OffsetEndMs": 4650}, {"Word": "little", "OffsetStartMs": 4650, "OffsetEndMs": 4800}, {"Word": "bit", "OffsetStartMs": 4800, "OffsetEndMs": 4950}, {"Word": "unintuitive", "OffsetStartMs": 4950, "OffsetEndMs": 5780}, {"Word": "but", "OffsetStartMs": 5920, "OffsetEndMs": 6320}, {"Word": "the", "OffsetStartMs": 6370, "OffsetEndMs": 6675}, {"Word": "key", "OffsetStartMs": 6675, "OffsetEndMs": 6885}, {"Word": "point", "OffsetStartMs": 6885, "OffsetEndMs": 7125}, {"Word": "here", "OffsetStartMs": 7125, "OffsetEndMs": 7320}, {"Word": "is", "OffsetStartMs": 7320, "OffsetEndMs": 7470}, {"Word": "that", "OffsetStartMs": 7470, "OffsetEndMs": 7665}, {"Word": "if", "OffsetStartMs": 7665, "OffsetEndMs": 7845}, {"Word": "we", "OffsetStartMs": 7845, "OffsetEndMs": 7995}, {"Word": "have", "OffsetStartMs": 7995, "OffsetEndMs": 8175}, {"Word": "the", "OffsetStartMs": 8175, "OffsetEndMs": 8340}, {"Word": "q", "OffsetStartMs": 8340, "OffsetEndMs": 8490}, {"Word": "function", "OffsetStartMs": 8490, "OffsetEndMs": 8760}, {"Word": "we", "OffsetStartMs": 8760, "OffsetEndMs": 9000}, {"Word": "can", "OffsetStartMs": 9000, "OffsetEndMs": 9195}, {"Word": "directly", "OffsetStartMs": 9195, "OffsetEndMs": 9480}, {"Word": "use", "OffsetStartMs": 9480, "OffsetEndMs": 9735}, {"Word": "it", "OffsetStartMs": 9735, "OffsetEndMs": 10040}, {"Word": "to", "OffsetStartMs": 10210, "OffsetEndMs": 10610}, {"Word": "determine", "OffsetStartMs": 10660, "OffsetEndMs": 11060}, {"Word": "you", "OffsetStartMs": 11080, "OffsetEndMs": 11325}, {"Word": "know", "OffsetStartMs": 11325, "OffsetEndMs": 11445}, {"Word": "what", "OffsetStartMs": 11445, "OffsetEndMs": 11610}, {"Word": "is", "OffsetStartMs": 11610, "OffsetEndMs": 11835}, {"Word": "the", "OffsetStartMs": 11835, "OffsetEndMs": 12045}, {"Word": "best", "OffsetStartMs": 12045, "OffsetEndMs": 12270}, {"Word": "action", "OffsetStartMs": 12270, "OffsetEndMs": 12620}, {"Word": "that", "OffsetStartMs": 12880, "OffsetEndMs": 13230}, {"Word": "we", "OffsetStartMs": 13230, "OffsetEndMs": 13440}, {"Word": "can", "OffsetStartMs": 13440, "OffsetEndMs": 13575}, {"Word": "take", "OffsetStartMs": 13575, "OffsetEndMs": 13740}, {"Word": "in", "OffsetStartMs": 13740, "OffsetEndMs": 13905}, {"Word": "any", "OffsetStartMs": 13905, "OffsetEndMs": 14100}, {"Word": "given", "OffsetStartMs": 14100, "OffsetEndMs": 14415}, {"Word": "state", "OffsetStartMs": 14415, "OffsetEndMs": 14810}, {"Word": "that", "OffsetStartMs": 14920, "OffsetEndMs": 15165}, {"Word": "we", "OffsetStartMs": 15165, "OffsetEndMs": 15285}, {"Word": "find", "OffsetStartMs": 15285, "OffsetEndMs": 15540}, {"Word": "ourselves", "OffsetStartMs": 15540, "OffsetEndMs": 15825}, {"Word": "in", "OffsetStartMs": 15825, "OffsetEndMs": 16050}, {"Word": "So", "OffsetStartMs": 16050, "OffsetEndMs": 16260}, {"Word": "now", "OffsetStartMs": 16260, "OffsetEndMs": 16410}, {"Word": "the", "OffsetStartMs": 16410, "OffsetEndMs": 16545}, {"Word": "question", "OffsetStartMs": 16545, "OffsetEndMs": 16820}, {"Word": "naturally", "OffsetStartMs": 17050, "OffsetEndMs": 17400}, {"Word": "is", "OffsetStartMs": 17400, "OffsetEndMs": 17750}, {"Word": "how", "OffsetStartMs": 17950, "OffsetEndMs": 18240}, {"Word": "can", "OffsetStartMs": 18240, "OffsetEndMs": 18390}, {"Word": "we", "OffsetStartMs": 18390, "OffsetEndMs": 18555}, {"Word": "train", "OffsetStartMs": 18555, "OffsetEndMs": 18750}, {"Word": "a", "OffsetStartMs": 18750, "OffsetEndMs": 18900}, {"Word": "neural", "OffsetStartMs": 18900, "OffsetEndMs": 19125}, {"Word": "network", "OffsetStartMs": 19125, "OffsetEndMs": 19400}, {"Word": "that", "OffsetStartMs": 19570, "OffsetEndMs": 19890}, {"Word": "can", "OffsetStartMs": 19890, "OffsetEndMs": 20210}, {"Word": "indeed", "OffsetStartMs": 20470, "OffsetEndMs": 20870}, {"Word": "learn", "OffsetStartMs": 20920, "OffsetEndMs": 21300}, {"Word": "this", "OffsetStartMs": 21300, "OffsetEndMs": 21630}, {"Word": "q", "OffsetStartMs": 21630, "OffsetEndMs": 21870}, {"Word": "function", "OffsetStartMs": 21870, "OffsetEndMs": 22160}], "SpeechSpeed": 16.4}, {"FinalSentence": "So the type of the neural network here, naturally, because we have a function that takes as input two things, let's imagine our neural network will also take as input these two objects as well. One object is going to be the state of the board. You can think of this as simply the pixels that are on the screen describing that board. So it's an image of the board at a particular time. Maybe you want to even provide two or three images to give it some sense of temporal information and some past history as well. But all of that information can be combined together and provided to the network in the form of a state.", "SliceSentence": "So the type of the neural network here naturally because we have a function that takes as input two things let's imagine our neural network will also take as input these two objects as well One object is going to be the state of the board You can think of this as simply the pixels that are on the screen describing that board So it's an image of the board at a particular time Maybe you want to even provide two or three images to give it some sense of temporal information and some past history as well But all of that information can be combined together and provided to the network in the form of a state", "StartMs": 1317180, "EndMs": 1348940, "WordsNum": 118, "Words": [{"Word": "So", "OffsetStartMs": 160, "OffsetEndMs": 560}, {"Word": "the", "OffsetStartMs": 1510, "OffsetEndMs": 1860}, {"Word": "type", "OffsetStartMs": 1860, "OffsetEndMs": 2100}, {"Word": "of", "OffsetStartMs": 2100, "OffsetEndMs": 2265}, {"Word": "the", "OffsetStartMs": 2265, "OffsetEndMs": 2385}, {"Word": "neural", "OffsetStartMs": 2385, "OffsetEndMs": 2580}, {"Word": "network", "OffsetStartMs": 2580, "OffsetEndMs": 2820}, {"Word": "here", "OffsetStartMs": 2820, "OffsetEndMs": 3200}, {"Word": "naturally", "OffsetStartMs": 3370, "OffsetEndMs": 3770}, {"Word": "because", "OffsetStartMs": 3850, "OffsetEndMs": 4140}, {"Word": "we", "OffsetStartMs": 4140, "OffsetEndMs": 4275}, {"Word": "have", "OffsetStartMs": 4275, "OffsetEndMs": 4365}, {"Word": "a", "OffsetStartMs": 4365, "OffsetEndMs": 4485}, {"Word": "function", "OffsetStartMs": 4485, "OffsetEndMs": 4755}, {"Word": "that", "OffsetStartMs": 4755, "OffsetEndMs": 5040}, {"Word": "takes", "OffsetStartMs": 5040, "OffsetEndMs": 5220}, {"Word": "as", "OffsetStartMs": 5220, "OffsetEndMs": 5460}, {"Word": "input", "OffsetStartMs": 5460, "OffsetEndMs": 5715}, {"Word": "two", "OffsetStartMs": 5715, "OffsetEndMs": 5910}, {"Word": "things", "OffsetStartMs": 5910, "OffsetEndMs": 6135}, {"Word": "let's", "OffsetStartMs": 6135, "OffsetEndMs": 6465}, {"Word": "imagine", "OffsetStartMs": 6465, "OffsetEndMs": 6675}, {"Word": "our", "OffsetStartMs": 6675, "OffsetEndMs": 6900}, {"Word": "neural", "OffsetStartMs": 6900, "OffsetEndMs": 7140}, {"Word": "network", "OffsetStartMs": 7140, "OffsetEndMs": 7365}, {"Word": "will", "OffsetStartMs": 7365, "OffsetEndMs": 7710}, {"Word": "also", "OffsetStartMs": 7710, "OffsetEndMs": 8025}, {"Word": "take", "OffsetStartMs": 8025, "OffsetEndMs": 8235}, {"Word": "as", "OffsetStartMs": 8235, "OffsetEndMs": 8510}, {"Word": "input", "OffsetStartMs": 8530, "OffsetEndMs": 8930}, {"Word": "these", "OffsetStartMs": 8950, "OffsetEndMs": 9345}, {"Word": "two", "OffsetStartMs": 9345, "OffsetEndMs": 9740}, {"Word": "objects", "OffsetStartMs": 10060, "OffsetEndMs": 10365}, {"Word": "as", "OffsetStartMs": 10365, "OffsetEndMs": 10560}, {"Word": "well", "OffsetStartMs": 10560, "OffsetEndMs": 10845}, {"Word": "One", "OffsetStartMs": 10845, "OffsetEndMs": 11240}, {"Word": "object", "OffsetStartMs": 11260, "OffsetEndMs": 11565}, {"Word": "is", "OffsetStartMs": 11565, "OffsetEndMs": 11760}, {"Word": "going", "OffsetStartMs": 11760, "OffsetEndMs": 11925}, {"Word": "to", "OffsetStartMs": 11925, "OffsetEndMs": 12045}, {"Word": "be", "OffsetStartMs": 12045, "OffsetEndMs": 12165}, {"Word": "the", "OffsetStartMs": 12165, "OffsetEndMs": 12345}, {"Word": "state", "OffsetStartMs": 12345, "OffsetEndMs": 12525}, {"Word": "of", "OffsetStartMs": 12525, "OffsetEndMs": 12675}, {"Word": "the", "OffsetStartMs": 12675, "OffsetEndMs": 12810}, {"Word": "board", "OffsetStartMs": 12810, "OffsetEndMs": 12990}, {"Word": "You", "OffsetStartMs": 12990, "OffsetEndMs": 13155}, {"Word": "can", "OffsetStartMs": 13155, "OffsetEndMs": 13275}, {"Word": "think", "OffsetStartMs": 13275, "OffsetEndMs": 13425}, {"Word": "of", "OffsetStartMs": 13425, "OffsetEndMs": 13560}, {"Word": "this", "OffsetStartMs": 13560, "OffsetEndMs": 13710}, {"Word": "as", "OffsetStartMs": 13710, "OffsetEndMs": 13890}, {"Word": "simply", "OffsetStartMs": 13890, "OffsetEndMs": 14145}, {"Word": "the", "OffsetStartMs": 14145, "OffsetEndMs": 14400}, {"Word": "pixels", "OffsetStartMs": 14400, "OffsetEndMs": 14835}, {"Word": "that", "OffsetStartMs": 14835, "OffsetEndMs": 15030}, {"Word": "are", "OffsetStartMs": 15030, "OffsetEndMs": 15135}, {"Word": "on", "OffsetStartMs": 15135, "OffsetEndMs": 15255}, {"Word": "the", "OffsetStartMs": 15255, "OffsetEndMs": 15450}, {"Word": "screen", "OffsetStartMs": 15450, "OffsetEndMs": 15770}, {"Word": "describing", "OffsetStartMs": 16030, "OffsetEndMs": 16530}, {"Word": "that", "OffsetStartMs": 16530, "OffsetEndMs": 16725}, {"Word": "board", "OffsetStartMs": 16725, "OffsetEndMs": 16980}, {"Word": "So", "OffsetStartMs": 16980, "OffsetEndMs": 17145}, {"Word": "it's", "OffsetStartMs": 17145, "OffsetEndMs": 17280}, {"Word": "an", "OffsetStartMs": 17280, "OffsetEndMs": 17370}, {"Word": "image", "OffsetStartMs": 17370, "OffsetEndMs": 17630}, {"Word": "of", "OffsetStartMs": 17680, "OffsetEndMs": 17955}, {"Word": "the", "OffsetStartMs": 17955, "OffsetEndMs": 18090}, {"Word": "board", "OffsetStartMs": 18090, "OffsetEndMs": 18255}, {"Word": "at", "OffsetStartMs": 18255, "OffsetEndMs": 18420}, {"Word": "a", "OffsetStartMs": 18420, "OffsetEndMs": 18600}, {"Word": "particular", "OffsetStartMs": 18600, "OffsetEndMs": 18920}, {"Word": "time", "OffsetStartMs": 18940, "OffsetEndMs": 19260}, {"Word": "Maybe", "OffsetStartMs": 19260, "OffsetEndMs": 19455}, {"Word": "you", "OffsetStartMs": 19455, "OffsetEndMs": 19590}, {"Word": "want", "OffsetStartMs": 19590, "OffsetEndMs": 19740}, {"Word": "to", "OffsetStartMs": 19740, "OffsetEndMs": 19860}, {"Word": "even", "OffsetStartMs": 19860, "OffsetEndMs": 20085}, {"Word": "provide", "OffsetStartMs": 20085, "OffsetEndMs": 20480}, {"Word": "two", "OffsetStartMs": 20740, "OffsetEndMs": 21030}, {"Word": "or", "OffsetStartMs": 21030, "OffsetEndMs": 21210}, {"Word": "three", "OffsetStartMs": 21210, "OffsetEndMs": 21360}, {"Word": "images", "OffsetStartMs": 21360, "OffsetEndMs": 21620}, {"Word": "to", "OffsetStartMs": 21640, "OffsetEndMs": 22040}, {"Word": "give", "OffsetStartMs": 22090, "OffsetEndMs": 22350}, {"Word": "it", "OffsetStartMs": 22350, "OffsetEndMs": 22500}, {"Word": "some", "OffsetStartMs": 22500, "OffsetEndMs": 22710}, {"Word": "sense", "OffsetStartMs": 22710, "OffsetEndMs": 22935}, {"Word": "of", "OffsetStartMs": 22935, "OffsetEndMs": 23160}, {"Word": "temporal", "OffsetStartMs": 23160, "OffsetEndMs": 23660}, {"Word": "information", "OffsetStartMs": 23770, "OffsetEndMs": 24170}, {"Word": "and", "OffsetStartMs": 24520, "OffsetEndMs": 24795}, {"Word": "some", "OffsetStartMs": 24795, "OffsetEndMs": 24975}, {"Word": "past", "OffsetStartMs": 24975, "OffsetEndMs": 25230}, {"Word": "history", "OffsetStartMs": 25230, "OffsetEndMs": 25545}, {"Word": "as", "OffsetStartMs": 25545, "OffsetEndMs": 25815}, {"Word": "well", "OffsetStartMs": 25815, "OffsetEndMs": 26055}, {"Word": "But", "OffsetStartMs": 26055, "OffsetEndMs": 26390}, {"Word": "all", "OffsetStartMs": 26620, "OffsetEndMs": 26895}, {"Word": "of", "OffsetStartMs": 26895, "OffsetEndMs": 27030}, {"Word": "that", "OffsetStartMs": 27030, "OffsetEndMs": 27255}, {"Word": "information", "OffsetStartMs": 27255, "OffsetEndMs": 27585}, {"Word": "can", "OffsetStartMs": 27585, "OffsetEndMs": 27825}, {"Word": "be", "OffsetStartMs": 27825, "OffsetEndMs": 28050}, {"Word": "combined", "OffsetStartMs": 28050, "OffsetEndMs": 28380}, {"Word": "together", "OffsetStartMs": 28380, "OffsetEndMs": 28760}, {"Word": "and", "OffsetStartMs": 29020, "OffsetEndMs": 29355}, {"Word": "provided", "OffsetStartMs": 29355, "OffsetEndMs": 29655}, {"Word": "to", "OffsetStartMs": 29655, "OffsetEndMs": 29850}, {"Word": "the", "OffsetStartMs": 29850, "OffsetEndMs": 29940}, {"Word": "network", "OffsetStartMs": 29940, "OffsetEndMs": 30150}, {"Word": "in", "OffsetStartMs": 30150, "OffsetEndMs": 30345}, {"Word": "the", "OffsetStartMs": 30345, "OffsetEndMs": 30465}, {"Word": "form", "OffsetStartMs": 30465, "OffsetEndMs": 30615}, {"Word": "of", "OffsetStartMs": 30615, "OffsetEndMs": 30750}, {"Word": "a", "OffsetStartMs": 30750, "OffsetEndMs": 30915}, {"Word": "state", "OffsetStartMs": 30915, "OffsetEndMs": 31220}], "SpeechSpeed": 19.1}, {"FinalSentence": "And in addition to that, you may also want to provide some actions as well, right? So in this case, the actions that a neural network or an agent could take in this game is to move to the right, to the left, to stay still. And those could be three different actions that could be provided and parameterized to the input of a neural network. The goal here is to, you know, estimate the single number output.", "SliceSentence": "And in addition to that you may also want to provide some actions as well right So in this case the actions that a neural network or an agent could take in this game is to move to the right to the left to stay still And those could be three different actions that could be provided and parameterized to the input of a neural network The goal here is to you know estimate the single number output", "StartMs": 1348940, "EndMs": 1371740, "WordsNum": 78, "Words": [{"Word": "And", "OffsetStartMs": 10, "OffsetEndMs": 315}, {"Word": "in", "OffsetStartMs": 315, "OffsetEndMs": 540}, {"Word": "addition", "OffsetStartMs": 540, "OffsetEndMs": 810}, {"Word": "to", "OffsetStartMs": 810, "OffsetEndMs": 1005}, {"Word": "that", "OffsetStartMs": 1005, "OffsetEndMs": 1140}, {"Word": "you", "OffsetStartMs": 1140, "OffsetEndMs": 1290}, {"Word": "may", "OffsetStartMs": 1290, "OffsetEndMs": 1500}, {"Word": "also", "OffsetStartMs": 1500, "OffsetEndMs": 1710}, {"Word": "want", "OffsetStartMs": 1710, "OffsetEndMs": 1875}, {"Word": "to", "OffsetStartMs": 1875, "OffsetEndMs": 2180}, {"Word": "provide", "OffsetStartMs": 2200, "OffsetEndMs": 2580}, {"Word": "some", "OffsetStartMs": 2580, "OffsetEndMs": 2850}, {"Word": "actions", "OffsetStartMs": 2850, "OffsetEndMs": 3140}, {"Word": "as", "OffsetStartMs": 3400, "OffsetEndMs": 3720}, {"Word": "well", "OffsetStartMs": 3720, "OffsetEndMs": 3990}, {"Word": "right", "OffsetStartMs": 3990, "OffsetEndMs": 4245}, {"Word": "So", "OffsetStartMs": 4245, "OffsetEndMs": 4380}, {"Word": "in", "OffsetStartMs": 4380, "OffsetEndMs": 4470}, {"Word": "this", "OffsetStartMs": 4470, "OffsetEndMs": 4635}, {"Word": "case", "OffsetStartMs": 4635, "OffsetEndMs": 4875}, {"Word": "the", "OffsetStartMs": 4875, "OffsetEndMs": 5055}, {"Word": "actions", "OffsetStartMs": 5055, "OffsetEndMs": 5300}, {"Word": "that", "OffsetStartMs": 5410, "OffsetEndMs": 5810}, {"Word": "a", "OffsetStartMs": 6100, "OffsetEndMs": 6500}, {"Word": "neural", "OffsetStartMs": 6730, "OffsetEndMs": 7095}, {"Word": "network", "OffsetStartMs": 7095, "OffsetEndMs": 7340}, {"Word": "or", "OffsetStartMs": 7360, "OffsetEndMs": 7605}, {"Word": "an", "OffsetStartMs": 7605, "OffsetEndMs": 7710}, {"Word": "agent", "OffsetStartMs": 7710, "OffsetEndMs": 7970}, {"Word": "could", "OffsetStartMs": 8110, "OffsetEndMs": 8400}, {"Word": "take", "OffsetStartMs": 8400, "OffsetEndMs": 8670}, {"Word": "in", "OffsetStartMs": 8670, "OffsetEndMs": 8925}, {"Word": "this", "OffsetStartMs": 8925, "OffsetEndMs": 9120}, {"Word": "game", "OffsetStartMs": 9120, "OffsetEndMs": 9440}, {"Word": "is", "OffsetStartMs": 9550, "OffsetEndMs": 9885}, {"Word": "to", "OffsetStartMs": 9885, "OffsetEndMs": 10080}, {"Word": "move", "OffsetStartMs": 10080, "OffsetEndMs": 10340}, {"Word": "to", "OffsetStartMs": 10390, "OffsetEndMs": 10635}, {"Word": "the", "OffsetStartMs": 10635, "OffsetEndMs": 10740}, {"Word": "right", "OffsetStartMs": 10740, "OffsetEndMs": 10965}, {"Word": "to", "OffsetStartMs": 10965, "OffsetEndMs": 11160}, {"Word": "the", "OffsetStartMs": 11160, "OffsetEndMs": 11250}, {"Word": "left", "OffsetStartMs": 11250, "OffsetEndMs": 11475}, {"Word": "to", "OffsetStartMs": 11475, "OffsetEndMs": 11730}, {"Word": "stay", "OffsetStartMs": 11730, "OffsetEndMs": 11970}, {"Word": "still", "OffsetStartMs": 11970, "OffsetEndMs": 12320}, {"Word": "And", "OffsetStartMs": 12880, "OffsetEndMs": 13140}, {"Word": "those", "OffsetStartMs": 13140, "OffsetEndMs": 13305}, {"Word": "could", "OffsetStartMs": 13305, "OffsetEndMs": 13440}, {"Word": "be", "OffsetStartMs": 13440, "OffsetEndMs": 13590}, {"Word": "three", "OffsetStartMs": 13590, "OffsetEndMs": 13785}, {"Word": "different", "OffsetStartMs": 13785, "OffsetEndMs": 13980}, {"Word": "actions", "OffsetStartMs": 13980, "OffsetEndMs": 14300}, {"Word": "that", "OffsetStartMs": 14350, "OffsetEndMs": 14625}, {"Word": "could", "OffsetStartMs": 14625, "OffsetEndMs": 14745}, {"Word": "be", "OffsetStartMs": 14745, "OffsetEndMs": 14990}, {"Word": "provided", "OffsetStartMs": 15040, "OffsetEndMs": 15440}, {"Word": "and", "OffsetStartMs": 15520, "OffsetEndMs": 15825}, {"Word": "parameterized", "OffsetStartMs": 15825, "OffsetEndMs": 16490}, {"Word": "to", "OffsetStartMs": 16660, "OffsetEndMs": 16905}, {"Word": "the", "OffsetStartMs": 16905, "OffsetEndMs": 17100}, {"Word": "input", "OffsetStartMs": 17100, "OffsetEndMs": 17310}, {"Word": "of", "OffsetStartMs": 17310, "OffsetEndMs": 17415}, {"Word": "a", "OffsetStartMs": 17415, "OffsetEndMs": 17520}, {"Word": "neural", "OffsetStartMs": 17520, "OffsetEndMs": 17715}, {"Word": "network", "OffsetStartMs": 17715, "OffsetEndMs": 17960}, {"Word": "The", "OffsetStartMs": 18310, "OffsetEndMs": 18600}, {"Word": "goal", "OffsetStartMs": 18600, "OffsetEndMs": 18810}, {"Word": "here", "OffsetStartMs": 18810, "OffsetEndMs": 19080}, {"Word": "is", "OffsetStartMs": 19080, "OffsetEndMs": 19365}, {"Word": "to", "OffsetStartMs": 19365, "OffsetEndMs": 19650}, {"Word": "you", "OffsetStartMs": 19650, "OffsetEndMs": 19860}, {"Word": "know", "OffsetStartMs": 19860, "OffsetEndMs": 20120}, {"Word": "estimate", "OffsetStartMs": 20410, "OffsetEndMs": 20700}, {"Word": "the", "OffsetStartMs": 20700, "OffsetEndMs": 20910}, {"Word": "single", "OffsetStartMs": 20910, "OffsetEndMs": 21225}, {"Word": "number", "OffsetStartMs": 21225, "OffsetEndMs": 21620}, {"Word": "output", "OffsetStartMs": 22000, "OffsetEndMs": 22400}], "SpeechSpeed": 17.3}, {"FinalSentence": "That measures what is the expected value or the expected q value of this neural network at this particular state action pair. Now oftentimes what you'll see is that if you wanted to evaluate, let's suppose a very large action space, it's going to be very inefficient to try the approach on the left with with a very large action space. Because what it would mean is that you'd have to run your neural network forward many different times one time for every single element of your action space. So what if instead you only provided it an input of your state and as output you gave it, let's say all n different q values, one q value for every single possible action. That way you only need to run your neural network once for the given state that you're in.", "SliceSentence": "That measures what is the expected value or the expected q value of this neural network at this particular state action pair Now oftentimes what you'll see is that if you wanted to evaluate let's suppose a very large action space it's going to be very inefficient to try the approach on the left with with a very large action space Because what it would mean is that you'd have to run your neural network forward many different times one time for every single element of your action space So what if instead you only provided it an input of your state and as output you gave it let's say all n different q values one q value for every single possible action That way you only need to run your neural network once for the given state that you're in", "StartMs": 1371740, "EndMs": 1415160, "WordsNum": 141, "Words": [{"Word": "That", "OffsetStartMs": 70, "OffsetEndMs": 375}, {"Word": "measures", "OffsetStartMs": 375, "OffsetEndMs": 680}, {"Word": "what", "OffsetStartMs": 730, "OffsetEndMs": 990}, {"Word": "is", "OffsetStartMs": 990, "OffsetEndMs": 1140}, {"Word": "the", "OffsetStartMs": 1140, "OffsetEndMs": 1365}, {"Word": "expected", "OffsetStartMs": 1365, "OffsetEndMs": 1700}, {"Word": "value", "OffsetStartMs": 2020, "OffsetEndMs": 2420}, {"Word": "or", "OffsetStartMs": 2890, "OffsetEndMs": 3165}, {"Word": "the", "OffsetStartMs": 3165, "OffsetEndMs": 3375}, {"Word": "expected", "OffsetStartMs": 3375, "OffsetEndMs": 3710}, {"Word": "q", "OffsetStartMs": 3730, "OffsetEndMs": 4020}, {"Word": "value", "OffsetStartMs": 4020, "OffsetEndMs": 4310}, {"Word": "of", "OffsetStartMs": 4600, "OffsetEndMs": 4920}, {"Word": "this", "OffsetStartMs": 4920, "OffsetEndMs": 5130}, {"Word": "neural", "OffsetStartMs": 5130, "OffsetEndMs": 5355}, {"Word": "network", "OffsetStartMs": 5355, "OffsetEndMs": 5580}, {"Word": "at", "OffsetStartMs": 5580, "OffsetEndMs": 5850}, {"Word": "this", "OffsetStartMs": 5850, "OffsetEndMs": 6140}, {"Word": "particular", "OffsetStartMs": 6190, "OffsetEndMs": 6590}, {"Word": "state", "OffsetStartMs": 6700, "OffsetEndMs": 6990}, {"Word": "action", "OffsetStartMs": 6990, "OffsetEndMs": 7280}, {"Word": "pair", "OffsetStartMs": 7480, "OffsetEndMs": 7880}, {"Word": "Now", "OffsetStartMs": 8440, "OffsetEndMs": 8840}, {"Word": "oftentimes", "OffsetStartMs": 8890, "OffsetEndMs": 9675}, {"Word": "what", "OffsetStartMs": 9675, "OffsetEndMs": 9900}, {"Word": "you'll", "OffsetStartMs": 9900, "OffsetEndMs": 10140}, {"Word": "see", "OffsetStartMs": 10140, "OffsetEndMs": 10425}, {"Word": "is", "OffsetStartMs": 10425, "OffsetEndMs": 10710}, {"Word": "that", "OffsetStartMs": 10710, "OffsetEndMs": 10935}, {"Word": "if", "OffsetStartMs": 10935, "OffsetEndMs": 11160}, {"Word": "you", "OffsetStartMs": 11160, "OffsetEndMs": 11310}, {"Word": "wanted", "OffsetStartMs": 11310, "OffsetEndMs": 11535}, {"Word": "to", "OffsetStartMs": 11535, "OffsetEndMs": 11895}, {"Word": "evaluate", "OffsetStartMs": 11895, "OffsetEndMs": 12290}, {"Word": "let's", "OffsetStartMs": 12550, "OffsetEndMs": 12930}, {"Word": "suppose", "OffsetStartMs": 12930, "OffsetEndMs": 13080}, {"Word": "a", "OffsetStartMs": 13080, "OffsetEndMs": 13230}, {"Word": "very", "OffsetStartMs": 13230, "OffsetEndMs": 13455}, {"Word": "large", "OffsetStartMs": 13455, "OffsetEndMs": 13725}, {"Word": "action", "OffsetStartMs": 13725, "OffsetEndMs": 14060}, {"Word": "space", "OffsetStartMs": 14140, "OffsetEndMs": 14430}, {"Word": "it's", "OffsetStartMs": 14430, "OffsetEndMs": 14655}, {"Word": "going", "OffsetStartMs": 14655, "OffsetEndMs": 14760}, {"Word": "to", "OffsetStartMs": 14760, "OffsetEndMs": 14850}, {"Word": "be", "OffsetStartMs": 14850, "OffsetEndMs": 14970}, {"Word": "very", "OffsetStartMs": 14970, "OffsetEndMs": 15180}, {"Word": "inefficient", "OffsetStartMs": 15180, "OffsetEndMs": 15920}, {"Word": "to", "OffsetStartMs": 16060, "OffsetEndMs": 16350}, {"Word": "try", "OffsetStartMs": 16350, "OffsetEndMs": 16545}, {"Word": "the", "OffsetStartMs": 16545, "OffsetEndMs": 16755}, {"Word": "approach", "OffsetStartMs": 16755, "OffsetEndMs": 16950}, {"Word": "on", "OffsetStartMs": 16950, "OffsetEndMs": 17115}, {"Word": "the", "OffsetStartMs": 17115, "OffsetEndMs": 17265}, {"Word": "left", "OffsetStartMs": 17265, "OffsetEndMs": 17540}, {"Word": "with", "OffsetStartMs": 17980, "OffsetEndMs": 18380}, {"Word": "with", "OffsetStartMs": 18520, "OffsetEndMs": 18795}, {"Word": "a", "OffsetStartMs": 18795, "OffsetEndMs": 18945}, {"Word": "very", "OffsetStartMs": 18945, "OffsetEndMs": 19125}, {"Word": "large", "OffsetStartMs": 19125, "OffsetEndMs": 19320}, {"Word": "action", "OffsetStartMs": 19320, "OffsetEndMs": 19610}, {"Word": "space", "OffsetStartMs": 19630, "OffsetEndMs": 20030}, {"Word": "Because", "OffsetStartMs": 20050, "OffsetEndMs": 20355}, {"Word": "what", "OffsetStartMs": 20355, "OffsetEndMs": 20520}, {"Word": "it", "OffsetStartMs": 20520, "OffsetEndMs": 20610}, {"Word": "would", "OffsetStartMs": 20610, "OffsetEndMs": 20700}, {"Word": "mean", "OffsetStartMs": 20700, "OffsetEndMs": 20835}, {"Word": "is", "OffsetStartMs": 20835, "OffsetEndMs": 20970}, {"Word": "that", "OffsetStartMs": 20970, "OffsetEndMs": 21075}, {"Word": "you'd", "OffsetStartMs": 21075, "OffsetEndMs": 21240}, {"Word": "have", "OffsetStartMs": 21240, "OffsetEndMs": 21360}, {"Word": "to", "OffsetStartMs": 21360, "OffsetEndMs": 21540}, {"Word": "run", "OffsetStartMs": 21540, "OffsetEndMs": 21830}, {"Word": "your", "OffsetStartMs": 22030, "OffsetEndMs": 22320}, {"Word": "neural", "OffsetStartMs": 22320, "OffsetEndMs": 22575}, {"Word": "network", "OffsetStartMs": 22575, "OffsetEndMs": 22850}, {"Word": "forward", "OffsetStartMs": 23200, "OffsetEndMs": 23600}, {"Word": "many", "OffsetStartMs": 24190, "OffsetEndMs": 24510}, {"Word": "different", "OffsetStartMs": 24510, "OffsetEndMs": 24765}, {"Word": "times", "OffsetStartMs": 24765, "OffsetEndMs": 25050}, {"Word": "one", "OffsetStartMs": 25050, "OffsetEndMs": 25335}, {"Word": "time", "OffsetStartMs": 25335, "OffsetEndMs": 25605}, {"Word": "for", "OffsetStartMs": 25605, "OffsetEndMs": 25785}, {"Word": "every", "OffsetStartMs": 25785, "OffsetEndMs": 26010}, {"Word": "single", "OffsetStartMs": 26010, "OffsetEndMs": 26370}, {"Word": "element", "OffsetStartMs": 26370, "OffsetEndMs": 26750}, {"Word": "of", "OffsetStartMs": 26800, "OffsetEndMs": 27060}, {"Word": "your", "OffsetStartMs": 27060, "OffsetEndMs": 27180}, {"Word": "action", "OffsetStartMs": 27180, "OffsetEndMs": 27440}, {"Word": "space", "OffsetStartMs": 27460, "OffsetEndMs": 27765}, {"Word": "So", "OffsetStartMs": 27765, "OffsetEndMs": 27930}, {"Word": "what", "OffsetStartMs": 27930, "OffsetEndMs": 28035}, {"Word": "if", "OffsetStartMs": 28035, "OffsetEndMs": 28245}, {"Word": "instead", "OffsetStartMs": 28245, "OffsetEndMs": 28610}, {"Word": "you", "OffsetStartMs": 28720, "OffsetEndMs": 28995}, {"Word": "only", "OffsetStartMs": 28995, "OffsetEndMs": 29270}, {"Word": "provided", "OffsetStartMs": 29350, "OffsetEndMs": 29685}, {"Word": "it", "OffsetStartMs": 29685, "OffsetEndMs": 29970}, {"Word": "an", "OffsetStartMs": 29970, "OffsetEndMs": 30315}, {"Word": "input", "OffsetStartMs": 30315, "OffsetEndMs": 30585}, {"Word": "of", "OffsetStartMs": 30585, "OffsetEndMs": 30735}, {"Word": "your", "OffsetStartMs": 30735, "OffsetEndMs": 30945}, {"Word": "state", "OffsetStartMs": 30945, "OffsetEndMs": 31280}, {"Word": "and", "OffsetStartMs": 31660, "OffsetEndMs": 32025}, {"Word": "as", "OffsetStartMs": 32025, "OffsetEndMs": 32390}, {"Word": "output", "OffsetStartMs": 32530, "OffsetEndMs": 32930}, {"Word": "you", "OffsetStartMs": 33010, "OffsetEndMs": 33285}, {"Word": "gave", "OffsetStartMs": 33285, "OffsetEndMs": 33465}, {"Word": "it", "OffsetStartMs": 33465, "OffsetEndMs": 33770}, {"Word": "let's", "OffsetStartMs": 33790, "OffsetEndMs": 34125}, {"Word": "say", "OffsetStartMs": 34125, "OffsetEndMs": 34275}, {"Word": "all", "OffsetStartMs": 34275, "OffsetEndMs": 34575}, {"Word": "n", "OffsetStartMs": 34575, "OffsetEndMs": 34965}, {"Word": "different", "OffsetStartMs": 34965, "OffsetEndMs": 35360}, {"Word": "q", "OffsetStartMs": 35650, "OffsetEndMs": 35940}, {"Word": "values", "OffsetStartMs": 35940, "OffsetEndMs": 36230}, {"Word": "one", "OffsetStartMs": 36670, "OffsetEndMs": 37020}, {"Word": "q", "OffsetStartMs": 37020, "OffsetEndMs": 37245}, {"Word": "value", "OffsetStartMs": 37245, "OffsetEndMs": 37500}, {"Word": "for", "OffsetStartMs": 37500, "OffsetEndMs": 37725}, {"Word": "every", "OffsetStartMs": 37725, "OffsetEndMs": 37935}, {"Word": "single", "OffsetStartMs": 37935, "OffsetEndMs": 38205}, {"Word": "possible", "OffsetStartMs": 38205, "OffsetEndMs": 38490}, {"Word": "action", "OffsetStartMs": 38490, "OffsetEndMs": 38870}, {"Word": "That", "OffsetStartMs": 38890, "OffsetEndMs": 39150}, {"Word": "way", "OffsetStartMs": 39150, "OffsetEndMs": 39270}, {"Word": "you", "OffsetStartMs": 39270, "OffsetEndMs": 39420}, {"Word": "only", "OffsetStartMs": 39420, "OffsetEndMs": 39645}, {"Word": "need", "OffsetStartMs": 39645, "OffsetEndMs": 39870}, {"Word": "to", "OffsetStartMs": 39870, "OffsetEndMs": 40020}, {"Word": "run", "OffsetStartMs": 40020, "OffsetEndMs": 40155}, {"Word": "your", "OffsetStartMs": 40155, "OffsetEndMs": 40305}, {"Word": "neural", "OffsetStartMs": 40305, "OffsetEndMs": 40545}, {"Word": "network", "OffsetStartMs": 40545, "OffsetEndMs": 40785}, {"Word": "once", "OffsetStartMs": 40785, "OffsetEndMs": 41180}, {"Word": "for", "OffsetStartMs": 41530, "OffsetEndMs": 41790}, {"Word": "the", "OffsetStartMs": 41790, "OffsetEndMs": 41910}, {"Word": "given", "OffsetStartMs": 41910, "OffsetEndMs": 42135}, {"Word": "state", "OffsetStartMs": 42135, "OffsetEndMs": 42405}, {"Word": "that", "OffsetStartMs": 42405, "OffsetEndMs": 42570}, {"Word": "you're", "OffsetStartMs": 42570, "OffsetEndMs": 42750}, {"Word": "in", "OffsetStartMs": 42750, "OffsetEndMs": 42980}], "SpeechSpeed": 17.2}, {"FinalSentence": "And then that neural network will tell you for all possible actions, what's the maximum? You simply then look at that output and pick the action that has the K S Q value.", "SliceSentence": "And then that neural network will tell you for all possible actions what's the maximum You simply then look at that output and pick the action that has the K S Q value", "StartMs": 1415160, "EndMs": 1426140, "WordsNum": 33, "Words": [{"Word": "And", "OffsetStartMs": 130, "OffsetEndMs": 390}, {"Word": "then", "OffsetStartMs": 390, "OffsetEndMs": 540}, {"Word": "that", "OffsetStartMs": 540, "OffsetEndMs": 735}, {"Word": "neural", "OffsetStartMs": 735, "OffsetEndMs": 990}, {"Word": "network", "OffsetStartMs": 990, "OffsetEndMs": 1200}, {"Word": "will", "OffsetStartMs": 1200, "OffsetEndMs": 1455}, {"Word": "tell", "OffsetStartMs": 1455, "OffsetEndMs": 1665}, {"Word": "you", "OffsetStartMs": 1665, "OffsetEndMs": 1965}, {"Word": "for", "OffsetStartMs": 1965, "OffsetEndMs": 2250}, {"Word": "all", "OffsetStartMs": 2250, "OffsetEndMs": 2490}, {"Word": "possible", "OffsetStartMs": 2490, "OffsetEndMs": 2805}, {"Word": "actions", "OffsetStartMs": 2805, "OffsetEndMs": 3170}, {"Word": "what's", "OffsetStartMs": 3520, "OffsetEndMs": 3930}, {"Word": "the", "OffsetStartMs": 3930, "OffsetEndMs": 4185}, {"Word": "maximum", "OffsetStartMs": 4185, "OffsetEndMs": 4550}, {"Word": "You", "OffsetStartMs": 5230, "OffsetEndMs": 5520}, {"Word": "simply", "OffsetStartMs": 5520, "OffsetEndMs": 5760}, {"Word": "then", "OffsetStartMs": 5760, "OffsetEndMs": 6015}, {"Word": "look", "OffsetStartMs": 6015, "OffsetEndMs": 6195}, {"Word": "at", "OffsetStartMs": 6195, "OffsetEndMs": 6360}, {"Word": "that", "OffsetStartMs": 6360, "OffsetEndMs": 6650}, {"Word": "output", "OffsetStartMs": 6790, "OffsetEndMs": 7190}, {"Word": "and", "OffsetStartMs": 7330, "OffsetEndMs": 7620}, {"Word": "pick", "OffsetStartMs": 7620, "OffsetEndMs": 7830}, {"Word": "the", "OffsetStartMs": 7830, "OffsetEndMs": 7995}, {"Word": "action", "OffsetStartMs": 7995, "OffsetEndMs": 8240}, {"Word": "that", "OffsetStartMs": 8650, "OffsetEndMs": 8925}, {"Word": "has", "OffsetStartMs": 8925, "OffsetEndMs": 9105}, {"Word": "the", "OffsetStartMs": 9105, "OffsetEndMs": 9285}, {"Word": "K", "OffsetStartMs": 9285, "OffsetEndMs": 9420}, {"Word": "S", "OffsetStartMs": 9420, "OffsetEndMs": 9585}, {"Word": "Q", "OffsetStartMs": 9585, "OffsetEndMs": 9765}, {"Word": "value", "OffsetStartMs": 9765, "OffsetEndMs": 10040}], "SpeechSpeed": 15.2}, {"FinalSentence": "Now, what would happen? Right. So actually the question I want to pose here is really, you know, we want to train one of these two networks. Let's stick with the network on the right for simplicity, just since it's a much more efficient version of the network on the left. And the question is, you know, how do we actually train that network on the right? And specifically I want all of you to think about really the best case scenario just to start with how an agent would perform ideally in a particular situation or what would happen if an agent took all of the ideal actions at any given state. This would mean that essentially the target return right, the, the predicted or the the value that we're trying to predict. The target is going to always be maximized, right? And this can serve as essentially the ground truth to the agent.", "SliceSentence": "Now what would happen Right So actually the question I want to pose here is really you know we want to train one of these two networks Let's stick with the network on the right for simplicity just since it's a much more efficient version of the network on the left And the question is you know how do we actually train that network on the right And specifically I want all of you to think about really the best case scenario just to start with how an agent would perform ideally in a particular situation or what would happen if an agent took all of the ideal actions at any given state This would mean that essentially the target return right the the predicted or the the value that we're trying to predict The target is going to always be maximized right And this can serve as essentially the ground truth to the agent", "StartMs": 1426840, "EndMs": 1476200, "WordsNum": 155, "Words": [{"Word": "Now", "OffsetStartMs": 100, "OffsetEndMs": 500}, {"Word": "what", "OffsetStartMs": 790, "OffsetEndMs": 1065}, {"Word": "would", "OffsetStartMs": 1065, "OffsetEndMs": 1215}, {"Word": "happen", "OffsetStartMs": 1215, "OffsetEndMs": 1490}, {"Word": "Right", "OffsetStartMs": 2260, "OffsetEndMs": 2580}, {"Word": "So", "OffsetStartMs": 2580, "OffsetEndMs": 2895}, {"Word": "actually", "OffsetStartMs": 2895, "OffsetEndMs": 3290}, {"Word": "the", "OffsetStartMs": 3340, "OffsetEndMs": 3720}, {"Word": "question", "OffsetStartMs": 3720, "OffsetEndMs": 4005}, {"Word": "I", "OffsetStartMs": 4005, "OffsetEndMs": 4170}, {"Word": "want", "OffsetStartMs": 4170, "OffsetEndMs": 4305}, {"Word": "to", "OffsetStartMs": 4305, "OffsetEndMs": 4455}, {"Word": "pose", "OffsetStartMs": 4455, "OffsetEndMs": 4695}, {"Word": "here", "OffsetStartMs": 4695, "OffsetEndMs": 4890}, {"Word": "is", "OffsetStartMs": 4890, "OffsetEndMs": 5025}, {"Word": "really", "OffsetStartMs": 5025, "OffsetEndMs": 5300}, {"Word": "you", "OffsetStartMs": 5530, "OffsetEndMs": 5760}, {"Word": "know", "OffsetStartMs": 5760, "OffsetEndMs": 5990}, {"Word": "we", "OffsetStartMs": 6490, "OffsetEndMs": 6765}, {"Word": "want", "OffsetStartMs": 6765, "OffsetEndMs": 6930}, {"Word": "to", "OffsetStartMs": 6930, "OffsetEndMs": 7110}, {"Word": "train", "OffsetStartMs": 7110, "OffsetEndMs": 7400}, {"Word": "one", "OffsetStartMs": 7480, "OffsetEndMs": 7740}, {"Word": "of", "OffsetStartMs": 7740, "OffsetEndMs": 7860}, {"Word": "these", "OffsetStartMs": 7860, "OffsetEndMs": 8025}, {"Word": "two", "OffsetStartMs": 8025, "OffsetEndMs": 8190}, {"Word": "networks", "OffsetStartMs": 8190, "OffsetEndMs": 8445}, {"Word": "Let's", "OffsetStartMs": 8445, "OffsetEndMs": 8820}, {"Word": "stick", "OffsetStartMs": 8820, "OffsetEndMs": 8970}, {"Word": "with", "OffsetStartMs": 8970, "OffsetEndMs": 9105}, {"Word": "the", "OffsetStartMs": 9105, "OffsetEndMs": 9225}, {"Word": "network", "OffsetStartMs": 9225, "OffsetEndMs": 9405}, {"Word": "on", "OffsetStartMs": 9405, "OffsetEndMs": 9615}, {"Word": "the", "OffsetStartMs": 9615, "OffsetEndMs": 9750}, {"Word": "right", "OffsetStartMs": 9750, "OffsetEndMs": 9960}, {"Word": "for", "OffsetStartMs": 9960, "OffsetEndMs": 10185}, {"Word": "simplicity", "OffsetStartMs": 10185, "OffsetEndMs": 10785}, {"Word": "just", "OffsetStartMs": 10785, "OffsetEndMs": 10935}, {"Word": "since", "OffsetStartMs": 10935, "OffsetEndMs": 11085}, {"Word": "it's", "OffsetStartMs": 11085, "OffsetEndMs": 11250}, {"Word": "a", "OffsetStartMs": 11250, "OffsetEndMs": 11325}, {"Word": "much", "OffsetStartMs": 11325, "OffsetEndMs": 11475}, {"Word": "more", "OffsetStartMs": 11475, "OffsetEndMs": 11700}, {"Word": "efficient", "OffsetStartMs": 11700, "OffsetEndMs": 11985}, {"Word": "version", "OffsetStartMs": 11985, "OffsetEndMs": 12315}, {"Word": "of", "OffsetStartMs": 12315, "OffsetEndMs": 12630}, {"Word": "the", "OffsetStartMs": 12630, "OffsetEndMs": 12840}, {"Word": "network", "OffsetStartMs": 12840, "OffsetEndMs": 13035}, {"Word": "on", "OffsetStartMs": 13035, "OffsetEndMs": 13245}, {"Word": "the", "OffsetStartMs": 13245, "OffsetEndMs": 13380}, {"Word": "left", "OffsetStartMs": 13380, "OffsetEndMs": 13640}, {"Word": "And", "OffsetStartMs": 14170, "OffsetEndMs": 14570}, {"Word": "the", "OffsetStartMs": 14650, "OffsetEndMs": 14925}, {"Word": "question", "OffsetStartMs": 14925, "OffsetEndMs": 15165}, {"Word": "is", "OffsetStartMs": 15165, "OffsetEndMs": 15480}, {"Word": "you", "OffsetStartMs": 15480, "OffsetEndMs": 15690}, {"Word": "know", "OffsetStartMs": 15690, "OffsetEndMs": 15870}, {"Word": "how", "OffsetStartMs": 15870, "OffsetEndMs": 16095}, {"Word": "do", "OffsetStartMs": 16095, "OffsetEndMs": 16245}, {"Word": "we", "OffsetStartMs": 16245, "OffsetEndMs": 16470}, {"Word": "actually", "OffsetStartMs": 16470, "OffsetEndMs": 16770}, {"Word": "train", "OffsetStartMs": 16770, "OffsetEndMs": 17090}, {"Word": "that", "OffsetStartMs": 17170, "OffsetEndMs": 17520}, {"Word": "network", "OffsetStartMs": 17520, "OffsetEndMs": 17870}, {"Word": "on", "OffsetStartMs": 17980, "OffsetEndMs": 18285}, {"Word": "the", "OffsetStartMs": 18285, "OffsetEndMs": 18450}, {"Word": "right", "OffsetStartMs": 18450, "OffsetEndMs": 18710}, {"Word": "And", "OffsetStartMs": 19000, "OffsetEndMs": 19380}, {"Word": "specifically", "OffsetStartMs": 19380, "OffsetEndMs": 19760}, {"Word": "I", "OffsetStartMs": 19810, "OffsetEndMs": 20070}, {"Word": "want", "OffsetStartMs": 20070, "OffsetEndMs": 20205}, {"Word": "all", "OffsetStartMs": 20205, "OffsetEndMs": 20355}, {"Word": "of", "OffsetStartMs": 20355, "OffsetEndMs": 20490}, {"Word": "you", "OffsetStartMs": 20490, "OffsetEndMs": 20640}, {"Word": "to", "OffsetStartMs": 20640, "OffsetEndMs": 20805}, {"Word": "think", "OffsetStartMs": 20805, "OffsetEndMs": 21015}, {"Word": "about", "OffsetStartMs": 21015, "OffsetEndMs": 21330}, {"Word": "really", "OffsetStartMs": 21330, "OffsetEndMs": 21660}, {"Word": "the", "OffsetStartMs": 21660, "OffsetEndMs": 21930}, {"Word": "best", "OffsetStartMs": 21930, "OffsetEndMs": 22245}, {"Word": "case", "OffsetStartMs": 22245, "OffsetEndMs": 22590}, {"Word": "scenario", "OffsetStartMs": 22590, "OffsetEndMs": 22940}, {"Word": "just", "OffsetStartMs": 23170, "OffsetEndMs": 23475}, {"Word": "to", "OffsetStartMs": 23475, "OffsetEndMs": 23670}, {"Word": "start", "OffsetStartMs": 23670, "OffsetEndMs": 23865}, {"Word": "with", "OffsetStartMs": 23865, "OffsetEndMs": 24120}, {"Word": "how", "OffsetStartMs": 24120, "OffsetEndMs": 24345}, {"Word": "an", "OffsetStartMs": 24345, "OffsetEndMs": 24480}, {"Word": "agent", "OffsetStartMs": 24480, "OffsetEndMs": 24705}, {"Word": "would", "OffsetStartMs": 24705, "OffsetEndMs": 25050}, {"Word": "perform", "OffsetStartMs": 25050, "OffsetEndMs": 25335}, {"Word": "ideally", "OffsetStartMs": 25335, "OffsetEndMs": 26120}, {"Word": "in", "OffsetStartMs": 26260, "OffsetEndMs": 26520}, {"Word": "a", "OffsetStartMs": 26520, "OffsetEndMs": 26730}, {"Word": "particular", "OffsetStartMs": 26730, "OffsetEndMs": 27080}, {"Word": "situation", "OffsetStartMs": 27670, "OffsetEndMs": 28070}, {"Word": "or", "OffsetStartMs": 28330, "OffsetEndMs": 28650}, {"Word": "what", "OffsetStartMs": 28650, "OffsetEndMs": 28845}, {"Word": "would", "OffsetStartMs": 28845, "OffsetEndMs": 28995}, {"Word": "happen", "OffsetStartMs": 28995, "OffsetEndMs": 29270}, {"Word": "if", "OffsetStartMs": 29680, "OffsetEndMs": 29940}, {"Word": "an", "OffsetStartMs": 29940, "OffsetEndMs": 30075}, {"Word": "agent", "OffsetStartMs": 30075, "OffsetEndMs": 30350}, {"Word": "took", "OffsetStartMs": 30430, "OffsetEndMs": 30830}, {"Word": "all", "OffsetStartMs": 31060, "OffsetEndMs": 31395}, {"Word": "of", "OffsetStartMs": 31395, "OffsetEndMs": 31620}, {"Word": "the", "OffsetStartMs": 31620, "OffsetEndMs": 31890}, {"Word": "ideal", "OffsetStartMs": 31890, "OffsetEndMs": 32270}, {"Word": "actions", "OffsetStartMs": 32410, "OffsetEndMs": 32810}, {"Word": "at", "OffsetStartMs": 33100, "OffsetEndMs": 33390}, {"Word": "any", "OffsetStartMs": 33390, "OffsetEndMs": 33600}, {"Word": "given", "OffsetStartMs": 33600, "OffsetEndMs": 33900}, {"Word": "state", "OffsetStartMs": 33900, "OffsetEndMs": 34280}, {"Word": "This", "OffsetStartMs": 34510, "OffsetEndMs": 34770}, {"Word": "would", "OffsetStartMs": 34770, "OffsetEndMs": 34920}, {"Word": "mean", "OffsetStartMs": 34920, "OffsetEndMs": 35100}, {"Word": "that", "OffsetStartMs": 35100, "OffsetEndMs": 35340}, {"Word": "essentially", "OffsetStartMs": 35340, "OffsetEndMs": 35690}, {"Word": "the", "OffsetStartMs": 35770, "OffsetEndMs": 36105}, {"Word": "target", "OffsetStartMs": 36105, "OffsetEndMs": 36440}, {"Word": "return", "OffsetStartMs": 36610, "OffsetEndMs": 37010}, {"Word": "right", "OffsetStartMs": 37210, "OffsetEndMs": 37560}, {"Word": "the", "OffsetStartMs": 37560, "OffsetEndMs": 37910}, {"Word": "the", "OffsetStartMs": 38290, "OffsetEndMs": 38580}, {"Word": "predicted", "OffsetStartMs": 38580, "OffsetEndMs": 39260}, {"Word": "or", "OffsetStartMs": 39340, "OffsetEndMs": 39660}, {"Word": "the", "OffsetStartMs": 39660, "OffsetEndMs": 39915}, {"Word": "the", "OffsetStartMs": 39915, "OffsetEndMs": 40110}, {"Word": "value", "OffsetStartMs": 40110, "OffsetEndMs": 40350}, {"Word": "that", "OffsetStartMs": 40350, "OffsetEndMs": 40590}, {"Word": "we're", "OffsetStartMs": 40590, "OffsetEndMs": 40830}, {"Word": "trying", "OffsetStartMs": 40830, "OffsetEndMs": 41055}, {"Word": "to", "OffsetStartMs": 41055, "OffsetEndMs": 41265}, {"Word": "predict", "OffsetStartMs": 41265, "OffsetEndMs": 41505}, {"Word": "The", "OffsetStartMs": 41505, "OffsetEndMs": 41775}, {"Word": "target", "OffsetStartMs": 41775, "OffsetEndMs": 42080}, {"Word": "is", "OffsetStartMs": 42400, "OffsetEndMs": 42690}, {"Word": "going", "OffsetStartMs": 42690, "OffsetEndMs": 42870}, {"Word": "to", "OffsetStartMs": 42870, "OffsetEndMs": 43110}, {"Word": "always", "OffsetStartMs": 43110, "OffsetEndMs": 43380}, {"Word": "be", "OffsetStartMs": 43380, "OffsetEndMs": 43695}, {"Word": "maximized", "OffsetStartMs": 43695, "OffsetEndMs": 44450}, {"Word": "right", "OffsetStartMs": 44800, "OffsetEndMs": 45135}, {"Word": "And", "OffsetStartMs": 45135, "OffsetEndMs": 45345}, {"Word": "this", "OffsetStartMs": 45345, "OffsetEndMs": 45510}, {"Word": "can", "OffsetStartMs": 45510, "OffsetEndMs": 45705}, {"Word": "serve", "OffsetStartMs": 45705, "OffsetEndMs": 45930}, {"Word": "as", "OffsetStartMs": 45930, "OffsetEndMs": 46170}, {"Word": "essentially", "OffsetStartMs": 46170, "OffsetEndMs": 46485}, {"Word": "the", "OffsetStartMs": 46485, "OffsetEndMs": 46785}, {"Word": "ground", "OffsetStartMs": 46785, "OffsetEndMs": 47055}, {"Word": "truth", "OffsetStartMs": 47055, "OffsetEndMs": 47420}, {"Word": "to", "OffsetStartMs": 47620, "OffsetEndMs": 47910}, {"Word": "the", "OffsetStartMs": 47910, "OffsetEndMs": 48045}, {"Word": "agent", "OffsetStartMs": 48045, "OffsetEndMs": 48290}], "SpeechSpeed": 16.6}, {"FinalSentence": "Now, for example, to do this, we want to formulate a loss function that's going to essentially represent our expected return if we're able to take all of the best actions, right. So, for example, if we select an initial reward plus selecting some action in our action space that maximizes our expected return, then for the next future state we need to apply that discounting factor and recursively apply the same equation, and that simply turns into our target.", "SliceSentence": "Now for example to do this we want to formulate a loss function that's going to essentially represent our expected return if we're able to take all of the best actions right So for example if we select an initial reward plus selecting some action in our action space that maximizes our expected return then for the next future state we need to apply that discounting factor and recursively apply the same equation and that simply turns into our target", "StartMs": 1476200, "EndMs": 1506420, "WordsNum": 80, "Words": [{"Word": "Now", "OffsetStartMs": 0, "OffsetEndMs": 350}, {"Word": "for", "OffsetStartMs": 430, "OffsetEndMs": 720}, {"Word": "example", "OffsetStartMs": 720, "OffsetEndMs": 1010}, {"Word": "to", "OffsetStartMs": 1690, "OffsetEndMs": 1965}, {"Word": "do", "OffsetStartMs": 1965, "OffsetEndMs": 2130}, {"Word": "this", "OffsetStartMs": 2130, "OffsetEndMs": 2420}, {"Word": "we", "OffsetStartMs": 2470, "OffsetEndMs": 2730}, {"Word": "want", "OffsetStartMs": 2730, "OffsetEndMs": 2880}, {"Word": "to", "OffsetStartMs": 2880, "OffsetEndMs": 3075}, {"Word": "formulate", "OffsetStartMs": 3075, "OffsetEndMs": 3630}, {"Word": "a", "OffsetStartMs": 3630, "OffsetEndMs": 3870}, {"Word": "loss", "OffsetStartMs": 3870, "OffsetEndMs": 4125}, {"Word": "function", "OffsetStartMs": 4125, "OffsetEndMs": 4490}, {"Word": "that's", "OffsetStartMs": 5080, "OffsetEndMs": 5475}, {"Word": "going", "OffsetStartMs": 5475, "OffsetEndMs": 5700}, {"Word": "to", "OffsetStartMs": 5700, "OffsetEndMs": 6045}, {"Word": "essentially", "OffsetStartMs": 6045, "OffsetEndMs": 6440}, {"Word": "represent", "OffsetStartMs": 6610, "OffsetEndMs": 7010}, {"Word": "our", "OffsetStartMs": 7540, "OffsetEndMs": 7940}, {"Word": "expected", "OffsetStartMs": 7960, "OffsetEndMs": 8360}, {"Word": "return", "OffsetStartMs": 8470, "OffsetEndMs": 8790}, {"Word": "if", "OffsetStartMs": 8790, "OffsetEndMs": 8985}, {"Word": "we're", "OffsetStartMs": 8985, "OffsetEndMs": 9180}, {"Word": "able", "OffsetStartMs": 9180, "OffsetEndMs": 9360}, {"Word": "to", "OffsetStartMs": 9360, "OffsetEndMs": 9585}, {"Word": "take", "OffsetStartMs": 9585, "OffsetEndMs": 9825}, {"Word": "all", "OffsetStartMs": 9825, "OffsetEndMs": 10065}, {"Word": "of", "OffsetStartMs": 10065, "OffsetEndMs": 10215}, {"Word": "the", "OffsetStartMs": 10215, "OffsetEndMs": 10365}, {"Word": "best", "OffsetStartMs": 10365, "OffsetEndMs": 10620}, {"Word": "actions", "OffsetStartMs": 10620, "OffsetEndMs": 11000}, {"Word": "right", "OffsetStartMs": 11590, "OffsetEndMs": 11940}, {"Word": "So", "OffsetStartMs": 11940, "OffsetEndMs": 12195}, {"Word": "for", "OffsetStartMs": 12195, "OffsetEndMs": 12390}, {"Word": "example", "OffsetStartMs": 12390, "OffsetEndMs": 12615}, {"Word": "if", "OffsetStartMs": 12615, "OffsetEndMs": 12825}, {"Word": "we", "OffsetStartMs": 12825, "OffsetEndMs": 13050}, {"Word": "select", "OffsetStartMs": 13050, "OffsetEndMs": 13290}, {"Word": "an", "OffsetStartMs": 13290, "OffsetEndMs": 13530}, {"Word": "initial", "OffsetStartMs": 13530, "OffsetEndMs": 13880}, {"Word": "reward", "OffsetStartMs": 13990, "OffsetEndMs": 14390}, {"Word": "plus", "OffsetStartMs": 14800, "OffsetEndMs": 15200}, {"Word": "selecting", "OffsetStartMs": 15220, "OffsetEndMs": 15735}, {"Word": "some", "OffsetStartMs": 15735, "OffsetEndMs": 15975}, {"Word": "action", "OffsetStartMs": 15975, "OffsetEndMs": 16280}, {"Word": "in", "OffsetStartMs": 16540, "OffsetEndMs": 16800}, {"Word": "our", "OffsetStartMs": 16800, "OffsetEndMs": 16950}, {"Word": "action", "OffsetStartMs": 16950, "OffsetEndMs": 17240}, {"Word": "space", "OffsetStartMs": 17320, "OffsetEndMs": 17625}, {"Word": "that", "OffsetStartMs": 17625, "OffsetEndMs": 17820}, {"Word": "maximizes", "OffsetStartMs": 17820, "OffsetEndMs": 18450}, {"Word": "our", "OffsetStartMs": 18450, "OffsetEndMs": 18780}, {"Word": "expected", "OffsetStartMs": 18780, "OffsetEndMs": 19130}, {"Word": "return", "OffsetStartMs": 19240, "OffsetEndMs": 19640}, {"Word": "then", "OffsetStartMs": 20200, "OffsetEndMs": 20600}, {"Word": "for", "OffsetStartMs": 20800, "OffsetEndMs": 21060}, {"Word": "the", "OffsetStartMs": 21060, "OffsetEndMs": 21225}, {"Word": "next", "OffsetStartMs": 21225, "OffsetEndMs": 21480}, {"Word": "future", "OffsetStartMs": 21480, "OffsetEndMs": 21830}, {"Word": "state", "OffsetStartMs": 21880, "OffsetEndMs": 22280}, {"Word": "we", "OffsetStartMs": 22540, "OffsetEndMs": 22860}, {"Word": "need", "OffsetStartMs": 22860, "OffsetEndMs": 23055}, {"Word": "to", "OffsetStartMs": 23055, "OffsetEndMs": 23235}, {"Word": "apply", "OffsetStartMs": 23235, "OffsetEndMs": 23445}, {"Word": "that", "OffsetStartMs": 23445, "OffsetEndMs": 23745}, {"Word": "discounting", "OffsetStartMs": 23745, "OffsetEndMs": 24390}, {"Word": "factor", "OffsetStartMs": 24390, "OffsetEndMs": 24680}, {"Word": "and", "OffsetStartMs": 24910, "OffsetEndMs": 25310}, {"Word": "recursively", "OffsetStartMs": 25720, "OffsetEndMs": 26520}, {"Word": "apply", "OffsetStartMs": 26520, "OffsetEndMs": 26730}, {"Word": "the", "OffsetStartMs": 26730, "OffsetEndMs": 26895}, {"Word": "same", "OffsetStartMs": 26895, "OffsetEndMs": 27135}, {"Word": "equation", "OffsetStartMs": 27135, "OffsetEndMs": 27500}, {"Word": "and", "OffsetStartMs": 27550, "OffsetEndMs": 27825}, {"Word": "that", "OffsetStartMs": 27825, "OffsetEndMs": 28035}, {"Word": "simply", "OffsetStartMs": 28035, "OffsetEndMs": 28370}, {"Word": "turns", "OffsetStartMs": 28540, "OffsetEndMs": 28845}, {"Word": "into", "OffsetStartMs": 28845, "OffsetEndMs": 29130}, {"Word": "our", "OffsetStartMs": 29130, "OffsetEndMs": 29430}, {"Word": "target", "OffsetStartMs": 29430, "OffsetEndMs": 29750}], "SpeechSpeed": 14.9}, {"FinalSentence": "Right now we can ask basically what does our neural network predict, right? So that's our target. And we recall from previous lectures if we have a target value in this case, our q value is a continuous variable. We have also a predicted variable that is going to come as part of the output of every single one of these potential actions that could be taken.", "SliceSentence": "Right now we can ask basically what does our neural network predict right So that's our target And we recall from previous lectures if we have a target value in this case our q value is a continuous variable We have also a predicted variable that is going to come as part of the output of every single one of these potential actions that could be taken", "StartMs": 1506420, "EndMs": 1527900, "WordsNum": 67, "Words": [{"Word": "Right", "OffsetStartMs": 0, "OffsetEndMs": 300}, {"Word": "now", "OffsetStartMs": 300, "OffsetEndMs": 525}, {"Word": "we", "OffsetStartMs": 525, "OffsetEndMs": 675}, {"Word": "can", "OffsetStartMs": 675, "OffsetEndMs": 810}, {"Word": "ask", "OffsetStartMs": 810, "OffsetEndMs": 1070}, {"Word": "basically", "OffsetStartMs": 1150, "OffsetEndMs": 1550}, {"Word": "what", "OffsetStartMs": 1750, "OffsetEndMs": 2150}, {"Word": "does", "OffsetStartMs": 2200, "OffsetEndMs": 2600}, {"Word": "our", "OffsetStartMs": 3400, "OffsetEndMs": 3705}, {"Word": "neural", "OffsetStartMs": 3705, "OffsetEndMs": 3990}, {"Word": "network", "OffsetStartMs": 3990, "OffsetEndMs": 4250}, {"Word": "predict", "OffsetStartMs": 4360, "OffsetEndMs": 4760}, {"Word": "right", "OffsetStartMs": 5020, "OffsetEndMs": 5325}, {"Word": "So", "OffsetStartMs": 5325, "OffsetEndMs": 5490}, {"Word": "that's", "OffsetStartMs": 5490, "OffsetEndMs": 5700}, {"Word": "our", "OffsetStartMs": 5700, "OffsetEndMs": 5850}, {"Word": "target", "OffsetStartMs": 5850, "OffsetEndMs": 6170}, {"Word": "And", "OffsetStartMs": 6520, "OffsetEndMs": 6920}, {"Word": "we", "OffsetStartMs": 6940, "OffsetEndMs": 7340}, {"Word": "recall", "OffsetStartMs": 7600, "OffsetEndMs": 8000}, {"Word": "from", "OffsetStartMs": 8020, "OffsetEndMs": 8310}, {"Word": "previous", "OffsetStartMs": 8310, "OffsetEndMs": 8580}, {"Word": "lectures", "OffsetStartMs": 8580, "OffsetEndMs": 9200}, {"Word": "if", "OffsetStartMs": 9340, "OffsetEndMs": 9600}, {"Word": "we", "OffsetStartMs": 9600, "OffsetEndMs": 9705}, {"Word": "have", "OffsetStartMs": 9705, "OffsetEndMs": 9810}, {"Word": "a", "OffsetStartMs": 9810, "OffsetEndMs": 9945}, {"Word": "target", "OffsetStartMs": 9945, "OffsetEndMs": 10170}, {"Word": "value", "OffsetStartMs": 10170, "OffsetEndMs": 10470}, {"Word": "in", "OffsetStartMs": 10470, "OffsetEndMs": 10665}, {"Word": "this", "OffsetStartMs": 10665, "OffsetEndMs": 10800}, {"Word": "case", "OffsetStartMs": 10800, "OffsetEndMs": 10980}, {"Word": "our", "OffsetStartMs": 10980, "OffsetEndMs": 11175}, {"Word": "q", "OffsetStartMs": 11175, "OffsetEndMs": 11340}, {"Word": "value", "OffsetStartMs": 11340, "OffsetEndMs": 11535}, {"Word": "is", "OffsetStartMs": 11535, "OffsetEndMs": 11730}, {"Word": "a", "OffsetStartMs": 11730, "OffsetEndMs": 11955}, {"Word": "continuous", "OffsetStartMs": 11955, "OffsetEndMs": 12315}, {"Word": "variable", "OffsetStartMs": 12315, "OffsetEndMs": 12710}, {"Word": "We", "OffsetStartMs": 13390, "OffsetEndMs": 13665}, {"Word": "have", "OffsetStartMs": 13665, "OffsetEndMs": 13940}, {"Word": "also", "OffsetStartMs": 14050, "OffsetEndMs": 14325}, {"Word": "a", "OffsetStartMs": 14325, "OffsetEndMs": 14490}, {"Word": "predicted", "OffsetStartMs": 14490, "OffsetEndMs": 14955}, {"Word": "variable", "OffsetStartMs": 14955, "OffsetEndMs": 15230}, {"Word": "that", "OffsetStartMs": 15730, "OffsetEndMs": 16020}, {"Word": "is", "OffsetStartMs": 16020, "OffsetEndMs": 16230}, {"Word": "going", "OffsetStartMs": 16230, "OffsetEndMs": 16455}, {"Word": "to", "OffsetStartMs": 16455, "OffsetEndMs": 16635}, {"Word": "come", "OffsetStartMs": 16635, "OffsetEndMs": 16860}, {"Word": "as", "OffsetStartMs": 16860, "OffsetEndMs": 17145}, {"Word": "part", "OffsetStartMs": 17145, "OffsetEndMs": 17340}, {"Word": "of", "OffsetStartMs": 17340, "OffsetEndMs": 17475}, {"Word": "the", "OffsetStartMs": 17475, "OffsetEndMs": 17700}, {"Word": "output", "OffsetStartMs": 17700, "OffsetEndMs": 17910}, {"Word": "of", "OffsetStartMs": 17910, "OffsetEndMs": 18045}, {"Word": "every", "OffsetStartMs": 18045, "OffsetEndMs": 18285}, {"Word": "single", "OffsetStartMs": 18285, "OffsetEndMs": 18585}, {"Word": "one", "OffsetStartMs": 18585, "OffsetEndMs": 18780}, {"Word": "of", "OffsetStartMs": 18780, "OffsetEndMs": 18900}, {"Word": "these", "OffsetStartMs": 18900, "OffsetEndMs": 19155}, {"Word": "potential", "OffsetStartMs": 19155, "OffsetEndMs": 19500}, {"Word": "actions", "OffsetStartMs": 19500, "OffsetEndMs": 19850}, {"Word": "that", "OffsetStartMs": 19900, "OffsetEndMs": 20190}, {"Word": "could", "OffsetStartMs": 20190, "OffsetEndMs": 20355}, {"Word": "be", "OffsetStartMs": 20355, "OffsetEndMs": 20520}, {"Word": "taken", "OffsetStartMs": 20520, "OffsetEndMs": 20810}], "SpeechSpeed": 16.4}, {"FinalSentence": "We can define what's called A Q loss, which is essentially just a very simple mean squared error loss between these two continuous variables. We minimize their distance over two over many, many different iterations of buying our neural network in this environment, observing actions and observing not only the actions but most importantly after the action is.", "SliceSentence": "We can define what's called A Q loss which is essentially just a very simple mean squared error loss between these two continuous variables We minimize their distance over two over many many different iterations of buying our neural network in this environment observing actions and observing not only the actions but most importantly after the action is", "StartMs": 1528800, "EndMs": 1551140, "WordsNum": 58, "Words": [{"Word": "We", "OffsetStartMs": 100, "OffsetEndMs": 360}, {"Word": "can", "OffsetStartMs": 360, "OffsetEndMs": 620}, {"Word": "define", "OffsetStartMs": 640, "OffsetEndMs": 960}, {"Word": "what's", "OffsetStartMs": 960, "OffsetEndMs": 1230}, {"Word": "called", "OffsetStartMs": 1230, "OffsetEndMs": 1365}, {"Word": "A", "OffsetStartMs": 1365, "OffsetEndMs": 1530}, {"Word": "Q", "OffsetStartMs": 1530, "OffsetEndMs": 1695}, {"Word": "loss", "OffsetStartMs": 1695, "OffsetEndMs": 1970}, {"Word": "which", "OffsetStartMs": 2110, "OffsetEndMs": 2385}, {"Word": "is", "OffsetStartMs": 2385, "OffsetEndMs": 2595}, {"Word": "essentially", "OffsetStartMs": 2595, "OffsetEndMs": 2930}, {"Word": "just", "OffsetStartMs": 2950, "OffsetEndMs": 3350}, {"Word": "a", "OffsetStartMs": 3520, "OffsetEndMs": 3810}, {"Word": "very", "OffsetStartMs": 3810, "OffsetEndMs": 4035}, {"Word": "simple", "OffsetStartMs": 4035, "OffsetEndMs": 4320}, {"Word": "mean", "OffsetStartMs": 4320, "OffsetEndMs": 4590}, {"Word": "squared", "OffsetStartMs": 4590, "OffsetEndMs": 4830}, {"Word": "error", "OffsetStartMs": 4830, "OffsetEndMs": 5070}, {"Word": "loss", "OffsetStartMs": 5070, "OffsetEndMs": 5420}, {"Word": "between", "OffsetStartMs": 5500, "OffsetEndMs": 5790}, {"Word": "these", "OffsetStartMs": 5790, "OffsetEndMs": 6000}, {"Word": "two", "OffsetStartMs": 6000, "OffsetEndMs": 6285}, {"Word": "continuous", "OffsetStartMs": 6285, "OffsetEndMs": 6645}, {"Word": "variables", "OffsetStartMs": 6645, "OffsetEndMs": 7280}, {"Word": "We", "OffsetStartMs": 7600, "OffsetEndMs": 7875}, {"Word": "minimize", "OffsetStartMs": 7875, "OffsetEndMs": 8295}, {"Word": "their", "OffsetStartMs": 8295, "OffsetEndMs": 8520}, {"Word": "distance", "OffsetStartMs": 8520, "OffsetEndMs": 8810}, {"Word": "over", "OffsetStartMs": 9370, "OffsetEndMs": 9770}, {"Word": "two", "OffsetStartMs": 10060, "OffsetEndMs": 10440}, {"Word": "over", "OffsetStartMs": 10440, "OffsetEndMs": 10785}, {"Word": "many", "OffsetStartMs": 10785, "OffsetEndMs": 11085}, {"Word": "many", "OffsetStartMs": 11085, "OffsetEndMs": 11340}, {"Word": "different", "OffsetStartMs": 11340, "OffsetEndMs": 11660}, {"Word": "iterations", "OffsetStartMs": 11920, "OffsetEndMs": 12530}, {"Word": "of", "OffsetStartMs": 12730, "OffsetEndMs": 13130}, {"Word": "buying", "OffsetStartMs": 13360, "OffsetEndMs": 13680}, {"Word": "our", "OffsetStartMs": 13680, "OffsetEndMs": 13890}, {"Word": "neural", "OffsetStartMs": 13890, "OffsetEndMs": 14130}, {"Word": "network", "OffsetStartMs": 14130, "OffsetEndMs": 14390}, {"Word": "in", "OffsetStartMs": 14440, "OffsetEndMs": 14730}, {"Word": "this", "OffsetStartMs": 14730, "OffsetEndMs": 14970}, {"Word": "environment", "OffsetStartMs": 14970, "OffsetEndMs": 15320}, {"Word": "observing", "OffsetStartMs": 15490, "OffsetEndMs": 15855}, {"Word": "actions", "OffsetStartMs": 15855, "OffsetEndMs": 16220}, {"Word": "and", "OffsetStartMs": 16750, "OffsetEndMs": 17150}, {"Word": "observing", "OffsetStartMs": 17260, "OffsetEndMs": 17660}, {"Word": "not", "OffsetStartMs": 17710, "OffsetEndMs": 17985}, {"Word": "only", "OffsetStartMs": 17985, "OffsetEndMs": 18180}, {"Word": "the", "OffsetStartMs": 18180, "OffsetEndMs": 18360}, {"Word": "actions", "OffsetStartMs": 18360, "OffsetEndMs": 18620}, {"Word": "but", "OffsetStartMs": 18700, "OffsetEndMs": 18975}, {"Word": "most", "OffsetStartMs": 18975, "OffsetEndMs": 19230}, {"Word": "importantly", "OffsetStartMs": 19230, "OffsetEndMs": 19610}, {"Word": "after", "OffsetStartMs": 19720, "OffsetEndMs": 20120}, {"Word": "the", "OffsetStartMs": 20170, "OffsetEndMs": 20415}, {"Word": "action", "OffsetStartMs": 20415, "OffsetEndMs": 20640}, {"Word": "is", "OffsetStartMs": 20640, "OffsetEndMs": 21020}], "SpeechSpeed": 15.8}, {"FinalSentence": "Committed or executed, we can see exactly the ground truth, expected return, right? So we have the ground truth labels to train and supervise this model directly from the actions that were executed as part of random selection, for example.", "SliceSentence": "Committed or executed we can see exactly the ground truth expected return right So we have the ground truth labels to train and supervise this model directly from the actions that were executed as part of random selection for example", "StartMs": 1551140, "EndMs": 1568320, "WordsNum": 40, "Words": [{"Word": "Committed", "OffsetStartMs": 10, "OffsetEndMs": 410}, {"Word": "or", "OffsetStartMs": 430, "OffsetEndMs": 810}, {"Word": "executed", "OffsetStartMs": 810, "OffsetEndMs": 1340}, {"Word": "we", "OffsetStartMs": 1720, "OffsetEndMs": 1995}, {"Word": "can", "OffsetStartMs": 1995, "OffsetEndMs": 2220}, {"Word": "see", "OffsetStartMs": 2220, "OffsetEndMs": 2570}, {"Word": "exactly", "OffsetStartMs": 2620, "OffsetEndMs": 3020}, {"Word": "the", "OffsetStartMs": 3520, "OffsetEndMs": 3810}, {"Word": "ground", "OffsetStartMs": 3810, "OffsetEndMs": 4100}, {"Word": "truth", "OffsetStartMs": 4120, "OffsetEndMs": 4520}, {"Word": "expected", "OffsetStartMs": 5800, "OffsetEndMs": 6200}, {"Word": "return", "OffsetStartMs": 6280, "OffsetEndMs": 6600}, {"Word": "right", "OffsetStartMs": 6600, "OffsetEndMs": 6810}, {"Word": "So", "OffsetStartMs": 6810, "OffsetEndMs": 6945}, {"Word": "we", "OffsetStartMs": 6945, "OffsetEndMs": 7065}, {"Word": "have", "OffsetStartMs": 7065, "OffsetEndMs": 7260}, {"Word": "the", "OffsetStartMs": 7260, "OffsetEndMs": 7455}, {"Word": "ground", "OffsetStartMs": 7455, "OffsetEndMs": 7665}, {"Word": "truth", "OffsetStartMs": 7665, "OffsetEndMs": 7905}, {"Word": "labels", "OffsetStartMs": 7905, "OffsetEndMs": 8420}, {"Word": "to", "OffsetStartMs": 8740, "OffsetEndMs": 9060}, {"Word": "train", "OffsetStartMs": 9060, "OffsetEndMs": 9330}, {"Word": "and", "OffsetStartMs": 9330, "OffsetEndMs": 9680}, {"Word": "supervise", "OffsetStartMs": 9700, "OffsetEndMs": 10050}, {"Word": "this", "OffsetStartMs": 10050, "OffsetEndMs": 10290}, {"Word": "model", "OffsetStartMs": 10290, "OffsetEndMs": 10610}, {"Word": "directly", "OffsetStartMs": 10960, "OffsetEndMs": 11360}, {"Word": "from", "OffsetStartMs": 11380, "OffsetEndMs": 11670}, {"Word": "the", "OffsetStartMs": 11670, "OffsetEndMs": 11805}, {"Word": "actions", "OffsetStartMs": 11805, "OffsetEndMs": 12050}, {"Word": "that", "OffsetStartMs": 12160, "OffsetEndMs": 12435}, {"Word": "were", "OffsetStartMs": 12435, "OffsetEndMs": 12710}, {"Word": "executed", "OffsetStartMs": 12970, "OffsetEndMs": 13485}, {"Word": "as", "OffsetStartMs": 13485, "OffsetEndMs": 13800}, {"Word": "part", "OffsetStartMs": 13800, "OffsetEndMs": 14010}, {"Word": "of", "OffsetStartMs": 14010, "OffsetEndMs": 14300}, {"Word": "random", "OffsetStartMs": 14440, "OffsetEndMs": 14840}, {"Word": "selection", "OffsetStartMs": 15100, "OffsetEndMs": 15495}, {"Word": "for", "OffsetStartMs": 15495, "OffsetEndMs": 15780}, {"Word": "example", "OffsetStartMs": 15780, "OffsetEndMs": 16070}], "SpeechSpeed": 13.6}, {"FinalSentence": "Now.", "SliceSentence": "Now", "StartMs": 1568320, "EndMs": 1569680, "WordsNum": 1, "Words": [{"Word": "Now", "OffsetStartMs": 100, "OffsetEndMs": 500}], "SpeechSpeed": 2.2}, {"FinalSentence": "Let me just stop right there and maybe summarize the whole process one more time and maybe a bit different terminology just to give everyone kind of a different perspective on this same problem. So our deep neural network that we're trying to train looks like this, right? It takes as input. A state is trying to output n different numbers. Those n different numbers correspond to the q value associated to n different actions. One q value per action.", "SliceSentence": "Let me just stop right there and maybe summarize the whole process one more time and maybe a bit different terminology just to give everyone kind of a different perspective on this same problem So our deep neural network that we're trying to train looks like this right It takes as input A state is trying to output n different numbers Those n different numbers correspond to the q value associated to n different actions One q value per action", "StartMs": 1569680, "EndMs": 1595140, "WordsNum": 80, "Words": [{"Word": "Let", "OffsetStartMs": 0, "OffsetEndMs": 180}, {"Word": "me", "OffsetStartMs": 180, "OffsetEndMs": 345}, {"Word": "just", "OffsetStartMs": 345, "OffsetEndMs": 650}, {"Word": "stop", "OffsetStartMs": 790, "OffsetEndMs": 1080}, {"Word": "right", "OffsetStartMs": 1080, "OffsetEndMs": 1260}, {"Word": "there", "OffsetStartMs": 1260, "OffsetEndMs": 1440}, {"Word": "and", "OffsetStartMs": 1440, "OffsetEndMs": 1635}, {"Word": "maybe", "OffsetStartMs": 1635, "OffsetEndMs": 1920}, {"Word": "summarize", "OffsetStartMs": 1920, "OffsetEndMs": 2370}, {"Word": "the", "OffsetStartMs": 2370, "OffsetEndMs": 2505}, {"Word": "whole", "OffsetStartMs": 2505, "OffsetEndMs": 2640}, {"Word": "process", "OffsetStartMs": 2640, "OffsetEndMs": 2930}, {"Word": "one", "OffsetStartMs": 2950, "OffsetEndMs": 3255}, {"Word": "more", "OffsetStartMs": 3255, "OffsetEndMs": 3510}, {"Word": "time", "OffsetStartMs": 3510, "OffsetEndMs": 3860}, {"Word": "and", "OffsetStartMs": 4000, "OffsetEndMs": 4305}, {"Word": "maybe", "OffsetStartMs": 4305, "OffsetEndMs": 4530}, {"Word": "a", "OffsetStartMs": 4530, "OffsetEndMs": 4770}, {"Word": "bit", "OffsetStartMs": 4770, "OffsetEndMs": 4995}, {"Word": "different", "OffsetStartMs": 4995, "OffsetEndMs": 5250}, {"Word": "terminology", "OffsetStartMs": 5250, "OffsetEndMs": 5985}, {"Word": "just", "OffsetStartMs": 5985, "OffsetEndMs": 6135}, {"Word": "to", "OffsetStartMs": 6135, "OffsetEndMs": 6255}, {"Word": "give", "OffsetStartMs": 6255, "OffsetEndMs": 6495}, {"Word": "everyone", "OffsetStartMs": 6495, "OffsetEndMs": 6825}, {"Word": "kind", "OffsetStartMs": 6825, "OffsetEndMs": 7005}, {"Word": "of", "OffsetStartMs": 7005, "OffsetEndMs": 7095}, {"Word": "a", "OffsetStartMs": 7095, "OffsetEndMs": 7185}, {"Word": "different", "OffsetStartMs": 7185, "OffsetEndMs": 7430}, {"Word": "perspective", "OffsetStartMs": 7510, "OffsetEndMs": 7910}, {"Word": "on", "OffsetStartMs": 8350, "OffsetEndMs": 8670}, {"Word": "this", "OffsetStartMs": 8670, "OffsetEndMs": 8895}, {"Word": "same", "OffsetStartMs": 8895, "OffsetEndMs": 9135}, {"Word": "problem", "OffsetStartMs": 9135, "OffsetEndMs": 9470}, {"Word": "So", "OffsetStartMs": 10210, "OffsetEndMs": 10500}, {"Word": "our", "OffsetStartMs": 10500, "OffsetEndMs": 10680}, {"Word": "deep", "OffsetStartMs": 10680, "OffsetEndMs": 10860}, {"Word": "neural", "OffsetStartMs": 10860, "OffsetEndMs": 11130}, {"Word": "network", "OffsetStartMs": 11130, "OffsetEndMs": 11390}, {"Word": "that", "OffsetStartMs": 11650, "OffsetEndMs": 11910}, {"Word": "we're", "OffsetStartMs": 11910, "OffsetEndMs": 12120}, {"Word": "trying", "OffsetStartMs": 12120, "OffsetEndMs": 12330}, {"Word": "to", "OffsetStartMs": 12330, "OffsetEndMs": 12540}, {"Word": "train", "OffsetStartMs": 12540, "OffsetEndMs": 12830}, {"Word": "looks", "OffsetStartMs": 12910, "OffsetEndMs": 13200}, {"Word": "like", "OffsetStartMs": 13200, "OffsetEndMs": 13395}, {"Word": "this", "OffsetStartMs": 13395, "OffsetEndMs": 13700}, {"Word": "right", "OffsetStartMs": 13750, "OffsetEndMs": 14070}, {"Word": "It", "OffsetStartMs": 14070, "OffsetEndMs": 14265}, {"Word": "takes", "OffsetStartMs": 14265, "OffsetEndMs": 14430}, {"Word": "as", "OffsetStartMs": 14430, "OffsetEndMs": 14655}, {"Word": "input", "OffsetStartMs": 14655, "OffsetEndMs": 14850}, {"Word": "A", "OffsetStartMs": 14850, "OffsetEndMs": 15015}, {"Word": "state", "OffsetStartMs": 15015, "OffsetEndMs": 15320}, {"Word": "is", "OffsetStartMs": 15610, "OffsetEndMs": 15900}, {"Word": "trying", "OffsetStartMs": 15900, "OffsetEndMs": 16080}, {"Word": "to", "OffsetStartMs": 16080, "OffsetEndMs": 16365}, {"Word": "output", "OffsetStartMs": 16365, "OffsetEndMs": 16710}, {"Word": "n", "OffsetStartMs": 16710, "OffsetEndMs": 17040}, {"Word": "different", "OffsetStartMs": 17040, "OffsetEndMs": 17420}, {"Word": "numbers", "OffsetStartMs": 17500, "OffsetEndMs": 17900}, {"Word": "Those", "OffsetStartMs": 18340, "OffsetEndMs": 18645}, {"Word": "n", "OffsetStartMs": 18645, "OffsetEndMs": 18855}, {"Word": "different", "OffsetStartMs": 18855, "OffsetEndMs": 19110}, {"Word": "numbers", "OffsetStartMs": 19110, "OffsetEndMs": 19460}, {"Word": "correspond", "OffsetStartMs": 19480, "OffsetEndMs": 19880}, {"Word": "to", "OffsetStartMs": 19900, "OffsetEndMs": 20145}, {"Word": "the", "OffsetStartMs": 20145, "OffsetEndMs": 20295}, {"Word": "q", "OffsetStartMs": 20295, "OffsetEndMs": 20475}, {"Word": "value", "OffsetStartMs": 20475, "OffsetEndMs": 20750}, {"Word": "associated", "OffsetStartMs": 21220, "OffsetEndMs": 21620}, {"Word": "to", "OffsetStartMs": 21790, "OffsetEndMs": 22050}, {"Word": "n", "OffsetStartMs": 22050, "OffsetEndMs": 22260}, {"Word": "different", "OffsetStartMs": 22260, "OffsetEndMs": 22560}, {"Word": "actions", "OffsetStartMs": 22560, "OffsetEndMs": 22910}, {"Word": "One", "OffsetStartMs": 23200, "OffsetEndMs": 23550}, {"Word": "q", "OffsetStartMs": 23550, "OffsetEndMs": 23760}, {"Word": "value", "OffsetStartMs": 23760, "OffsetEndMs": 24020}, {"Word": "per", "OffsetStartMs": 24100, "OffsetEndMs": 24450}, {"Word": "action", "OffsetStartMs": 24450, "OffsetEndMs": 24800}], "SpeechSpeed": 17.4}, {"FinalSentence": "Here the actions in atari breakout, for example, should be three actions. We can either go left, we can go right, or we can do nothing. We can stay where we are.", "SliceSentence": "Here the actions in atari breakout for example should be three actions We can either go left we can go right or we can do nothing We can stay where we are", "StartMs": 1596100, "EndMs": 1606180, "WordsNum": 32, "Words": [{"Word": "Here", "OffsetStartMs": 100, "OffsetEndMs": 500}, {"Word": "the", "OffsetStartMs": 610, "OffsetEndMs": 855}, {"Word": "actions", "OffsetStartMs": 855, "OffsetEndMs": 1100}, {"Word": "in", "OffsetStartMs": 1210, "OffsetEndMs": 1610}, {"Word": "atari", "OffsetStartMs": 1870, "OffsetEndMs": 2420}, {"Word": "breakout", "OffsetStartMs": 2680, "OffsetEndMs": 3290}, {"Word": "for", "OffsetStartMs": 3310, "OffsetEndMs": 3615}, {"Word": "example", "OffsetStartMs": 3615, "OffsetEndMs": 3920}, {"Word": "should", "OffsetStartMs": 3970, "OffsetEndMs": 4260}, {"Word": "be", "OffsetStartMs": 4260, "OffsetEndMs": 4500}, {"Word": "three", "OffsetStartMs": 4500, "OffsetEndMs": 4725}, {"Word": "actions", "OffsetStartMs": 4725, "OffsetEndMs": 5000}, {"Word": "We", "OffsetStartMs": 5140, "OffsetEndMs": 5400}, {"Word": "can", "OffsetStartMs": 5400, "OffsetEndMs": 5505}, {"Word": "either", "OffsetStartMs": 5505, "OffsetEndMs": 5670}, {"Word": "go", "OffsetStartMs": 5670, "OffsetEndMs": 5865}, {"Word": "left", "OffsetStartMs": 5865, "OffsetEndMs": 6090}, {"Word": "we", "OffsetStartMs": 6090, "OffsetEndMs": 6300}, {"Word": "can", "OffsetStartMs": 6300, "OffsetEndMs": 6420}, {"Word": "go", "OffsetStartMs": 6420, "OffsetEndMs": 6555}, {"Word": "right", "OffsetStartMs": 6555, "OffsetEndMs": 6830}, {"Word": "or", "OffsetStartMs": 7060, "OffsetEndMs": 7350}, {"Word": "we", "OffsetStartMs": 7350, "OffsetEndMs": 7530}, {"Word": "can", "OffsetStartMs": 7530, "OffsetEndMs": 7725}, {"Word": "do", "OffsetStartMs": 7725, "OffsetEndMs": 7890}, {"Word": "nothing", "OffsetStartMs": 7890, "OffsetEndMs": 8115}, {"Word": "We", "OffsetStartMs": 8115, "OffsetEndMs": 8340}, {"Word": "can", "OffsetStartMs": 8340, "OffsetEndMs": 8505}, {"Word": "stay", "OffsetStartMs": 8505, "OffsetEndMs": 8700}, {"Word": "where", "OffsetStartMs": 8700, "OffsetEndMs": 8865}, {"Word": "we", "OffsetStartMs": 8865, "OffsetEndMs": 8985}, {"Word": "are", "OffsetStartMs": 8985, "OffsetEndMs": 9230}], "SpeechSpeed": 15.3}, {"FinalSentence": "Right. So the next step from this we saw if we have this hue value output, what we can do with it is we can make an action or we can even let me be more formal about it. We can develop what's called a policy function. Policy function is a function that given a state, it determines what is the best action. So that's different than the q function, right? The q function tells us given a state, what is the best or what is the value, the return of every action that we could take. The policy function tells us one step more than that.", "SliceSentence": "Right So the next step from this we saw if we have this hue value output what we can do with it is we can make an action or we can even let me be more formal about it We can develop what's called a policy function Policy function is a function that given a state it determines what is the best action So that's different than the q function right The q function tells us given a state what is the best or what is the value the return of every action that we could take The policy function tells us one step more than that", "StartMs": 1608620, "EndMs": 1641580, "WordsNum": 107, "Words": [{"Word": "Right", "OffsetStartMs": 100, "OffsetEndMs": 500}, {"Word": "So", "OffsetStartMs": 850, "OffsetEndMs": 1250}, {"Word": "the", "OffsetStartMs": 1390, "OffsetEndMs": 1665}, {"Word": "next", "OffsetStartMs": 1665, "OffsetEndMs": 1890}, {"Word": "step", "OffsetStartMs": 1890, "OffsetEndMs": 2240}, {"Word": "from", "OffsetStartMs": 2290, "OffsetEndMs": 2595}, {"Word": "this", "OffsetStartMs": 2595, "OffsetEndMs": 2900}, {"Word": "we", "OffsetStartMs": 3040, "OffsetEndMs": 3360}, {"Word": "saw", "OffsetStartMs": 3360, "OffsetEndMs": 3675}, {"Word": "if", "OffsetStartMs": 3675, "OffsetEndMs": 3945}, {"Word": "we", "OffsetStartMs": 3945, "OffsetEndMs": 4155}, {"Word": "have", "OffsetStartMs": 4155, "OffsetEndMs": 4490}, {"Word": "this", "OffsetStartMs": 4810, "OffsetEndMs": 5210}, {"Word": "hue", "OffsetStartMs": 5800, "OffsetEndMs": 6090}, {"Word": "value", "OffsetStartMs": 6090, "OffsetEndMs": 6350}, {"Word": "output", "OffsetStartMs": 6580, "OffsetEndMs": 6900}, {"Word": "what", "OffsetStartMs": 6900, "OffsetEndMs": 7080}, {"Word": "we", "OffsetStartMs": 7080, "OffsetEndMs": 7200}, {"Word": "can", "OffsetStartMs": 7200, "OffsetEndMs": 7350}, {"Word": "do", "OffsetStartMs": 7350, "OffsetEndMs": 7515}, {"Word": "with", "OffsetStartMs": 7515, "OffsetEndMs": 7680}, {"Word": "it", "OffsetStartMs": 7680, "OffsetEndMs": 7970}, {"Word": "is", "OffsetStartMs": 8260, "OffsetEndMs": 8660}, {"Word": "we", "OffsetStartMs": 9070, "OffsetEndMs": 9345}, {"Word": "can", "OffsetStartMs": 9345, "OffsetEndMs": 9600}, {"Word": "make", "OffsetStartMs": 9600, "OffsetEndMs": 9855}, {"Word": "an", "OffsetStartMs": 9855, "OffsetEndMs": 9975}, {"Word": "action", "OffsetStartMs": 9975, "OffsetEndMs": 10220}, {"Word": "or", "OffsetStartMs": 10300, "OffsetEndMs": 10575}, {"Word": "we", "OffsetStartMs": 10575, "OffsetEndMs": 10725}, {"Word": "can", "OffsetStartMs": 10725, "OffsetEndMs": 10965}, {"Word": "even", "OffsetStartMs": 10965, "OffsetEndMs": 11330}, {"Word": "let", "OffsetStartMs": 11800, "OffsetEndMs": 12060}, {"Word": "me", "OffsetStartMs": 12060, "OffsetEndMs": 12255}, {"Word": "be", "OffsetStartMs": 12255, "OffsetEndMs": 12465}, {"Word": "more", "OffsetStartMs": 12465, "OffsetEndMs": 12630}, {"Word": "formal", "OffsetStartMs": 12630, "OffsetEndMs": 12885}, {"Word": "about", "OffsetStartMs": 12885, "OffsetEndMs": 13110}, {"Word": "it", "OffsetStartMs": 13110, "OffsetEndMs": 13260}, {"Word": "We", "OffsetStartMs": 13260, "OffsetEndMs": 13425}, {"Word": "can", "OffsetStartMs": 13425, "OffsetEndMs": 13650}, {"Word": "develop", "OffsetStartMs": 13650, "OffsetEndMs": 13920}, {"Word": "what's", "OffsetStartMs": 13920, "OffsetEndMs": 14190}, {"Word": "called", "OffsetStartMs": 14190, "OffsetEndMs": 14340}, {"Word": "a", "OffsetStartMs": 14340, "OffsetEndMs": 14520}, {"Word": "policy", "OffsetStartMs": 14520, "OffsetEndMs": 14810}, {"Word": "function", "OffsetStartMs": 14830, "OffsetEndMs": 15230}, {"Word": "Policy", "OffsetStartMs": 15250, "OffsetEndMs": 15645}, {"Word": "function", "OffsetStartMs": 15645, "OffsetEndMs": 16040}, {"Word": "is", "OffsetStartMs": 16270, "OffsetEndMs": 16530}, {"Word": "a", "OffsetStartMs": 16530, "OffsetEndMs": 16665}, {"Word": "function", "OffsetStartMs": 16665, "OffsetEndMs": 16940}, {"Word": "that", "OffsetStartMs": 17080, "OffsetEndMs": 17430}, {"Word": "given", "OffsetStartMs": 17430, "OffsetEndMs": 17685}, {"Word": "a", "OffsetStartMs": 17685, "OffsetEndMs": 17895}, {"Word": "state", "OffsetStartMs": 17895, "OffsetEndMs": 18200}, {"Word": "it", "OffsetStartMs": 18550, "OffsetEndMs": 18915}, {"Word": "determines", "OffsetStartMs": 18915, "OffsetEndMs": 19440}, {"Word": "what", "OffsetStartMs": 19440, "OffsetEndMs": 19710}, {"Word": "is", "OffsetStartMs": 19710, "OffsetEndMs": 19920}, {"Word": "the", "OffsetStartMs": 19920, "OffsetEndMs": 20145}, {"Word": "best", "OffsetStartMs": 20145, "OffsetEndMs": 20385}, {"Word": "action", "OffsetStartMs": 20385, "OffsetEndMs": 20720}, {"Word": "So", "OffsetStartMs": 20800, "OffsetEndMs": 21045}, {"Word": "that's", "OffsetStartMs": 21045, "OffsetEndMs": 21255}, {"Word": "different", "OffsetStartMs": 21255, "OffsetEndMs": 21495}, {"Word": "than", "OffsetStartMs": 21495, "OffsetEndMs": 21735}, {"Word": "the", "OffsetStartMs": 21735, "OffsetEndMs": 21915}, {"Word": "q", "OffsetStartMs": 21915, "OffsetEndMs": 22110}, {"Word": "function", "OffsetStartMs": 22110, "OffsetEndMs": 22400}, {"Word": "right", "OffsetStartMs": 22450, "OffsetEndMs": 22740}, {"Word": "The", "OffsetStartMs": 22740, "OffsetEndMs": 22905}, {"Word": "q", "OffsetStartMs": 22905, "OffsetEndMs": 23055}, {"Word": "function", "OffsetStartMs": 23055, "OffsetEndMs": 23310}, {"Word": "tells", "OffsetStartMs": 23310, "OffsetEndMs": 23580}, {"Word": "us", "OffsetStartMs": 23580, "OffsetEndMs": 23870}, {"Word": "given", "OffsetStartMs": 24040, "OffsetEndMs": 24330}, {"Word": "a", "OffsetStartMs": 24330, "OffsetEndMs": 24540}, {"Word": "state", "OffsetStartMs": 24540, "OffsetEndMs": 24855}, {"Word": "what", "OffsetStartMs": 24855, "OffsetEndMs": 25080}, {"Word": "is", "OffsetStartMs": 25080, "OffsetEndMs": 25200}, {"Word": "the", "OffsetStartMs": 25200, "OffsetEndMs": 25350}, {"Word": "best", "OffsetStartMs": 25350, "OffsetEndMs": 25610}, {"Word": "or", "OffsetStartMs": 25690, "OffsetEndMs": 25965}, {"Word": "what", "OffsetStartMs": 25965, "OffsetEndMs": 26100}, {"Word": "is", "OffsetStartMs": 26100, "OffsetEndMs": 26280}, {"Word": "the", "OffsetStartMs": 26280, "OffsetEndMs": 26600}, {"Word": "value", "OffsetStartMs": 26770, "OffsetEndMs": 27170}, {"Word": "the", "OffsetStartMs": 27460, "OffsetEndMs": 27840}, {"Word": "return", "OffsetStartMs": 27840, "OffsetEndMs": 28200}, {"Word": "of", "OffsetStartMs": 28200, "OffsetEndMs": 28455}, {"Word": "every", "OffsetStartMs": 28455, "OffsetEndMs": 28650}, {"Word": "action", "OffsetStartMs": 28650, "OffsetEndMs": 28905}, {"Word": "that", "OffsetStartMs": 28905, "OffsetEndMs": 29100}, {"Word": "we", "OffsetStartMs": 29100, "OffsetEndMs": 29220}, {"Word": "could", "OffsetStartMs": 29220, "OffsetEndMs": 29355}, {"Word": "take", "OffsetStartMs": 29355, "OffsetEndMs": 29630}, {"Word": "The", "OffsetStartMs": 29920, "OffsetEndMs": 30225}, {"Word": "policy", "OffsetStartMs": 30225, "OffsetEndMs": 30530}, {"Word": "function", "OffsetStartMs": 30550, "OffsetEndMs": 30950}, {"Word": "tells", "OffsetStartMs": 31000, "OffsetEndMs": 31290}, {"Word": "us", "OffsetStartMs": 31290, "OffsetEndMs": 31485}, {"Word": "one", "OffsetStartMs": 31485, "OffsetEndMs": 31725}, {"Word": "step", "OffsetStartMs": 31725, "OffsetEndMs": 31965}, {"Word": "more", "OffsetStartMs": 31965, "OffsetEndMs": 32175}, {"Word": "than", "OffsetStartMs": 32175, "OffsetEndMs": 32355}, {"Word": "that", "OffsetStartMs": 32355, "OffsetEndMs": 32630}], "SpeechSpeed": 15.8}, {"FinalSentence": "Given, given a state, what is the best action, right? So it's a very end to end way of thinking about, you know, the agent's decision making process based on what I see right now, what is the action that I should take? And we can determine that policy function directly from the q function itself simply by maximizing and optimizing all of the different q values for all of the different actions that we see here. So for example, here we can see that given this state, the q function as the result of these three different values has A Q value of twenty. If it goes to the left, has A Q value of three, if it stays in the same place and it has A Q value of zero, it's going to basically die after this iteration if it moves to the right because you can see that the ball is coming to the left of it. If it moves to the right, the game is over, right. So it needs to move to the left in order to do that in order to continue the game. And the q value reflects that. The optimal action here is simply going to be the maximum of these three q values. In this case it's going to be.", "SliceSentence": "Given given a state what is the best action right So it's a very end to end way of thinking about you know the agent's decision making process based on what I see right now what is the action that I should take And we can determine that policy function directly from the q function itself simply by maximizing and optimizing all of the different q values for all of the different actions that we see here So for example here we can see that given this state the q function as the result of these three different values has A Q value of twenty If it goes to the left has A Q value of three if it stays in the same place and it has A Q value of zero it's going to basically die after this iteration if it moves to the right because you can see that the ball is coming to the left of it If it moves to the right the game is over right So it needs to move to the left in order to do that in order to continue the game And the q value reflects that The optimal action here is simply going to be the maximum of these three q values In this case it's going to be", "StartMs": 1641580, "EndMs": 1701860, "WordsNum": 219, "Words": [{"Word": "Given", "OffsetStartMs": 0, "OffsetEndMs": 320}, {"Word": "given", "OffsetStartMs": 580, "OffsetEndMs": 930}, {"Word": "a", "OffsetStartMs": 930, "OffsetEndMs": 1215}, {"Word": "state", "OffsetStartMs": 1215, "OffsetEndMs": 1550}, {"Word": "what", "OffsetStartMs": 1870, "OffsetEndMs": 2145}, {"Word": "is", "OffsetStartMs": 2145, "OffsetEndMs": 2340}, {"Word": "the", "OffsetStartMs": 2340, "OffsetEndMs": 2550}, {"Word": "best", "OffsetStartMs": 2550, "OffsetEndMs": 2775}, {"Word": "action", "OffsetStartMs": 2775, "OffsetEndMs": 3110}, {"Word": "right", "OffsetStartMs": 3310, "OffsetEndMs": 3615}, {"Word": "So", "OffsetStartMs": 3615, "OffsetEndMs": 3765}, {"Word": "it's", "OffsetStartMs": 3765, "OffsetEndMs": 3915}, {"Word": "a", "OffsetStartMs": 3915, "OffsetEndMs": 4005}, {"Word": "very", "OffsetStartMs": 4005, "OffsetEndMs": 4230}, {"Word": "end", "OffsetStartMs": 4230, "OffsetEndMs": 4515}, {"Word": "to", "OffsetStartMs": 4515, "OffsetEndMs": 4695}, {"Word": "end", "OffsetStartMs": 4695, "OffsetEndMs": 4940}, {"Word": "way", "OffsetStartMs": 5170, "OffsetEndMs": 5460}, {"Word": "of", "OffsetStartMs": 5460, "OffsetEndMs": 5640}, {"Word": "thinking", "OffsetStartMs": 5640, "OffsetEndMs": 5930}, {"Word": "about", "OffsetStartMs": 5980, "OffsetEndMs": 6380}, {"Word": "you", "OffsetStartMs": 6670, "OffsetEndMs": 6900}, {"Word": "know", "OffsetStartMs": 6900, "OffsetEndMs": 7050}, {"Word": "the", "OffsetStartMs": 7050, "OffsetEndMs": 7230}, {"Word": "agent's", "OffsetStartMs": 7230, "OffsetEndMs": 7740}, {"Word": "decision", "OffsetStartMs": 7740, "OffsetEndMs": 7995}, {"Word": "making", "OffsetStartMs": 7995, "OffsetEndMs": 8310}, {"Word": "process", "OffsetStartMs": 8310, "OffsetEndMs": 8690}, {"Word": "based", "OffsetStartMs": 8860, "OffsetEndMs": 9165}, {"Word": "on", "OffsetStartMs": 9165, "OffsetEndMs": 9345}, {"Word": "what", "OffsetStartMs": 9345, "OffsetEndMs": 9480}, {"Word": "I", "OffsetStartMs": 9480, "OffsetEndMs": 9645}, {"Word": "see", "OffsetStartMs": 9645, "OffsetEndMs": 9810}, {"Word": "right", "OffsetStartMs": 9810, "OffsetEndMs": 9975}, {"Word": "now", "OffsetStartMs": 9975, "OffsetEndMs": 10280}, {"Word": "what", "OffsetStartMs": 10630, "OffsetEndMs": 10890}, {"Word": "is", "OffsetStartMs": 10890, "OffsetEndMs": 11040}, {"Word": "the", "OffsetStartMs": 11040, "OffsetEndMs": 11175}, {"Word": "action", "OffsetStartMs": 11175, "OffsetEndMs": 11415}, {"Word": "that", "OffsetStartMs": 11415, "OffsetEndMs": 11640}, {"Word": "I", "OffsetStartMs": 11640, "OffsetEndMs": 11760}, {"Word": "should", "OffsetStartMs": 11760, "OffsetEndMs": 11940}, {"Word": "take", "OffsetStartMs": 11940, "OffsetEndMs": 12230}, {"Word": "And", "OffsetStartMs": 12520, "OffsetEndMs": 12765}, {"Word": "we", "OffsetStartMs": 12765, "OffsetEndMs": 12870}, {"Word": "can", "OffsetStartMs": 12870, "OffsetEndMs": 13095}, {"Word": "determine", "OffsetStartMs": 13095, "OffsetEndMs": 13395}, {"Word": "that", "OffsetStartMs": 13395, "OffsetEndMs": 13710}, {"Word": "policy", "OffsetStartMs": 13710, "OffsetEndMs": 14090}, {"Word": "function", "OffsetStartMs": 14110, "OffsetEndMs": 14510}, {"Word": "directly", "OffsetStartMs": 15100, "OffsetEndMs": 15500}, {"Word": "from", "OffsetStartMs": 15820, "OffsetEndMs": 16140}, {"Word": "the", "OffsetStartMs": 16140, "OffsetEndMs": 16335}, {"Word": "q", "OffsetStartMs": 16335, "OffsetEndMs": 16500}, {"Word": "function", "OffsetStartMs": 16500, "OffsetEndMs": 16790}, {"Word": "itself", "OffsetStartMs": 16840, "OffsetEndMs": 17190}, {"Word": "simply", "OffsetStartMs": 17190, "OffsetEndMs": 17490}, {"Word": "by", "OffsetStartMs": 17490, "OffsetEndMs": 17840}, {"Word": "maximizing", "OffsetStartMs": 18010, "OffsetEndMs": 18710}, {"Word": "and", "OffsetStartMs": 19030, "OffsetEndMs": 19395}, {"Word": "optimizing", "OffsetStartMs": 19395, "OffsetEndMs": 19880}, {"Word": "all", "OffsetStartMs": 20050, "OffsetEndMs": 20325}, {"Word": "of", "OffsetStartMs": 20325, "OffsetEndMs": 20460}, {"Word": "the", "OffsetStartMs": 20460, "OffsetEndMs": 20565}, {"Word": "different", "OffsetStartMs": 20565, "OffsetEndMs": 20775}, {"Word": "q", "OffsetStartMs": 20775, "OffsetEndMs": 21000}, {"Word": "values", "OffsetStartMs": 21000, "OffsetEndMs": 21260}, {"Word": "for", "OffsetStartMs": 21430, "OffsetEndMs": 21660}, {"Word": "all", "OffsetStartMs": 21660, "OffsetEndMs": 21765}, {"Word": "of", "OffsetStartMs": 21765, "OffsetEndMs": 21900}, {"Word": "the", "OffsetStartMs": 21900, "OffsetEndMs": 22020}, {"Word": "different", "OffsetStartMs": 22020, "OffsetEndMs": 22280}, {"Word": "actions", "OffsetStartMs": 22450, "OffsetEndMs": 22850}, {"Word": "that", "OffsetStartMs": 22900, "OffsetEndMs": 23175}, {"Word": "we", "OffsetStartMs": 23175, "OffsetEndMs": 23340}, {"Word": "see", "OffsetStartMs": 23340, "OffsetEndMs": 23505}, {"Word": "here", "OffsetStartMs": 23505, "OffsetEndMs": 23780}, {"Word": "So", "OffsetStartMs": 24370, "OffsetEndMs": 24645}, {"Word": "for", "OffsetStartMs": 24645, "OffsetEndMs": 24825}, {"Word": "example", "OffsetStartMs": 24825, "OffsetEndMs": 25110}, {"Word": "here", "OffsetStartMs": 25110, "OffsetEndMs": 25490}, {"Word": "we", "OffsetStartMs": 25540, "OffsetEndMs": 25815}, {"Word": "can", "OffsetStartMs": 25815, "OffsetEndMs": 25980}, {"Word": "see", "OffsetStartMs": 25980, "OffsetEndMs": 26130}, {"Word": "that", "OffsetStartMs": 26130, "OffsetEndMs": 26385}, {"Word": "given", "OffsetStartMs": 26385, "OffsetEndMs": 26715}, {"Word": "this", "OffsetStartMs": 26715, "OffsetEndMs": 26985}, {"Word": "state", "OffsetStartMs": 26985, "OffsetEndMs": 27320}, {"Word": "the", "OffsetStartMs": 27910, "OffsetEndMs": 28215}, {"Word": "q", "OffsetStartMs": 28215, "OffsetEndMs": 28425}, {"Word": "function", "OffsetStartMs": 28425, "OffsetEndMs": 28730}, {"Word": "as", "OffsetStartMs": 29230, "OffsetEndMs": 29535}, {"Word": "the", "OffsetStartMs": 29535, "OffsetEndMs": 29775}, {"Word": "result", "OffsetStartMs": 29775, "OffsetEndMs": 30015}, {"Word": "of", "OffsetStartMs": 30015, "OffsetEndMs": 30195}, {"Word": "these", "OffsetStartMs": 30195, "OffsetEndMs": 30405}, {"Word": "three", "OffsetStartMs": 30405, "OffsetEndMs": 30615}, {"Word": "different", "OffsetStartMs": 30615, "OffsetEndMs": 30855}, {"Word": "values", "OffsetStartMs": 30855, "OffsetEndMs": 31220}, {"Word": "has", "OffsetStartMs": 31660, "OffsetEndMs": 31935}, {"Word": "A", "OffsetStartMs": 31935, "OffsetEndMs": 32115}, {"Word": "Q", "OffsetStartMs": 32115, "OffsetEndMs": 32310}, {"Word": "value", "OffsetStartMs": 32310, "OffsetEndMs": 32565}, {"Word": "of", "OffsetStartMs": 32565, "OffsetEndMs": 32850}, {"Word": "twenty", "OffsetStartMs": 32850, "OffsetEndMs": 33170}, {"Word": "If", "OffsetStartMs": 33310, "OffsetEndMs": 33555}, {"Word": "it", "OffsetStartMs": 33555, "OffsetEndMs": 33660}, {"Word": "goes", "OffsetStartMs": 33660, "OffsetEndMs": 33840}, {"Word": "to", "OffsetStartMs": 33840, "OffsetEndMs": 34005}, {"Word": "the", "OffsetStartMs": 34005, "OffsetEndMs": 34095}, {"Word": "left", "OffsetStartMs": 34095, "OffsetEndMs": 34340}, {"Word": "has", "OffsetStartMs": 34510, "OffsetEndMs": 34785}, {"Word": "A", "OffsetStartMs": 34785, "OffsetEndMs": 34920}, {"Word": "Q", "OffsetStartMs": 34920, "OffsetEndMs": 35055}, {"Word": "value", "OffsetStartMs": 35055, "OffsetEndMs": 35250}, {"Word": "of", "OffsetStartMs": 35250, "OffsetEndMs": 35475}, {"Word": "three", "OffsetStartMs": 35475, "OffsetEndMs": 35780}, {"Word": "if", "OffsetStartMs": 35830, "OffsetEndMs": 36075}, {"Word": "it", "OffsetStartMs": 36075, "OffsetEndMs": 36225}, {"Word": "stays", "OffsetStartMs": 36225, "OffsetEndMs": 36465}, {"Word": "in", "OffsetStartMs": 36465, "OffsetEndMs": 36645}, {"Word": "the", "OffsetStartMs": 36645, "OffsetEndMs": 36750}, {"Word": "same", "OffsetStartMs": 36750, "OffsetEndMs": 36915}, {"Word": "place", "OffsetStartMs": 36915, "OffsetEndMs": 37125}, {"Word": "and", "OffsetStartMs": 37125, "OffsetEndMs": 37275}, {"Word": "it", "OffsetStartMs": 37275, "OffsetEndMs": 37380}, {"Word": "has", "OffsetStartMs": 37380, "OffsetEndMs": 37515}, {"Word": "A", "OffsetStartMs": 37515, "OffsetEndMs": 37650}, {"Word": "Q", "OffsetStartMs": 37650, "OffsetEndMs": 37785}, {"Word": "value", "OffsetStartMs": 37785, "OffsetEndMs": 37980}, {"Word": "of", "OffsetStartMs": 37980, "OffsetEndMs": 38220}, {"Word": "zero", "OffsetStartMs": 38220, "OffsetEndMs": 38540}, {"Word": "it's", "OffsetStartMs": 38800, "OffsetEndMs": 39150}, {"Word": "going", "OffsetStartMs": 39150, "OffsetEndMs": 39360}, {"Word": "to", "OffsetStartMs": 39360, "OffsetEndMs": 39660}, {"Word": "basically", "OffsetStartMs": 39660, "OffsetEndMs": 40040}, {"Word": "die", "OffsetStartMs": 40060, "OffsetEndMs": 40380}, {"Word": "after", "OffsetStartMs": 40380, "OffsetEndMs": 40635}, {"Word": "this", "OffsetStartMs": 40635, "OffsetEndMs": 40845}, {"Word": "iteration", "OffsetStartMs": 40845, "OffsetEndMs": 41300}, {"Word": "if", "OffsetStartMs": 41470, "OffsetEndMs": 41730}, {"Word": "it", "OffsetStartMs": 41730, "OffsetEndMs": 41850}, {"Word": "moves", "OffsetStartMs": 41850, "OffsetEndMs": 42030}, {"Word": "to", "OffsetStartMs": 42030, "OffsetEndMs": 42195}, {"Word": "the", "OffsetStartMs": 42195, "OffsetEndMs": 42300}, {"Word": "right", "OffsetStartMs": 42300, "OffsetEndMs": 42525}, {"Word": "because", "OffsetStartMs": 42525, "OffsetEndMs": 42750}, {"Word": "you", "OffsetStartMs": 42750, "OffsetEndMs": 42855}, {"Word": "can", "OffsetStartMs": 42855, "OffsetEndMs": 42975}, {"Word": "see", "OffsetStartMs": 42975, "OffsetEndMs": 43095}, {"Word": "that", "OffsetStartMs": 43095, "OffsetEndMs": 43200}, {"Word": "the", "OffsetStartMs": 43200, "OffsetEndMs": 43320}, {"Word": "ball", "OffsetStartMs": 43320, "OffsetEndMs": 43455}, {"Word": "is", "OffsetStartMs": 43455, "OffsetEndMs": 43605}, {"Word": "coming", "OffsetStartMs": 43605, "OffsetEndMs": 43815}, {"Word": "to", "OffsetStartMs": 43815, "OffsetEndMs": 43980}, {"Word": "the", "OffsetStartMs": 43980, "OffsetEndMs": 44055}, {"Word": "left", "OffsetStartMs": 44055, "OffsetEndMs": 44205}, {"Word": "of", "OffsetStartMs": 44205, "OffsetEndMs": 44355}, {"Word": "it", "OffsetStartMs": 44355, "OffsetEndMs": 44490}, {"Word": "If", "OffsetStartMs": 44490, "OffsetEndMs": 44625}, {"Word": "it", "OffsetStartMs": 44625, "OffsetEndMs": 44730}, {"Word": "moves", "OffsetStartMs": 44730, "OffsetEndMs": 44895}, {"Word": "to", "OffsetStartMs": 44895, "OffsetEndMs": 45045}, {"Word": "the", "OffsetStartMs": 45045, "OffsetEndMs": 45150}, {"Word": "right", "OffsetStartMs": 45150, "OffsetEndMs": 45410}, {"Word": "the", "OffsetStartMs": 45610, "OffsetEndMs": 45870}, {"Word": "game", "OffsetStartMs": 45870, "OffsetEndMs": 46005}, {"Word": "is", "OffsetStartMs": 46005, "OffsetEndMs": 46140}, {"Word": "over", "OffsetStartMs": 46140, "OffsetEndMs": 46400}, {"Word": "right", "OffsetStartMs": 46510, "OffsetEndMs": 46815}, {"Word": "So", "OffsetStartMs": 46815, "OffsetEndMs": 46965}, {"Word": "it", "OffsetStartMs": 46965, "OffsetEndMs": 47085}, {"Word": "needs", "OffsetStartMs": 47085, "OffsetEndMs": 47295}, {"Word": "to", "OffsetStartMs": 47295, "OffsetEndMs": 47475}, {"Word": "move", "OffsetStartMs": 47475, "OffsetEndMs": 47625}, {"Word": "to", "OffsetStartMs": 47625, "OffsetEndMs": 47790}, {"Word": "the", "OffsetStartMs": 47790, "OffsetEndMs": 47910}, {"Word": "left", "OffsetStartMs": 47910, "OffsetEndMs": 48170}, {"Word": "in", "OffsetStartMs": 48460, "OffsetEndMs": 48720}, {"Word": "order", "OffsetStartMs": 48720, "OffsetEndMs": 48930}, {"Word": "to", "OffsetStartMs": 48930, "OffsetEndMs": 49185}, {"Word": "do", "OffsetStartMs": 49185, "OffsetEndMs": 49365}, {"Word": "that", "OffsetStartMs": 49365, "OffsetEndMs": 49640}, {"Word": "in", "OffsetStartMs": 49690, "OffsetEndMs": 49950}, {"Word": "order", "OffsetStartMs": 49950, "OffsetEndMs": 50115}, {"Word": "to", "OffsetStartMs": 50115, "OffsetEndMs": 50355}, {"Word": "continue", "OffsetStartMs": 50355, "OffsetEndMs": 50610}, {"Word": "the", "OffsetStartMs": 50610, "OffsetEndMs": 50790}, {"Word": "game", "OffsetStartMs": 50790, "OffsetEndMs": 51050}, {"Word": "And", "OffsetStartMs": 51250, "OffsetEndMs": 51555}, {"Word": "the", "OffsetStartMs": 51555, "OffsetEndMs": 51735}, {"Word": "q", "OffsetStartMs": 51735, "OffsetEndMs": 51870}, {"Word": "value", "OffsetStartMs": 51870, "OffsetEndMs": 52130}, {"Word": "reflects", "OffsetStartMs": 52210, "OffsetEndMs": 52530}, {"Word": "that", "OffsetStartMs": 52530, "OffsetEndMs": 52850}, {"Word": "The", "OffsetStartMs": 53680, "OffsetEndMs": 54075}, {"Word": "optimal", "OffsetStartMs": 54075, "OffsetEndMs": 54420}, {"Word": "action", "OffsetStartMs": 54420, "OffsetEndMs": 54680}, {"Word": "here", "OffsetStartMs": 54700, "OffsetEndMs": 55020}, {"Word": "is", "OffsetStartMs": 55020, "OffsetEndMs": 55230}, {"Word": "simply", "OffsetStartMs": 55230, "OffsetEndMs": 55455}, {"Word": "going", "OffsetStartMs": 55455, "OffsetEndMs": 55695}, {"Word": "to", "OffsetStartMs": 55695, "OffsetEndMs": 55830}, {"Word": "be", "OffsetStartMs": 55830, "OffsetEndMs": 55905}, {"Word": "the", "OffsetStartMs": 55905, "OffsetEndMs": 56025}, {"Word": "maximum", "OffsetStartMs": 56025, "OffsetEndMs": 56300}, {"Word": "of", "OffsetStartMs": 56650, "OffsetEndMs": 56985}, {"Word": "these", "OffsetStartMs": 56985, "OffsetEndMs": 57300}, {"Word": "three", "OffsetStartMs": 57300, "OffsetEndMs": 57680}, {"Word": "q", "OffsetStartMs": 57730, "OffsetEndMs": 58020}, {"Word": "values", "OffsetStartMs": 58020, "OffsetEndMs": 58310}, {"Word": "In", "OffsetStartMs": 58450, "OffsetEndMs": 58710}, {"Word": "this", "OffsetStartMs": 58710, "OffsetEndMs": 58890}, {"Word": "case", "OffsetStartMs": 58890, "OffsetEndMs": 59210}, {"Word": "it's", "OffsetStartMs": 59410, "OffsetEndMs": 59790}, {"Word": "going", "OffsetStartMs": 59790, "OffsetEndMs": 59940}, {"Word": "to", "OffsetStartMs": 59940, "OffsetEndMs": 60075}, {"Word": "be", "OffsetStartMs": 60075, "OffsetEndMs": 60240}], "SpeechSpeed": 17.5}, {"FinalSentence": "Twenty, and then the action is going to be the corresponding action that comes from that twenty, which is moving left.", "SliceSentence": "Twenty and then the action is going to be the corresponding action that comes from that twenty which is moving left", "StartMs": 1701860, "EndMs": 1708540, "WordsNum": 21, "Words": [{"Word": "Twenty", "OffsetStartMs": 0, "OffsetEndMs": 260}, {"Word": "and", "OffsetStartMs": 520, "OffsetEndMs": 825}, {"Word": "then", "OffsetStartMs": 825, "OffsetEndMs": 1020}, {"Word": "the", "OffsetStartMs": 1020, "OffsetEndMs": 1155}, {"Word": "action", "OffsetStartMs": 1155, "OffsetEndMs": 1395}, {"Word": "is", "OffsetStartMs": 1395, "OffsetEndMs": 1665}, {"Word": "going", "OffsetStartMs": 1665, "OffsetEndMs": 1830}, {"Word": "to", "OffsetStartMs": 1830, "OffsetEndMs": 1950}, {"Word": "be", "OffsetStartMs": 1950, "OffsetEndMs": 2040}, {"Word": "the", "OffsetStartMs": 2040, "OffsetEndMs": 2175}, {"Word": "corresponding", "OffsetStartMs": 2175, "OffsetEndMs": 2865}, {"Word": "action", "OffsetStartMs": 2865, "OffsetEndMs": 3140}, {"Word": "that", "OffsetStartMs": 3340, "OffsetEndMs": 3630}, {"Word": "comes", "OffsetStartMs": 3630, "OffsetEndMs": 3825}, {"Word": "from", "OffsetStartMs": 3825, "OffsetEndMs": 3990}, {"Word": "that", "OffsetStartMs": 3990, "OffsetEndMs": 4155}, {"Word": "twenty", "OffsetStartMs": 4155, "OffsetEndMs": 4395}, {"Word": "which", "OffsetStartMs": 4395, "OffsetEndMs": 4605}, {"Word": "is", "OffsetStartMs": 4605, "OffsetEndMs": 4830}, {"Word": "moving", "OffsetStartMs": 4830, "OffsetEndMs": 5145}, {"Word": "left", "OffsetStartMs": 5145, "OffsetEndMs": 5510}], "SpeechSpeed": 17.2}, {"FinalSentence": "Now.", "SliceSentence": "Now", "StartMs": 1709240, "EndMs": 1710900, "WordsNum": 1, "Words": [{"Word": "Now", "OffsetStartMs": 100, "OffsetEndMs": 500}], "SpeechSpeed": 1.8}, {"FinalSentence": "We can send this action back to the environment in the form of the game to execute the next step, right. And as the agent moves through this environment, it's going to be responded with not only by new pixels that come from the game, but more importantly, some reward signal. Now it's very important to remember that the reward signals in pong, or sorry in atari, breakout.", "SliceSentence": "We can send this action back to the environment in the form of the game to execute the next step right And as the agent moves through this environment it's going to be responded with not only by new pixels that come from the game but more importantly some reward signal Now it's very important to remember that the reward signals in pong or sorry in atari breakout", "StartMs": 1711020, "EndMs": 1734440, "WordsNum": 68, "Words": [{"Word": "We", "OffsetStartMs": 100, "OffsetEndMs": 375}, {"Word": "can", "OffsetStartMs": 375, "OffsetEndMs": 650}, {"Word": "send", "OffsetStartMs": 1060, "OffsetEndMs": 1460}, {"Word": "this", "OffsetStartMs": 1600, "OffsetEndMs": 1905}, {"Word": "action", "OffsetStartMs": 1905, "OffsetEndMs": 2210}, {"Word": "back", "OffsetStartMs": 2710, "OffsetEndMs": 3110}, {"Word": "to", "OffsetStartMs": 3400, "OffsetEndMs": 3800}, {"Word": "the", "OffsetStartMs": 3820, "OffsetEndMs": 4155}, {"Word": "environment", "OffsetStartMs": 4155, "OffsetEndMs": 4490}, {"Word": "in", "OffsetStartMs": 4720, "OffsetEndMs": 4965}, {"Word": "the", "OffsetStartMs": 4965, "OffsetEndMs": 5085}, {"Word": "form", "OffsetStartMs": 5085, "OffsetEndMs": 5235}, {"Word": "of", "OffsetStartMs": 5235, "OffsetEndMs": 5370}, {"Word": "the", "OffsetStartMs": 5370, "OffsetEndMs": 5505}, {"Word": "game", "OffsetStartMs": 5505, "OffsetEndMs": 5780}, {"Word": "to", "OffsetStartMs": 6040, "OffsetEndMs": 6440}, {"Word": "execute", "OffsetStartMs": 6520, "OffsetEndMs": 6810}, {"Word": "the", "OffsetStartMs": 6810, "OffsetEndMs": 6975}, {"Word": "next", "OffsetStartMs": 6975, "OffsetEndMs": 7215}, {"Word": "step", "OffsetStartMs": 7215, "OffsetEndMs": 7580}, {"Word": "right", "OffsetStartMs": 7840, "OffsetEndMs": 8130}, {"Word": "And", "OffsetStartMs": 8130, "OffsetEndMs": 8310}, {"Word": "as", "OffsetStartMs": 8310, "OffsetEndMs": 8580}, {"Word": "the", "OffsetStartMs": 8580, "OffsetEndMs": 8805}, {"Word": "agent", "OffsetStartMs": 8805, "OffsetEndMs": 9050}, {"Word": "moves", "OffsetStartMs": 9130, "OffsetEndMs": 9530}, {"Word": "through", "OffsetStartMs": 9580, "OffsetEndMs": 9855}, {"Word": "this", "OffsetStartMs": 9855, "OffsetEndMs": 10095}, {"Word": "environment", "OffsetStartMs": 10095, "OffsetEndMs": 10460}, {"Word": "it's", "OffsetStartMs": 10870, "OffsetEndMs": 11220}, {"Word": "going", "OffsetStartMs": 11220, "OffsetEndMs": 11370}, {"Word": "to", "OffsetStartMs": 11370, "OffsetEndMs": 11505}, {"Word": "be", "OffsetStartMs": 11505, "OffsetEndMs": 11730}, {"Word": "responded", "OffsetStartMs": 11730, "OffsetEndMs": 12090}, {"Word": "with", "OffsetStartMs": 12090, "OffsetEndMs": 12470}, {"Word": "not", "OffsetStartMs": 12490, "OffsetEndMs": 12765}, {"Word": "only", "OffsetStartMs": 12765, "OffsetEndMs": 13035}, {"Word": "by", "OffsetStartMs": 13035, "OffsetEndMs": 13350}, {"Word": "new", "OffsetStartMs": 13350, "OffsetEndMs": 13575}, {"Word": "pixels", "OffsetStartMs": 13575, "OffsetEndMs": 14100}, {"Word": "that", "OffsetStartMs": 14100, "OffsetEndMs": 14370}, {"Word": "come", "OffsetStartMs": 14370, "OffsetEndMs": 14550}, {"Word": "from", "OffsetStartMs": 14550, "OffsetEndMs": 14730}, {"Word": "the", "OffsetStartMs": 14730, "OffsetEndMs": 14865}, {"Word": "game", "OffsetStartMs": 14865, "OffsetEndMs": 15110}, {"Word": "but", "OffsetStartMs": 15430, "OffsetEndMs": 15705}, {"Word": "more", "OffsetStartMs": 15705, "OffsetEndMs": 15930}, {"Word": "importantly", "OffsetStartMs": 15930, "OffsetEndMs": 16280}, {"Word": "some", "OffsetStartMs": 16600, "OffsetEndMs": 16980}, {"Word": "reward", "OffsetStartMs": 16980, "OffsetEndMs": 17295}, {"Word": "signal", "OffsetStartMs": 17295, "OffsetEndMs": 17630}, {"Word": "Now", "OffsetStartMs": 17680, "OffsetEndMs": 17925}, {"Word": "it's", "OffsetStartMs": 17925, "OffsetEndMs": 18105}, {"Word": "very", "OffsetStartMs": 18105, "OffsetEndMs": 18270}, {"Word": "important", "OffsetStartMs": 18270, "OffsetEndMs": 18510}, {"Word": "to", "OffsetStartMs": 18510, "OffsetEndMs": 18735}, {"Word": "remember", "OffsetStartMs": 18735, "OffsetEndMs": 18990}, {"Word": "that", "OffsetStartMs": 18990, "OffsetEndMs": 19230}, {"Word": "the", "OffsetStartMs": 19230, "OffsetEndMs": 19455}, {"Word": "reward", "OffsetStartMs": 19455, "OffsetEndMs": 19725}, {"Word": "signals", "OffsetStartMs": 19725, "OffsetEndMs": 20130}, {"Word": "in", "OffsetStartMs": 20130, "OffsetEndMs": 20370}, {"Word": "pong", "OffsetStartMs": 20370, "OffsetEndMs": 20720}, {"Word": "or", "OffsetStartMs": 21010, "OffsetEndMs": 21285}, {"Word": "sorry", "OffsetStartMs": 21285, "OffsetEndMs": 21560}, {"Word": "in", "OffsetStartMs": 21580, "OffsetEndMs": 21945}, {"Word": "atari", "OffsetStartMs": 21945, "OffsetEndMs": 22410}, {"Word": "breakout", "OffsetStartMs": 22410, "OffsetEndMs": 22970}], "SpeechSpeed": 15.5}, {"FinalSentence": "Are very sparse, right? You get a reward, not necessarily based on the action that you take at this exact moment. It usually takes a few time steps for that ball to travel back up to the top of the screen. So usually your rewards will be quite delayed, maybe at least by several time steps, sometimes even more if you're bouncing off of the corners of the screen.", "SliceSentence": "Are very sparse right You get a reward not necessarily based on the action that you take at this exact moment It usually takes a few time steps for that ball to travel back up to the top of the screen So usually your rewards will be quite delayed maybe at least by several time steps sometimes even more if you're bouncing off of the corners of the screen", "StartMs": 1734440, "EndMs": 1756060, "WordsNum": 69, "Words": [{"Word": "Are", "OffsetStartMs": 0, "OffsetEndMs": 260}, {"Word": "very", "OffsetStartMs": 280, "OffsetEndMs": 645}, {"Word": "sparse", "OffsetStartMs": 645, "OffsetEndMs": 1215}, {"Word": "right", "OffsetStartMs": 1215, "OffsetEndMs": 1590}, {"Word": "You", "OffsetStartMs": 1590, "OffsetEndMs": 1860}, {"Word": "get", "OffsetStartMs": 1860, "OffsetEndMs": 2055}, {"Word": "a", "OffsetStartMs": 2055, "OffsetEndMs": 2360}, {"Word": "reward", "OffsetStartMs": 2470, "OffsetEndMs": 2870}, {"Word": "not", "OffsetStartMs": 2950, "OffsetEndMs": 3350}, {"Word": "necessarily", "OffsetStartMs": 3460, "OffsetEndMs": 3825}, {"Word": "based", "OffsetStartMs": 3825, "OffsetEndMs": 4140}, {"Word": "on", "OffsetStartMs": 4140, "OffsetEndMs": 4490}, {"Word": "the", "OffsetStartMs": 5410, "OffsetEndMs": 5670}, {"Word": "action", "OffsetStartMs": 5670, "OffsetEndMs": 5850}, {"Word": "that", "OffsetStartMs": 5850, "OffsetEndMs": 6045}, {"Word": "you", "OffsetStartMs": 6045, "OffsetEndMs": 6180}, {"Word": "take", "OffsetStartMs": 6180, "OffsetEndMs": 6315}, {"Word": "at", "OffsetStartMs": 6315, "OffsetEndMs": 6450}, {"Word": "this", "OffsetStartMs": 6450, "OffsetEndMs": 6645}, {"Word": "exact", "OffsetStartMs": 6645, "OffsetEndMs": 6930}, {"Word": "moment", "OffsetStartMs": 6930, "OffsetEndMs": 7280}, {"Word": "It", "OffsetStartMs": 7420, "OffsetEndMs": 7710}, {"Word": "usually", "OffsetStartMs": 7710, "OffsetEndMs": 8000}, {"Word": "takes", "OffsetStartMs": 8020, "OffsetEndMs": 8325}, {"Word": "a", "OffsetStartMs": 8325, "OffsetEndMs": 8520}, {"Word": "few", "OffsetStartMs": 8520, "OffsetEndMs": 8745}, {"Word": "time", "OffsetStartMs": 8745, "OffsetEndMs": 9045}, {"Word": "steps", "OffsetStartMs": 9045, "OffsetEndMs": 9360}, {"Word": "for", "OffsetStartMs": 9360, "OffsetEndMs": 9555}, {"Word": "that", "OffsetStartMs": 9555, "OffsetEndMs": 9705}, {"Word": "ball", "OffsetStartMs": 9705, "OffsetEndMs": 9945}, {"Word": "to", "OffsetStartMs": 9945, "OffsetEndMs": 10155}, {"Word": "travel", "OffsetStartMs": 10155, "OffsetEndMs": 10380}, {"Word": "back", "OffsetStartMs": 10380, "OffsetEndMs": 10665}, {"Word": "up", "OffsetStartMs": 10665, "OffsetEndMs": 10905}, {"Word": "to", "OffsetStartMs": 10905, "OffsetEndMs": 11055}, {"Word": "the", "OffsetStartMs": 11055, "OffsetEndMs": 11190}, {"Word": "top", "OffsetStartMs": 11190, "OffsetEndMs": 11370}, {"Word": "of", "OffsetStartMs": 11370, "OffsetEndMs": 11520}, {"Word": "the", "OffsetStartMs": 11520, "OffsetEndMs": 11700}, {"Word": "screen", "OffsetStartMs": 11700, "OffsetEndMs": 12020}, {"Word": "So", "OffsetStartMs": 12250, "OffsetEndMs": 12555}, {"Word": "usually", "OffsetStartMs": 12555, "OffsetEndMs": 12840}, {"Word": "your", "OffsetStartMs": 12840, "OffsetEndMs": 13185}, {"Word": "rewards", "OffsetStartMs": 13185, "OffsetEndMs": 13605}, {"Word": "will", "OffsetStartMs": 13605, "OffsetEndMs": 13815}, {"Word": "be", "OffsetStartMs": 13815, "OffsetEndMs": 14010}, {"Word": "quite", "OffsetStartMs": 14010, "OffsetEndMs": 14325}, {"Word": "delayed", "OffsetStartMs": 14325, "OffsetEndMs": 14720}, {"Word": "maybe", "OffsetStartMs": 15010, "OffsetEndMs": 15330}, {"Word": "at", "OffsetStartMs": 15330, "OffsetEndMs": 15540}, {"Word": "least", "OffsetStartMs": 15540, "OffsetEndMs": 15780}, {"Word": "by", "OffsetStartMs": 15780, "OffsetEndMs": 16125}, {"Word": "several", "OffsetStartMs": 16125, "OffsetEndMs": 16500}, {"Word": "time", "OffsetStartMs": 16500, "OffsetEndMs": 16815}, {"Word": "steps", "OffsetStartMs": 16815, "OffsetEndMs": 17100}, {"Word": "sometimes", "OffsetStartMs": 17100, "OffsetEndMs": 17450}, {"Word": "even", "OffsetStartMs": 17590, "OffsetEndMs": 17910}, {"Word": "more", "OffsetStartMs": 17910, "OffsetEndMs": 18120}, {"Word": "if", "OffsetStartMs": 18120, "OffsetEndMs": 18270}, {"Word": "you're", "OffsetStartMs": 18270, "OffsetEndMs": 18420}, {"Word": "bouncing", "OffsetStartMs": 18420, "OffsetEndMs": 18750}, {"Word": "off", "OffsetStartMs": 18750, "OffsetEndMs": 18900}, {"Word": "of", "OffsetStartMs": 18900, "OffsetEndMs": 19065}, {"Word": "the", "OffsetStartMs": 19065, "OffsetEndMs": 19215}, {"Word": "corners", "OffsetStartMs": 19215, "OffsetEndMs": 19640}, {"Word": "of", "OffsetStartMs": 19870, "OffsetEndMs": 20145}, {"Word": "the", "OffsetStartMs": 20145, "OffsetEndMs": 20325}, {"Word": "screen", "OffsetStartMs": 20325, "OffsetEndMs": 20630}], "SpeechSpeed": 16.4}, {"FinalSentence": "Now, one very popular or very famous approach that showed this was presented by deepmind Google deepmind several years ago, where they showed that you could train A Q value network and you can see the input on the left hand side is simply the raw pixels coming from the screen all the way to the actions of a controller on the right hand side. And you could train this one network for a variety of different tasks all across the atari breakout ecosystem of games.", "SliceSentence": "Now one very popular or very famous approach that showed this was presented by deepmind Google deepmind several years ago where they showed that you could train A Q value network and you can see the input on the left hand side is simply the raw pixels coming from the screen all the way to the actions of a controller on the right hand side And you could train this one network for a variety of different tasks all across the atari breakout ecosystem of games", "StartMs": 1756240, "EndMs": 1787720, "WordsNum": 86, "Words": [{"Word": "Now", "OffsetStartMs": 190, "OffsetEndMs": 590}, {"Word": "one", "OffsetStartMs": 1300, "OffsetEndMs": 1650}, {"Word": "very", "OffsetStartMs": 1650, "OffsetEndMs": 2000}, {"Word": "popular", "OffsetStartMs": 2710, "OffsetEndMs": 3110}, {"Word": "or", "OffsetStartMs": 3400, "OffsetEndMs": 3795}, {"Word": "very", "OffsetStartMs": 3795, "OffsetEndMs": 4190}, {"Word": "famous", "OffsetStartMs": 4210, "OffsetEndMs": 4610}, {"Word": "approach", "OffsetStartMs": 4780, "OffsetEndMs": 5160}, {"Word": "that", "OffsetStartMs": 5160, "OffsetEndMs": 5445}, {"Word": "showed", "OffsetStartMs": 5445, "OffsetEndMs": 5670}, {"Word": "this", "OffsetStartMs": 5670, "OffsetEndMs": 5910}, {"Word": "was", "OffsetStartMs": 5910, "OffsetEndMs": 6230}, {"Word": "presented", "OffsetStartMs": 6400, "OffsetEndMs": 6800}, {"Word": "by", "OffsetStartMs": 6880, "OffsetEndMs": 7280}, {"Word": "deepmind", "OffsetStartMs": 7540, "OffsetEndMs": 8180}, {"Word": "Google", "OffsetStartMs": 8230, "OffsetEndMs": 8595}, {"Word": "deepmind", "OffsetStartMs": 8595, "OffsetEndMs": 9135}, {"Word": "several", "OffsetStartMs": 9135, "OffsetEndMs": 9450}, {"Word": "years", "OffsetStartMs": 9450, "OffsetEndMs": 9780}, {"Word": "ago", "OffsetStartMs": 9780, "OffsetEndMs": 10095}, {"Word": "where", "OffsetStartMs": 10095, "OffsetEndMs": 10305}, {"Word": "they", "OffsetStartMs": 10305, "OffsetEndMs": 10500}, {"Word": "showed", "OffsetStartMs": 10500, "OffsetEndMs": 10725}, {"Word": "that", "OffsetStartMs": 10725, "OffsetEndMs": 10920}, {"Word": "you", "OffsetStartMs": 10920, "OffsetEndMs": 11085}, {"Word": "could", "OffsetStartMs": 11085, "OffsetEndMs": 11280}, {"Word": "train", "OffsetStartMs": 11280, "OffsetEndMs": 11600}, {"Word": "A", "OffsetStartMs": 11650, "OffsetEndMs": 11970}, {"Word": "Q", "OffsetStartMs": 11970, "OffsetEndMs": 12165}, {"Word": "value", "OffsetStartMs": 12165, "OffsetEndMs": 12435}, {"Word": "network", "OffsetStartMs": 12435, "OffsetEndMs": 12830}, {"Word": "and", "OffsetStartMs": 12850, "OffsetEndMs": 13110}, {"Word": "you", "OffsetStartMs": 13110, "OffsetEndMs": 13215}, {"Word": "can", "OffsetStartMs": 13215, "OffsetEndMs": 13365}, {"Word": "see", "OffsetStartMs": 13365, "OffsetEndMs": 13530}, {"Word": "the", "OffsetStartMs": 13530, "OffsetEndMs": 13740}, {"Word": "input", "OffsetStartMs": 13740, "OffsetEndMs": 13950}, {"Word": "on", "OffsetStartMs": 13950, "OffsetEndMs": 14070}, {"Word": "the", "OffsetStartMs": 14070, "OffsetEndMs": 14190}, {"Word": "left", "OffsetStartMs": 14190, "OffsetEndMs": 14355}, {"Word": "hand", "OffsetStartMs": 14355, "OffsetEndMs": 14580}, {"Word": "side", "OffsetStartMs": 14580, "OffsetEndMs": 14900}, {"Word": "is", "OffsetStartMs": 15100, "OffsetEndMs": 15390}, {"Word": "simply", "OffsetStartMs": 15390, "OffsetEndMs": 15630}, {"Word": "the", "OffsetStartMs": 15630, "OffsetEndMs": 15885}, {"Word": "raw", "OffsetStartMs": 15885, "OffsetEndMs": 16125}, {"Word": "pixels", "OffsetStartMs": 16125, "OffsetEndMs": 16635}, {"Word": "coming", "OffsetStartMs": 16635, "OffsetEndMs": 16905}, {"Word": "from", "OffsetStartMs": 16905, "OffsetEndMs": 17100}, {"Word": "the", "OffsetStartMs": 17100, "OffsetEndMs": 17265}, {"Word": "screen", "OffsetStartMs": 17265, "OffsetEndMs": 17570}, {"Word": "all", "OffsetStartMs": 17950, "OffsetEndMs": 18255}, {"Word": "the", "OffsetStartMs": 18255, "OffsetEndMs": 18420}, {"Word": "way", "OffsetStartMs": 18420, "OffsetEndMs": 18675}, {"Word": "to", "OffsetStartMs": 18675, "OffsetEndMs": 18930}, {"Word": "the", "OffsetStartMs": 18930, "OffsetEndMs": 19065}, {"Word": "actions", "OffsetStartMs": 19065, "OffsetEndMs": 19340}, {"Word": "of", "OffsetStartMs": 19900, "OffsetEndMs": 20160}, {"Word": "a", "OffsetStartMs": 20160, "OffsetEndMs": 20385}, {"Word": "controller", "OffsetStartMs": 20385, "OffsetEndMs": 20900}, {"Word": "on", "OffsetStartMs": 20950, "OffsetEndMs": 21225}, {"Word": "the", "OffsetStartMs": 21225, "OffsetEndMs": 21360}, {"Word": "right", "OffsetStartMs": 21360, "OffsetEndMs": 21540}, {"Word": "hand", "OffsetStartMs": 21540, "OffsetEndMs": 21795}, {"Word": "side", "OffsetStartMs": 21795, "OffsetEndMs": 22130}, {"Word": "And", "OffsetStartMs": 22720, "OffsetEndMs": 22980}, {"Word": "you", "OffsetStartMs": 22980, "OffsetEndMs": 23115}, {"Word": "could", "OffsetStartMs": 23115, "OffsetEndMs": 23310}, {"Word": "train", "OffsetStartMs": 23310, "OffsetEndMs": 23630}, {"Word": "this", "OffsetStartMs": 23740, "OffsetEndMs": 24075}, {"Word": "one", "OffsetStartMs": 24075, "OffsetEndMs": 24330}, {"Word": "network", "OffsetStartMs": 24330, "OffsetEndMs": 24650}, {"Word": "for", "OffsetStartMs": 24940, "OffsetEndMs": 25185}, {"Word": "a", "OffsetStartMs": 25185, "OffsetEndMs": 25320}, {"Word": "variety", "OffsetStartMs": 25320, "OffsetEndMs": 25610}, {"Word": "of", "OffsetStartMs": 25930, "OffsetEndMs": 26220}, {"Word": "different", "OffsetStartMs": 26220, "OffsetEndMs": 26505}, {"Word": "tasks", "OffsetStartMs": 26505, "OffsetEndMs": 26900}, {"Word": "all", "OffsetStartMs": 27100, "OffsetEndMs": 27480}, {"Word": "across", "OffsetStartMs": 27480, "OffsetEndMs": 27825}, {"Word": "the", "OffsetStartMs": 27825, "OffsetEndMs": 28020}, {"Word": "atari", "OffsetStartMs": 28020, "OffsetEndMs": 28430}, {"Word": "breakout", "OffsetStartMs": 28510, "OffsetEndMs": 29120}, {"Word": "ecosystem", "OffsetStartMs": 29950, "OffsetEndMs": 30350}, {"Word": "of", "OffsetStartMs": 30370, "OffsetEndMs": 30675}, {"Word": "games", "OffsetStartMs": 30675, "OffsetEndMs": 30980}], "SpeechSpeed": 14.6}, {"FinalSentence": "And for each of these tasks, the really fascinating thing that they showed was for this very simple algorithm which really relies on random choice of selection of actions and then, you know, learning from, you know, actions that don't do very well, that you discourage them and trying to do actions that did perform well more frequently, very simple algorithm, but what they found was even with that type of algorithm.", "SliceSentence": "And for each of these tasks the really fascinating thing that they showed was for this very simple algorithm which really relies on random choice of selection of actions and then you know learning from you know actions that don't do very well that you discourage them and trying to do actions that did perform well more frequently very simple algorithm but what they found was even with that type of algorithm", "StartMs": 1787720, "EndMs": 1810160, "WordsNum": 72, "Words": [{"Word": "And", "OffsetStartMs": 190, "OffsetEndMs": 555}, {"Word": "for", "OffsetStartMs": 555, "OffsetEndMs": 780}, {"Word": "each", "OffsetStartMs": 780, "OffsetEndMs": 960}, {"Word": "of", "OffsetStartMs": 960, "OffsetEndMs": 1170}, {"Word": "these", "OffsetStartMs": 1170, "OffsetEndMs": 1395}, {"Word": "tasks", "OffsetStartMs": 1395, "OffsetEndMs": 1730}, {"Word": "the", "OffsetStartMs": 2020, "OffsetEndMs": 2280}, {"Word": "really", "OffsetStartMs": 2280, "OffsetEndMs": 2540}, {"Word": "fascinating", "OffsetStartMs": 2800, "OffsetEndMs": 3165}, {"Word": "thing", "OffsetStartMs": 3165, "OffsetEndMs": 3405}, {"Word": "that", "OffsetStartMs": 3405, "OffsetEndMs": 3555}, {"Word": "they", "OffsetStartMs": 3555, "OffsetEndMs": 3735}, {"Word": "showed", "OffsetStartMs": 3735, "OffsetEndMs": 3960}, {"Word": "was", "OffsetStartMs": 3960, "OffsetEndMs": 4245}, {"Word": "for", "OffsetStartMs": 4245, "OffsetEndMs": 4470}, {"Word": "this", "OffsetStartMs": 4470, "OffsetEndMs": 4635}, {"Word": "very", "OffsetStartMs": 4635, "OffsetEndMs": 4920}, {"Word": "simple", "OffsetStartMs": 4920, "OffsetEndMs": 5300}, {"Word": "algorithm", "OffsetStartMs": 5440, "OffsetEndMs": 5910}, {"Word": "which", "OffsetStartMs": 5910, "OffsetEndMs": 6165}, {"Word": "really", "OffsetStartMs": 6165, "OffsetEndMs": 6390}, {"Word": "relies", "OffsetStartMs": 6390, "OffsetEndMs": 6810}, {"Word": "on", "OffsetStartMs": 6810, "OffsetEndMs": 7160}, {"Word": "random", "OffsetStartMs": 7270, "OffsetEndMs": 7670}, {"Word": "choice", "OffsetStartMs": 7870, "OffsetEndMs": 8235}, {"Word": "of", "OffsetStartMs": 8235, "OffsetEndMs": 8580}, {"Word": "selection", "OffsetStartMs": 8580, "OffsetEndMs": 8895}, {"Word": "of", "OffsetStartMs": 8895, "OffsetEndMs": 9090}, {"Word": "actions", "OffsetStartMs": 9090, "OffsetEndMs": 9350}, {"Word": "and", "OffsetStartMs": 9430, "OffsetEndMs": 9675}, {"Word": "then", "OffsetStartMs": 9675, "OffsetEndMs": 9920}, {"Word": "you", "OffsetStartMs": 10030, "OffsetEndMs": 10275}, {"Word": "know", "OffsetStartMs": 10275, "OffsetEndMs": 10520}, {"Word": "learning", "OffsetStartMs": 10570, "OffsetEndMs": 10970}, {"Word": "from", "OffsetStartMs": 11080, "OffsetEndMs": 11460}, {"Word": "you", "OffsetStartMs": 11460, "OffsetEndMs": 11670}, {"Word": "know", "OffsetStartMs": 11670, "OffsetEndMs": 11760}, {"Word": "actions", "OffsetStartMs": 11760, "OffsetEndMs": 12000}, {"Word": "that", "OffsetStartMs": 12000, "OffsetEndMs": 12285}, {"Word": "don't", "OffsetStartMs": 12285, "OffsetEndMs": 12540}, {"Word": "do", "OffsetStartMs": 12540, "OffsetEndMs": 12720}, {"Word": "very", "OffsetStartMs": 12720, "OffsetEndMs": 12945}, {"Word": "well", "OffsetStartMs": 12945, "OffsetEndMs": 13140}, {"Word": "that", "OffsetStartMs": 13140, "OffsetEndMs": 13305}, {"Word": "you", "OffsetStartMs": 13305, "OffsetEndMs": 13455}, {"Word": "discourage", "OffsetStartMs": 13455, "OffsetEndMs": 13905}, {"Word": "them", "OffsetStartMs": 13905, "OffsetEndMs": 14235}, {"Word": "and", "OffsetStartMs": 14235, "OffsetEndMs": 14630}, {"Word": "trying", "OffsetStartMs": 14710, "OffsetEndMs": 15015}, {"Word": "to", "OffsetStartMs": 15015, "OffsetEndMs": 15320}, {"Word": "do", "OffsetStartMs": 15370, "OffsetEndMs": 15645}, {"Word": "actions", "OffsetStartMs": 15645, "OffsetEndMs": 15920}, {"Word": "that", "OffsetStartMs": 15970, "OffsetEndMs": 16290}, {"Word": "did", "OffsetStartMs": 16290, "OffsetEndMs": 16610}, {"Word": "perform", "OffsetStartMs": 16690, "OffsetEndMs": 16995}, {"Word": "well", "OffsetStartMs": 16995, "OffsetEndMs": 17250}, {"Word": "more", "OffsetStartMs": 17250, "OffsetEndMs": 17520}, {"Word": "frequently", "OffsetStartMs": 17520, "OffsetEndMs": 17840}, {"Word": "very", "OffsetStartMs": 18370, "OffsetEndMs": 18705}, {"Word": "simple", "OffsetStartMs": 18705, "OffsetEndMs": 19040}, {"Word": "algorithm", "OffsetStartMs": 19090, "OffsetEndMs": 19440}, {"Word": "but", "OffsetStartMs": 19440, "OffsetEndMs": 19545}, {"Word": "what", "OffsetStartMs": 19545, "OffsetEndMs": 19635}, {"Word": "they", "OffsetStartMs": 19635, "OffsetEndMs": 19770}, {"Word": "found", "OffsetStartMs": 19770, "OffsetEndMs": 19965}, {"Word": "was", "OffsetStartMs": 19965, "OffsetEndMs": 20175}, {"Word": "even", "OffsetStartMs": 20175, "OffsetEndMs": 20445}, {"Word": "with", "OffsetStartMs": 20445, "OffsetEndMs": 20700}, {"Word": "that", "OffsetStartMs": 20700, "OffsetEndMs": 20940}, {"Word": "type", "OffsetStartMs": 20940, "OffsetEndMs": 21195}, {"Word": "of", "OffsetStartMs": 21195, "OffsetEndMs": 21495}, {"Word": "algorithm", "OffsetStartMs": 21495, "OffsetEndMs": 22010}], "SpeechSpeed": 18.2}, {"FinalSentence": "They were able to surpass human level performance on over half of the game. There were some games that you can see here were still below human level performance, but as we'll see, this was really like such an exciting advance because of the simplicity of the algorithm and how you clean the formulation of the training was you only needed a very little amount of prior knowledge to impose onto this neural network for it to be able to learn how to play these games. You never had to teach any of the rules of the game.", "SliceSentence": "They were able to surpass human level performance on over half of the game There were some games that you can see here were still below human level performance but as we'll see this was really like such an exciting advance because of the simplicity of the algorithm and how you clean the formulation of the training was you only needed a very little amount of prior knowledge to impose onto this neural network for it to be able to learn how to play these games You never had to teach any of the rules of the game", "StartMs": 1810160, "EndMs": 1838340, "WordsNum": 98, "Words": [{"Word": "They", "OffsetStartMs": 0, "OffsetEndMs": 195}, {"Word": "were", "OffsetStartMs": 195, "OffsetEndMs": 330}, {"Word": "able", "OffsetStartMs": 330, "OffsetEndMs": 525}, {"Word": "to", "OffsetStartMs": 525, "OffsetEndMs": 750}, {"Word": "surpass", "OffsetStartMs": 750, "OffsetEndMs": 1245}, {"Word": "human", "OffsetStartMs": 1245, "OffsetEndMs": 1590}, {"Word": "level", "OffsetStartMs": 1590, "OffsetEndMs": 1940}, {"Word": "performance", "OffsetStartMs": 2050, "OffsetEndMs": 2450}, {"Word": "on", "OffsetStartMs": 2830, "OffsetEndMs": 3105}, {"Word": "over", "OffsetStartMs": 3105, "OffsetEndMs": 3315}, {"Word": "half", "OffsetStartMs": 3315, "OffsetEndMs": 3540}, {"Word": "of", "OffsetStartMs": 3540, "OffsetEndMs": 3705}, {"Word": "the", "OffsetStartMs": 3705, "OffsetEndMs": 3840}, {"Word": "game", "OffsetStartMs": 3840, "OffsetEndMs": 4100}, {"Word": "There", "OffsetStartMs": 4180, "OffsetEndMs": 4440}, {"Word": "were", "OffsetStartMs": 4440, "OffsetEndMs": 4590}, {"Word": "some", "OffsetStartMs": 4590, "OffsetEndMs": 4800}, {"Word": "games", "OffsetStartMs": 4800, "OffsetEndMs": 5120}, {"Word": "that", "OffsetStartMs": 5290, "OffsetEndMs": 5595}, {"Word": "you", "OffsetStartMs": 5595, "OffsetEndMs": 5760}, {"Word": "can", "OffsetStartMs": 5760, "OffsetEndMs": 5910}, {"Word": "see", "OffsetStartMs": 5910, "OffsetEndMs": 6090}, {"Word": "here", "OffsetStartMs": 6090, "OffsetEndMs": 6330}, {"Word": "were", "OffsetStartMs": 6330, "OffsetEndMs": 6615}, {"Word": "still", "OffsetStartMs": 6615, "OffsetEndMs": 6855}, {"Word": "below", "OffsetStartMs": 6855, "OffsetEndMs": 7125}, {"Word": "human", "OffsetStartMs": 7125, "OffsetEndMs": 7410}, {"Word": "level", "OffsetStartMs": 7410, "OffsetEndMs": 7730}, {"Word": "performance", "OffsetStartMs": 7750, "OffsetEndMs": 8150}, {"Word": "but", "OffsetStartMs": 8440, "OffsetEndMs": 8685}, {"Word": "as", "OffsetStartMs": 8685, "OffsetEndMs": 8805}, {"Word": "we'll", "OffsetStartMs": 8805, "OffsetEndMs": 9030}, {"Word": "see", "OffsetStartMs": 9030, "OffsetEndMs": 9180}, {"Word": "this", "OffsetStartMs": 9180, "OffsetEndMs": 9345}, {"Word": "was", "OffsetStartMs": 9345, "OffsetEndMs": 9510}, {"Word": "really", "OffsetStartMs": 9510, "OffsetEndMs": 9800}, {"Word": "like", "OffsetStartMs": 10060, "OffsetEndMs": 10460}, {"Word": "such", "OffsetStartMs": 10900, "OffsetEndMs": 11190}, {"Word": "an", "OffsetStartMs": 11190, "OffsetEndMs": 11430}, {"Word": "exciting", "OffsetStartMs": 11430, "OffsetEndMs": 11780}, {"Word": "advance", "OffsetStartMs": 11830, "OffsetEndMs": 12230}, {"Word": "because", "OffsetStartMs": 12310, "OffsetEndMs": 12600}, {"Word": "of", "OffsetStartMs": 12600, "OffsetEndMs": 12765}, {"Word": "the", "OffsetStartMs": 12765, "OffsetEndMs": 12915}, {"Word": "simplicity", "OffsetStartMs": 12915, "OffsetEndMs": 13545}, {"Word": "of", "OffsetStartMs": 13545, "OffsetEndMs": 13680}, {"Word": "the", "OffsetStartMs": 13680, "OffsetEndMs": 13935}, {"Word": "algorithm", "OffsetStartMs": 13935, "OffsetEndMs": 14420}, {"Word": "and", "OffsetStartMs": 14440, "OffsetEndMs": 14730}, {"Word": "how", "OffsetStartMs": 14730, "OffsetEndMs": 15020}, {"Word": "you", "OffsetStartMs": 15250, "OffsetEndMs": 15645}, {"Word": "clean", "OffsetStartMs": 15645, "OffsetEndMs": 15990}, {"Word": "the", "OffsetStartMs": 15990, "OffsetEndMs": 16215}, {"Word": "formulation", "OffsetStartMs": 16215, "OffsetEndMs": 16740}, {"Word": "of", "OffsetStartMs": 16740, "OffsetEndMs": 17010}, {"Word": "the", "OffsetStartMs": 17010, "OffsetEndMs": 17190}, {"Word": "training", "OffsetStartMs": 17190, "OffsetEndMs": 17460}, {"Word": "was", "OffsetStartMs": 17460, "OffsetEndMs": 17840}, {"Word": "you", "OffsetStartMs": 18100, "OffsetEndMs": 18360}, {"Word": "only", "OffsetStartMs": 18360, "OffsetEndMs": 18585}, {"Word": "needed", "OffsetStartMs": 18585, "OffsetEndMs": 18885}, {"Word": "a", "OffsetStartMs": 18885, "OffsetEndMs": 19110}, {"Word": "very", "OffsetStartMs": 19110, "OffsetEndMs": 19350}, {"Word": "little", "OffsetStartMs": 19350, "OffsetEndMs": 19650}, {"Word": "amount", "OffsetStartMs": 19650, "OffsetEndMs": 19950}, {"Word": "of", "OffsetStartMs": 19950, "OffsetEndMs": 20295}, {"Word": "prior", "OffsetStartMs": 20295, "OffsetEndMs": 20655}, {"Word": "knowledge", "OffsetStartMs": 20655, "OffsetEndMs": 21020}, {"Word": "to", "OffsetStartMs": 21520, "OffsetEndMs": 21780}, {"Word": "impose", "OffsetStartMs": 21780, "OffsetEndMs": 22230}, {"Word": "onto", "OffsetStartMs": 22230, "OffsetEndMs": 22575}, {"Word": "this", "OffsetStartMs": 22575, "OffsetEndMs": 22845}, {"Word": "neural", "OffsetStartMs": 22845, "OffsetEndMs": 23130}, {"Word": "network", "OffsetStartMs": 23130, "OffsetEndMs": 23390}, {"Word": "for", "OffsetStartMs": 23500, "OffsetEndMs": 23730}, {"Word": "it", "OffsetStartMs": 23730, "OffsetEndMs": 23835}, {"Word": "to", "OffsetStartMs": 23835, "OffsetEndMs": 23970}, {"Word": "be", "OffsetStartMs": 23970, "OffsetEndMs": 24075}, {"Word": "able", "OffsetStartMs": 24075, "OffsetEndMs": 24285}, {"Word": "to", "OffsetStartMs": 24285, "OffsetEndMs": 24570}, {"Word": "learn", "OffsetStartMs": 24570, "OffsetEndMs": 24795}, {"Word": "how", "OffsetStartMs": 24795, "OffsetEndMs": 24945}, {"Word": "to", "OffsetStartMs": 24945, "OffsetEndMs": 25050}, {"Word": "play", "OffsetStartMs": 25050, "OffsetEndMs": 25200}, {"Word": "these", "OffsetStartMs": 25200, "OffsetEndMs": 25380}, {"Word": "games", "OffsetStartMs": 25380, "OffsetEndMs": 25575}, {"Word": "You", "OffsetStartMs": 25575, "OffsetEndMs": 25725}, {"Word": "never", "OffsetStartMs": 25725, "OffsetEndMs": 25860}, {"Word": "had", "OffsetStartMs": 25860, "OffsetEndMs": 26010}, {"Word": "to", "OffsetStartMs": 26010, "OffsetEndMs": 26190}, {"Word": "teach", "OffsetStartMs": 26190, "OffsetEndMs": 26430}, {"Word": "any", "OffsetStartMs": 26430, "OffsetEndMs": 26640}, {"Word": "of", "OffsetStartMs": 26640, "OffsetEndMs": 26790}, {"Word": "the", "OffsetStartMs": 26790, "OffsetEndMs": 26925}, {"Word": "rules", "OffsetStartMs": 26925, "OffsetEndMs": 27150}, {"Word": "of", "OffsetStartMs": 27150, "OffsetEndMs": 27375}, {"Word": "the", "OffsetStartMs": 27375, "OffsetEndMs": 27525}, {"Word": "game", "OffsetStartMs": 27525, "OffsetEndMs": 27800}], "SpeechSpeed": 18.2}, {"FinalSentence": "You only had to let it explore its environment, play the game many, many times against itself, and learn directly from that data.", "SliceSentence": "You only had to let it explore its environment play the game many many times against itself and learn directly from that data", "StartMs": 1838340, "EndMs": 1845800, "WordsNum": 23, "Words": [{"Word": "You", "OffsetStartMs": 0, "OffsetEndMs": 270}, {"Word": "only", "OffsetStartMs": 270, "OffsetEndMs": 525}, {"Word": "had", "OffsetStartMs": 525, "OffsetEndMs": 765}, {"Word": "to", "OffsetStartMs": 765, "OffsetEndMs": 900}, {"Word": "let", "OffsetStartMs": 900, "OffsetEndMs": 1035}, {"Word": "it", "OffsetStartMs": 1035, "OffsetEndMs": 1310}, {"Word": "explore", "OffsetStartMs": 1360, "OffsetEndMs": 1635}, {"Word": "its", "OffsetStartMs": 1635, "OffsetEndMs": 1845}, {"Word": "environment", "OffsetStartMs": 1845, "OffsetEndMs": 2175}, {"Word": "play", "OffsetStartMs": 2175, "OffsetEndMs": 2445}, {"Word": "the", "OffsetStartMs": 2445, "OffsetEndMs": 2565}, {"Word": "game", "OffsetStartMs": 2565, "OffsetEndMs": 2700}, {"Word": "many", "OffsetStartMs": 2700, "OffsetEndMs": 2910}, {"Word": "many", "OffsetStartMs": 2910, "OffsetEndMs": 3165}, {"Word": "times", "OffsetStartMs": 3165, "OffsetEndMs": 3480}, {"Word": "against", "OffsetStartMs": 3480, "OffsetEndMs": 3855}, {"Word": "itself", "OffsetStartMs": 3855, "OffsetEndMs": 4250}, {"Word": "and", "OffsetStartMs": 4390, "OffsetEndMs": 4710}, {"Word": "learn", "OffsetStartMs": 4710, "OffsetEndMs": 5030}, {"Word": "directly", "OffsetStartMs": 5410, "OffsetEndMs": 5775}, {"Word": "from", "OffsetStartMs": 5775, "OffsetEndMs": 6015}, {"Word": "that", "OffsetStartMs": 6015, "OffsetEndMs": 6180}, {"Word": "data", "OffsetStartMs": 6180, "OffsetEndMs": 6470}], "SpeechSpeed": 16.8}, {"FinalSentence": "Now there are several very important downsides of que learning and hopefully these are going to motivate the second part of today's lecture, which we'll talk about. But the first one that I want to really convey to everyone here is that you learning is naturally applicable to discrete action spaces, right? Because you can think of this output space that we're providing as kind of like one number per action that could be taken. Now if we have a continuous action space, we have to think about clever ways to work around that. In fact, there are now more recently there are some solutions to achieve que learning and continuous action spaces. But for the most part, queue learning is very well suited for discrete action spaces. And we'll talk about ways of overcoming that with other approaches a bit later.", "SliceSentence": "Now there are several very important downsides of que learning and hopefully these are going to motivate the second part of today's lecture which we'll talk about But the first one that I want to really convey to everyone here is that you learning is naturally applicable to discrete action spaces right Because you can think of this output space that we're providing as kind of like one number per action that could be taken Now if we have a continuous action space we have to think about clever ways to work around that In fact there are now more recently there are some solutions to achieve que learning and continuous action spaces But for the most part queue learning is very well suited for discrete action spaces And we'll talk about ways of overcoming that with other approaches a bit later", "StartMs": 1847140, "EndMs": 1892620, "WordsNum": 142, "Words": [{"Word": "Now", "OffsetStartMs": 130, "OffsetEndMs": 530}, {"Word": "there", "OffsetStartMs": 820, "OffsetEndMs": 1065}, {"Word": "are", "OffsetStartMs": 1065, "OffsetEndMs": 1200}, {"Word": "several", "OffsetStartMs": 1200, "OffsetEndMs": 1490}, {"Word": "very", "OffsetStartMs": 1720, "OffsetEndMs": 2085}, {"Word": "important", "OffsetStartMs": 2085, "OffsetEndMs": 2370}, {"Word": "downsides", "OffsetStartMs": 2370, "OffsetEndMs": 2955}, {"Word": "of", "OffsetStartMs": 2955, "OffsetEndMs": 3195}, {"Word": "que", "OffsetStartMs": 3195, "OffsetEndMs": 3390}, {"Word": "learning", "OffsetStartMs": 3390, "OffsetEndMs": 3555}, {"Word": "and", "OffsetStartMs": 3555, "OffsetEndMs": 3720}, {"Word": "hopefully", "OffsetStartMs": 3720, "OffsetEndMs": 3945}, {"Word": "these", "OffsetStartMs": 3945, "OffsetEndMs": 4185}, {"Word": "are", "OffsetStartMs": 4185, "OffsetEndMs": 4320}, {"Word": "going", "OffsetStartMs": 4320, "OffsetEndMs": 4470}, {"Word": "to", "OffsetStartMs": 4470, "OffsetEndMs": 4635}, {"Word": "motivate", "OffsetStartMs": 4635, "OffsetEndMs": 5180}, {"Word": "the", "OffsetStartMs": 5350, "OffsetEndMs": 5625}, {"Word": "second", "OffsetStartMs": 5625, "OffsetEndMs": 5865}, {"Word": "part", "OffsetStartMs": 5865, "OffsetEndMs": 6090}, {"Word": "of", "OffsetStartMs": 6090, "OffsetEndMs": 6240}, {"Word": "today's", "OffsetStartMs": 6240, "OffsetEndMs": 6675}, {"Word": "lecture", "OffsetStartMs": 6675, "OffsetEndMs": 6980}, {"Word": "which", "OffsetStartMs": 7120, "OffsetEndMs": 7425}, {"Word": "we'll", "OffsetStartMs": 7425, "OffsetEndMs": 7680}, {"Word": "talk", "OffsetStartMs": 7680, "OffsetEndMs": 7860}, {"Word": "about", "OffsetStartMs": 7860, "OffsetEndMs": 8180}, {"Word": "But", "OffsetStartMs": 8350, "OffsetEndMs": 8610}, {"Word": "the", "OffsetStartMs": 8610, "OffsetEndMs": 8760}, {"Word": "first", "OffsetStartMs": 8760, "OffsetEndMs": 8970}, {"Word": "one", "OffsetStartMs": 8970, "OffsetEndMs": 9290}, {"Word": "that", "OffsetStartMs": 9310, "OffsetEndMs": 9645}, {"Word": "I", "OffsetStartMs": 9645, "OffsetEndMs": 9855}, {"Word": "want", "OffsetStartMs": 9855, "OffsetEndMs": 10035}, {"Word": "to", "OffsetStartMs": 10035, "OffsetEndMs": 10200}, {"Word": "really", "OffsetStartMs": 10200, "OffsetEndMs": 10455}, {"Word": "convey", "OffsetStartMs": 10455, "OffsetEndMs": 11000}, {"Word": "to", "OffsetStartMs": 11020, "OffsetEndMs": 11370}, {"Word": "everyone", "OffsetStartMs": 11370, "OffsetEndMs": 11580}, {"Word": "here", "OffsetStartMs": 11580, "OffsetEndMs": 11715}, {"Word": "is", "OffsetStartMs": 11715, "OffsetEndMs": 11895}, {"Word": "that", "OffsetStartMs": 11895, "OffsetEndMs": 12200}, {"Word": "you", "OffsetStartMs": 12640, "OffsetEndMs": 12930}, {"Word": "learning", "OffsetStartMs": 12930, "OffsetEndMs": 13125}, {"Word": "is", "OffsetStartMs": 13125, "OffsetEndMs": 13430}, {"Word": "naturally", "OffsetStartMs": 13600, "OffsetEndMs": 14000}, {"Word": "applicable", "OffsetStartMs": 15400, "OffsetEndMs": 16070}, {"Word": "to", "OffsetStartMs": 16150, "OffsetEndMs": 16455}, {"Word": "discrete", "OffsetStartMs": 16455, "OffsetEndMs": 16860}, {"Word": "action", "OffsetStartMs": 16860, "OffsetEndMs": 17150}, {"Word": "spaces", "OffsetStartMs": 17200, "OffsetEndMs": 17600}, {"Word": "right", "OffsetStartMs": 17710, "OffsetEndMs": 18030}, {"Word": "Because", "OffsetStartMs": 18030, "OffsetEndMs": 18225}, {"Word": "you", "OffsetStartMs": 18225, "OffsetEndMs": 18345}, {"Word": "can", "OffsetStartMs": 18345, "OffsetEndMs": 18495}, {"Word": "think", "OffsetStartMs": 18495, "OffsetEndMs": 18675}, {"Word": "of", "OffsetStartMs": 18675, "OffsetEndMs": 18950}, {"Word": "this", "OffsetStartMs": 19330, "OffsetEndMs": 19730}, {"Word": "output", "OffsetStartMs": 20110, "OffsetEndMs": 20475}, {"Word": "space", "OffsetStartMs": 20475, "OffsetEndMs": 20775}, {"Word": "that", "OffsetStartMs": 20775, "OffsetEndMs": 20970}, {"Word": "we're", "OffsetStartMs": 20970, "OffsetEndMs": 21195}, {"Word": "providing", "OffsetStartMs": 21195, "OffsetEndMs": 21420}, {"Word": "as", "OffsetStartMs": 21420, "OffsetEndMs": 21645}, {"Word": "kind", "OffsetStartMs": 21645, "OffsetEndMs": 21810}, {"Word": "of", "OffsetStartMs": 21810, "OffsetEndMs": 21915}, {"Word": "like", "OffsetStartMs": 21915, "OffsetEndMs": 22080}, {"Word": "one", "OffsetStartMs": 22080, "OffsetEndMs": 22320}, {"Word": "number", "OffsetStartMs": 22320, "OffsetEndMs": 22640}, {"Word": "per", "OffsetStartMs": 23050, "OffsetEndMs": 23340}, {"Word": "action", "OffsetStartMs": 23340, "OffsetEndMs": 23630}, {"Word": "that", "OffsetStartMs": 23830, "OffsetEndMs": 24120}, {"Word": "could", "OffsetStartMs": 24120, "OffsetEndMs": 24285}, {"Word": "be", "OffsetStartMs": 24285, "OffsetEndMs": 24465}, {"Word": "taken", "OffsetStartMs": 24465, "OffsetEndMs": 24770}, {"Word": "Now", "OffsetStartMs": 24910, "OffsetEndMs": 25185}, {"Word": "if", "OffsetStartMs": 25185, "OffsetEndMs": 25320}, {"Word": "we", "OffsetStartMs": 25320, "OffsetEndMs": 25425}, {"Word": "have", "OffsetStartMs": 25425, "OffsetEndMs": 25515}, {"Word": "a", "OffsetStartMs": 25515, "OffsetEndMs": 25710}, {"Word": "continuous", "OffsetStartMs": 25710, "OffsetEndMs": 26010}, {"Word": "action", "OffsetStartMs": 26010, "OffsetEndMs": 26360}, {"Word": "space", "OffsetStartMs": 26470, "OffsetEndMs": 26870}, {"Word": "we", "OffsetStartMs": 27130, "OffsetEndMs": 27375}, {"Word": "have", "OffsetStartMs": 27375, "OffsetEndMs": 27495}, {"Word": "to", "OffsetStartMs": 27495, "OffsetEndMs": 27660}, {"Word": "think", "OffsetStartMs": 27660, "OffsetEndMs": 27870}, {"Word": "about", "OffsetStartMs": 27870, "OffsetEndMs": 28095}, {"Word": "clever", "OffsetStartMs": 28095, "OffsetEndMs": 28335}, {"Word": "ways", "OffsetStartMs": 28335, "OffsetEndMs": 28605}, {"Word": "to", "OffsetStartMs": 28605, "OffsetEndMs": 28800}, {"Word": "work", "OffsetStartMs": 28800, "OffsetEndMs": 29025}, {"Word": "around", "OffsetStartMs": 29025, "OffsetEndMs": 29310}, {"Word": "that", "OffsetStartMs": 29310, "OffsetEndMs": 29520}, {"Word": "In", "OffsetStartMs": 29520, "OffsetEndMs": 29685}, {"Word": "fact", "OffsetStartMs": 29685, "OffsetEndMs": 29850}, {"Word": "there", "OffsetStartMs": 29850, "OffsetEndMs": 30015}, {"Word": "are", "OffsetStartMs": 30015, "OffsetEndMs": 30240}, {"Word": "now", "OffsetStartMs": 30240, "OffsetEndMs": 30590}, {"Word": "more", "OffsetStartMs": 31060, "OffsetEndMs": 31350}, {"Word": "recently", "OffsetStartMs": 31350, "OffsetEndMs": 31640}, {"Word": "there", "OffsetStartMs": 31930, "OffsetEndMs": 32175}, {"Word": "are", "OffsetStartMs": 32175, "OffsetEndMs": 32295}, {"Word": "some", "OffsetStartMs": 32295, "OffsetEndMs": 32475}, {"Word": "solutions", "OffsetStartMs": 32475, "OffsetEndMs": 32780}, {"Word": "to", "OffsetStartMs": 33100, "OffsetEndMs": 33435}, {"Word": "achieve", "OffsetStartMs": 33435, "OffsetEndMs": 33720}, {"Word": "que", "OffsetStartMs": 33720, "OffsetEndMs": 33975}, {"Word": "learning", "OffsetStartMs": 33975, "OffsetEndMs": 34200}, {"Word": "and", "OffsetStartMs": 34200, "OffsetEndMs": 34515}, {"Word": "continuous", "OffsetStartMs": 34515, "OffsetEndMs": 34830}, {"Word": "action", "OffsetStartMs": 34830, "OffsetEndMs": 35180}, {"Word": "spaces", "OffsetStartMs": 35200, "OffsetEndMs": 35600}, {"Word": "But", "OffsetStartMs": 35710, "OffsetEndMs": 36110}, {"Word": "for", "OffsetStartMs": 36280, "OffsetEndMs": 36540}, {"Word": "the", "OffsetStartMs": 36540, "OffsetEndMs": 36660}, {"Word": "most", "OffsetStartMs": 36660, "OffsetEndMs": 36870}, {"Word": "part", "OffsetStartMs": 36870, "OffsetEndMs": 37220}, {"Word": "queue", "OffsetStartMs": 37360, "OffsetEndMs": 37680}, {"Word": "learning", "OffsetStartMs": 37680, "OffsetEndMs": 37940}, {"Word": "is", "OffsetStartMs": 38050, "OffsetEndMs": 38450}, {"Word": "very", "OffsetStartMs": 38560, "OffsetEndMs": 38895}, {"Word": "well", "OffsetStartMs": 38895, "OffsetEndMs": 39165}, {"Word": "suited", "OffsetStartMs": 39165, "OffsetEndMs": 39510}, {"Word": "for", "OffsetStartMs": 39510, "OffsetEndMs": 39690}, {"Word": "discrete", "OffsetStartMs": 39690, "OffsetEndMs": 40065}, {"Word": "action", "OffsetStartMs": 40065, "OffsetEndMs": 40340}, {"Word": "spaces", "OffsetStartMs": 40420, "OffsetEndMs": 40820}, {"Word": "And", "OffsetStartMs": 41260, "OffsetEndMs": 41520}, {"Word": "we'll", "OffsetStartMs": 41520, "OffsetEndMs": 41730}, {"Word": "talk", "OffsetStartMs": 41730, "OffsetEndMs": 41910}, {"Word": "about", "OffsetStartMs": 41910, "OffsetEndMs": 42105}, {"Word": "ways", "OffsetStartMs": 42105, "OffsetEndMs": 42270}, {"Word": "of", "OffsetStartMs": 42270, "OffsetEndMs": 42420}, {"Word": "overcoming", "OffsetStartMs": 42420, "OffsetEndMs": 42900}, {"Word": "that", "OffsetStartMs": 42900, "OffsetEndMs": 43140}, {"Word": "with", "OffsetStartMs": 43140, "OffsetEndMs": 43290}, {"Word": "other", "OffsetStartMs": 43290, "OffsetEndMs": 43530}, {"Word": "approaches", "OffsetStartMs": 43530, "OffsetEndMs": 43910}, {"Word": "a", "OffsetStartMs": 44110, "OffsetEndMs": 44385}, {"Word": "bit", "OffsetStartMs": 44385, "OffsetEndMs": 44580}, {"Word": "later", "OffsetStartMs": 44580, "OffsetEndMs": 44900}], "SpeechSpeed": 17.5}, {"FinalSentence": "And the second component here is that the policy that we're learning, right, the q function is giving rise to that policy, which is the thing that we're actually using to determine what action to take. Given any state that policy is determined by, you know, deterministically optimizing that q function, we simply look at the results from the q function and apply our, or we, we look at the results of the q function and we pick the action that has the best or the highest q value.", "SliceSentence": "And the second component here is that the policy that we're learning right the q function is giving rise to that policy which is the thing that we're actually using to determine what action to take Given any state that policy is determined by you know deterministically optimizing that q function we simply look at the results from the q function and apply our or we we look at the results of the q function and we pick the action that has the best or the highest q value", "StartMs": 1892620, "EndMs": 1925240, "WordsNum": 89, "Words": [{"Word": "And", "OffsetStartMs": 40, "OffsetEndMs": 440}, {"Word": "the", "OffsetStartMs": 670, "OffsetEndMs": 975}, {"Word": "second", "OffsetStartMs": 975, "OffsetEndMs": 1280}, {"Word": "component", "OffsetStartMs": 1450, "OffsetEndMs": 1845}, {"Word": "here", "OffsetStartMs": 1845, "OffsetEndMs": 2240}, {"Word": "is", "OffsetStartMs": 2470, "OffsetEndMs": 2775}, {"Word": "that", "OffsetStartMs": 2775, "OffsetEndMs": 3080}, {"Word": "the", "OffsetStartMs": 4210, "OffsetEndMs": 4515}, {"Word": "policy", "OffsetStartMs": 4515, "OffsetEndMs": 4820}, {"Word": "that", "OffsetStartMs": 5200, "OffsetEndMs": 5490}, {"Word": "we're", "OffsetStartMs": 5490, "OffsetEndMs": 5715}, {"Word": "learning", "OffsetStartMs": 5715, "OffsetEndMs": 5960}, {"Word": "right", "OffsetStartMs": 6100, "OffsetEndMs": 6435}, {"Word": "the", "OffsetStartMs": 6435, "OffsetEndMs": 6660}, {"Word": "q", "OffsetStartMs": 6660, "OffsetEndMs": 6840}, {"Word": "function", "OffsetStartMs": 6840, "OffsetEndMs": 7130}, {"Word": "is", "OffsetStartMs": 7600, "OffsetEndMs": 7995}, {"Word": "giving", "OffsetStartMs": 7995, "OffsetEndMs": 8355}, {"Word": "rise", "OffsetStartMs": 8355, "OffsetEndMs": 8700}, {"Word": "to", "OffsetStartMs": 8700, "OffsetEndMs": 8925}, {"Word": "that", "OffsetStartMs": 8925, "OffsetEndMs": 9090}, {"Word": "policy", "OffsetStartMs": 9090, "OffsetEndMs": 9410}, {"Word": "which", "OffsetStartMs": 9460, "OffsetEndMs": 9720}, {"Word": "is", "OffsetStartMs": 9720, "OffsetEndMs": 9855}, {"Word": "the", "OffsetStartMs": 9855, "OffsetEndMs": 9990}, {"Word": "thing", "OffsetStartMs": 9990, "OffsetEndMs": 10140}, {"Word": "that", "OffsetStartMs": 10140, "OffsetEndMs": 10290}, {"Word": "we're", "OffsetStartMs": 10290, "OffsetEndMs": 10545}, {"Word": "actually", "OffsetStartMs": 10545, "OffsetEndMs": 10710}, {"Word": "using", "OffsetStartMs": 10710, "OffsetEndMs": 10970}, {"Word": "to", "OffsetStartMs": 10990, "OffsetEndMs": 11325}, {"Word": "determine", "OffsetStartMs": 11325, "OffsetEndMs": 11595}, {"Word": "what", "OffsetStartMs": 11595, "OffsetEndMs": 11805}, {"Word": "action", "OffsetStartMs": 11805, "OffsetEndMs": 12080}, {"Word": "to", "OffsetStartMs": 12130, "OffsetEndMs": 12405}, {"Word": "take", "OffsetStartMs": 12405, "OffsetEndMs": 12680}, {"Word": "Given", "OffsetStartMs": 12790, "OffsetEndMs": 13170}, {"Word": "any", "OffsetStartMs": 13170, "OffsetEndMs": 13545}, {"Word": "state", "OffsetStartMs": 13545, "OffsetEndMs": 13940}, {"Word": "that", "OffsetStartMs": 14260, "OffsetEndMs": 14610}, {"Word": "policy", "OffsetStartMs": 14610, "OffsetEndMs": 14960}, {"Word": "is", "OffsetStartMs": 15520, "OffsetEndMs": 15920}, {"Word": "determined", "OffsetStartMs": 16210, "OffsetEndMs": 16610}, {"Word": "by", "OffsetStartMs": 16780, "OffsetEndMs": 17180}, {"Word": "you", "OffsetStartMs": 17860, "OffsetEndMs": 18105}, {"Word": "know", "OffsetStartMs": 18105, "OffsetEndMs": 18350}, {"Word": "deterministically", "OffsetStartMs": 18550, "OffsetEndMs": 19640}, {"Word": "optimizing", "OffsetStartMs": 20440, "OffsetEndMs": 20960}, {"Word": "that", "OffsetStartMs": 21100, "OffsetEndMs": 21420}, {"Word": "q", "OffsetStartMs": 21420, "OffsetEndMs": 21630}, {"Word": "function", "OffsetStartMs": 21630, "OffsetEndMs": 21920}, {"Word": "we", "OffsetStartMs": 21970, "OffsetEndMs": 22260}, {"Word": "simply", "OffsetStartMs": 22260, "OffsetEndMs": 22545}, {"Word": "look", "OffsetStartMs": 22545, "OffsetEndMs": 22830}, {"Word": "at", "OffsetStartMs": 22830, "OffsetEndMs": 23010}, {"Word": "the", "OffsetStartMs": 23010, "OffsetEndMs": 23265}, {"Word": "results", "OffsetStartMs": 23265, "OffsetEndMs": 23580}, {"Word": "from", "OffsetStartMs": 23580, "OffsetEndMs": 23790}, {"Word": "the", "OffsetStartMs": 23790, "OffsetEndMs": 23925}, {"Word": "q", "OffsetStartMs": 23925, "OffsetEndMs": 24090}, {"Word": "function", "OffsetStartMs": 24090, "OffsetEndMs": 24380}, {"Word": "and", "OffsetStartMs": 24970, "OffsetEndMs": 25365}, {"Word": "apply", "OffsetStartMs": 25365, "OffsetEndMs": 25760}, {"Word": "our", "OffsetStartMs": 25810, "OffsetEndMs": 26210}, {"Word": "or", "OffsetStartMs": 26410, "OffsetEndMs": 26700}, {"Word": "we", "OffsetStartMs": 26700, "OffsetEndMs": 26910}, {"Word": "we", "OffsetStartMs": 26910, "OffsetEndMs": 27090}, {"Word": "look", "OffsetStartMs": 27090, "OffsetEndMs": 27210}, {"Word": "at", "OffsetStartMs": 27210, "OffsetEndMs": 27330}, {"Word": "the", "OffsetStartMs": 27330, "OffsetEndMs": 27495}, {"Word": "results", "OffsetStartMs": 27495, "OffsetEndMs": 27705}, {"Word": "of", "OffsetStartMs": 27705, "OffsetEndMs": 27855}, {"Word": "the", "OffsetStartMs": 27855, "OffsetEndMs": 27960}, {"Word": "q", "OffsetStartMs": 27960, "OffsetEndMs": 28095}, {"Word": "function", "OffsetStartMs": 28095, "OffsetEndMs": 28365}, {"Word": "and", "OffsetStartMs": 28365, "OffsetEndMs": 28635}, {"Word": "we", "OffsetStartMs": 28635, "OffsetEndMs": 28845}, {"Word": "pick", "OffsetStartMs": 28845, "OffsetEndMs": 29130}, {"Word": "the", "OffsetStartMs": 29130, "OffsetEndMs": 29340}, {"Word": "action", "OffsetStartMs": 29340, "OffsetEndMs": 29600}, {"Word": "that", "OffsetStartMs": 29830, "OffsetEndMs": 30105}, {"Word": "has", "OffsetStartMs": 30105, "OffsetEndMs": 30285}, {"Word": "the", "OffsetStartMs": 30285, "OffsetEndMs": 30495}, {"Word": "best", "OffsetStartMs": 30495, "OffsetEndMs": 30765}, {"Word": "or", "OffsetStartMs": 30765, "OffsetEndMs": 31020}, {"Word": "the", "OffsetStartMs": 31020, "OffsetEndMs": 31185}, {"Word": "highest", "OffsetStartMs": 31185, "OffsetEndMs": 31460}, {"Word": "q", "OffsetStartMs": 31540, "OffsetEndMs": 31830}, {"Word": "value", "OffsetStartMs": 31830, "OffsetEndMs": 32120}], "SpeechSpeed": 14.4}, {"FinalSentence": "That is very dangerous in many cases because of the fact that it's always going to pick the best value for a given state. There's no stochasticity in that pipeline, so you can very frequently get caught in situations where you keep repeating the same actions and you don't learn to explore potentially different options that you may be thinking of. So to address these very important challenges, that's hopefully going to motivate now the next part of today's lecture, which is going to be focused on policy learning, which is a different class of reinforcement learning algorithms that are different than queue learning algorithms.", "SliceSentence": "That is very dangerous in many cases because of the fact that it's always going to pick the best value for a given state There's no stochasticity in that pipeline so you can very frequently get caught in situations where you keep repeating the same actions and you don't learn to explore potentially different options that you may be thinking of So to address these very important challenges that's hopefully going to motivate now the next part of today's lecture which is going to be focused on policy learning which is a different class of reinforcement learning algorithms that are different than queue learning algorithms", "StartMs": 1925240, "EndMs": 1961600, "WordsNum": 105, "Words": [{"Word": "That", "OffsetStartMs": 100, "OffsetEndMs": 405}, {"Word": "is", "OffsetStartMs": 405, "OffsetEndMs": 710}, {"Word": "very", "OffsetStartMs": 880, "OffsetEndMs": 1280}, {"Word": "dangerous", "OffsetStartMs": 1450, "OffsetEndMs": 1850}, {"Word": "in", "OffsetStartMs": 2080, "OffsetEndMs": 2370}, {"Word": "many", "OffsetStartMs": 2370, "OffsetEndMs": 2595}, {"Word": "cases", "OffsetStartMs": 2595, "OffsetEndMs": 2930}, {"Word": "because", "OffsetStartMs": 3190, "OffsetEndMs": 3480}, {"Word": "of", "OffsetStartMs": 3480, "OffsetEndMs": 3645}, {"Word": "the", "OffsetStartMs": 3645, "OffsetEndMs": 3780}, {"Word": "fact", "OffsetStartMs": 3780, "OffsetEndMs": 3960}, {"Word": "that", "OffsetStartMs": 3960, "OffsetEndMs": 4140}, {"Word": "it's", "OffsetStartMs": 4140, "OffsetEndMs": 4410}, {"Word": "always", "OffsetStartMs": 4410, "OffsetEndMs": 4650}, {"Word": "going", "OffsetStartMs": 4650, "OffsetEndMs": 4815}, {"Word": "to", "OffsetStartMs": 4815, "OffsetEndMs": 4965}, {"Word": "pick", "OffsetStartMs": 4965, "OffsetEndMs": 5190}, {"Word": "the", "OffsetStartMs": 5190, "OffsetEndMs": 5445}, {"Word": "best", "OffsetStartMs": 5445, "OffsetEndMs": 5730}, {"Word": "value", "OffsetStartMs": 5730, "OffsetEndMs": 6110}, {"Word": "for", "OffsetStartMs": 6580, "OffsetEndMs": 6825}, {"Word": "a", "OffsetStartMs": 6825, "OffsetEndMs": 6945}, {"Word": "given", "OffsetStartMs": 6945, "OffsetEndMs": 7185}, {"Word": "state", "OffsetStartMs": 7185, "OffsetEndMs": 7425}, {"Word": "There's", "OffsetStartMs": 7425, "OffsetEndMs": 7665}, {"Word": "no", "OffsetStartMs": 7665, "OffsetEndMs": 7830}, {"Word": "stochasticity", "OffsetStartMs": 7830, "OffsetEndMs": 8840}, {"Word": "in", "OffsetStartMs": 8890, "OffsetEndMs": 9165}, {"Word": "that", "OffsetStartMs": 9165, "OffsetEndMs": 9345}, {"Word": "pipeline", "OffsetStartMs": 9345, "OffsetEndMs": 9650}, {"Word": "so", "OffsetStartMs": 9760, "OffsetEndMs": 10005}, {"Word": "you", "OffsetStartMs": 10005, "OffsetEndMs": 10125}, {"Word": "can", "OffsetStartMs": 10125, "OffsetEndMs": 10290}, {"Word": "very", "OffsetStartMs": 10290, "OffsetEndMs": 10530}, {"Word": "frequently", "OffsetStartMs": 10530, "OffsetEndMs": 10880}, {"Word": "get", "OffsetStartMs": 10930, "OffsetEndMs": 11265}, {"Word": "caught", "OffsetStartMs": 11265, "OffsetEndMs": 11600}, {"Word": "in", "OffsetStartMs": 11890, "OffsetEndMs": 12290}, {"Word": "situations", "OffsetStartMs": 12490, "OffsetEndMs": 12890}, {"Word": "where", "OffsetStartMs": 13270, "OffsetEndMs": 13530}, {"Word": "you", "OffsetStartMs": 13530, "OffsetEndMs": 13695}, {"Word": "keep", "OffsetStartMs": 13695, "OffsetEndMs": 13950}, {"Word": "repeating", "OffsetStartMs": 13950, "OffsetEndMs": 14280}, {"Word": "the", "OffsetStartMs": 14280, "OffsetEndMs": 14415}, {"Word": "same", "OffsetStartMs": 14415, "OffsetEndMs": 14580}, {"Word": "actions", "OffsetStartMs": 14580, "OffsetEndMs": 14870}, {"Word": "and", "OffsetStartMs": 14890, "OffsetEndMs": 15135}, {"Word": "you", "OffsetStartMs": 15135, "OffsetEndMs": 15270}, {"Word": "don't", "OffsetStartMs": 15270, "OffsetEndMs": 15555}, {"Word": "learn", "OffsetStartMs": 15555, "OffsetEndMs": 15780}, {"Word": "to", "OffsetStartMs": 15780, "OffsetEndMs": 16110}, {"Word": "explore", "OffsetStartMs": 16110, "OffsetEndMs": 16485}, {"Word": "potentially", "OffsetStartMs": 16485, "OffsetEndMs": 16880}, {"Word": "different", "OffsetStartMs": 17230, "OffsetEndMs": 17630}, {"Word": "options", "OffsetStartMs": 17770, "OffsetEndMs": 18170}, {"Word": "that", "OffsetStartMs": 18340, "OffsetEndMs": 18630}, {"Word": "you", "OffsetStartMs": 18630, "OffsetEndMs": 18795}, {"Word": "may", "OffsetStartMs": 18795, "OffsetEndMs": 19050}, {"Word": "be", "OffsetStartMs": 19050, "OffsetEndMs": 19305}, {"Word": "thinking", "OffsetStartMs": 19305, "OffsetEndMs": 19515}, {"Word": "of", "OffsetStartMs": 19515, "OffsetEndMs": 19850}, {"Word": "So", "OffsetStartMs": 20140, "OffsetEndMs": 20540}, {"Word": "to", "OffsetStartMs": 20710, "OffsetEndMs": 21015}, {"Word": "address", "OffsetStartMs": 21015, "OffsetEndMs": 21255}, {"Word": "these", "OffsetStartMs": 21255, "OffsetEndMs": 21590}, {"Word": "very", "OffsetStartMs": 21820, "OffsetEndMs": 22200}, {"Word": "important", "OffsetStartMs": 22200, "OffsetEndMs": 22575}, {"Word": "challenges", "OffsetStartMs": 22575, "OffsetEndMs": 22970}, {"Word": "that's", "OffsetStartMs": 23650, "OffsetEndMs": 24030}, {"Word": "hopefully", "OffsetStartMs": 24030, "OffsetEndMs": 24225}, {"Word": "going", "OffsetStartMs": 24225, "OffsetEndMs": 24450}, {"Word": "to", "OffsetStartMs": 24450, "OffsetEndMs": 24615}, {"Word": "motivate", "OffsetStartMs": 24615, "OffsetEndMs": 25065}, {"Word": "now", "OffsetStartMs": 25065, "OffsetEndMs": 25290}, {"Word": "the", "OffsetStartMs": 25290, "OffsetEndMs": 25500}, {"Word": "next", "OffsetStartMs": 25500, "OffsetEndMs": 25755}, {"Word": "part", "OffsetStartMs": 25755, "OffsetEndMs": 26040}, {"Word": "of", "OffsetStartMs": 26040, "OffsetEndMs": 26295}, {"Word": "today's", "OffsetStartMs": 26295, "OffsetEndMs": 26715}, {"Word": "lecture", "OffsetStartMs": 26715, "OffsetEndMs": 26990}, {"Word": "which", "OffsetStartMs": 27370, "OffsetEndMs": 27630}, {"Word": "is", "OffsetStartMs": 27630, "OffsetEndMs": 27780}, {"Word": "going", "OffsetStartMs": 27780, "OffsetEndMs": 27930}, {"Word": "to", "OffsetStartMs": 27930, "OffsetEndMs": 28020}, {"Word": "be", "OffsetStartMs": 28020, "OffsetEndMs": 28125}, {"Word": "focused", "OffsetStartMs": 28125, "OffsetEndMs": 28400}, {"Word": "on", "OffsetStartMs": 28450, "OffsetEndMs": 28830}, {"Word": "policy", "OffsetStartMs": 28830, "OffsetEndMs": 29210}, {"Word": "learning", "OffsetStartMs": 29230, "OffsetEndMs": 29630}, {"Word": "which", "OffsetStartMs": 29800, "OffsetEndMs": 30105}, {"Word": "is", "OffsetStartMs": 30105, "OffsetEndMs": 30405}, {"Word": "a", "OffsetStartMs": 30405, "OffsetEndMs": 30750}, {"Word": "different", "OffsetStartMs": 30750, "OffsetEndMs": 31095}, {"Word": "class", "OffsetStartMs": 31095, "OffsetEndMs": 31490}, {"Word": "of", "OffsetStartMs": 31570, "OffsetEndMs": 31875}, {"Word": "reinforcement", "OffsetStartMs": 31875, "OffsetEndMs": 32475}, {"Word": "learning", "OffsetStartMs": 32475, "OffsetEndMs": 32750}, {"Word": "algorithms", "OffsetStartMs": 32770, "OffsetEndMs": 33210}, {"Word": "that", "OffsetStartMs": 33210, "OffsetEndMs": 33390}, {"Word": "are", "OffsetStartMs": 33390, "OffsetEndMs": 33555}, {"Word": "different", "OffsetStartMs": 33555, "OffsetEndMs": 33860}, {"Word": "than", "OffsetStartMs": 33880, "OffsetEndMs": 34280}, {"Word": "queue", "OffsetStartMs": 34510, "OffsetEndMs": 34815}, {"Word": "learning", "OffsetStartMs": 34815, "OffsetEndMs": 35090}, {"Word": "algorithms", "OffsetStartMs": 35410, "OffsetEndMs": 35900}], "SpeechSpeed": 17.2}, {"FinalSentence": "And like I said, those are called policy gradient algorithms and policy gradient algorithms. The main difference is that instead of trying to infer the policy from the q function, we're just going to build a neural network that will directly learn that policy function from the data. So it kind of skips one step and we'll see how we can train those networks.", "SliceSentence": "And like I said those are called policy gradient algorithms and policy gradient algorithms The main difference is that instead of trying to infer the policy from the q function we're just going to build a neural network that will directly learn that policy function from the data So it kind of skips one step and we'll see how we can train those networks", "StartMs": 1961600, "EndMs": 1982100, "WordsNum": 64, "Words": [{"Word": "And", "OffsetStartMs": 0, "OffsetEndMs": 320}, {"Word": "like", "OffsetStartMs": 490, "OffsetEndMs": 765}, {"Word": "I", "OffsetStartMs": 765, "OffsetEndMs": 915}, {"Word": "said", "OffsetStartMs": 915, "OffsetEndMs": 1065}, {"Word": "those", "OffsetStartMs": 1065, "OffsetEndMs": 1215}, {"Word": "are", "OffsetStartMs": 1215, "OffsetEndMs": 1365}, {"Word": "called", "OffsetStartMs": 1365, "OffsetEndMs": 1560}, {"Word": "policy", "OffsetStartMs": 1560, "OffsetEndMs": 1875}, {"Word": "gradient", "OffsetStartMs": 1875, "OffsetEndMs": 2370}, {"Word": "algorithms", "OffsetStartMs": 2370, "OffsetEndMs": 2730}, {"Word": "and", "OffsetStartMs": 2730, "OffsetEndMs": 2925}, {"Word": "policy", "OffsetStartMs": 2925, "OffsetEndMs": 3210}, {"Word": "gradient", "OffsetStartMs": 3210, "OffsetEndMs": 3720}, {"Word": "algorithms", "OffsetStartMs": 3720, "OffsetEndMs": 4095}, {"Word": "The", "OffsetStartMs": 4095, "OffsetEndMs": 4275}, {"Word": "main", "OffsetStartMs": 4275, "OffsetEndMs": 4455}, {"Word": "difference", "OffsetStartMs": 4455, "OffsetEndMs": 4740}, {"Word": "is", "OffsetStartMs": 4740, "OffsetEndMs": 4995}, {"Word": "that", "OffsetStartMs": 4995, "OffsetEndMs": 5270}, {"Word": "instead", "OffsetStartMs": 5770, "OffsetEndMs": 6045}, {"Word": "of", "OffsetStartMs": 6045, "OffsetEndMs": 6320}, {"Word": "trying", "OffsetStartMs": 6700, "OffsetEndMs": 7065}, {"Word": "to", "OffsetStartMs": 7065, "OffsetEndMs": 7430}, {"Word": "infer", "OffsetStartMs": 7480, "OffsetEndMs": 7880}, {"Word": "the", "OffsetStartMs": 8020, "OffsetEndMs": 8325}, {"Word": "policy", "OffsetStartMs": 8325, "OffsetEndMs": 8630}, {"Word": "from", "OffsetStartMs": 8800, "OffsetEndMs": 9075}, {"Word": "the", "OffsetStartMs": 9075, "OffsetEndMs": 9225}, {"Word": "q", "OffsetStartMs": 9225, "OffsetEndMs": 9375}, {"Word": "function", "OffsetStartMs": 9375, "OffsetEndMs": 9650}, {"Word": "we're", "OffsetStartMs": 9880, "OffsetEndMs": 10200}, {"Word": "just", "OffsetStartMs": 10200, "OffsetEndMs": 10305}, {"Word": "going", "OffsetStartMs": 10305, "OffsetEndMs": 10470}, {"Word": "to", "OffsetStartMs": 10470, "OffsetEndMs": 10605}, {"Word": "build", "OffsetStartMs": 10605, "OffsetEndMs": 10755}, {"Word": "a", "OffsetStartMs": 10755, "OffsetEndMs": 10920}, {"Word": "neural", "OffsetStartMs": 10920, "OffsetEndMs": 11130}, {"Word": "network", "OffsetStartMs": 11130, "OffsetEndMs": 11370}, {"Word": "that", "OffsetStartMs": 11370, "OffsetEndMs": 11610}, {"Word": "will", "OffsetStartMs": 11610, "OffsetEndMs": 11835}, {"Word": "directly", "OffsetStartMs": 11835, "OffsetEndMs": 12195}, {"Word": "learn", "OffsetStartMs": 12195, "OffsetEndMs": 12590}, {"Word": "that", "OffsetStartMs": 12880, "OffsetEndMs": 13230}, {"Word": "policy", "OffsetStartMs": 13230, "OffsetEndMs": 13575}, {"Word": "function", "OffsetStartMs": 13575, "OffsetEndMs": 13970}, {"Word": "from", "OffsetStartMs": 14440, "OffsetEndMs": 14730}, {"Word": "the", "OffsetStartMs": 14730, "OffsetEndMs": 14880}, {"Word": "data", "OffsetStartMs": 14880, "OffsetEndMs": 15140}, {"Word": "So", "OffsetStartMs": 15370, "OffsetEndMs": 15615}, {"Word": "it", "OffsetStartMs": 15615, "OffsetEndMs": 15735}, {"Word": "kind", "OffsetStartMs": 15735, "OffsetEndMs": 15870}, {"Word": "of", "OffsetStartMs": 15870, "OffsetEndMs": 16095}, {"Word": "skips", "OffsetStartMs": 16095, "OffsetEndMs": 16425}, {"Word": "one", "OffsetStartMs": 16425, "OffsetEndMs": 16740}, {"Word": "step", "OffsetStartMs": 16740, "OffsetEndMs": 17120}, {"Word": "and", "OffsetStartMs": 17320, "OffsetEndMs": 17580}, {"Word": "we'll", "OffsetStartMs": 17580, "OffsetEndMs": 17775}, {"Word": "see", "OffsetStartMs": 17775, "OffsetEndMs": 17925}, {"Word": "how", "OffsetStartMs": 17925, "OffsetEndMs": 18075}, {"Word": "we", "OffsetStartMs": 18075, "OffsetEndMs": 18210}, {"Word": "can", "OffsetStartMs": 18210, "OffsetEndMs": 18375}, {"Word": "train", "OffsetStartMs": 18375, "OffsetEndMs": 18585}, {"Word": "those", "OffsetStartMs": 18585, "OffsetEndMs": 18825}, {"Word": "networks", "OffsetStartMs": 18825, "OffsetEndMs": 19160}], "SpeechSpeed": 17.3}, {"FinalSentence": "So before we get there, let me just revisit one more time. The q function illustration that we are looking at, right q function, we are trying to build a neural network outputs these q values, one value per action, and we determine the policy by looking over this state of q values, picking the value that has the highest.", "SliceSentence": "So before we get there let me just revisit one more time The q function illustration that we are looking at right q function we are trying to build a neural network outputs these q values one value per action and we determine the policy by looking over this state of q values picking the value that has the highest", "StartMs": 1982860, "EndMs": 2002500, "WordsNum": 60, "Words": [{"Word": "So", "OffsetStartMs": 310, "OffsetEndMs": 675}, {"Word": "before", "OffsetStartMs": 675, "OffsetEndMs": 960}, {"Word": "we", "OffsetStartMs": 960, "OffsetEndMs": 1140}, {"Word": "get", "OffsetStartMs": 1140, "OffsetEndMs": 1290}, {"Word": "there", "OffsetStartMs": 1290, "OffsetEndMs": 1470}, {"Word": "let", "OffsetStartMs": 1470, "OffsetEndMs": 1605}, {"Word": "me", "OffsetStartMs": 1605, "OffsetEndMs": 1740}, {"Word": "just", "OffsetStartMs": 1740, "OffsetEndMs": 1920}, {"Word": "revisit", "OffsetStartMs": 1920, "OffsetEndMs": 2445}, {"Word": "one", "OffsetStartMs": 2445, "OffsetEndMs": 2655}, {"Word": "more", "OffsetStartMs": 2655, "OffsetEndMs": 2865}, {"Word": "time", "OffsetStartMs": 2865, "OffsetEndMs": 3150}, {"Word": "The", "OffsetStartMs": 3150, "OffsetEndMs": 3435}, {"Word": "q", "OffsetStartMs": 3435, "OffsetEndMs": 3660}, {"Word": "function", "OffsetStartMs": 3660, "OffsetEndMs": 3980}, {"Word": "illustration", "OffsetStartMs": 4450, "OffsetEndMs": 5130}, {"Word": "that", "OffsetStartMs": 5130, "OffsetEndMs": 5370}, {"Word": "we", "OffsetStartMs": 5370, "OffsetEndMs": 5460}, {"Word": "are", "OffsetStartMs": 5460, "OffsetEndMs": 5550}, {"Word": "looking", "OffsetStartMs": 5550, "OffsetEndMs": 5715}, {"Word": "at", "OffsetStartMs": 5715, "OffsetEndMs": 5925}, {"Word": "right", "OffsetStartMs": 5925, "OffsetEndMs": 6195}, {"Word": "q", "OffsetStartMs": 6195, "OffsetEndMs": 6450}, {"Word": "function", "OffsetStartMs": 6450, "OffsetEndMs": 6740}, {"Word": "we", "OffsetStartMs": 7270, "OffsetEndMs": 7515}, {"Word": "are", "OffsetStartMs": 7515, "OffsetEndMs": 7760}, {"Word": "trying", "OffsetStartMs": 7960, "OffsetEndMs": 8250}, {"Word": "to", "OffsetStartMs": 8250, "OffsetEndMs": 8400}, {"Word": "build", "OffsetStartMs": 8400, "OffsetEndMs": 8535}, {"Word": "a", "OffsetStartMs": 8535, "OffsetEndMs": 8670}, {"Word": "neural", "OffsetStartMs": 8670, "OffsetEndMs": 8880}, {"Word": "network", "OffsetStartMs": 8880, "OffsetEndMs": 9140}, {"Word": "outputs", "OffsetStartMs": 9400, "OffsetEndMs": 9765}, {"Word": "these", "OffsetStartMs": 9765, "OffsetEndMs": 9975}, {"Word": "q", "OffsetStartMs": 9975, "OffsetEndMs": 10185}, {"Word": "values", "OffsetStartMs": 10185, "OffsetEndMs": 10460}, {"Word": "one", "OffsetStartMs": 10750, "OffsetEndMs": 11070}, {"Word": "value", "OffsetStartMs": 11070, "OffsetEndMs": 11355}, {"Word": "per", "OffsetStartMs": 11355, "OffsetEndMs": 11595}, {"Word": "action", "OffsetStartMs": 11595, "OffsetEndMs": 11870}, {"Word": "and", "OffsetStartMs": 12430, "OffsetEndMs": 12675}, {"Word": "we", "OffsetStartMs": 12675, "OffsetEndMs": 12870}, {"Word": "determine", "OffsetStartMs": 12870, "OffsetEndMs": 13200}, {"Word": "the", "OffsetStartMs": 13200, "OffsetEndMs": 13485}, {"Word": "policy", "OffsetStartMs": 13485, "OffsetEndMs": 13790}, {"Word": "by", "OffsetStartMs": 14500, "OffsetEndMs": 14835}, {"Word": "looking", "OffsetStartMs": 14835, "OffsetEndMs": 15105}, {"Word": "over", "OffsetStartMs": 15105, "OffsetEndMs": 15390}, {"Word": "this", "OffsetStartMs": 15390, "OffsetEndMs": 15705}, {"Word": "state", "OffsetStartMs": 15705, "OffsetEndMs": 16020}, {"Word": "of", "OffsetStartMs": 16020, "OffsetEndMs": 16275}, {"Word": "q", "OffsetStartMs": 16275, "OffsetEndMs": 16455}, {"Word": "values", "OffsetStartMs": 16455, "OffsetEndMs": 16730}, {"Word": "picking", "OffsetStartMs": 17110, "OffsetEndMs": 17510}, {"Word": "the", "OffsetStartMs": 17530, "OffsetEndMs": 17820}, {"Word": "value", "OffsetStartMs": 17820, "OffsetEndMs": 18075}, {"Word": "that", "OffsetStartMs": 18075, "OffsetEndMs": 18300}, {"Word": "has", "OffsetStartMs": 18300, "OffsetEndMs": 18450}, {"Word": "the", "OffsetStartMs": 18450, "OffsetEndMs": 18600}, {"Word": "highest", "OffsetStartMs": 18600, "OffsetEndMs": 18860}], "SpeechSpeed": 16.0}, {"FinalSentence": "And looking at its corresponding action now with policy networks, the idea that we want to keep here is that instead of predicting the key values themselves, let's directly try to optimize this policy function. Here we're calling the policy function pi of s, right? So pi is the policy, s is our state. So it's a function that takes as input only the state and it's going to directly output the action. So the outputs here give us the desired action that we should take in any given state that we find ourselves in that represents not only the best action that we should take, but let's denote this as basically the probability that selecting that action would result in a very desirable outcome.", "SliceSentence": "And looking at its corresponding action now with policy networks the idea that we want to keep here is that instead of predicting the key values themselves let's directly try to optimize this policy function Here we're calling the policy function pi of s right So pi is the policy s is our state So it's a function that takes as input only the state and it's going to directly output the action So the outputs here give us the desired action that we should take in any given state that we find ourselves in that represents not only the best action that we should take but let's denote this as basically the probability that selecting that action would result in a very desirable outcome", "StartMs": 2002500, "EndMs": 2047240, "WordsNum": 125, "Words": [{"Word": "And", "OffsetStartMs": 0, "OffsetEndMs": 330}, {"Word": "looking", "OffsetStartMs": 330, "OffsetEndMs": 570}, {"Word": "at", "OffsetStartMs": 570, "OffsetEndMs": 795}, {"Word": "its", "OffsetStartMs": 795, "OffsetEndMs": 1050}, {"Word": "corresponding", "OffsetStartMs": 1050, "OffsetEndMs": 1575}, {"Word": "action", "OffsetStartMs": 1575, "OffsetEndMs": 1820}, {"Word": "now", "OffsetStartMs": 2620, "OffsetEndMs": 3000}, {"Word": "with", "OffsetStartMs": 3000, "OffsetEndMs": 3315}, {"Word": "policy", "OffsetStartMs": 3315, "OffsetEndMs": 3650}, {"Word": "networks", "OffsetStartMs": 3670, "OffsetEndMs": 4070}, {"Word": "the", "OffsetStartMs": 4420, "OffsetEndMs": 4820}, {"Word": "idea", "OffsetStartMs": 4840, "OffsetEndMs": 5235}, {"Word": "that", "OffsetStartMs": 5235, "OffsetEndMs": 5490}, {"Word": "we", "OffsetStartMs": 5490, "OffsetEndMs": 5625}, {"Word": "want", "OffsetStartMs": 5625, "OffsetEndMs": 5805}, {"Word": "to", "OffsetStartMs": 5805, "OffsetEndMs": 5970}, {"Word": "keep", "OffsetStartMs": 5970, "OffsetEndMs": 6135}, {"Word": "here", "OffsetStartMs": 6135, "OffsetEndMs": 6315}, {"Word": "is", "OffsetStartMs": 6315, "OffsetEndMs": 6480}, {"Word": "that", "OffsetStartMs": 6480, "OffsetEndMs": 6765}, {"Word": "instead", "OffsetStartMs": 6765, "OffsetEndMs": 7005}, {"Word": "of", "OffsetStartMs": 7005, "OffsetEndMs": 7140}, {"Word": "predicting", "OffsetStartMs": 7140, "OffsetEndMs": 7695}, {"Word": "the", "OffsetStartMs": 7695, "OffsetEndMs": 7965}, {"Word": "key", "OffsetStartMs": 7965, "OffsetEndMs": 8175}, {"Word": "values", "OffsetStartMs": 8175, "OffsetEndMs": 8450}, {"Word": "themselves", "OffsetStartMs": 8860, "OffsetEndMs": 9260}, {"Word": "let's", "OffsetStartMs": 9850, "OffsetEndMs": 10305}, {"Word": "directly", "OffsetStartMs": 10305, "OffsetEndMs": 10635}, {"Word": "try", "OffsetStartMs": 10635, "OffsetEndMs": 10920}, {"Word": "to", "OffsetStartMs": 10920, "OffsetEndMs": 11175}, {"Word": "optimize", "OffsetStartMs": 11175, "OffsetEndMs": 11630}, {"Word": "this", "OffsetStartMs": 11980, "OffsetEndMs": 12315}, {"Word": "policy", "OffsetStartMs": 12315, "OffsetEndMs": 12645}, {"Word": "function", "OffsetStartMs": 12645, "OffsetEndMs": 13020}, {"Word": "Here", "OffsetStartMs": 13020, "OffsetEndMs": 13305}, {"Word": "we're", "OffsetStartMs": 13305, "OffsetEndMs": 13515}, {"Word": "calling", "OffsetStartMs": 13515, "OffsetEndMs": 13665}, {"Word": "the", "OffsetStartMs": 13665, "OffsetEndMs": 13830}, {"Word": "policy", "OffsetStartMs": 13830, "OffsetEndMs": 14070}, {"Word": "function", "OffsetStartMs": 14070, "OffsetEndMs": 14450}, {"Word": "pi", "OffsetStartMs": 14770, "OffsetEndMs": 15090}, {"Word": "of", "OffsetStartMs": 15090, "OffsetEndMs": 15270}, {"Word": "s", "OffsetStartMs": 15270, "OffsetEndMs": 15530}, {"Word": "right", "OffsetStartMs": 15580, "OffsetEndMs": 15870}, {"Word": "So", "OffsetStartMs": 15870, "OffsetEndMs": 16065}, {"Word": "pi", "OffsetStartMs": 16065, "OffsetEndMs": 16260}, {"Word": "is", "OffsetStartMs": 16260, "OffsetEndMs": 16425}, {"Word": "the", "OffsetStartMs": 16425, "OffsetEndMs": 16575}, {"Word": "policy", "OffsetStartMs": 16575, "OffsetEndMs": 16850}, {"Word": "s", "OffsetStartMs": 17380, "OffsetEndMs": 17730}, {"Word": "is", "OffsetStartMs": 17730, "OffsetEndMs": 17955}, {"Word": "our", "OffsetStartMs": 17955, "OffsetEndMs": 18165}, {"Word": "state", "OffsetStartMs": 18165, "OffsetEndMs": 18500}, {"Word": "So", "OffsetStartMs": 18640, "OffsetEndMs": 18870}, {"Word": "it's", "OffsetStartMs": 18870, "OffsetEndMs": 19190}, {"Word": "a", "OffsetStartMs": 19210, "OffsetEndMs": 19515}, {"Word": "function", "OffsetStartMs": 19515, "OffsetEndMs": 19815}, {"Word": "that", "OffsetStartMs": 19815, "OffsetEndMs": 20100}, {"Word": "takes", "OffsetStartMs": 20100, "OffsetEndMs": 20280}, {"Word": "as", "OffsetStartMs": 20280, "OffsetEndMs": 20520}, {"Word": "input", "OffsetStartMs": 20520, "OffsetEndMs": 20730}, {"Word": "only", "OffsetStartMs": 20730, "OffsetEndMs": 20940}, {"Word": "the", "OffsetStartMs": 20940, "OffsetEndMs": 21195}, {"Word": "state", "OffsetStartMs": 21195, "OffsetEndMs": 21500}, {"Word": "and", "OffsetStartMs": 21640, "OffsetEndMs": 21870}, {"Word": "it's", "OffsetStartMs": 21870, "OffsetEndMs": 22005}, {"Word": "going", "OffsetStartMs": 22005, "OffsetEndMs": 22140}, {"Word": "to", "OffsetStartMs": 22140, "OffsetEndMs": 22380}, {"Word": "directly", "OffsetStartMs": 22380, "OffsetEndMs": 22730}, {"Word": "output", "OffsetStartMs": 22900, "OffsetEndMs": 23300}, {"Word": "the", "OffsetStartMs": 23380, "OffsetEndMs": 23625}, {"Word": "action", "OffsetStartMs": 23625, "OffsetEndMs": 23870}, {"Word": "So", "OffsetStartMs": 24700, "OffsetEndMs": 24960}, {"Word": "the", "OffsetStartMs": 24960, "OffsetEndMs": 25185}, {"Word": "outputs", "OffsetStartMs": 25185, "OffsetEndMs": 25515}, {"Word": "here", "OffsetStartMs": 25515, "OffsetEndMs": 25790}, {"Word": "give", "OffsetStartMs": 25930, "OffsetEndMs": 26205}, {"Word": "us", "OffsetStartMs": 26205, "OffsetEndMs": 26480}, {"Word": "the", "OffsetStartMs": 26710, "OffsetEndMs": 26985}, {"Word": "desired", "OffsetStartMs": 26985, "OffsetEndMs": 27390}, {"Word": "action", "OffsetStartMs": 27390, "OffsetEndMs": 27770}, {"Word": "that", "OffsetStartMs": 27790, "OffsetEndMs": 28050}, {"Word": "we", "OffsetStartMs": 28050, "OffsetEndMs": 28185}, {"Word": "should", "OffsetStartMs": 28185, "OffsetEndMs": 28365}, {"Word": "take", "OffsetStartMs": 28365, "OffsetEndMs": 28670}, {"Word": "in", "OffsetStartMs": 28840, "OffsetEndMs": 29130}, {"Word": "any", "OffsetStartMs": 29130, "OffsetEndMs": 29385}, {"Word": "given", "OffsetStartMs": 29385, "OffsetEndMs": 29750}, {"Word": "state", "OffsetStartMs": 29770, "OffsetEndMs": 30090}, {"Word": "that", "OffsetStartMs": 30090, "OffsetEndMs": 30270}, {"Word": "we", "OffsetStartMs": 30270, "OffsetEndMs": 30405}, {"Word": "find", "OffsetStartMs": 30405, "OffsetEndMs": 30675}, {"Word": "ourselves", "OffsetStartMs": 30675, "OffsetEndMs": 30975}, {"Word": "in", "OffsetStartMs": 30975, "OffsetEndMs": 31280}, {"Word": "that", "OffsetStartMs": 31690, "OffsetEndMs": 31995}, {"Word": "represents", "OffsetStartMs": 31995, "OffsetEndMs": 32300}, {"Word": "not", "OffsetStartMs": 33070, "OffsetEndMs": 33375}, {"Word": "only", "OffsetStartMs": 33375, "OffsetEndMs": 33680}, {"Word": "the", "OffsetStartMs": 33910, "OffsetEndMs": 34310}, {"Word": "best", "OffsetStartMs": 34330, "OffsetEndMs": 34710}, {"Word": "action", "OffsetStartMs": 34710, "OffsetEndMs": 35090}, {"Word": "that", "OffsetStartMs": 35230, "OffsetEndMs": 35505}, {"Word": "we", "OffsetStartMs": 35505, "OffsetEndMs": 35640}, {"Word": "should", "OffsetStartMs": 35640, "OffsetEndMs": 35790}, {"Word": "take", "OffsetStartMs": 35790, "OffsetEndMs": 36045}, {"Word": "but", "OffsetStartMs": 36045, "OffsetEndMs": 36270}, {"Word": "let's", "OffsetStartMs": 36270, "OffsetEndMs": 36650}, {"Word": "denote", "OffsetStartMs": 36850, "OffsetEndMs": 37335}, {"Word": "this", "OffsetStartMs": 37335, "OffsetEndMs": 37575}, {"Word": "as", "OffsetStartMs": 37575, "OffsetEndMs": 37785}, {"Word": "basically", "OffsetStartMs": 37785, "OffsetEndMs": 38090}, {"Word": "the", "OffsetStartMs": 38140, "OffsetEndMs": 38445}, {"Word": "probability", "OffsetStartMs": 38445, "OffsetEndMs": 39020}, {"Word": "that", "OffsetStartMs": 39460, "OffsetEndMs": 39860}, {"Word": "selecting", "OffsetStartMs": 39910, "OffsetEndMs": 40455}, {"Word": "that", "OffsetStartMs": 40455, "OffsetEndMs": 40665}, {"Word": "action", "OffsetStartMs": 40665, "OffsetEndMs": 40970}, {"Word": "would", "OffsetStartMs": 41500, "OffsetEndMs": 41880}, {"Word": "result", "OffsetStartMs": 41880, "OffsetEndMs": 42260}, {"Word": "in", "OffsetStartMs": 42340, "OffsetEndMs": 42585}, {"Word": "a", "OffsetStartMs": 42585, "OffsetEndMs": 42735}, {"Word": "very", "OffsetStartMs": 42735, "OffsetEndMs": 42975}, {"Word": "desirable", "OffsetStartMs": 42975, "OffsetEndMs": 43790}, {"Word": "outcome", "OffsetStartMs": 43960, "OffsetEndMs": 44360}], "SpeechSpeed": 15.3}, {"FinalSentence": "For our network, so not necessarily the value of that that action, but rather the probability that selecting that action would be the highest value, right? So you don't care exactly about what is the numerical value that selecting this action takes or gives rise to rather, but rather.", "SliceSentence": "For our network so not necessarily the value of that that action but rather the probability that selecting that action would be the highest value right So you don't care exactly about what is the numerical value that selecting this action takes or gives rise to rather but rather", "StartMs": 2047240, "EndMs": 2066940, "WordsNum": 49, "Words": [{"Word": "For", "OffsetStartMs": 40, "OffsetEndMs": 330}, {"Word": "our", "OffsetStartMs": 330, "OffsetEndMs": 600}, {"Word": "network", "OffsetStartMs": 600, "OffsetEndMs": 975}, {"Word": "so", "OffsetStartMs": 975, "OffsetEndMs": 1245}, {"Word": "not", "OffsetStartMs": 1245, "OffsetEndMs": 1520}, {"Word": "necessarily", "OffsetStartMs": 1600, "OffsetEndMs": 2000}, {"Word": "the", "OffsetStartMs": 2020, "OffsetEndMs": 2310}, {"Word": "value", "OffsetStartMs": 2310, "OffsetEndMs": 2600}, {"Word": "of", "OffsetStartMs": 3190, "OffsetEndMs": 3590}, {"Word": "that", "OffsetStartMs": 3910, "OffsetEndMs": 4275}, {"Word": "that", "OffsetStartMs": 4275, "OffsetEndMs": 4530}, {"Word": "action", "OffsetStartMs": 4530, "OffsetEndMs": 4820}, {"Word": "but", "OffsetStartMs": 5290, "OffsetEndMs": 5610}, {"Word": "rather", "OffsetStartMs": 5610, "OffsetEndMs": 5930}, {"Word": "the", "OffsetStartMs": 6160, "OffsetEndMs": 6450}, {"Word": "probability", "OffsetStartMs": 6450, "OffsetEndMs": 6980}, {"Word": "that", "OffsetStartMs": 7150, "OffsetEndMs": 7530}, {"Word": "selecting", "OffsetStartMs": 7530, "OffsetEndMs": 7920}, {"Word": "that", "OffsetStartMs": 7920, "OffsetEndMs": 8055}, {"Word": "action", "OffsetStartMs": 8055, "OffsetEndMs": 8330}, {"Word": "would", "OffsetStartMs": 8350, "OffsetEndMs": 8655}, {"Word": "be", "OffsetStartMs": 8655, "OffsetEndMs": 8940}, {"Word": "the", "OffsetStartMs": 8940, "OffsetEndMs": 9225}, {"Word": "highest", "OffsetStartMs": 9225, "OffsetEndMs": 9530}, {"Word": "value", "OffsetStartMs": 9550, "OffsetEndMs": 9950}, {"Word": "right", "OffsetStartMs": 10570, "OffsetEndMs": 10970}, {"Word": "So", "OffsetStartMs": 11050, "OffsetEndMs": 11295}, {"Word": "you", "OffsetStartMs": 11295, "OffsetEndMs": 11400}, {"Word": "don't", "OffsetStartMs": 11400, "OffsetEndMs": 11610}, {"Word": "care", "OffsetStartMs": 11610, "OffsetEndMs": 11820}, {"Word": "exactly", "OffsetStartMs": 11820, "OffsetEndMs": 12170}, {"Word": "about", "OffsetStartMs": 12190, "OffsetEndMs": 12525}, {"Word": "what", "OffsetStartMs": 12525, "OffsetEndMs": 12735}, {"Word": "is", "OffsetStartMs": 12735, "OffsetEndMs": 12930}, {"Word": "the", "OffsetStartMs": 12930, "OffsetEndMs": 13250}, {"Word": "numerical", "OffsetStartMs": 13540, "OffsetEndMs": 14130}, {"Word": "value", "OffsetStartMs": 14130, "OffsetEndMs": 14420}, {"Word": "that", "OffsetStartMs": 14440, "OffsetEndMs": 14775}, {"Word": "selecting", "OffsetStartMs": 14775, "OffsetEndMs": 15150}, {"Word": "this", "OffsetStartMs": 15150, "OffsetEndMs": 15270}, {"Word": "action", "OffsetStartMs": 15270, "OffsetEndMs": 15530}, {"Word": "takes", "OffsetStartMs": 15580, "OffsetEndMs": 15980}, {"Word": "or", "OffsetStartMs": 16570, "OffsetEndMs": 16875}, {"Word": "gives", "OffsetStartMs": 16875, "OffsetEndMs": 17100}, {"Word": "rise", "OffsetStartMs": 17100, "OffsetEndMs": 17355}, {"Word": "to", "OffsetStartMs": 17355, "OffsetEndMs": 17550}, {"Word": "rather", "OffsetStartMs": 17550, "OffsetEndMs": 17810}, {"Word": "but", "OffsetStartMs": 18280, "OffsetEndMs": 18585}, {"Word": "rather", "OffsetStartMs": 18585, "OffsetEndMs": 18890}], "SpeechSpeed": 14.2}, {"FinalSentence": "What is the likelihood that selecting this action will give you the best performing value that you could expect? Exact value itself doesn't matter. You only care about if selecting this action is going to give you, with high likelihood, the best one.", "SliceSentence": "What is the likelihood that selecting this action will give you the best performing value that you could expect Exact value itself doesn't matter You only care about if selecting this action is going to give you with high likelihood the best one", "StartMs": 2067220, "EndMs": 2083000, "WordsNum": 43, "Words": [{"Word": "What", "OffsetStartMs": 190, "OffsetEndMs": 465}, {"Word": "is", "OffsetStartMs": 465, "OffsetEndMs": 690}, {"Word": "the", "OffsetStartMs": 690, "OffsetEndMs": 1040}, {"Word": "likelihood", "OffsetStartMs": 1270, "OffsetEndMs": 1995}, {"Word": "that", "OffsetStartMs": 1995, "OffsetEndMs": 2325}, {"Word": "selecting", "OffsetStartMs": 2325, "OffsetEndMs": 2745}, {"Word": "this", "OffsetStartMs": 2745, "OffsetEndMs": 2880}, {"Word": "action", "OffsetStartMs": 2880, "OffsetEndMs": 3140}, {"Word": "will", "OffsetStartMs": 3700, "OffsetEndMs": 4005}, {"Word": "give", "OffsetStartMs": 4005, "OffsetEndMs": 4200}, {"Word": "you", "OffsetStartMs": 4200, "OffsetEndMs": 4470}, {"Word": "the", "OffsetStartMs": 4470, "OffsetEndMs": 4725}, {"Word": "best", "OffsetStartMs": 4725, "OffsetEndMs": 5000}, {"Word": "performing", "OffsetStartMs": 5020, "OffsetEndMs": 5355}, {"Word": "value", "OffsetStartMs": 5355, "OffsetEndMs": 5655}, {"Word": "that", "OffsetStartMs": 5655, "OffsetEndMs": 5880}, {"Word": "you", "OffsetStartMs": 5880, "OffsetEndMs": 6045}, {"Word": "could", "OffsetStartMs": 6045, "OffsetEndMs": 6315}, {"Word": "expect", "OffsetStartMs": 6315, "OffsetEndMs": 6680}, {"Word": "Exact", "OffsetStartMs": 7450, "OffsetEndMs": 7785}, {"Word": "value", "OffsetStartMs": 7785, "OffsetEndMs": 8120}, {"Word": "itself", "OffsetStartMs": 8710, "OffsetEndMs": 9110}, {"Word": "doesn't", "OffsetStartMs": 9160, "OffsetEndMs": 9585}, {"Word": "matter", "OffsetStartMs": 9585, "OffsetEndMs": 9855}, {"Word": "You", "OffsetStartMs": 9855, "OffsetEndMs": 10110}, {"Word": "only", "OffsetStartMs": 10110, "OffsetEndMs": 10320}, {"Word": "care", "OffsetStartMs": 10320, "OffsetEndMs": 10575}, {"Word": "about", "OffsetStartMs": 10575, "OffsetEndMs": 10755}, {"Word": "if", "OffsetStartMs": 10755, "OffsetEndMs": 10980}, {"Word": "selecting", "OffsetStartMs": 10980, "OffsetEndMs": 11340}, {"Word": "this", "OffsetStartMs": 11340, "OffsetEndMs": 11460}, {"Word": "action", "OffsetStartMs": 11460, "OffsetEndMs": 11720}, {"Word": "is", "OffsetStartMs": 12130, "OffsetEndMs": 12480}, {"Word": "going", "OffsetStartMs": 12480, "OffsetEndMs": 12735}, {"Word": "to", "OffsetStartMs": 12735, "OffsetEndMs": 13035}, {"Word": "give", "OffsetStartMs": 13035, "OffsetEndMs": 13305}, {"Word": "you", "OffsetStartMs": 13305, "OffsetEndMs": 13440}, {"Word": "with", "OffsetStartMs": 13440, "OffsetEndMs": 13575}, {"Word": "high", "OffsetStartMs": 13575, "OffsetEndMs": 13740}, {"Word": "likelihood", "OffsetStartMs": 13740, "OffsetEndMs": 14175}, {"Word": "the", "OffsetStartMs": 14175, "OffsetEndMs": 14310}, {"Word": "best", "OffsetStartMs": 14310, "OffsetEndMs": 14490}, {"Word": "one", "OffsetStartMs": 14490, "OffsetEndMs": 14810}], "SpeechSpeed": 15.5}, {"FinalSentence": "So we can see that if these predicted probabilities here, right in this example of atari.", "SliceSentence": "So we can see that if these predicted probabilities here right in this example of atari", "StartMs": 2083260, "EndMs": 2090120, "WordsNum": 16, "Words": [{"Word": "So", "OffsetStartMs": 310, "OffsetEndMs": 710}, {"Word": "we", "OffsetStartMs": 790, "OffsetEndMs": 1050}, {"Word": "can", "OffsetStartMs": 1050, "OffsetEndMs": 1200}, {"Word": "see", "OffsetStartMs": 1200, "OffsetEndMs": 1350}, {"Word": "that", "OffsetStartMs": 1350, "OffsetEndMs": 1485}, {"Word": "if", "OffsetStartMs": 1485, "OffsetEndMs": 1665}, {"Word": "these", "OffsetStartMs": 1665, "OffsetEndMs": 1970}, {"Word": "predicted", "OffsetStartMs": 2050, "OffsetEndMs": 2685}, {"Word": "probabilities", "OffsetStartMs": 2685, "OffsetEndMs": 3260}, {"Word": "here", "OffsetStartMs": 3370, "OffsetEndMs": 3770}, {"Word": "right", "OffsetStartMs": 3850, "OffsetEndMs": 4185}, {"Word": "in", "OffsetStartMs": 4185, "OffsetEndMs": 4395}, {"Word": "this", "OffsetStartMs": 4395, "OffsetEndMs": 4635}, {"Word": "example", "OffsetStartMs": 4635, "OffsetEndMs": 4980}, {"Word": "of", "OffsetStartMs": 4980, "OffsetEndMs": 5280}, {"Word": "atari", "OffsetStartMs": 5280, "OffsetEndMs": 5780}], "SpeechSpeed": 12.7}, {"FinalSentence": "Going left has the probability of being the highest value action with 90% staying in the center has a probability of 10%. Going right is 0%. So ideally what our neural networks should do in this case is 90% of the time in this situation go to the left 10% of the time it could still try staying at where it is, but never it should go to the right. Now note that this now is a probability distribution. This is very different than A Q function. A que function has actually no eh structure, right? The q values themselves can take any real number.", "SliceSentence": "Going left has the probability of being the highest value action with 90% staying in the center has a probability of 10 % Goingright is 0 % So ideally what our neural networks should do in this case is 90% of the time in this situation go to the left 10% of the time it could still try staying at where it is but never it should go to the right Now note that this now is a probability distribution This is very different than A Q function A que function has actually no eh structure right The q values themselves can take any real number", "StartMs": 2090460, "EndMs": 2128860, "WordsNum": 106, "Words": [{"Word": "Going", "OffsetStartMs": 100, "OffsetEndMs": 465}, {"Word": "left", "OffsetStartMs": 465, "OffsetEndMs": 830}, {"Word": "has", "OffsetStartMs": 940, "OffsetEndMs": 1340}, {"Word": "the", "OffsetStartMs": 1570, "OffsetEndMs": 1860}, {"Word": "probability", "OffsetStartMs": 1860, "OffsetEndMs": 2420}, {"Word": "of", "OffsetStartMs": 2920, "OffsetEndMs": 3255}, {"Word": "being", "OffsetStartMs": 3255, "OffsetEndMs": 3585}, {"Word": "the", "OffsetStartMs": 3585, "OffsetEndMs": 3885}, {"Word": "highest", "OffsetStartMs": 3885, "OffsetEndMs": 4190}, {"Word": "value", "OffsetStartMs": 5290, "OffsetEndMs": 5690}, {"Word": "action", "OffsetStartMs": 6130, "OffsetEndMs": 6530}, {"Word": "with", "OffsetStartMs": 6850, "OffsetEndMs": 7140}, {"Word": "90%", "OffsetStartMs": 7140, "OffsetEndMs": 7730}, {"Word": "staying", "OffsetStartMs": 8260, "OffsetEndMs": 8625}, {"Word": "in", "OffsetStartMs": 8625, "OffsetEndMs": 8880}, {"Word": "the", "OffsetStartMs": 8880, "OffsetEndMs": 9045}, {"Word": "center", "OffsetStartMs": 9045, "OffsetEndMs": 9320}, {"Word": "has", "OffsetStartMs": 9430, "OffsetEndMs": 9720}, {"Word": "a", "OffsetStartMs": 9720, "OffsetEndMs": 9960}, {"Word": "probability", "OffsetStartMs": 9960, "OffsetEndMs": 10455}, {"Word": "of", "OffsetStartMs": 10455, "OffsetEndMs": 10790}, {"Word": "10", "OffsetStartMs": 12070, "OffsetEndMs": 12680}, {"Word": "%", "OffsetStartMs": 13150, "OffsetEndMs": 13485}, {"Word": "Goingright", "OffsetStartMs": 13485, "OffsetEndMs": 13755}, {"Word": "is", "OffsetStartMs": 13755, "OffsetEndMs": 13995}, {"Word": "0", "OffsetStartMs": 13995, "OffsetEndMs": 14220}, {"Word": "%", "OffsetStartMs": 14220, "OffsetEndMs": 14540}, {"Word": "So", "OffsetStartMs": 14920, "OffsetEndMs": 15180}, {"Word": "ideally", "OffsetStartMs": 15180, "OffsetEndMs": 15765}, {"Word": "what", "OffsetStartMs": 15765, "OffsetEndMs": 15960}, {"Word": "our", "OffsetStartMs": 15960, "OffsetEndMs": 16095}, {"Word": "neural", "OffsetStartMs": 16095, "OffsetEndMs": 16320}, {"Word": "networks", "OffsetStartMs": 16320, "OffsetEndMs": 16515}, {"Word": "should", "OffsetStartMs": 16515, "OffsetEndMs": 16710}, {"Word": "do", "OffsetStartMs": 16710, "OffsetEndMs": 16830}, {"Word": "in", "OffsetStartMs": 16830, "OffsetEndMs": 16950}, {"Word": "this", "OffsetStartMs": 16950, "OffsetEndMs": 17115}, {"Word": "case", "OffsetStartMs": 17115, "OffsetEndMs": 17340}, {"Word": "is", "OffsetStartMs": 17340, "OffsetEndMs": 17565}, {"Word": "90%", "OffsetStartMs": 17565, "OffsetEndMs": 18135}, {"Word": "of", "OffsetStartMs": 18135, "OffsetEndMs": 18360}, {"Word": "the", "OffsetStartMs": 18360, "OffsetEndMs": 18510}, {"Word": "time", "OffsetStartMs": 18510, "OffsetEndMs": 18750}, {"Word": "in", "OffsetStartMs": 18750, "OffsetEndMs": 18975}, {"Word": "this", "OffsetStartMs": 18975, "OffsetEndMs": 19155}, {"Word": "situation", "OffsetStartMs": 19155, "OffsetEndMs": 19460}, {"Word": "go", "OffsetStartMs": 20170, "OffsetEndMs": 20475}, {"Word": "to", "OffsetStartMs": 20475, "OffsetEndMs": 20625}, {"Word": "the", "OffsetStartMs": 20625, "OffsetEndMs": 20715}, {"Word": "left", "OffsetStartMs": 20715, "OffsetEndMs": 20960}, {"Word": "10%", "OffsetStartMs": 21100, "OffsetEndMs": 21615}, {"Word": "of", "OffsetStartMs": 21615, "OffsetEndMs": 21780}, {"Word": "the", "OffsetStartMs": 21780, "OffsetEndMs": 21900}, {"Word": "time", "OffsetStartMs": 21900, "OffsetEndMs": 22065}, {"Word": "it", "OffsetStartMs": 22065, "OffsetEndMs": 22200}, {"Word": "could", "OffsetStartMs": 22200, "OffsetEndMs": 22365}, {"Word": "still", "OffsetStartMs": 22365, "OffsetEndMs": 22590}, {"Word": "try", "OffsetStartMs": 22590, "OffsetEndMs": 22910}, {"Word": "staying", "OffsetStartMs": 23380, "OffsetEndMs": 23700}, {"Word": "at", "OffsetStartMs": 23700, "OffsetEndMs": 23880}, {"Word": "where", "OffsetStartMs": 23880, "OffsetEndMs": 24015}, {"Word": "it", "OffsetStartMs": 24015, "OffsetEndMs": 24135}, {"Word": "is", "OffsetStartMs": 24135, "OffsetEndMs": 24330}, {"Word": "but", "OffsetStartMs": 24330, "OffsetEndMs": 24600}, {"Word": "never", "OffsetStartMs": 24600, "OffsetEndMs": 24920}, {"Word": "it", "OffsetStartMs": 24970, "OffsetEndMs": 25260}, {"Word": "should", "OffsetStartMs": 25260, "OffsetEndMs": 25425}, {"Word": "go", "OffsetStartMs": 25425, "OffsetEndMs": 25620}, {"Word": "to", "OffsetStartMs": 25620, "OffsetEndMs": 25785}, {"Word": "the", "OffsetStartMs": 25785, "OffsetEndMs": 25890}, {"Word": "right", "OffsetStartMs": 25890, "OffsetEndMs": 26150}, {"Word": "Now", "OffsetStartMs": 26920, "OffsetEndMs": 27320}, {"Word": "note", "OffsetStartMs": 27340, "OffsetEndMs": 27660}, {"Word": "that", "OffsetStartMs": 27660, "OffsetEndMs": 27915}, {"Word": "this", "OffsetStartMs": 27915, "OffsetEndMs": 28230}, {"Word": "now", "OffsetStartMs": 28230, "OffsetEndMs": 28610}, {"Word": "is", "OffsetStartMs": 28750, "OffsetEndMs": 29150}, {"Word": "a", "OffsetStartMs": 29260, "OffsetEndMs": 29550}, {"Word": "probability", "OffsetStartMs": 29550, "OffsetEndMs": 30080}, {"Word": "distribution", "OffsetStartMs": 30160, "OffsetEndMs": 30555}, {"Word": "This", "OffsetStartMs": 30555, "OffsetEndMs": 30795}, {"Word": "is", "OffsetStartMs": 30795, "OffsetEndMs": 30930}, {"Word": "very", "OffsetStartMs": 30930, "OffsetEndMs": 31155}, {"Word": "different", "OffsetStartMs": 31155, "OffsetEndMs": 31440}, {"Word": "than", "OffsetStartMs": 31440, "OffsetEndMs": 31650}, {"Word": "A", "OffsetStartMs": 31650, "OffsetEndMs": 31785}, {"Word": "Q", "OffsetStartMs": 31785, "OffsetEndMs": 31935}, {"Word": "function", "OffsetStartMs": 31935, "OffsetEndMs": 32160}, {"Word": "A", "OffsetStartMs": 32160, "OffsetEndMs": 32370}, {"Word": "que", "OffsetStartMs": 32370, "OffsetEndMs": 32505}, {"Word": "function", "OffsetStartMs": 32505, "OffsetEndMs": 32745}, {"Word": "has", "OffsetStartMs": 32745, "OffsetEndMs": 33110}, {"Word": "actually", "OffsetStartMs": 33160, "OffsetEndMs": 33510}, {"Word": "no", "OffsetStartMs": 33510, "OffsetEndMs": 33860}, {"Word": "eh", "OffsetStartMs": 34300, "OffsetEndMs": 34700}, {"Word": "structure", "OffsetStartMs": 34720, "OffsetEndMs": 35115}, {"Word": "right", "OffsetStartMs": 35115, "OffsetEndMs": 35430}, {"Word": "The", "OffsetStartMs": 35430, "OffsetEndMs": 35640}, {"Word": "q", "OffsetStartMs": 35640, "OffsetEndMs": 35835}, {"Word": "values", "OffsetStartMs": 35835, "OffsetEndMs": 36140}, {"Word": "themselves", "OffsetStartMs": 36370, "OffsetEndMs": 36705}, {"Word": "can", "OffsetStartMs": 36705, "OffsetEndMs": 36915}, {"Word": "take", "OffsetStartMs": 36915, "OffsetEndMs": 37080}, {"Word": "any", "OffsetStartMs": 37080, "OffsetEndMs": 37320}, {"Word": "real", "OffsetStartMs": 37320, "OffsetEndMs": 37575}, {"Word": "number", "OffsetStartMs": 37575, "OffsetEndMs": 37880}], "SpeechSpeed": 15.2}, {"FinalSentence": "Right. But here the policy network has a very formulated output. All of the numbers here in the output have to sum to one because this is a probability distribution, right? And that gives it a very rigorous version of how we can train this model that makes it a bit easier to train than hue functions as well.", "SliceSentence": "Right But here the policy network has a very formulated output All of the numbers here in the output have to sum to one because this is a probability distribution right And that gives it a very rigorous version of how we can train this model that makes it a bit easier to train than hue functions as well", "StartMs": 2128860, "EndMs": 2153540, "WordsNum": 59, "Words": [{"Word": "Right", "OffsetStartMs": 0, "OffsetEndMs": 290}, {"Word": "But", "OffsetStartMs": 880, "OffsetEndMs": 1230}, {"Word": "here", "OffsetStartMs": 1230, "OffsetEndMs": 1580}, {"Word": "the", "OffsetStartMs": 2200, "OffsetEndMs": 2505}, {"Word": "policy", "OffsetStartMs": 2505, "OffsetEndMs": 2810}, {"Word": "network", "OffsetStartMs": 2830, "OffsetEndMs": 3230}, {"Word": "has", "OffsetStartMs": 3400, "OffsetEndMs": 3705}, {"Word": "a", "OffsetStartMs": 3705, "OffsetEndMs": 3915}, {"Word": "very", "OffsetStartMs": 3915, "OffsetEndMs": 4220}, {"Word": "formulated", "OffsetStartMs": 4690, "OffsetEndMs": 5450}, {"Word": "output", "OffsetStartMs": 5770, "OffsetEndMs": 6170}, {"Word": "All", "OffsetStartMs": 6550, "OffsetEndMs": 6870}, {"Word": "of", "OffsetStartMs": 6870, "OffsetEndMs": 7095}, {"Word": "the", "OffsetStartMs": 7095, "OffsetEndMs": 7260}, {"Word": "numbers", "OffsetStartMs": 7260, "OffsetEndMs": 7520}, {"Word": "here", "OffsetStartMs": 7540, "OffsetEndMs": 7940}, {"Word": "in", "OffsetStartMs": 8320, "OffsetEndMs": 8580}, {"Word": "the", "OffsetStartMs": 8580, "OffsetEndMs": 8805}, {"Word": "output", "OffsetStartMs": 8805, "OffsetEndMs": 9090}, {"Word": "have", "OffsetStartMs": 9090, "OffsetEndMs": 9345}, {"Word": "to", "OffsetStartMs": 9345, "OffsetEndMs": 9555}, {"Word": "sum", "OffsetStartMs": 9555, "OffsetEndMs": 9735}, {"Word": "to", "OffsetStartMs": 9735, "OffsetEndMs": 9900}, {"Word": "one", "OffsetStartMs": 9900, "OffsetEndMs": 10160}, {"Word": "because", "OffsetStartMs": 10210, "OffsetEndMs": 10515}, {"Word": "this", "OffsetStartMs": 10515, "OffsetEndMs": 10695}, {"Word": "is", "OffsetStartMs": 10695, "OffsetEndMs": 10830}, {"Word": "a", "OffsetStartMs": 10830, "OffsetEndMs": 10950}, {"Word": "probability", "OffsetStartMs": 10950, "OffsetEndMs": 11420}, {"Word": "distribution", "OffsetStartMs": 11500, "OffsetEndMs": 11900}, {"Word": "right", "OffsetStartMs": 12550, "OffsetEndMs": 12950}, {"Word": "And", "OffsetStartMs": 13120, "OffsetEndMs": 13365}, {"Word": "that", "OffsetStartMs": 13365, "OffsetEndMs": 13515}, {"Word": "gives", "OffsetStartMs": 13515, "OffsetEndMs": 13710}, {"Word": "it", "OffsetStartMs": 13710, "OffsetEndMs": 13890}, {"Word": "a", "OffsetStartMs": 13890, "OffsetEndMs": 14100}, {"Word": "very", "OffsetStartMs": 14100, "OffsetEndMs": 14420}, {"Word": "rigorous", "OffsetStartMs": 14650, "OffsetEndMs": 15290}, {"Word": "version", "OffsetStartMs": 15730, "OffsetEndMs": 16130}, {"Word": "of", "OffsetStartMs": 16360, "OffsetEndMs": 16760}, {"Word": "how", "OffsetStartMs": 17410, "OffsetEndMs": 17685}, {"Word": "we", "OffsetStartMs": 17685, "OffsetEndMs": 17820}, {"Word": "can", "OffsetStartMs": 17820, "OffsetEndMs": 18000}, {"Word": "train", "OffsetStartMs": 18000, "OffsetEndMs": 18225}, {"Word": "this", "OffsetStartMs": 18225, "OffsetEndMs": 18450}, {"Word": "model", "OffsetStartMs": 18450, "OffsetEndMs": 18770}, {"Word": "that", "OffsetStartMs": 18910, "OffsetEndMs": 19185}, {"Word": "makes", "OffsetStartMs": 19185, "OffsetEndMs": 19335}, {"Word": "it", "OffsetStartMs": 19335, "OffsetEndMs": 19440}, {"Word": "a", "OffsetStartMs": 19440, "OffsetEndMs": 19575}, {"Word": "bit", "OffsetStartMs": 19575, "OffsetEndMs": 19755}, {"Word": "easier", "OffsetStartMs": 19755, "OffsetEndMs": 20030}, {"Word": "to", "OffsetStartMs": 20050, "OffsetEndMs": 20340}, {"Word": "train", "OffsetStartMs": 20340, "OffsetEndMs": 20595}, {"Word": "than", "OffsetStartMs": 20595, "OffsetEndMs": 20960}, {"Word": "hue", "OffsetStartMs": 21220, "OffsetEndMs": 21525}, {"Word": "functions", "OffsetStartMs": 21525, "OffsetEndMs": 21800}, {"Word": "as", "OffsetStartMs": 21910, "OffsetEndMs": 22215}, {"Word": "well", "OffsetStartMs": 22215, "OffsetEndMs": 22520}], "SpeechSpeed": 12.3}, {"FinalSentence": "One other very important advantage of having an output that is a probability distribution is actually going to tie back to this other issue of q functions and q neural networks that we saw before and that is the fact that q functions are naturally suited towards discrete action spaces. Now when we're looking at this policy network we're puttingting a distributions, right? And remember those those distributions can also take continuous forms. In fact, we've seen this in the last two lectures. In the generative lecture we saw how ves could be used to predict gaussian distributions over their latent space. In the last lecture we also saw how we could learn to predict uncertainties which are continuous probability distributions using data. And just like that, we could also use this same formulation to move beyond discrete action spaces like you can see here, which are one possible action, a probability associated to one possible action.", "SliceSentence": "One other very important advantage of having an output that is a probability distribution is actually going to tie back to this other issue of q functions and q neural networks that we saw before and that is the fact that q functions are naturally suited towards discrete action spaces Now when we're looking at this policy network we're puttingting a distributions right And remember those those distributions can also take continuous forms In fact we've seen this in the last two lectures In the generative lecture we saw how ves could be used to predict gaussian distributions over their latent space In the last lecture we also saw how we could learn to predict uncertainties which are continuous probability distributions using data And just like that we could also use this same formulation to move beyond discrete action spaces like you can see here which are one possible action a probability associated to one possible action", "StartMs": 2153660, "EndMs": 2214140, "WordsNum": 157, "Words": [{"Word": "One", "OffsetStartMs": 100, "OffsetEndMs": 435}, {"Word": "other", "OffsetStartMs": 435, "OffsetEndMs": 765}, {"Word": "very", "OffsetStartMs": 765, "OffsetEndMs": 1140}, {"Word": "important", "OffsetStartMs": 1140, "OffsetEndMs": 1520}, {"Word": "advantage", "OffsetStartMs": 1540, "OffsetEndMs": 1940}, {"Word": "of", "OffsetStartMs": 2380, "OffsetEndMs": 2780}, {"Word": "having", "OffsetStartMs": 3130, "OffsetEndMs": 3465}, {"Word": "an", "OffsetStartMs": 3465, "OffsetEndMs": 3795}, {"Word": "output", "OffsetStartMs": 3795, "OffsetEndMs": 4140}, {"Word": "that", "OffsetStartMs": 4140, "OffsetEndMs": 4350}, {"Word": "is", "OffsetStartMs": 4350, "OffsetEndMs": 4470}, {"Word": "a", "OffsetStartMs": 4470, "OffsetEndMs": 4590}, {"Word": "probability", "OffsetStartMs": 4590, "OffsetEndMs": 5060}, {"Word": "distribution", "OffsetStartMs": 5200, "OffsetEndMs": 5600}, {"Word": "is", "OffsetStartMs": 6220, "OffsetEndMs": 6620}, {"Word": "actually", "OffsetStartMs": 6790, "OffsetEndMs": 7065}, {"Word": "going", "OffsetStartMs": 7065, "OffsetEndMs": 7245}, {"Word": "to", "OffsetStartMs": 7245, "OffsetEndMs": 7530}, {"Word": "tie", "OffsetStartMs": 7530, "OffsetEndMs": 7845}, {"Word": "back", "OffsetStartMs": 7845, "OffsetEndMs": 8160}, {"Word": "to", "OffsetStartMs": 8160, "OffsetEndMs": 8400}, {"Word": "this", "OffsetStartMs": 8400, "OffsetEndMs": 8520}, {"Word": "other", "OffsetStartMs": 8520, "OffsetEndMs": 8715}, {"Word": "issue", "OffsetStartMs": 8715, "OffsetEndMs": 9050}, {"Word": "of", "OffsetStartMs": 9190, "OffsetEndMs": 9540}, {"Word": "q", "OffsetStartMs": 9540, "OffsetEndMs": 9780}, {"Word": "functions", "OffsetStartMs": 9780, "OffsetEndMs": 10070}, {"Word": "and", "OffsetStartMs": 10360, "OffsetEndMs": 10680}, {"Word": "q", "OffsetStartMs": 10680, "OffsetEndMs": 10890}, {"Word": "neural", "OffsetStartMs": 10890, "OffsetEndMs": 11130}, {"Word": "networks", "OffsetStartMs": 11130, "OffsetEndMs": 11385}, {"Word": "that", "OffsetStartMs": 11385, "OffsetEndMs": 11625}, {"Word": "we", "OffsetStartMs": 11625, "OffsetEndMs": 11745}, {"Word": "saw", "OffsetStartMs": 11745, "OffsetEndMs": 11910}, {"Word": "before", "OffsetStartMs": 11910, "OffsetEndMs": 12200}, {"Word": "and", "OffsetStartMs": 12490, "OffsetEndMs": 12765}, {"Word": "that", "OffsetStartMs": 12765, "OffsetEndMs": 12930}, {"Word": "is", "OffsetStartMs": 12930, "OffsetEndMs": 13215}, {"Word": "the", "OffsetStartMs": 13215, "OffsetEndMs": 13470}, {"Word": "fact", "OffsetStartMs": 13470, "OffsetEndMs": 13650}, {"Word": "that", "OffsetStartMs": 13650, "OffsetEndMs": 13970}, {"Word": "q", "OffsetStartMs": 14020, "OffsetEndMs": 14325}, {"Word": "functions", "OffsetStartMs": 14325, "OffsetEndMs": 14630}, {"Word": "are", "OffsetStartMs": 15430, "OffsetEndMs": 15830}, {"Word": "naturally", "OffsetStartMs": 15880, "OffsetEndMs": 16230}, {"Word": "suited", "OffsetStartMs": 16230, "OffsetEndMs": 16635}, {"Word": "towards", "OffsetStartMs": 16635, "OffsetEndMs": 16920}, {"Word": "discrete", "OffsetStartMs": 16920, "OffsetEndMs": 17445}, {"Word": "action", "OffsetStartMs": 17445, "OffsetEndMs": 17750}, {"Word": "spaces", "OffsetStartMs": 17890, "OffsetEndMs": 18290}, {"Word": "Now", "OffsetStartMs": 18550, "OffsetEndMs": 18930}, {"Word": "when", "OffsetStartMs": 18930, "OffsetEndMs": 19200}, {"Word": "we're", "OffsetStartMs": 19200, "OffsetEndMs": 19425}, {"Word": "looking", "OffsetStartMs": 19425, "OffsetEndMs": 19605}, {"Word": "at", "OffsetStartMs": 19605, "OffsetEndMs": 19905}, {"Word": "this", "OffsetStartMs": 19905, "OffsetEndMs": 20270}, {"Word": "policy", "OffsetStartMs": 20410, "OffsetEndMs": 20810}, {"Word": "network", "OffsetStartMs": 20830, "OffsetEndMs": 21230}, {"Word": "we're", "OffsetStartMs": 21640, "OffsetEndMs": 22065}, {"Word": "puttingting", "OffsetStartMs": 22065, "OffsetEndMs": 22365}, {"Word": "a", "OffsetStartMs": 22365, "OffsetEndMs": 22545}, {"Word": "distributions", "OffsetStartMs": 22545, "OffsetEndMs": 23000}, {"Word": "right", "OffsetStartMs": 23260, "OffsetEndMs": 23610}, {"Word": "And", "OffsetStartMs": 23610, "OffsetEndMs": 23940}, {"Word": "remember", "OffsetStartMs": 23940, "OffsetEndMs": 24270}, {"Word": "those", "OffsetStartMs": 24270, "OffsetEndMs": 24555}, {"Word": "those", "OffsetStartMs": 24555, "OffsetEndMs": 24890}, {"Word": "distributions", "OffsetStartMs": 24970, "OffsetEndMs": 25490}, {"Word": "can", "OffsetStartMs": 25810, "OffsetEndMs": 26210}, {"Word": "also", "OffsetStartMs": 26290, "OffsetEndMs": 26595}, {"Word": "take", "OffsetStartMs": 26595, "OffsetEndMs": 26900}, {"Word": "continuous", "OffsetStartMs": 27190, "OffsetEndMs": 27585}, {"Word": "forms", "OffsetStartMs": 27585, "OffsetEndMs": 27975}, {"Word": "In", "OffsetStartMs": 27975, "OffsetEndMs": 28245}, {"Word": "fact", "OffsetStartMs": 28245, "OffsetEndMs": 28410}, {"Word": "we've", "OffsetStartMs": 28410, "OffsetEndMs": 28650}, {"Word": "seen", "OffsetStartMs": 28650, "OffsetEndMs": 28785}, {"Word": "this", "OffsetStartMs": 28785, "OffsetEndMs": 29060}, {"Word": "in", "OffsetStartMs": 29200, "OffsetEndMs": 29460}, {"Word": "the", "OffsetStartMs": 29460, "OffsetEndMs": 29580}, {"Word": "last", "OffsetStartMs": 29580, "OffsetEndMs": 29820}, {"Word": "two", "OffsetStartMs": 29820, "OffsetEndMs": 30075}, {"Word": "lectures", "OffsetStartMs": 30075, "OffsetEndMs": 30620}, {"Word": "In", "OffsetStartMs": 31300, "OffsetEndMs": 31560}, {"Word": "the", "OffsetStartMs": 31560, "OffsetEndMs": 31820}, {"Word": "generative", "OffsetStartMs": 31930, "OffsetEndMs": 32445}, {"Word": "lecture", "OffsetStartMs": 32445, "OffsetEndMs": 32685}, {"Word": "we", "OffsetStartMs": 32685, "OffsetEndMs": 32925}, {"Word": "saw", "OffsetStartMs": 32925, "OffsetEndMs": 33075}, {"Word": "how", "OffsetStartMs": 33075, "OffsetEndMs": 33270}, {"Word": "ves", "OffsetStartMs": 33270, "OffsetEndMs": 33795}, {"Word": "could", "OffsetStartMs": 33795, "OffsetEndMs": 34035}, {"Word": "be", "OffsetStartMs": 34035, "OffsetEndMs": 34310}, {"Word": "used", "OffsetStartMs": 34420, "OffsetEndMs": 34815}, {"Word": "to", "OffsetStartMs": 34815, "OffsetEndMs": 35085}, {"Word": "predict", "OffsetStartMs": 35085, "OffsetEndMs": 35360}, {"Word": "gaussian", "OffsetStartMs": 35770, "OffsetEndMs": 36420}, {"Word": "distributions", "OffsetStartMs": 36420, "OffsetEndMs": 36860}, {"Word": "over", "OffsetStartMs": 36910, "OffsetEndMs": 37245}, {"Word": "their", "OffsetStartMs": 37245, "OffsetEndMs": 37455}, {"Word": "latent", "OffsetStartMs": 37455, "OffsetEndMs": 37785}, {"Word": "space", "OffsetStartMs": 37785, "OffsetEndMs": 38090}, {"Word": "In", "OffsetStartMs": 38140, "OffsetEndMs": 38400}, {"Word": "the", "OffsetStartMs": 38400, "OffsetEndMs": 38520}, {"Word": "last", "OffsetStartMs": 38520, "OffsetEndMs": 38730}, {"Word": "lecture", "OffsetStartMs": 38730, "OffsetEndMs": 39030}, {"Word": "we", "OffsetStartMs": 39030, "OffsetEndMs": 39315}, {"Word": "also", "OffsetStartMs": 39315, "OffsetEndMs": 39540}, {"Word": "saw", "OffsetStartMs": 39540, "OffsetEndMs": 39830}, {"Word": "how", "OffsetStartMs": 39940, "OffsetEndMs": 40200}, {"Word": "we", "OffsetStartMs": 40200, "OffsetEndMs": 40320}, {"Word": "could", "OffsetStartMs": 40320, "OffsetEndMs": 40455}, {"Word": "learn", "OffsetStartMs": 40455, "OffsetEndMs": 40635}, {"Word": "to", "OffsetStartMs": 40635, "OffsetEndMs": 40815}, {"Word": "predict", "OffsetStartMs": 40815, "OffsetEndMs": 41090}, {"Word": "uncertainties", "OffsetStartMs": 41140, "OffsetEndMs": 41540}, {"Word": "which", "OffsetStartMs": 41770, "OffsetEndMs": 42045}, {"Word": "are", "OffsetStartMs": 42045, "OffsetEndMs": 42300}, {"Word": "continuous", "OffsetStartMs": 42300, "OffsetEndMs": 42660}, {"Word": "probability", "OffsetStartMs": 42660, "OffsetEndMs": 43250}, {"Word": "distributions", "OffsetStartMs": 43330, "OffsetEndMs": 43820}, {"Word": "using", "OffsetStartMs": 44470, "OffsetEndMs": 44870}, {"Word": "data", "OffsetStartMs": 45040, "OffsetEndMs": 45440}, {"Word": "And", "OffsetStartMs": 46420, "OffsetEndMs": 46710}, {"Word": "just", "OffsetStartMs": 46710, "OffsetEndMs": 46905}, {"Word": "like", "OffsetStartMs": 46905, "OffsetEndMs": 47115}, {"Word": "that", "OffsetStartMs": 47115, "OffsetEndMs": 47420}, {"Word": "we", "OffsetStartMs": 47620, "OffsetEndMs": 47895}, {"Word": "could", "OffsetStartMs": 47895, "OffsetEndMs": 48170}, {"Word": "also", "OffsetStartMs": 48190, "OffsetEndMs": 48590}, {"Word": "use", "OffsetStartMs": 48970, "OffsetEndMs": 49370}, {"Word": "this", "OffsetStartMs": 49870, "OffsetEndMs": 50270}, {"Word": "same", "OffsetStartMs": 50380, "OffsetEndMs": 50700}, {"Word": "formulation", "OffsetStartMs": 50700, "OffsetEndMs": 51260}, {"Word": "to", "OffsetStartMs": 51400, "OffsetEndMs": 51660}, {"Word": "move", "OffsetStartMs": 51660, "OffsetEndMs": 51885}, {"Word": "beyond", "OffsetStartMs": 51885, "OffsetEndMs": 52250}, {"Word": "discrete", "OffsetStartMs": 52780, "OffsetEndMs": 53235}, {"Word": "action", "OffsetStartMs": 53235, "OffsetEndMs": 53510}, {"Word": "spaces", "OffsetStartMs": 53560, "OffsetEndMs": 53955}, {"Word": "like", "OffsetStartMs": 53955, "OffsetEndMs": 54225}, {"Word": "you", "OffsetStartMs": 54225, "OffsetEndMs": 54345}, {"Word": "can", "OffsetStartMs": 54345, "OffsetEndMs": 54495}, {"Word": "see", "OffsetStartMs": 54495, "OffsetEndMs": 54720}, {"Word": "here", "OffsetStartMs": 54720, "OffsetEndMs": 55040}, {"Word": "which", "OffsetStartMs": 55120, "OffsetEndMs": 55395}, {"Word": "are", "OffsetStartMs": 55395, "OffsetEndMs": 55670}, {"Word": "one", "OffsetStartMs": 56080, "OffsetEndMs": 56480}, {"Word": "possible", "OffsetStartMs": 56860, "OffsetEndMs": 57260}, {"Word": "action", "OffsetStartMs": 57310, "OffsetEndMs": 57710}, {"Word": "a", "OffsetStartMs": 57760, "OffsetEndMs": 58050}, {"Word": "probability", "OffsetStartMs": 58050, "OffsetEndMs": 58575}, {"Word": "associated", "OffsetStartMs": 58575, "OffsetEndMs": 58950}, {"Word": "to", "OffsetStartMs": 58950, "OffsetEndMs": 59220}, {"Word": "one", "OffsetStartMs": 59220, "OffsetEndMs": 59430}, {"Word": "possible", "OffsetStartMs": 59430, "OffsetEndMs": 59730}, {"Word": "action", "OffsetStartMs": 59730, "OffsetEndMs": 60110}], "SpeechSpeed": 15.4}, {"FinalSentence": "In a discrete set of possible actions, now we may have a space which is not what action should I take, go left, right or say center, but rather how quickly should I move and in what direction should I move right? That is a continuous variable as opposed to a discrete variable. And you could say that now the answer should look like this, moving very fast to the right versus very slow to the, excuse me, very fast to the left versus very slow to the left has this continuous spectrum that we may want to model.", "SliceSentence": "In a discrete set of possible actions now we may have a space which is not what action should I take go left right or say center but rather how quickly should I move and in what direction should I move right That is a continuous variable as opposed to a discrete variable And you could say that now the answer should look like this moving very fast to the right versus very slow to the excuse me very fast to the left versus very slow to the left has this continuous spectrum that we may want to model", "StartMs": 2214140, "EndMs": 2244580, "WordsNum": 99, "Words": [{"Word": "In", "OffsetStartMs": 0, "OffsetEndMs": 120}, {"Word": "a", "OffsetStartMs": 120, "OffsetEndMs": 270}, {"Word": "discrete", "OffsetStartMs": 270, "OffsetEndMs": 765}, {"Word": "set", "OffsetStartMs": 765, "OffsetEndMs": 1035}, {"Word": "of", "OffsetStartMs": 1035, "OffsetEndMs": 1245}, {"Word": "possible", "OffsetStartMs": 1245, "OffsetEndMs": 1545}, {"Word": "actions", "OffsetStartMs": 1545, "OffsetEndMs": 1940}, {"Word": "now", "OffsetStartMs": 2740, "OffsetEndMs": 3140}, {"Word": "we", "OffsetStartMs": 3310, "OffsetEndMs": 3585}, {"Word": "may", "OffsetStartMs": 3585, "OffsetEndMs": 3765}, {"Word": "have", "OffsetStartMs": 3765, "OffsetEndMs": 4020}, {"Word": "a", "OffsetStartMs": 4020, "OffsetEndMs": 4305}, {"Word": "space", "OffsetStartMs": 4305, "OffsetEndMs": 4640}, {"Word": "which", "OffsetStartMs": 4660, "OffsetEndMs": 4935}, {"Word": "is", "OffsetStartMs": 4935, "OffsetEndMs": 5145}, {"Word": "not", "OffsetStartMs": 5145, "OffsetEndMs": 5475}, {"Word": "what", "OffsetStartMs": 5475, "OffsetEndMs": 5775}, {"Word": "action", "OffsetStartMs": 5775, "OffsetEndMs": 6080}, {"Word": "should", "OffsetStartMs": 6250, "OffsetEndMs": 6495}, {"Word": "I", "OffsetStartMs": 6495, "OffsetEndMs": 6660}, {"Word": "take", "OffsetStartMs": 6660, "OffsetEndMs": 6980}, {"Word": "go", "OffsetStartMs": 7000, "OffsetEndMs": 7305}, {"Word": "left", "OffsetStartMs": 7305, "OffsetEndMs": 7575}, {"Word": "right", "OffsetStartMs": 7575, "OffsetEndMs": 7845}, {"Word": "or", "OffsetStartMs": 7845, "OffsetEndMs": 8055}, {"Word": "say", "OffsetStartMs": 8055, "OffsetEndMs": 8295}, {"Word": "center", "OffsetStartMs": 8295, "OffsetEndMs": 8630}, {"Word": "but", "OffsetStartMs": 8860, "OffsetEndMs": 9165}, {"Word": "rather", "OffsetStartMs": 9165, "OffsetEndMs": 9470}, {"Word": "how", "OffsetStartMs": 9700, "OffsetEndMs": 10035}, {"Word": "quickly", "OffsetStartMs": 10035, "OffsetEndMs": 10370}, {"Word": "should", "OffsetStartMs": 10480, "OffsetEndMs": 10725}, {"Word": "I", "OffsetStartMs": 10725, "OffsetEndMs": 10860}, {"Word": "move", "OffsetStartMs": 10860, "OffsetEndMs": 11085}, {"Word": "and", "OffsetStartMs": 11085, "OffsetEndMs": 11265}, {"Word": "in", "OffsetStartMs": 11265, "OffsetEndMs": 11385}, {"Word": "what", "OffsetStartMs": 11385, "OffsetEndMs": 11610}, {"Word": "direction", "OffsetStartMs": 11610, "OffsetEndMs": 11940}, {"Word": "should", "OffsetStartMs": 11940, "OffsetEndMs": 12180}, {"Word": "I", "OffsetStartMs": 12180, "OffsetEndMs": 12330}, {"Word": "move", "OffsetStartMs": 12330, "OffsetEndMs": 12555}, {"Word": "right", "OffsetStartMs": 12555, "OffsetEndMs": 12810}, {"Word": "That", "OffsetStartMs": 12810, "OffsetEndMs": 13020}, {"Word": "is", "OffsetStartMs": 13020, "OffsetEndMs": 13185}, {"Word": "a", "OffsetStartMs": 13185, "OffsetEndMs": 13460}, {"Word": "continuous", "OffsetStartMs": 13510, "OffsetEndMs": 13910}, {"Word": "variable", "OffsetStartMs": 13930, "OffsetEndMs": 14310}, {"Word": "as", "OffsetStartMs": 14310, "OffsetEndMs": 14625}, {"Word": "opposed", "OffsetStartMs": 14625, "OffsetEndMs": 14865}, {"Word": "to", "OffsetStartMs": 14865, "OffsetEndMs": 15000}, {"Word": "a", "OffsetStartMs": 15000, "OffsetEndMs": 15090}, {"Word": "discrete", "OffsetStartMs": 15090, "OffsetEndMs": 15495}, {"Word": "variable", "OffsetStartMs": 15495, "OffsetEndMs": 15800}, {"Word": "And", "OffsetStartMs": 16330, "OffsetEndMs": 16710}, {"Word": "you", "OffsetStartMs": 16710, "OffsetEndMs": 16965}, {"Word": "could", "OffsetStartMs": 16965, "OffsetEndMs": 17145}, {"Word": "say", "OffsetStartMs": 17145, "OffsetEndMs": 17415}, {"Word": "that", "OffsetStartMs": 17415, "OffsetEndMs": 17745}, {"Word": "now", "OffsetStartMs": 17745, "OffsetEndMs": 18015}, {"Word": "the", "OffsetStartMs": 18015, "OffsetEndMs": 18165}, {"Word": "answer", "OffsetStartMs": 18165, "OffsetEndMs": 18410}, {"Word": "should", "OffsetStartMs": 18430, "OffsetEndMs": 18705}, {"Word": "look", "OffsetStartMs": 18705, "OffsetEndMs": 18945}, {"Word": "like", "OffsetStartMs": 18945, "OffsetEndMs": 19230}, {"Word": "this", "OffsetStartMs": 19230, "OffsetEndMs": 19550}, {"Word": "moving", "OffsetStartMs": 20350, "OffsetEndMs": 20750}, {"Word": "very", "OffsetStartMs": 21010, "OffsetEndMs": 21360}, {"Word": "fast", "OffsetStartMs": 21360, "OffsetEndMs": 21660}, {"Word": "to", "OffsetStartMs": 21660, "OffsetEndMs": 21840}, {"Word": "the", "OffsetStartMs": 21840, "OffsetEndMs": 21930}, {"Word": "right", "OffsetStartMs": 21930, "OffsetEndMs": 22125}, {"Word": "versus", "OffsetStartMs": 22125, "OffsetEndMs": 22425}, {"Word": "very", "OffsetStartMs": 22425, "OffsetEndMs": 22755}, {"Word": "slow", "OffsetStartMs": 22755, "OffsetEndMs": 23055}, {"Word": "to", "OffsetStartMs": 23055, "OffsetEndMs": 23235}, {"Word": "the", "OffsetStartMs": 23235, "OffsetEndMs": 23480}, {"Word": "excuse", "OffsetStartMs": 23680, "OffsetEndMs": 23970}, {"Word": "me", "OffsetStartMs": 23970, "OffsetEndMs": 24165}, {"Word": "very", "OffsetStartMs": 24165, "OffsetEndMs": 24375}, {"Word": "fast", "OffsetStartMs": 24375, "OffsetEndMs": 24630}, {"Word": "to", "OffsetStartMs": 24630, "OffsetEndMs": 24810}, {"Word": "the", "OffsetStartMs": 24810, "OffsetEndMs": 24885}, {"Word": "left", "OffsetStartMs": 24885, "OffsetEndMs": 25035}, {"Word": "versus", "OffsetStartMs": 25035, "OffsetEndMs": 25290}, {"Word": "very", "OffsetStartMs": 25290, "OffsetEndMs": 25590}, {"Word": "slow", "OffsetStartMs": 25590, "OffsetEndMs": 25845}, {"Word": "to", "OffsetStartMs": 25845, "OffsetEndMs": 25995}, {"Word": "the", "OffsetStartMs": 25995, "OffsetEndMs": 26100}, {"Word": "left", "OffsetStartMs": 26100, "OffsetEndMs": 26360}, {"Word": "has", "OffsetStartMs": 26830, "OffsetEndMs": 27230}, {"Word": "this", "OffsetStartMs": 27340, "OffsetEndMs": 27740}, {"Word": "continuous", "OffsetStartMs": 27880, "OffsetEndMs": 28280}, {"Word": "spectrum", "OffsetStartMs": 28330, "OffsetEndMs": 28730}, {"Word": "that", "OffsetStartMs": 28810, "OffsetEndMs": 29070}, {"Word": "we", "OffsetStartMs": 29070, "OffsetEndMs": 29205}, {"Word": "may", "OffsetStartMs": 29205, "OffsetEndMs": 29370}, {"Word": "want", "OffsetStartMs": 29370, "OffsetEndMs": 29580}, {"Word": "to", "OffsetStartMs": 29580, "OffsetEndMs": 29760}, {"Word": "model", "OffsetStartMs": 29760, "OffsetEndMs": 30020}], "SpeechSpeed": 16.5}, {"FinalSentence": "Now, when we plot this entire distribution of taking an action, giving a state, you can see basically a very simple illustration of that right here. This, this distribution has most of its mass over, sorry, it has all of its mass over the entire real number line. First of all, it has most of its mass right in the optimal action space that we want to take. So if we want to determine the best action to take, we would simply take the mode of this distribution, the highest point. That would be the speed at which we should move and the direction that we should move in.", "SliceSentence": "Now when we plot this entire distribution of taking an action giving a state you can see basically a very simple illustration of that right here This this distribution has most of its mass over sorry it has all of its mass over the entire real number line First of all it has most of its mass right in the optimal action space that we want to take So if we want to determine the best action to take we would simply take the mode of this distribution the highest point That would be the speed at which we should move and the direction that we should move in", "StartMs": 2245060, "EndMs": 2278200, "WordsNum": 109, "Words": [{"Word": "Now", "OffsetStartMs": 100, "OffsetEndMs": 450}, {"Word": "when", "OffsetStartMs": 450, "OffsetEndMs": 660}, {"Word": "we", "OffsetStartMs": 660, "OffsetEndMs": 840}, {"Word": "plot", "OffsetStartMs": 840, "OffsetEndMs": 1065}, {"Word": "this", "OffsetStartMs": 1065, "OffsetEndMs": 1370}, {"Word": "entire", "OffsetStartMs": 1390, "OffsetEndMs": 1790}, {"Word": "distribution", "OffsetStartMs": 1900, "OffsetEndMs": 2300}, {"Word": "of", "OffsetStartMs": 2560, "OffsetEndMs": 2910}, {"Word": "taking", "OffsetStartMs": 2910, "OffsetEndMs": 3210}, {"Word": "an", "OffsetStartMs": 3210, "OffsetEndMs": 3420}, {"Word": "action", "OffsetStartMs": 3420, "OffsetEndMs": 3680}, {"Word": "giving", "OffsetStartMs": 4090, "OffsetEndMs": 4410}, {"Word": "a", "OffsetStartMs": 4410, "OffsetEndMs": 4665}, {"Word": "state", "OffsetStartMs": 4665, "OffsetEndMs": 5000}, {"Word": "you", "OffsetStartMs": 5200, "OffsetEndMs": 5460}, {"Word": "can", "OffsetStartMs": 5460, "OffsetEndMs": 5670}, {"Word": "see", "OffsetStartMs": 5670, "OffsetEndMs": 6020}, {"Word": "basically", "OffsetStartMs": 6130, "OffsetEndMs": 6510}, {"Word": "a", "OffsetStartMs": 6510, "OffsetEndMs": 6765}, {"Word": "very", "OffsetStartMs": 6765, "OffsetEndMs": 6990}, {"Word": "simple", "OffsetStartMs": 6990, "OffsetEndMs": 7275}, {"Word": "illustration", "OffsetStartMs": 7275, "OffsetEndMs": 7845}, {"Word": "of", "OffsetStartMs": 7845, "OffsetEndMs": 8055}, {"Word": "that", "OffsetStartMs": 8055, "OffsetEndMs": 8330}, {"Word": "right", "OffsetStartMs": 8380, "OffsetEndMs": 8685}, {"Word": "here", "OffsetStartMs": 8685, "OffsetEndMs": 8940}, {"Word": "This", "OffsetStartMs": 8940, "OffsetEndMs": 9290}, {"Word": "this", "OffsetStartMs": 9700, "OffsetEndMs": 10100}, {"Word": "distribution", "OffsetStartMs": 10360, "OffsetEndMs": 10760}, {"Word": "has", "OffsetStartMs": 10930, "OffsetEndMs": 11325}, {"Word": "most", "OffsetStartMs": 11325, "OffsetEndMs": 11670}, {"Word": "of", "OffsetStartMs": 11670, "OffsetEndMs": 11865}, {"Word": "its", "OffsetStartMs": 11865, "OffsetEndMs": 12090}, {"Word": "mass", "OffsetStartMs": 12090, "OffsetEndMs": 12470}, {"Word": "over", "OffsetStartMs": 13450, "OffsetEndMs": 13850}, {"Word": "sorry", "OffsetStartMs": 14290, "OffsetEndMs": 14565}, {"Word": "it", "OffsetStartMs": 14565, "OffsetEndMs": 14685}, {"Word": "has", "OffsetStartMs": 14685, "OffsetEndMs": 14820}, {"Word": "all", "OffsetStartMs": 14820, "OffsetEndMs": 14985}, {"Word": "of", "OffsetStartMs": 14985, "OffsetEndMs": 15090}, {"Word": "its", "OffsetStartMs": 15090, "OffsetEndMs": 15225}, {"Word": "mass", "OffsetStartMs": 15225, "OffsetEndMs": 15450}, {"Word": "over", "OffsetStartMs": 15450, "OffsetEndMs": 15690}, {"Word": "the", "OffsetStartMs": 15690, "OffsetEndMs": 15915}, {"Word": "entire", "OffsetStartMs": 15915, "OffsetEndMs": 16140}, {"Word": "real", "OffsetStartMs": 16140, "OffsetEndMs": 16350}, {"Word": "number", "OffsetStartMs": 16350, "OffsetEndMs": 16575}, {"Word": "line", "OffsetStartMs": 16575, "OffsetEndMs": 16860}, {"Word": "First", "OffsetStartMs": 16860, "OffsetEndMs": 17100}, {"Word": "of", "OffsetStartMs": 17100, "OffsetEndMs": 17235}, {"Word": "all", "OffsetStartMs": 17235, "OffsetEndMs": 17385}, {"Word": "it", "OffsetStartMs": 17385, "OffsetEndMs": 17535}, {"Word": "has", "OffsetStartMs": 17535, "OffsetEndMs": 17730}, {"Word": "most", "OffsetStartMs": 17730, "OffsetEndMs": 18000}, {"Word": "of", "OffsetStartMs": 18000, "OffsetEndMs": 18165}, {"Word": "its", "OffsetStartMs": 18165, "OffsetEndMs": 18330}, {"Word": "mass", "OffsetStartMs": 18330, "OffsetEndMs": 18650}, {"Word": "right", "OffsetStartMs": 19090, "OffsetEndMs": 19485}, {"Word": "in", "OffsetStartMs": 19485, "OffsetEndMs": 19845}, {"Word": "the", "OffsetStartMs": 19845, "OffsetEndMs": 20205}, {"Word": "optimal", "OffsetStartMs": 20205, "OffsetEndMs": 20550}, {"Word": "action", "OffsetStartMs": 20550, "OffsetEndMs": 20810}, {"Word": "space", "OffsetStartMs": 20980, "OffsetEndMs": 21300}, {"Word": "that", "OffsetStartMs": 21300, "OffsetEndMs": 21480}, {"Word": "we", "OffsetStartMs": 21480, "OffsetEndMs": 21600}, {"Word": "want", "OffsetStartMs": 21600, "OffsetEndMs": 21735}, {"Word": "to", "OffsetStartMs": 21735, "OffsetEndMs": 21855}, {"Word": "take", "OffsetStartMs": 21855, "OffsetEndMs": 21990}, {"Word": "So", "OffsetStartMs": 21990, "OffsetEndMs": 22125}, {"Word": "if", "OffsetStartMs": 22125, "OffsetEndMs": 22230}, {"Word": "we", "OffsetStartMs": 22230, "OffsetEndMs": 22335}, {"Word": "want", "OffsetStartMs": 22335, "OffsetEndMs": 22470}, {"Word": "to", "OffsetStartMs": 22470, "OffsetEndMs": 22680}, {"Word": "determine", "OffsetStartMs": 22680, "OffsetEndMs": 22995}, {"Word": "the", "OffsetStartMs": 22995, "OffsetEndMs": 23280}, {"Word": "best", "OffsetStartMs": 23280, "OffsetEndMs": 23520}, {"Word": "action", "OffsetStartMs": 23520, "OffsetEndMs": 23865}, {"Word": "to", "OffsetStartMs": 23865, "OffsetEndMs": 24135}, {"Word": "take", "OffsetStartMs": 24135, "OffsetEndMs": 24410}, {"Word": "we", "OffsetStartMs": 24610, "OffsetEndMs": 24870}, {"Word": "would", "OffsetStartMs": 24870, "OffsetEndMs": 25065}, {"Word": "simply", "OffsetStartMs": 25065, "OffsetEndMs": 25365}, {"Word": "take", "OffsetStartMs": 25365, "OffsetEndMs": 25730}, {"Word": "the", "OffsetStartMs": 25780, "OffsetEndMs": 26175}, {"Word": "mode", "OffsetStartMs": 26175, "OffsetEndMs": 26570}, {"Word": "of", "OffsetStartMs": 26590, "OffsetEndMs": 26880}, {"Word": "this", "OffsetStartMs": 26880, "OffsetEndMs": 27135}, {"Word": "distribution", "OffsetStartMs": 27135, "OffsetEndMs": 27500}, {"Word": "the", "OffsetStartMs": 27730, "OffsetEndMs": 27975}, {"Word": "highest", "OffsetStartMs": 27975, "OffsetEndMs": 28200}, {"Word": "point", "OffsetStartMs": 28200, "OffsetEndMs": 28580}, {"Word": "That", "OffsetStartMs": 28780, "OffsetEndMs": 29055}, {"Word": "would", "OffsetStartMs": 29055, "OffsetEndMs": 29205}, {"Word": "be", "OffsetStartMs": 29205, "OffsetEndMs": 29445}, {"Word": "the", "OffsetStartMs": 29445, "OffsetEndMs": 29810}, {"Word": "speed", "OffsetStartMs": 29920, "OffsetEndMs": 30270}, {"Word": "at", "OffsetStartMs": 30270, "OffsetEndMs": 30495}, {"Word": "which", "OffsetStartMs": 30495, "OffsetEndMs": 30660}, {"Word": "we", "OffsetStartMs": 30660, "OffsetEndMs": 30855}, {"Word": "should", "OffsetStartMs": 30855, "OffsetEndMs": 31065}, {"Word": "move", "OffsetStartMs": 31065, "OffsetEndMs": 31260}, {"Word": "and", "OffsetStartMs": 31260, "OffsetEndMs": 31440}, {"Word": "the", "OffsetStartMs": 31440, "OffsetEndMs": 31605}, {"Word": "direction", "OffsetStartMs": 31605, "OffsetEndMs": 31845}, {"Word": "that", "OffsetStartMs": 31845, "OffsetEndMs": 32070}, {"Word": "we", "OffsetStartMs": 32070, "OffsetEndMs": 32190}, {"Word": "should", "OffsetStartMs": 32190, "OffsetEndMs": 32325}, {"Word": "move", "OffsetStartMs": 32325, "OffsetEndMs": 32475}, {"Word": "in", "OffsetStartMs": 32475, "OffsetEndMs": 32750}], "SpeechSpeed": 16.8}, {"FinalSentence": "If we wanted to also, you know, try out different things and explore our space, we could sample from this distribution and still obtain some stochasticity.", "SliceSentence": "If we wanted to also you know try out different things and explore our space we could sample from this distribution and still obtain some stochasticity", "StartMs": 2278220, "EndMs": 2288280, "WordsNum": 26, "Words": [{"Word": "If", "OffsetStartMs": 220, "OffsetEndMs": 510}, {"Word": "we", "OffsetStartMs": 510, "OffsetEndMs": 675}, {"Word": "wanted", "OffsetStartMs": 675, "OffsetEndMs": 950}, {"Word": "to", "OffsetStartMs": 1060, "OffsetEndMs": 1460}, {"Word": "also", "OffsetStartMs": 1630, "OffsetEndMs": 2025}, {"Word": "you", "OffsetStartMs": 2025, "OffsetEndMs": 2280}, {"Word": "know", "OffsetStartMs": 2280, "OffsetEndMs": 2460}, {"Word": "try", "OffsetStartMs": 2460, "OffsetEndMs": 2655}, {"Word": "out", "OffsetStartMs": 2655, "OffsetEndMs": 2835}, {"Word": "different", "OffsetStartMs": 2835, "OffsetEndMs": 3135}, {"Word": "things", "OffsetStartMs": 3135, "OffsetEndMs": 3450}, {"Word": "and", "OffsetStartMs": 3450, "OffsetEndMs": 3750}, {"Word": "explore", "OffsetStartMs": 3750, "OffsetEndMs": 4035}, {"Word": "our", "OffsetStartMs": 4035, "OffsetEndMs": 4275}, {"Word": "space", "OffsetStartMs": 4275, "OffsetEndMs": 4610}, {"Word": "we", "OffsetStartMs": 4840, "OffsetEndMs": 5100}, {"Word": "could", "OffsetStartMs": 5100, "OffsetEndMs": 5310}, {"Word": "sample", "OffsetStartMs": 5310, "OffsetEndMs": 5660}, {"Word": "from", "OffsetStartMs": 5740, "OffsetEndMs": 6030}, {"Word": "this", "OffsetStartMs": 6030, "OffsetEndMs": 6300}, {"Word": "distribution", "OffsetStartMs": 6300, "OffsetEndMs": 6680}, {"Word": "and", "OffsetStartMs": 6880, "OffsetEndMs": 7245}, {"Word": "still", "OffsetStartMs": 7245, "OffsetEndMs": 7455}, {"Word": "obtain", "OffsetStartMs": 7455, "OffsetEndMs": 7815}, {"Word": "some", "OffsetStartMs": 7815, "OffsetEndMs": 8055}, {"Word": "stochasticity", "OffsetStartMs": 8055, "OffsetEndMs": 8990}], "SpeechSpeed": 15.0}, {"FinalSentence": "Now let's look at an example of how we can actually model these continuous distributions and actually we've already seen some examples of this in the previous two lectures like I mentioned, but let's take a look specifically in the context of reinforcement learning and policy gradient learning. So instead of predicting this probability of taking an action, giving all possible states, which in this case there is now an infinite number of, because we're in the continuous domain, we can't simply predict a single probability for every possible action because there's an infinite number of them. So instead, what if we parameterized our action space by distribution, right? So let's take for example, the gaussian distribution to parameterize a gaussian distribution. We only need two outputs, right, we need a mean and a variance. Given a mean and a variance we can actually have a probability mass and we can compute a probability over any possible action that we may want to take just from those two numbers. So for example, in this image here we may want to output a gou.", "SliceSentence": "Now let's look at an example of how we can actually model these continuous distributions and actually we've already seen some examples of this in the previous two lectures like I mentioned but let's take a look specifically in the context of reinforcement learning and policy gradient learning So instead of predicting this probability of taking an action giving all possible states which in this case there is now an infinite number of because we're in the continuous domain we can't simply predict a single probability for every possible action because there's an infinite number of them So instead what if we parameterized our action space by distribution right So let's take for example the gaussian distribution to parameterize a gaussian distribution We only need two outputs right we need a mean and a variance Given a mean and a variance we can actually have a probability mass and we can compute a probability over any possible action that we may want to take just from those two numbers So for example in this image here we may want to output a gou", "StartMs": 2289380, "EndMs": 2349860, "WordsNum": 183, "Words": [{"Word": "Now", "OffsetStartMs": 100, "OffsetEndMs": 500}, {"Word": "let's", "OffsetStartMs": 550, "OffsetEndMs": 885}, {"Word": "look", "OffsetStartMs": 885, "OffsetEndMs": 990}, {"Word": "at", "OffsetStartMs": 990, "OffsetEndMs": 1215}, {"Word": "an", "OffsetStartMs": 1215, "OffsetEndMs": 1545}, {"Word": "example", "OffsetStartMs": 1545, "OffsetEndMs": 1890}, {"Word": "of", "OffsetStartMs": 1890, "OffsetEndMs": 2130}, {"Word": "how", "OffsetStartMs": 2130, "OffsetEndMs": 2280}, {"Word": "we", "OffsetStartMs": 2280, "OffsetEndMs": 2415}, {"Word": "can", "OffsetStartMs": 2415, "OffsetEndMs": 2595}, {"Word": "actually", "OffsetStartMs": 2595, "OffsetEndMs": 2910}, {"Word": "model", "OffsetStartMs": 2910, "OffsetEndMs": 3290}, {"Word": "these", "OffsetStartMs": 3430, "OffsetEndMs": 3830}, {"Word": "continuous", "OffsetStartMs": 4060, "OffsetEndMs": 4460}, {"Word": "distributions", "OffsetStartMs": 4570, "OffsetEndMs": 5090}, {"Word": "and", "OffsetStartMs": 5140, "OffsetEndMs": 5475}, {"Word": "actually", "OffsetStartMs": 5475, "OffsetEndMs": 5685}, {"Word": "we've", "OffsetStartMs": 5685, "OffsetEndMs": 5940}, {"Word": "already", "OffsetStartMs": 5940, "OffsetEndMs": 6165}, {"Word": "seen", "OffsetStartMs": 6165, "OffsetEndMs": 6435}, {"Word": "some", "OffsetStartMs": 6435, "OffsetEndMs": 6705}, {"Word": "examples", "OffsetStartMs": 6705, "OffsetEndMs": 7005}, {"Word": "of", "OffsetStartMs": 7005, "OffsetEndMs": 7245}, {"Word": "this", "OffsetStartMs": 7245, "OffsetEndMs": 7410}, {"Word": "in", "OffsetStartMs": 7410, "OffsetEndMs": 7575}, {"Word": "the", "OffsetStartMs": 7575, "OffsetEndMs": 7710}, {"Word": "previous", "OffsetStartMs": 7710, "OffsetEndMs": 7935}, {"Word": "two", "OffsetStartMs": 7935, "OffsetEndMs": 8160}, {"Word": "lectures", "OffsetStartMs": 8160, "OffsetEndMs": 8475}, {"Word": "like", "OffsetStartMs": 8475, "OffsetEndMs": 8625}, {"Word": "I", "OffsetStartMs": 8625, "OffsetEndMs": 8835}, {"Word": "mentioned", "OffsetStartMs": 8835, "OffsetEndMs": 9170}, {"Word": "but", "OffsetStartMs": 9520, "OffsetEndMs": 9765}, {"Word": "let's", "OffsetStartMs": 9765, "OffsetEndMs": 10020}, {"Word": "take", "OffsetStartMs": 10020, "OffsetEndMs": 10185}, {"Word": "a", "OffsetStartMs": 10185, "OffsetEndMs": 10320}, {"Word": "look", "OffsetStartMs": 10320, "OffsetEndMs": 10575}, {"Word": "specifically", "OffsetStartMs": 10575, "OffsetEndMs": 10970}, {"Word": "in", "OffsetStartMs": 11020, "OffsetEndMs": 11265}, {"Word": "the", "OffsetStartMs": 11265, "OffsetEndMs": 11385}, {"Word": "context", "OffsetStartMs": 11385, "OffsetEndMs": 11660}, {"Word": "of", "OffsetStartMs": 11770, "OffsetEndMs": 12075}, {"Word": "reinforcement", "OffsetStartMs": 12075, "OffsetEndMs": 12660}, {"Word": "learning", "OffsetStartMs": 12660, "OffsetEndMs": 12870}, {"Word": "and", "OffsetStartMs": 12870, "OffsetEndMs": 13110}, {"Word": "policy", "OffsetStartMs": 13110, "OffsetEndMs": 13380}, {"Word": "gradient", "OffsetStartMs": 13380, "OffsetEndMs": 13815}, {"Word": "learning", "OffsetStartMs": 13815, "OffsetEndMs": 14090}, {"Word": "So", "OffsetStartMs": 14680, "OffsetEndMs": 15030}, {"Word": "instead", "OffsetStartMs": 15030, "OffsetEndMs": 15240}, {"Word": "of", "OffsetStartMs": 15240, "OffsetEndMs": 15390}, {"Word": "predicting", "OffsetStartMs": 15390, "OffsetEndMs": 16005}, {"Word": "this", "OffsetStartMs": 16005, "OffsetEndMs": 16400}, {"Word": "probability", "OffsetStartMs": 16570, "OffsetEndMs": 17270}, {"Word": "of", "OffsetStartMs": 17650, "OffsetEndMs": 17955}, {"Word": "taking", "OffsetStartMs": 17955, "OffsetEndMs": 18180}, {"Word": "an", "OffsetStartMs": 18180, "OffsetEndMs": 18360}, {"Word": "action", "OffsetStartMs": 18360, "OffsetEndMs": 18620}, {"Word": "giving", "OffsetStartMs": 18670, "OffsetEndMs": 19005}, {"Word": "all", "OffsetStartMs": 19005, "OffsetEndMs": 19275}, {"Word": "possible", "OffsetStartMs": 19275, "OffsetEndMs": 19610}, {"Word": "states", "OffsetStartMs": 19930, "OffsetEndMs": 20325}, {"Word": "which", "OffsetStartMs": 20325, "OffsetEndMs": 20655}, {"Word": "in", "OffsetStartMs": 20655, "OffsetEndMs": 20880}, {"Word": "this", "OffsetStartMs": 20880, "OffsetEndMs": 21090}, {"Word": "case", "OffsetStartMs": 21090, "OffsetEndMs": 21410}, {"Word": "there", "OffsetStartMs": 21430, "OffsetEndMs": 21690}, {"Word": "is", "OffsetStartMs": 21690, "OffsetEndMs": 21825}, {"Word": "now", "OffsetStartMs": 21825, "OffsetEndMs": 21975}, {"Word": "an", "OffsetStartMs": 21975, "OffsetEndMs": 22125}, {"Word": "infinite", "OffsetStartMs": 22125, "OffsetEndMs": 22635}, {"Word": "number", "OffsetStartMs": 22635, "OffsetEndMs": 22890}, {"Word": "of", "OffsetStartMs": 22890, "OffsetEndMs": 23240}, {"Word": "because", "OffsetStartMs": 23260, "OffsetEndMs": 23535}, {"Word": "we're", "OffsetStartMs": 23535, "OffsetEndMs": 23715}, {"Word": "in", "OffsetStartMs": 23715, "OffsetEndMs": 23760}, {"Word": "the", "OffsetStartMs": 23760, "OffsetEndMs": 23955}, {"Word": "continuous", "OffsetStartMs": 23955, "OffsetEndMs": 24300}, {"Word": "domain", "OffsetStartMs": 24300, "OffsetEndMs": 24680}, {"Word": "we", "OffsetStartMs": 25000, "OffsetEndMs": 25290}, {"Word": "can't", "OffsetStartMs": 25290, "OffsetEndMs": 25700}, {"Word": "simply", "OffsetStartMs": 25720, "OffsetEndMs": 26085}, {"Word": "predict", "OffsetStartMs": 26085, "OffsetEndMs": 26400}, {"Word": "a", "OffsetStartMs": 26400, "OffsetEndMs": 26670}, {"Word": "single", "OffsetStartMs": 26670, "OffsetEndMs": 26925}, {"Word": "probability", "OffsetStartMs": 26925, "OffsetEndMs": 27405}, {"Word": "for", "OffsetStartMs": 27405, "OffsetEndMs": 27660}, {"Word": "every", "OffsetStartMs": 27660, "OffsetEndMs": 27915}, {"Word": "possible", "OffsetStartMs": 27915, "OffsetEndMs": 28260}, {"Word": "action", "OffsetStartMs": 28260, "OffsetEndMs": 28640}, {"Word": "because", "OffsetStartMs": 29380, "OffsetEndMs": 29655}, {"Word": "there's", "OffsetStartMs": 29655, "OffsetEndMs": 29880}, {"Word": "an", "OffsetStartMs": 29880, "OffsetEndMs": 29955}, {"Word": "infinite", "OffsetStartMs": 29955, "OffsetEndMs": 30315}, {"Word": "number", "OffsetStartMs": 30315, "OffsetEndMs": 30465}, {"Word": "of", "OffsetStartMs": 30465, "OffsetEndMs": 30645}, {"Word": "them", "OffsetStartMs": 30645, "OffsetEndMs": 30920}, {"Word": "So", "OffsetStartMs": 31180, "OffsetEndMs": 31530}, {"Word": "instead", "OffsetStartMs": 31530, "OffsetEndMs": 31880}, {"Word": "what", "OffsetStartMs": 32230, "OffsetEndMs": 32490}, {"Word": "if", "OffsetStartMs": 32490, "OffsetEndMs": 32640}, {"Word": "we", "OffsetStartMs": 32640, "OffsetEndMs": 32930}, {"Word": "parameterized", "OffsetStartMs": 32950, "OffsetEndMs": 33740}, {"Word": "our", "OffsetStartMs": 34060, "OffsetEndMs": 34350}, {"Word": "action", "OffsetStartMs": 34350, "OffsetEndMs": 34640}, {"Word": "space", "OffsetStartMs": 34750, "OffsetEndMs": 35150}, {"Word": "by", "OffsetStartMs": 35260, "OffsetEndMs": 35660}, {"Word": "distribution", "OffsetStartMs": 36610, "OffsetEndMs": 37010}, {"Word": "right", "OffsetStartMs": 37180, "OffsetEndMs": 37485}, {"Word": "So", "OffsetStartMs": 37485, "OffsetEndMs": 37635}, {"Word": "let's", "OffsetStartMs": 37635, "OffsetEndMs": 37830}, {"Word": "take", "OffsetStartMs": 37830, "OffsetEndMs": 37980}, {"Word": "for", "OffsetStartMs": 37980, "OffsetEndMs": 38160}, {"Word": "example", "OffsetStartMs": 38160, "OffsetEndMs": 38450}, {"Word": "the", "OffsetStartMs": 38470, "OffsetEndMs": 38730}, {"Word": "gaussian", "OffsetStartMs": 38730, "OffsetEndMs": 39195}, {"Word": "distribution", "OffsetStartMs": 39195, "OffsetEndMs": 39560}, {"Word": "to", "OffsetStartMs": 40600, "OffsetEndMs": 40980}, {"Word": "parameterize", "OffsetStartMs": 40980, "OffsetEndMs": 41655}, {"Word": "a", "OffsetStartMs": 41655, "OffsetEndMs": 41895}, {"Word": "gaussian", "OffsetStartMs": 41895, "OffsetEndMs": 42330}, {"Word": "distribution", "OffsetStartMs": 42330, "OffsetEndMs": 42680}, {"Word": "We", "OffsetStartMs": 42940, "OffsetEndMs": 43215}, {"Word": "only", "OffsetStartMs": 43215, "OffsetEndMs": 43440}, {"Word": "need", "OffsetStartMs": 43440, "OffsetEndMs": 43740}, {"Word": "two", "OffsetStartMs": 43740, "OffsetEndMs": 44085}, {"Word": "outputs", "OffsetStartMs": 44085, "OffsetEndMs": 44565}, {"Word": "right", "OffsetStartMs": 44565, "OffsetEndMs": 44925}, {"Word": "we", "OffsetStartMs": 44925, "OffsetEndMs": 45180}, {"Word": "need", "OffsetStartMs": 45180, "OffsetEndMs": 45300}, {"Word": "a", "OffsetStartMs": 45300, "OffsetEndMs": 45435}, {"Word": "mean", "OffsetStartMs": 45435, "OffsetEndMs": 45660}, {"Word": "and", "OffsetStartMs": 45660, "OffsetEndMs": 45870}, {"Word": "a", "OffsetStartMs": 45870, "OffsetEndMs": 45990}, {"Word": "variance", "OffsetStartMs": 45990, "OffsetEndMs": 46490}, {"Word": "Given", "OffsetStartMs": 46540, "OffsetEndMs": 46845}, {"Word": "a", "OffsetStartMs": 46845, "OffsetEndMs": 47010}, {"Word": "mean", "OffsetStartMs": 47010, "OffsetEndMs": 47160}, {"Word": "and", "OffsetStartMs": 47160, "OffsetEndMs": 47310}, {"Word": "a", "OffsetStartMs": 47310, "OffsetEndMs": 47430}, {"Word": "variance", "OffsetStartMs": 47430, "OffsetEndMs": 47930}, {"Word": "we", "OffsetStartMs": 48070, "OffsetEndMs": 48330}, {"Word": "can", "OffsetStartMs": 48330, "OffsetEndMs": 48555}, {"Word": "actually", "OffsetStartMs": 48555, "OffsetEndMs": 48810}, {"Word": "have", "OffsetStartMs": 48810, "OffsetEndMs": 48975}, {"Word": "a", "OffsetStartMs": 48975, "OffsetEndMs": 49125}, {"Word": "probability", "OffsetStartMs": 49125, "OffsetEndMs": 49575}, {"Word": "mass", "OffsetStartMs": 49575, "OffsetEndMs": 49940}, {"Word": "and", "OffsetStartMs": 50050, "OffsetEndMs": 50310}, {"Word": "we", "OffsetStartMs": 50310, "OffsetEndMs": 50445}, {"Word": "can", "OffsetStartMs": 50445, "OffsetEndMs": 50595}, {"Word": "compute", "OffsetStartMs": 50595, "OffsetEndMs": 50865}, {"Word": "a", "OffsetStartMs": 50865, "OffsetEndMs": 50985}, {"Word": "probability", "OffsetStartMs": 50985, "OffsetEndMs": 51440}, {"Word": "over", "OffsetStartMs": 51670, "OffsetEndMs": 52020}, {"Word": "any", "OffsetStartMs": 52020, "OffsetEndMs": 52370}, {"Word": "possible", "OffsetStartMs": 52660, "OffsetEndMs": 53040}, {"Word": "action", "OffsetStartMs": 53040, "OffsetEndMs": 53420}, {"Word": "that", "OffsetStartMs": 53560, "OffsetEndMs": 53820}, {"Word": "we", "OffsetStartMs": 53820, "OffsetEndMs": 53940}, {"Word": "may", "OffsetStartMs": 53940, "OffsetEndMs": 54075}, {"Word": "want", "OffsetStartMs": 54075, "OffsetEndMs": 54240}, {"Word": "to", "OffsetStartMs": 54240, "OffsetEndMs": 54420}, {"Word": "take", "OffsetStartMs": 54420, "OffsetEndMs": 54660}, {"Word": "just", "OffsetStartMs": 54660, "OffsetEndMs": 54900}, {"Word": "from", "OffsetStartMs": 54900, "OffsetEndMs": 55065}, {"Word": "those", "OffsetStartMs": 55065, "OffsetEndMs": 55275}, {"Word": "two", "OffsetStartMs": 55275, "OffsetEndMs": 55485}, {"Word": "numbers", "OffsetStartMs": 55485, "OffsetEndMs": 55760}, {"Word": "So", "OffsetStartMs": 56380, "OffsetEndMs": 56640}, {"Word": "for", "OffsetStartMs": 56640, "OffsetEndMs": 56790}, {"Word": "example", "OffsetStartMs": 56790, "OffsetEndMs": 57000}, {"Word": "in", "OffsetStartMs": 57000, "OffsetEndMs": 57195}, {"Word": "this", "OffsetStartMs": 57195, "OffsetEndMs": 57360}, {"Word": "image", "OffsetStartMs": 57360, "OffsetEndMs": 57645}, {"Word": "here", "OffsetStartMs": 57645, "OffsetEndMs": 58040}, {"Word": "we", "OffsetStartMs": 58330, "OffsetEndMs": 58620}, {"Word": "may", "OffsetStartMs": 58620, "OffsetEndMs": 58905}, {"Word": "want", "OffsetStartMs": 58905, "OffsetEndMs": 59235}, {"Word": "to", "OffsetStartMs": 59235, "OffsetEndMs": 59565}, {"Word": "output", "OffsetStartMs": 59565, "OffsetEndMs": 59880}, {"Word": "a", "OffsetStartMs": 59880, "OffsetEndMs": 60135}, {"Word": "gou", "OffsetStartMs": 60135, "OffsetEndMs": 60450}], "SpeechSpeed": 17.5}, {"FinalSentence": "That looks like this right? Its mean is centered at, let's see, negative 0.8 indicating that we should move basically left with a speed of 0.8 meters per second for example. And again we can see that because this is a probability distribution because of the format of policy networks, right, we're enforcing that this is a probability distribution. That means that the integral now of this, of this outputs right by definition of it being a gaussian, must also integrate to one.", "SliceSentence": "That looks like this right Its mean is centered at let's see negative 0.8 indicating that we should move basically left with a speed of 0.8 meters per second for example And again we can see that because this is a probability distribution because of the format of policy networks right we're enforcing that this is a probability distribution That means that the integral now of this of this outputs right by definition of it being a gaussian must also integrate to one", "StartMs": 2349860, "EndMs": 2384720, "WordsNum": 83, "Words": [{"Word": "That", "OffsetStartMs": 250, "OffsetEndMs": 540}, {"Word": "looks", "OffsetStartMs": 540, "OffsetEndMs": 735}, {"Word": "like", "OffsetStartMs": 735, "OffsetEndMs": 945}, {"Word": "this", "OffsetStartMs": 945, "OffsetEndMs": 1200}, {"Word": "right", "OffsetStartMs": 1200, "OffsetEndMs": 1440}, {"Word": "Its", "OffsetStartMs": 1440, "OffsetEndMs": 1680}, {"Word": "mean", "OffsetStartMs": 1680, "OffsetEndMs": 2030}, {"Word": "is", "OffsetStartMs": 2140, "OffsetEndMs": 2445}, {"Word": "centered", "OffsetStartMs": 2445, "OffsetEndMs": 2960}, {"Word": "at", "OffsetStartMs": 3430, "OffsetEndMs": 3830}, {"Word": "let's", "OffsetStartMs": 4690, "OffsetEndMs": 5040}, {"Word": "see", "OffsetStartMs": 5040, "OffsetEndMs": 5205}, {"Word": "negative", "OffsetStartMs": 5205, "OffsetEndMs": 5540}, {"Word": "0.8", "OffsetStartMs": 5560, "OffsetEndMs": 6440}, {"Word": "indicating", "OffsetStartMs": 6640, "OffsetEndMs": 7230}, {"Word": "that", "OffsetStartMs": 7230, "OffsetEndMs": 7455}, {"Word": "we", "OffsetStartMs": 7455, "OffsetEndMs": 7605}, {"Word": "should", "OffsetStartMs": 7605, "OffsetEndMs": 7755}, {"Word": "move", "OffsetStartMs": 7755, "OffsetEndMs": 8030}, {"Word": "basically", "OffsetStartMs": 8170, "OffsetEndMs": 8570}, {"Word": "left", "OffsetStartMs": 8890, "OffsetEndMs": 9290}, {"Word": "with", "OffsetStartMs": 9640, "OffsetEndMs": 9915}, {"Word": "a", "OffsetStartMs": 9915, "OffsetEndMs": 10155}, {"Word": "speed", "OffsetStartMs": 10155, "OffsetEndMs": 10485}, {"Word": "of", "OffsetStartMs": 10485, "OffsetEndMs": 10850}, {"Word": "0.8", "OffsetStartMs": 11230, "OffsetEndMs": 12045}, {"Word": "meters", "OffsetStartMs": 12045, "OffsetEndMs": 12390}, {"Word": "per", "OffsetStartMs": 12390, "OffsetEndMs": 12645}, {"Word": "second", "OffsetStartMs": 12645, "OffsetEndMs": 12920}, {"Word": "for", "OffsetStartMs": 12940, "OffsetEndMs": 13260}, {"Word": "example", "OffsetStartMs": 13260, "OffsetEndMs": 13580}, {"Word": "And", "OffsetStartMs": 14080, "OffsetEndMs": 14385}, {"Word": "again", "OffsetStartMs": 14385, "OffsetEndMs": 14655}, {"Word": "we", "OffsetStartMs": 14655, "OffsetEndMs": 14880}, {"Word": "can", "OffsetStartMs": 14880, "OffsetEndMs": 15030}, {"Word": "see", "OffsetStartMs": 15030, "OffsetEndMs": 15180}, {"Word": "that", "OffsetStartMs": 15180, "OffsetEndMs": 15440}, {"Word": "because", "OffsetStartMs": 16060, "OffsetEndMs": 16440}, {"Word": "this", "OffsetStartMs": 16440, "OffsetEndMs": 16695}, {"Word": "is", "OffsetStartMs": 16695, "OffsetEndMs": 16830}, {"Word": "a", "OffsetStartMs": 16830, "OffsetEndMs": 17090}, {"Word": "probability", "OffsetStartMs": 17200, "OffsetEndMs": 17810}, {"Word": "distribution", "OffsetStartMs": 17920, "OffsetEndMs": 18320}, {"Word": "because", "OffsetStartMs": 18460, "OffsetEndMs": 18860}, {"Word": "of", "OffsetStartMs": 19840, "OffsetEndMs": 20115}, {"Word": "the", "OffsetStartMs": 20115, "OffsetEndMs": 20295}, {"Word": "format", "OffsetStartMs": 20295, "OffsetEndMs": 20600}, {"Word": "of", "OffsetStartMs": 20920, "OffsetEndMs": 21320}, {"Word": "policy", "OffsetStartMs": 21460, "OffsetEndMs": 21860}, {"Word": "networks", "OffsetStartMs": 22180, "OffsetEndMs": 22580}, {"Word": "right", "OffsetStartMs": 23050, "OffsetEndMs": 23385}, {"Word": "we're", "OffsetStartMs": 23385, "OffsetEndMs": 23625}, {"Word": "enforcing", "OffsetStartMs": 23625, "OffsetEndMs": 24150}, {"Word": "that", "OffsetStartMs": 24150, "OffsetEndMs": 24270}, {"Word": "this", "OffsetStartMs": 24270, "OffsetEndMs": 24390}, {"Word": "is", "OffsetStartMs": 24390, "OffsetEndMs": 24510}, {"Word": "a", "OffsetStartMs": 24510, "OffsetEndMs": 24630}, {"Word": "probability", "OffsetStartMs": 24630, "OffsetEndMs": 25100}, {"Word": "distribution", "OffsetStartMs": 25180, "OffsetEndMs": 25580}, {"Word": "That", "OffsetStartMs": 25990, "OffsetEndMs": 26295}, {"Word": "means", "OffsetStartMs": 26295, "OffsetEndMs": 26600}, {"Word": "that", "OffsetStartMs": 26710, "OffsetEndMs": 26985}, {"Word": "the", "OffsetStartMs": 26985, "OffsetEndMs": 27135}, {"Word": "integral", "OffsetStartMs": 27135, "OffsetEndMs": 27720}, {"Word": "now", "OffsetStartMs": 27720, "OffsetEndMs": 28100}, {"Word": "of", "OffsetStartMs": 28330, "OffsetEndMs": 28665}, {"Word": "this", "OffsetStartMs": 28665, "OffsetEndMs": 29000}, {"Word": "of", "OffsetStartMs": 29110, "OffsetEndMs": 29400}, {"Word": "this", "OffsetStartMs": 29400, "OffsetEndMs": 29690}, {"Word": "outputs", "OffsetStartMs": 29740, "OffsetEndMs": 30255}, {"Word": "right", "OffsetStartMs": 30255, "OffsetEndMs": 30650}, {"Word": "by", "OffsetStartMs": 30760, "OffsetEndMs": 31035}, {"Word": "definition", "OffsetStartMs": 31035, "OffsetEndMs": 31310}, {"Word": "of", "OffsetStartMs": 31390, "OffsetEndMs": 31650}, {"Word": "it", "OffsetStartMs": 31650, "OffsetEndMs": 31770}, {"Word": "being", "OffsetStartMs": 31770, "OffsetEndMs": 31905}, {"Word": "a", "OffsetStartMs": 31905, "OffsetEndMs": 32055}, {"Word": "gaussian", "OffsetStartMs": 32055, "OffsetEndMs": 32550}, {"Word": "must", "OffsetStartMs": 32550, "OffsetEndMs": 32900}, {"Word": "also", "OffsetStartMs": 32980, "OffsetEndMs": 33380}, {"Word": "integrate", "OffsetStartMs": 33400, "OffsetEndMs": 34035}, {"Word": "to", "OffsetStartMs": 34035, "OffsetEndMs": 34290}, {"Word": "one", "OffsetStartMs": 34290, "OffsetEndMs": 34550}], "SpeechSpeed": 14.2}, {"FinalSentence": "Okay, great. So now let's maybe take a look at how policy gradient networks can be trained and, you know, step through that process as well as we look at a very concrete example. And maybe let's start by just revisiting this reinforcement learning loop that we started this class with now.", "SliceSentence": "Okay great So now let's maybe take a look at how policy gradient networks can be trained and you know step through that process as well as we look at a very concrete example And maybe let's start by just revisiting this reinforcement learning loop that we started this class with now", "StartMs": 2387640, "EndMs": 2407620, "WordsNum": 52, "Words": [{"Word": "Okay", "OffsetStartMs": 250, "OffsetEndMs": 540}, {"Word": "great", "OffsetStartMs": 540, "OffsetEndMs": 765}, {"Word": "So", "OffsetStartMs": 765, "OffsetEndMs": 1080}, {"Word": "now", "OffsetStartMs": 1080, "OffsetEndMs": 1380}, {"Word": "let's", "OffsetStartMs": 1380, "OffsetEndMs": 1845}, {"Word": "maybe", "OffsetStartMs": 1845, "OffsetEndMs": 2235}, {"Word": "take", "OffsetStartMs": 2235, "OffsetEndMs": 2520}, {"Word": "a", "OffsetStartMs": 2520, "OffsetEndMs": 2700}, {"Word": "look", "OffsetStartMs": 2700, "OffsetEndMs": 2990}, {"Word": "at", "OffsetStartMs": 3100, "OffsetEndMs": 3435}, {"Word": "how", "OffsetStartMs": 3435, "OffsetEndMs": 3770}, {"Word": "policy", "OffsetStartMs": 4000, "OffsetEndMs": 4400}, {"Word": "gradient", "OffsetStartMs": 4420, "OffsetEndMs": 4920}, {"Word": "networks", "OffsetStartMs": 4920, "OffsetEndMs": 5240}, {"Word": "can", "OffsetStartMs": 5650, "OffsetEndMs": 5925}, {"Word": "be", "OffsetStartMs": 5925, "OffsetEndMs": 6120}, {"Word": "trained", "OffsetStartMs": 6120, "OffsetEndMs": 6440}, {"Word": "and", "OffsetStartMs": 6820, "OffsetEndMs": 7220}, {"Word": "you", "OffsetStartMs": 7270, "OffsetEndMs": 7515}, {"Word": "know", "OffsetStartMs": 7515, "OffsetEndMs": 7650}, {"Word": "step", "OffsetStartMs": 7650, "OffsetEndMs": 7860}, {"Word": "through", "OffsetStartMs": 7860, "OffsetEndMs": 8040}, {"Word": "that", "OffsetStartMs": 8040, "OffsetEndMs": 8235}, {"Word": "process", "OffsetStartMs": 8235, "OffsetEndMs": 8570}, {"Word": "as", "OffsetStartMs": 8590, "OffsetEndMs": 8910}, {"Word": "well", "OffsetStartMs": 8910, "OffsetEndMs": 9230}, {"Word": "as", "OffsetStartMs": 9580, "OffsetEndMs": 9930}, {"Word": "we", "OffsetStartMs": 9930, "OffsetEndMs": 10280}, {"Word": "look", "OffsetStartMs": 10480, "OffsetEndMs": 10755}, {"Word": "at", "OffsetStartMs": 10755, "OffsetEndMs": 10920}, {"Word": "a", "OffsetStartMs": 10920, "OffsetEndMs": 11070}, {"Word": "very", "OffsetStartMs": 11070, "OffsetEndMs": 11330}, {"Word": "concrete", "OffsetStartMs": 11410, "OffsetEndMs": 11745}, {"Word": "example", "OffsetStartMs": 11745, "OffsetEndMs": 12080}, {"Word": "And", "OffsetStartMs": 12130, "OffsetEndMs": 12420}, {"Word": "maybe", "OffsetStartMs": 12420, "OffsetEndMs": 12630}, {"Word": "let's", "OffsetStartMs": 12630, "OffsetEndMs": 13065}, {"Word": "start", "OffsetStartMs": 13065, "OffsetEndMs": 13365}, {"Word": "by", "OffsetStartMs": 13365, "OffsetEndMs": 13575}, {"Word": "just", "OffsetStartMs": 13575, "OffsetEndMs": 13770}, {"Word": "revisiting", "OffsetStartMs": 13770, "OffsetEndMs": 14475}, {"Word": "this", "OffsetStartMs": 14475, "OffsetEndMs": 14745}, {"Word": "reinforcement", "OffsetStartMs": 14745, "OffsetEndMs": 15405}, {"Word": "learning", "OffsetStartMs": 15405, "OffsetEndMs": 15680}, {"Word": "loop", "OffsetStartMs": 16090, "OffsetEndMs": 16490}, {"Word": "that", "OffsetStartMs": 16540, "OffsetEndMs": 16815}, {"Word": "we", "OffsetStartMs": 16815, "OffsetEndMs": 17010}, {"Word": "started", "OffsetStartMs": 17010, "OffsetEndMs": 17280}, {"Word": "this", "OffsetStartMs": 17280, "OffsetEndMs": 17580}, {"Word": "class", "OffsetStartMs": 17580, "OffsetEndMs": 17880}, {"Word": "with", "OffsetStartMs": 17880, "OffsetEndMs": 18230}, {"Word": "now", "OffsetStartMs": 18880, "OffsetEndMs": 19280}], "SpeechSpeed": 14.2}, {"FinalSentence": "Let's specifically consider the example of training an autonomous vehicles, since I think that this is a particularly very intuitive example that we can walk through the agent. Here is the vehicle, right?", "SliceSentence": "Let's specifically consider the example of training an autonomous vehicles since I think that this is a particularly very intuitive example that we can walk through the agent Here is the vehicle right", "StartMs": 2407740, "EndMs": 2419740, "WordsNum": 33, "Words": [{"Word": "Let's", "OffsetStartMs": 130, "OffsetEndMs": 525}, {"Word": "specifically", "OffsetStartMs": 525, "OffsetEndMs": 800}, {"Word": "consider", "OffsetStartMs": 1090, "OffsetEndMs": 1410}, {"Word": "the", "OffsetStartMs": 1410, "OffsetEndMs": 1665}, {"Word": "example", "OffsetStartMs": 1665, "OffsetEndMs": 2000}, {"Word": "of", "OffsetStartMs": 2200, "OffsetEndMs": 2600}, {"Word": "training", "OffsetStartMs": 2770, "OffsetEndMs": 3150}, {"Word": "an", "OffsetStartMs": 3150, "OffsetEndMs": 3375}, {"Word": "autonomous", "OffsetStartMs": 3375, "OffsetEndMs": 3825}, {"Word": "vehicles", "OffsetStartMs": 3825, "OffsetEndMs": 4100}, {"Word": "since", "OffsetStartMs": 4120, "OffsetEndMs": 4380}, {"Word": "I", "OffsetStartMs": 4380, "OffsetEndMs": 4515}, {"Word": "think", "OffsetStartMs": 4515, "OffsetEndMs": 4665}, {"Word": "that", "OffsetStartMs": 4665, "OffsetEndMs": 4800}, {"Word": "this", "OffsetStartMs": 4800, "OffsetEndMs": 4920}, {"Word": "is", "OffsetStartMs": 4920, "OffsetEndMs": 5040}, {"Word": "a", "OffsetStartMs": 5040, "OffsetEndMs": 5280}, {"Word": "particularly", "OffsetStartMs": 5280, "OffsetEndMs": 5660}, {"Word": "very", "OffsetStartMs": 5890, "OffsetEndMs": 6255}, {"Word": "intuitive", "OffsetStartMs": 6255, "OffsetEndMs": 7065}, {"Word": "example", "OffsetStartMs": 7065, "OffsetEndMs": 7380}, {"Word": "that", "OffsetStartMs": 7380, "OffsetEndMs": 7590}, {"Word": "we", "OffsetStartMs": 7590, "OffsetEndMs": 7725}, {"Word": "can", "OffsetStartMs": 7725, "OffsetEndMs": 7875}, {"Word": "walk", "OffsetStartMs": 7875, "OffsetEndMs": 8100}, {"Word": "through", "OffsetStartMs": 8100, "OffsetEndMs": 8450}, {"Word": "the", "OffsetStartMs": 8710, "OffsetEndMs": 8955}, {"Word": "agent", "OffsetStartMs": 8955, "OffsetEndMs": 9195}, {"Word": "Here", "OffsetStartMs": 9195, "OffsetEndMs": 9590}, {"Word": "is", "OffsetStartMs": 9940, "OffsetEndMs": 10320}, {"Word": "the", "OffsetStartMs": 10320, "OffsetEndMs": 10545}, {"Word": "vehicle", "OffsetStartMs": 10545, "OffsetEndMs": 10790}, {"Word": "right", "OffsetStartMs": 11410, "OffsetEndMs": 11810}], "SpeechSpeed": 16.7}, {"FinalSentence": "The state could be obtained through many sensors that could be mounted on the vehicle itself. So, for example, autonomous vehicles are typically equipped with sensors like cameras, lidars, radars etc, all of these are giving observational inputs to the to the vehicle.", "SliceSentence": "The state could be obtained through many sensors that could be mounted on the vehicle itself So for example autonomous vehicles are typically equipped with sensors like cameras lidars radars etc all of these are giving observational inputs to the to the vehicle", "StartMs": 2419880, "EndMs": 2436720, "WordsNum": 43, "Words": [{"Word": "The", "OffsetStartMs": 130, "OffsetEndMs": 450}, {"Word": "state", "OffsetStartMs": 450, "OffsetEndMs": 770}, {"Word": "could", "OffsetStartMs": 1120, "OffsetEndMs": 1380}, {"Word": "be", "OffsetStartMs": 1380, "OffsetEndMs": 1500}, {"Word": "obtained", "OffsetStartMs": 1500, "OffsetEndMs": 2000}, {"Word": "through", "OffsetStartMs": 2140, "OffsetEndMs": 2445}, {"Word": "many", "OffsetStartMs": 2445, "OffsetEndMs": 2700}, {"Word": "sensors", "OffsetStartMs": 2700, "OffsetEndMs": 3270}, {"Word": "that", "OffsetStartMs": 3270, "OffsetEndMs": 3555}, {"Word": "could", "OffsetStartMs": 3555, "OffsetEndMs": 3720}, {"Word": "be", "OffsetStartMs": 3720, "OffsetEndMs": 3930}, {"Word": "mounted", "OffsetStartMs": 3930, "OffsetEndMs": 4470}, {"Word": "on", "OffsetStartMs": 4470, "OffsetEndMs": 4695}, {"Word": "the", "OffsetStartMs": 4695, "OffsetEndMs": 4860}, {"Word": "vehicle", "OffsetStartMs": 4860, "OffsetEndMs": 5120}, {"Word": "itself", "OffsetStartMs": 5230, "OffsetEndMs": 5580}, {"Word": "So", "OffsetStartMs": 5580, "OffsetEndMs": 5820}, {"Word": "for", "OffsetStartMs": 5820, "OffsetEndMs": 6015}, {"Word": "example", "OffsetStartMs": 6015, "OffsetEndMs": 6320}, {"Word": "autonomous", "OffsetStartMs": 6580, "OffsetEndMs": 7185}, {"Word": "vehicles", "OffsetStartMs": 7185, "OffsetEndMs": 7425}, {"Word": "are", "OffsetStartMs": 7425, "OffsetEndMs": 7665}, {"Word": "typically", "OffsetStartMs": 7665, "OffsetEndMs": 7940}, {"Word": "equipped", "OffsetStartMs": 8110, "OffsetEndMs": 8475}, {"Word": "with", "OffsetStartMs": 8475, "OffsetEndMs": 8715}, {"Word": "sensors", "OffsetStartMs": 8715, "OffsetEndMs": 9195}, {"Word": "like", "OffsetStartMs": 9195, "OffsetEndMs": 9530}, {"Word": "cameras", "OffsetStartMs": 9580, "OffsetEndMs": 9980}, {"Word": "lidars", "OffsetStartMs": 10150, "OffsetEndMs": 10755}, {"Word": "radars", "OffsetStartMs": 10755, "OffsetEndMs": 11340}, {"Word": "etc", "OffsetStartMs": 11340, "OffsetEndMs": 11870}, {"Word": "all", "OffsetStartMs": 12070, "OffsetEndMs": 12345}, {"Word": "of", "OffsetStartMs": 12345, "OffsetEndMs": 12480}, {"Word": "these", "OffsetStartMs": 12480, "OffsetEndMs": 12615}, {"Word": "are", "OffsetStartMs": 12615, "OffsetEndMs": 12780}, {"Word": "giving", "OffsetStartMs": 12780, "OffsetEndMs": 13070}, {"Word": "observational", "OffsetStartMs": 13120, "OffsetEndMs": 13610}, {"Word": "inputs", "OffsetStartMs": 13780, "OffsetEndMs": 14270}, {"Word": "to", "OffsetStartMs": 14560, "OffsetEndMs": 14895}, {"Word": "the", "OffsetStartMs": 14895, "OffsetEndMs": 15230}, {"Word": "to", "OffsetStartMs": 15490, "OffsetEndMs": 15750}, {"Word": "the", "OffsetStartMs": 15750, "OffsetEndMs": 15855}, {"Word": "vehicle", "OffsetStartMs": 15855, "OffsetEndMs": 16100}], "SpeechSpeed": 15.5}, {"FinalSentence": "The action that we could take is a steering wheel angle. This is not a discrete variable. This is a continuous variable. It's actually an angle that could take any real number. And finally, the reward in this very simplistic example is the distance that we travel before we crash.", "SliceSentence": "The action that we could take is a steering wheel angle This is not a discrete variable This is a continuous variable It's actually an angle that could take any real number And finally the reward in this very simplistic example is the distance that we travel before we crash", "StartMs": 2436720, "EndMs": 2452700, "WordsNum": 50, "Words": [{"Word": "The", "OffsetStartMs": 130, "OffsetEndMs": 375}, {"Word": "action", "OffsetStartMs": 375, "OffsetEndMs": 620}, {"Word": "that", "OffsetStartMs": 850, "OffsetEndMs": 1110}, {"Word": "we", "OffsetStartMs": 1110, "OffsetEndMs": 1230}, {"Word": "could", "OffsetStartMs": 1230, "OffsetEndMs": 1380}, {"Word": "take", "OffsetStartMs": 1380, "OffsetEndMs": 1670}, {"Word": "is", "OffsetStartMs": 1720, "OffsetEndMs": 2040}, {"Word": "a", "OffsetStartMs": 2040, "OffsetEndMs": 2280}, {"Word": "steering", "OffsetStartMs": 2280, "OffsetEndMs": 2565}, {"Word": "wheel", "OffsetStartMs": 2565, "OffsetEndMs": 2700}, {"Word": "angle", "OffsetStartMs": 2700, "OffsetEndMs": 2960}, {"Word": "This", "OffsetStartMs": 3190, "OffsetEndMs": 3450}, {"Word": "is", "OffsetStartMs": 3450, "OffsetEndMs": 3600}, {"Word": "not", "OffsetStartMs": 3600, "OffsetEndMs": 3765}, {"Word": "a", "OffsetStartMs": 3765, "OffsetEndMs": 3900}, {"Word": "discrete", "OffsetStartMs": 3900, "OffsetEndMs": 4275}, {"Word": "variable", "OffsetStartMs": 4275, "OffsetEndMs": 4575}, {"Word": "This", "OffsetStartMs": 4575, "OffsetEndMs": 4830}, {"Word": "is", "OffsetStartMs": 4830, "OffsetEndMs": 4950}, {"Word": "a", "OffsetStartMs": 4950, "OffsetEndMs": 5160}, {"Word": "continuous", "OffsetStartMs": 5160, "OffsetEndMs": 5490}, {"Word": "variable", "OffsetStartMs": 5490, "OffsetEndMs": 5870}, {"Word": "It's", "OffsetStartMs": 5890, "OffsetEndMs": 6330}, {"Word": "actually", "OffsetStartMs": 6330, "OffsetEndMs": 6525}, {"Word": "an", "OffsetStartMs": 6525, "OffsetEndMs": 6645}, {"Word": "angle", "OffsetStartMs": 6645, "OffsetEndMs": 6900}, {"Word": "that", "OffsetStartMs": 6900, "OffsetEndMs": 7155}, {"Word": "could", "OffsetStartMs": 7155, "OffsetEndMs": 7305}, {"Word": "take", "OffsetStartMs": 7305, "OffsetEndMs": 7470}, {"Word": "any", "OffsetStartMs": 7470, "OffsetEndMs": 7695}, {"Word": "real", "OffsetStartMs": 7695, "OffsetEndMs": 7950}, {"Word": "number", "OffsetStartMs": 7950, "OffsetEndMs": 8270}, {"Word": "And", "OffsetStartMs": 9100, "OffsetEndMs": 9390}, {"Word": "finally", "OffsetStartMs": 9390, "OffsetEndMs": 9680}, {"Word": "the", "OffsetStartMs": 9760, "OffsetEndMs": 10110}, {"Word": "reward", "OffsetStartMs": 10110, "OffsetEndMs": 10460}, {"Word": "in", "OffsetStartMs": 10780, "OffsetEndMs": 11055}, {"Word": "this", "OffsetStartMs": 11055, "OffsetEndMs": 11265}, {"Word": "very", "OffsetStartMs": 11265, "OffsetEndMs": 11550}, {"Word": "simplistic", "OffsetStartMs": 11550, "OffsetEndMs": 12195}, {"Word": "example", "OffsetStartMs": 12195, "OffsetEndMs": 12480}, {"Word": "is", "OffsetStartMs": 12480, "OffsetEndMs": 12735}, {"Word": "the", "OffsetStartMs": 12735, "OffsetEndMs": 12915}, {"Word": "distance", "OffsetStartMs": 12915, "OffsetEndMs": 13170}, {"Word": "that", "OffsetStartMs": 13170, "OffsetEndMs": 13425}, {"Word": "we", "OffsetStartMs": 13425, "OffsetEndMs": 13575}, {"Word": "travel", "OffsetStartMs": 13575, "OffsetEndMs": 13850}, {"Word": "before", "OffsetStartMs": 13900, "OffsetEndMs": 14220}, {"Word": "we", "OffsetStartMs": 14220, "OffsetEndMs": 14430}, {"Word": "crash", "OffsetStartMs": 14430, "OffsetEndMs": 14720}], "SpeechSpeed": 17.1}, {"FinalSentence": "Okay, so now let's take a look at how we could train a policy gradient neural network to solve this task of self driving cars as a concrete example. So we start by initializing our agent right. Remember that we have no training data, right? So we have to think about actually reinforcement learning is almost like a data acquisition plus learning pipeline combined together. So the first part of that data acquisition pipeline is first to initialize our agent to go out and collect some data.", "SliceSentence": "Okay so now let's take a look at how we could train a policy gradient neural network to solve this task of self driving cars as a concrete example So we start by initializing our agent right Remember that we have no training data right So we have to think about actually reinforcement learning is almost like a data acquisition plus learning pipeline combined together So the first part of that data acquisition pipeline is first to initialize our agent to go out and collect some data", "StartMs": 2453440, "EndMs": 2482680, "WordsNum": 87, "Words": [{"Word": "Okay", "OffsetStartMs": 220, "OffsetEndMs": 540}, {"Word": "so", "OffsetStartMs": 540, "OffsetEndMs": 720}, {"Word": "now", "OffsetStartMs": 720, "OffsetEndMs": 855}, {"Word": "let's", "OffsetStartMs": 855, "OffsetEndMs": 1155}, {"Word": "take", "OffsetStartMs": 1155, "OffsetEndMs": 1365}, {"Word": "a", "OffsetStartMs": 1365, "OffsetEndMs": 1500}, {"Word": "look", "OffsetStartMs": 1500, "OffsetEndMs": 1635}, {"Word": "at", "OffsetStartMs": 1635, "OffsetEndMs": 1785}, {"Word": "how", "OffsetStartMs": 1785, "OffsetEndMs": 1950}, {"Word": "we", "OffsetStartMs": 1950, "OffsetEndMs": 2115}, {"Word": "could", "OffsetStartMs": 2115, "OffsetEndMs": 2325}, {"Word": "train", "OffsetStartMs": 2325, "OffsetEndMs": 2655}, {"Word": "a", "OffsetStartMs": 2655, "OffsetEndMs": 2955}, {"Word": "policy", "OffsetStartMs": 2955, "OffsetEndMs": 3260}, {"Word": "gradient", "OffsetStartMs": 3280, "OffsetEndMs": 3860}, {"Word": "neural", "OffsetStartMs": 4210, "OffsetEndMs": 4575}, {"Word": "network", "OffsetStartMs": 4575, "OffsetEndMs": 4850}, {"Word": "to", "OffsetStartMs": 5080, "OffsetEndMs": 5400}, {"Word": "solve", "OffsetStartMs": 5400, "OffsetEndMs": 5685}, {"Word": "this", "OffsetStartMs": 5685, "OffsetEndMs": 5970}, {"Word": "task", "OffsetStartMs": 5970, "OffsetEndMs": 6290}, {"Word": "of", "OffsetStartMs": 6340, "OffsetEndMs": 6630}, {"Word": "self", "OffsetStartMs": 6630, "OffsetEndMs": 6840}, {"Word": "driving", "OffsetStartMs": 6840, "OffsetEndMs": 7140}, {"Word": "cars", "OffsetStartMs": 7140, "OffsetEndMs": 7520}, {"Word": "as", "OffsetStartMs": 7540, "OffsetEndMs": 7815}, {"Word": "a", "OffsetStartMs": 7815, "OffsetEndMs": 8085}, {"Word": "concrete", "OffsetStartMs": 8085, "OffsetEndMs": 8400}, {"Word": "example", "OffsetStartMs": 8400, "OffsetEndMs": 8720}, {"Word": "So", "OffsetStartMs": 9910, "OffsetEndMs": 10310}, {"Word": "we", "OffsetStartMs": 10480, "OffsetEndMs": 10815}, {"Word": "start", "OffsetStartMs": 10815, "OffsetEndMs": 11150}, {"Word": "by", "OffsetStartMs": 11710, "OffsetEndMs": 12110}, {"Word": "initializing", "OffsetStartMs": 12190, "OffsetEndMs": 12810}, {"Word": "our", "OffsetStartMs": 12810, "OffsetEndMs": 13080}, {"Word": "agent", "OffsetStartMs": 13080, "OffsetEndMs": 13400}, {"Word": "right", "OffsetStartMs": 13720, "OffsetEndMs": 14120}, {"Word": "Remember", "OffsetStartMs": 14350, "OffsetEndMs": 14670}, {"Word": "that", "OffsetStartMs": 14670, "OffsetEndMs": 14835}, {"Word": "we", "OffsetStartMs": 14835, "OffsetEndMs": 14925}, {"Word": "have", "OffsetStartMs": 14925, "OffsetEndMs": 15045}, {"Word": "no", "OffsetStartMs": 15045, "OffsetEndMs": 15255}, {"Word": "training", "OffsetStartMs": 15255, "OffsetEndMs": 15540}, {"Word": "data", "OffsetStartMs": 15540, "OffsetEndMs": 15810}, {"Word": "right", "OffsetStartMs": 15810, "OffsetEndMs": 16035}, {"Word": "So", "OffsetStartMs": 16035, "OffsetEndMs": 16320}, {"Word": "we", "OffsetStartMs": 16320, "OffsetEndMs": 16545}, {"Word": "have", "OffsetStartMs": 16545, "OffsetEndMs": 16680}, {"Word": "to", "OffsetStartMs": 16680, "OffsetEndMs": 16830}, {"Word": "think", "OffsetStartMs": 16830, "OffsetEndMs": 17010}, {"Word": "about", "OffsetStartMs": 17010, "OffsetEndMs": 17310}, {"Word": "actually", "OffsetStartMs": 17310, "OffsetEndMs": 17640}, {"Word": "reinforcement", "OffsetStartMs": 17640, "OffsetEndMs": 18315}, {"Word": "learning", "OffsetStartMs": 18315, "OffsetEndMs": 18510}, {"Word": "is", "OffsetStartMs": 18510, "OffsetEndMs": 18765}, {"Word": "almost", "OffsetStartMs": 18765, "OffsetEndMs": 18990}, {"Word": "like", "OffsetStartMs": 18990, "OffsetEndMs": 19140}, {"Word": "a", "OffsetStartMs": 19140, "OffsetEndMs": 19260}, {"Word": "data", "OffsetStartMs": 19260, "OffsetEndMs": 19500}, {"Word": "acquisition", "OffsetStartMs": 19500, "OffsetEndMs": 19880}, {"Word": "plus", "OffsetStartMs": 20170, "OffsetEndMs": 20550}, {"Word": "learning", "OffsetStartMs": 20550, "OffsetEndMs": 20930}, {"Word": "pipeline", "OffsetStartMs": 20980, "OffsetEndMs": 21380}, {"Word": "combined", "OffsetStartMs": 21910, "OffsetEndMs": 22305}, {"Word": "together", "OffsetStartMs": 22305, "OffsetEndMs": 22650}, {"Word": "So", "OffsetStartMs": 22650, "OffsetEndMs": 22845}, {"Word": "the", "OffsetStartMs": 22845, "OffsetEndMs": 22950}, {"Word": "first", "OffsetStartMs": 22950, "OffsetEndMs": 23145}, {"Word": "part", "OffsetStartMs": 23145, "OffsetEndMs": 23355}, {"Word": "of", "OffsetStartMs": 23355, "OffsetEndMs": 23505}, {"Word": "that", "OffsetStartMs": 23505, "OffsetEndMs": 23780}, {"Word": "data", "OffsetStartMs": 23830, "OffsetEndMs": 24225}, {"Word": "acquisition", "OffsetStartMs": 24225, "OffsetEndMs": 24620}, {"Word": "pipeline", "OffsetStartMs": 24700, "OffsetEndMs": 25100}, {"Word": "is", "OffsetStartMs": 25480, "OffsetEndMs": 25770}, {"Word": "first", "OffsetStartMs": 25770, "OffsetEndMs": 25980}, {"Word": "to", "OffsetStartMs": 25980, "OffsetEndMs": 26175}, {"Word": "initialize", "OffsetStartMs": 26175, "OffsetEndMs": 26625}, {"Word": "our", "OffsetStartMs": 26625, "OffsetEndMs": 26805}, {"Word": "agent", "OffsetStartMs": 26805, "OffsetEndMs": 27080}, {"Word": "to", "OffsetStartMs": 27220, "OffsetEndMs": 27480}, {"Word": "go", "OffsetStartMs": 27480, "OffsetEndMs": 27615}, {"Word": "out", "OffsetStartMs": 27615, "OffsetEndMs": 27765}, {"Word": "and", "OffsetStartMs": 27765, "OffsetEndMs": 27945}, {"Word": "collect", "OffsetStartMs": 27945, "OffsetEndMs": 28170}, {"Word": "some", "OffsetStartMs": 28170, "OffsetEndMs": 28380}, {"Word": "data", "OffsetStartMs": 28380, "OffsetEndMs": 28670}], "SpeechSpeed": 16.6}, {"FinalSentence": "So we start our.", "SliceSentence": "So we start our", "StartMs": 2484380, "EndMs": 2486640, "WordsNum": 4, "Words": [{"Word": "So", "OffsetStartMs": 130, "OffsetEndMs": 375}, {"Word": "we", "OffsetStartMs": 375, "OffsetEndMs": 510}, {"Word": "start", "OffsetStartMs": 510, "OffsetEndMs": 750}, {"Word": "our", "OffsetStartMs": 750, "OffsetEndMs": 1100}], "SpeechSpeed": 6.6}, {"FinalSentence": "Vehicle, our agent. And in the beginning, of course, it knows nothing about driving. It's never been exposed to any of these rules of the environment or the observation before. So it runs its policy, which right now is untrained entirely until it terminates, right until it goes outside of some bounds that we define. We measure basically the reward as the distance that it traveled before it terminated.", "SliceSentence": "Vehicle our agent And in the beginning of course it knows nothing about driving It's never been exposed to any of these rules of the environment or the observation before So it runs its policy which right now is untrained entirely until it terminates right until it goes outside of some bounds that we define We measure basically the reward as the distance that it traveled before it terminated", "StartMs": 2486640, "EndMs": 2510540, "WordsNum": 69, "Words": [{"Word": "Vehicle", "OffsetStartMs": 0, "OffsetEndMs": 380}, {"Word": "our", "OffsetStartMs": 430, "OffsetEndMs": 735}, {"Word": "agent", "OffsetStartMs": 735, "OffsetEndMs": 1040}, {"Word": "And", "OffsetStartMs": 1450, "OffsetEndMs": 1845}, {"Word": "in", "OffsetStartMs": 1845, "OffsetEndMs": 2100}, {"Word": "the", "OffsetStartMs": 2100, "OffsetEndMs": 2235}, {"Word": "beginning", "OffsetStartMs": 2235, "OffsetEndMs": 2430}, {"Word": "of", "OffsetStartMs": 2430, "OffsetEndMs": 2640}, {"Word": "course", "OffsetStartMs": 2640, "OffsetEndMs": 2820}, {"Word": "it", "OffsetStartMs": 2820, "OffsetEndMs": 2985}, {"Word": "knows", "OffsetStartMs": 2985, "OffsetEndMs": 3195}, {"Word": "nothing", "OffsetStartMs": 3195, "OffsetEndMs": 3495}, {"Word": "about", "OffsetStartMs": 3495, "OffsetEndMs": 3780}, {"Word": "driving", "OffsetStartMs": 3780, "OffsetEndMs": 4100}, {"Word": "It's", "OffsetStartMs": 4120, "OffsetEndMs": 4485}, {"Word": "never", "OffsetStartMs": 4485, "OffsetEndMs": 4760}, {"Word": "been", "OffsetStartMs": 5200, "OffsetEndMs": 5565}, {"Word": "exposed", "OffsetStartMs": 5565, "OffsetEndMs": 5835}, {"Word": "to", "OffsetStartMs": 5835, "OffsetEndMs": 5970}, {"Word": "any", "OffsetStartMs": 5970, "OffsetEndMs": 6090}, {"Word": "of", "OffsetStartMs": 6090, "OffsetEndMs": 6255}, {"Word": "these", "OffsetStartMs": 6255, "OffsetEndMs": 6450}, {"Word": "rules", "OffsetStartMs": 6450, "OffsetEndMs": 6770}, {"Word": "of", "OffsetStartMs": 6820, "OffsetEndMs": 7110}, {"Word": "the", "OffsetStartMs": 7110, "OffsetEndMs": 7305}, {"Word": "environment", "OffsetStartMs": 7305, "OffsetEndMs": 7610}, {"Word": "or", "OffsetStartMs": 7660, "OffsetEndMs": 7935}, {"Word": "the", "OffsetStartMs": 7935, "OffsetEndMs": 8130}, {"Word": "observation", "OffsetStartMs": 8130, "OffsetEndMs": 8450}, {"Word": "before", "OffsetStartMs": 8560, "OffsetEndMs": 8960}, {"Word": "So", "OffsetStartMs": 9010, "OffsetEndMs": 9410}, {"Word": "it", "OffsetStartMs": 9550, "OffsetEndMs": 9870}, {"Word": "runs", "OffsetStartMs": 9870, "OffsetEndMs": 10095}, {"Word": "its", "OffsetStartMs": 10095, "OffsetEndMs": 10335}, {"Word": "policy", "OffsetStartMs": 10335, "OffsetEndMs": 10670}, {"Word": "which", "OffsetStartMs": 10840, "OffsetEndMs": 11240}, {"Word": "right", "OffsetStartMs": 11290, "OffsetEndMs": 11580}, {"Word": "now", "OffsetStartMs": 11580, "OffsetEndMs": 11760}, {"Word": "is", "OffsetStartMs": 11760, "OffsetEndMs": 12000}, {"Word": "untrained", "OffsetStartMs": 12000, "OffsetEndMs": 12650}, {"Word": "entirely", "OffsetStartMs": 12880, "OffsetEndMs": 13280}, {"Word": "until", "OffsetStartMs": 14020, "OffsetEndMs": 14280}, {"Word": "it", "OffsetStartMs": 14280, "OffsetEndMs": 14445}, {"Word": "terminates", "OffsetStartMs": 14445, "OffsetEndMs": 14880}, {"Word": "right", "OffsetStartMs": 14880, "OffsetEndMs": 15180}, {"Word": "until", "OffsetStartMs": 15180, "OffsetEndMs": 15435}, {"Word": "it", "OffsetStartMs": 15435, "OffsetEndMs": 15585}, {"Word": "goes", "OffsetStartMs": 15585, "OffsetEndMs": 15860}, {"Word": "outside", "OffsetStartMs": 15880, "OffsetEndMs": 16140}, {"Word": "of", "OffsetStartMs": 16140, "OffsetEndMs": 16275}, {"Word": "some", "OffsetStartMs": 16275, "OffsetEndMs": 16410}, {"Word": "bounds", "OffsetStartMs": 16410, "OffsetEndMs": 16680}, {"Word": "that", "OffsetStartMs": 16680, "OffsetEndMs": 16875}, {"Word": "we", "OffsetStartMs": 16875, "OffsetEndMs": 17040}, {"Word": "define", "OffsetStartMs": 17040, "OffsetEndMs": 17360}, {"Word": "We", "OffsetStartMs": 17620, "OffsetEndMs": 17940}, {"Word": "measure", "OffsetStartMs": 17940, "OffsetEndMs": 18260}, {"Word": "basically", "OffsetStartMs": 18850, "OffsetEndMs": 19250}, {"Word": "the", "OffsetStartMs": 19300, "OffsetEndMs": 19650}, {"Word": "reward", "OffsetStartMs": 19650, "OffsetEndMs": 19965}, {"Word": "as", "OffsetStartMs": 19965, "OffsetEndMs": 20265}, {"Word": "the", "OffsetStartMs": 20265, "OffsetEndMs": 20490}, {"Word": "distance", "OffsetStartMs": 20490, "OffsetEndMs": 20780}, {"Word": "that", "OffsetStartMs": 20860, "OffsetEndMs": 21120}, {"Word": "it", "OffsetStartMs": 21120, "OffsetEndMs": 21300}, {"Word": "traveled", "OffsetStartMs": 21300, "OffsetEndMs": 21780}, {"Word": "before", "OffsetStartMs": 21780, "OffsetEndMs": 22130}, {"Word": "it", "OffsetStartMs": 22330, "OffsetEndMs": 22635}, {"Word": "terminated", "OffsetStartMs": 22635, "OffsetEndMs": 23210}], "SpeechSpeed": 16.5}, {"FinalSentence": "And we record all of the states, all of the actions and the final reward that it obtained until that termination, right? This becomes our mini data set that we'll use for the first round of training. Let's take those data sets. And now we'll do one step of training. The first step of training that we'll do is to take me to take the later half of our.", "SliceSentence": "And we record all of the states all of the actions and the final reward that it obtained until that termination right This becomes our mini data set that we'll use for the first round of training Let's take those data sets And now we'll do one step of training The first step of training that we'll do is to take me to take the later half of our", "StartMs": 2510540, "EndMs": 2536640, "WordsNum": 69, "Words": [{"Word": "And", "OffsetStartMs": 130, "OffsetEndMs": 405}, {"Word": "we", "OffsetStartMs": 405, "OffsetEndMs": 660}, {"Word": "record", "OffsetStartMs": 660, "OffsetEndMs": 1040}, {"Word": "all", "OffsetStartMs": 1150, "OffsetEndMs": 1470}, {"Word": "of", "OffsetStartMs": 1470, "OffsetEndMs": 1680}, {"Word": "the", "OffsetStartMs": 1680, "OffsetEndMs": 1905}, {"Word": "states", "OffsetStartMs": 1905, "OffsetEndMs": 2240}, {"Word": "all", "OffsetStartMs": 2470, "OffsetEndMs": 2760}, {"Word": "of", "OffsetStartMs": 2760, "OffsetEndMs": 2925}, {"Word": "the", "OffsetStartMs": 2925, "OffsetEndMs": 3060}, {"Word": "actions", "OffsetStartMs": 3060, "OffsetEndMs": 3320}, {"Word": "and", "OffsetStartMs": 3850, "OffsetEndMs": 4250}, {"Word": "the", "OffsetStartMs": 4270, "OffsetEndMs": 4545}, {"Word": "final", "OffsetStartMs": 4545, "OffsetEndMs": 4820}, {"Word": "reward", "OffsetStartMs": 4870, "OffsetEndMs": 5270}, {"Word": "that", "OffsetStartMs": 5320, "OffsetEndMs": 5580}, {"Word": "it", "OffsetStartMs": 5580, "OffsetEndMs": 5700}, {"Word": "obtained", "OffsetStartMs": 5700, "OffsetEndMs": 6170}, {"Word": "until", "OffsetStartMs": 6940, "OffsetEndMs": 7305}, {"Word": "that", "OffsetStartMs": 7305, "OffsetEndMs": 7590}, {"Word": "termination", "OffsetStartMs": 7590, "OffsetEndMs": 8120}, {"Word": "right", "OffsetStartMs": 8290, "OffsetEndMs": 8690}, {"Word": "This", "OffsetStartMs": 8740, "OffsetEndMs": 9140}, {"Word": "becomes", "OffsetStartMs": 9250, "OffsetEndMs": 9650}, {"Word": "our", "OffsetStartMs": 9670, "OffsetEndMs": 10065}, {"Word": "mini", "OffsetStartMs": 10065, "OffsetEndMs": 10460}, {"Word": "data", "OffsetStartMs": 10540, "OffsetEndMs": 10890}, {"Word": "set", "OffsetStartMs": 10890, "OffsetEndMs": 11240}, {"Word": "that", "OffsetStartMs": 11260, "OffsetEndMs": 11550}, {"Word": "we'll", "OffsetStartMs": 11550, "OffsetEndMs": 11760}, {"Word": "use", "OffsetStartMs": 11760, "OffsetEndMs": 12000}, {"Word": "for", "OffsetStartMs": 12000, "OffsetEndMs": 12240}, {"Word": "the", "OffsetStartMs": 12240, "OffsetEndMs": 12360}, {"Word": "first", "OffsetStartMs": 12360, "OffsetEndMs": 12555}, {"Word": "round", "OffsetStartMs": 12555, "OffsetEndMs": 12840}, {"Word": "of", "OffsetStartMs": 12840, "OffsetEndMs": 13095}, {"Word": "training", "OffsetStartMs": 13095, "OffsetEndMs": 13400}, {"Word": "Let's", "OffsetStartMs": 14080, "OffsetEndMs": 14475}, {"Word": "take", "OffsetStartMs": 14475, "OffsetEndMs": 14670}, {"Word": "those", "OffsetStartMs": 14670, "OffsetEndMs": 14910}, {"Word": "data", "OffsetStartMs": 14910, "OffsetEndMs": 15195}, {"Word": "sets", "OffsetStartMs": 15195, "OffsetEndMs": 15560}, {"Word": "And", "OffsetStartMs": 15700, "OffsetEndMs": 16005}, {"Word": "now", "OffsetStartMs": 16005, "OffsetEndMs": 16310}, {"Word": "we'll", "OffsetStartMs": 16360, "OffsetEndMs": 16665}, {"Word": "do", "OffsetStartMs": 16665, "OffsetEndMs": 16815}, {"Word": "one", "OffsetStartMs": 16815, "OffsetEndMs": 17100}, {"Word": "step", "OffsetStartMs": 17100, "OffsetEndMs": 17475}, {"Word": "of", "OffsetStartMs": 17475, "OffsetEndMs": 17790}, {"Word": "training", "OffsetStartMs": 17790, "OffsetEndMs": 18110}, {"Word": "The", "OffsetStartMs": 18160, "OffsetEndMs": 18450}, {"Word": "first", "OffsetStartMs": 18450, "OffsetEndMs": 18705}, {"Word": "step", "OffsetStartMs": 18705, "OffsetEndMs": 18945}, {"Word": "of", "OffsetStartMs": 18945, "OffsetEndMs": 19140}, {"Word": "training", "OffsetStartMs": 19140, "OffsetEndMs": 19425}, {"Word": "that", "OffsetStartMs": 19425, "OffsetEndMs": 19650}, {"Word": "we'll", "OffsetStartMs": 19650, "OffsetEndMs": 19860}, {"Word": "do", "OffsetStartMs": 19860, "OffsetEndMs": 20120}, {"Word": "is", "OffsetStartMs": 20410, "OffsetEndMs": 20715}, {"Word": "to", "OffsetStartMs": 20715, "OffsetEndMs": 20925}, {"Word": "take", "OffsetStartMs": 20925, "OffsetEndMs": 21230}, {"Word": "me", "OffsetStartMs": 21880, "OffsetEndMs": 22245}, {"Word": "to", "OffsetStartMs": 22245, "OffsetEndMs": 22500}, {"Word": "take", "OffsetStartMs": 22500, "OffsetEndMs": 22725}, {"Word": "the", "OffsetStartMs": 22725, "OffsetEndMs": 23060}, {"Word": "later", "OffsetStartMs": 23500, "OffsetEndMs": 23900}, {"Word": "half", "OffsetStartMs": 23980, "OffsetEndMs": 24380}, {"Word": "of", "OffsetStartMs": 24910, "OffsetEndMs": 25185}, {"Word": "our", "OffsetStartMs": 25185, "OffsetEndMs": 25460}], "SpeechSpeed": 13.2}, {"FinalSentence": "Of our trajectory that our agent ran and decreased the probability of actions that resulted in low rewards. Now, because the vehicle we know the vehicle terminated, we can assume that all of the actions that occurred in the later half of this trajectory were probably not very good actions because they came very close to termination. So let's decrease the probability of all of those things happening again in the future, and we'll take all of the things that happen in the beginning half of our training episode.", "SliceSentence": "Of our trajectory that our agent ran and decreased the probability of actions that resulted in low rewards Now because the vehicle we know the vehicle terminated we can assume that all of the actions that occurred in the later half of this trajectory were probably not very good actions because they came very close to termination So let's decrease the probability of all of those things happening again in the future and we'll take all of the things that happen in the beginning half of our training episode", "StartMs": 2537160, "EndMs": 2566620, "WordsNum": 89, "Words": [{"Word": "Of", "OffsetStartMs": 100, "OffsetEndMs": 360}, {"Word": "our", "OffsetStartMs": 360, "OffsetEndMs": 525}, {"Word": "trajectory", "OffsetStartMs": 525, "OffsetEndMs": 1245}, {"Word": "that", "OffsetStartMs": 1245, "OffsetEndMs": 1485}, {"Word": "our", "OffsetStartMs": 1485, "OffsetEndMs": 1635}, {"Word": "agent", "OffsetStartMs": 1635, "OffsetEndMs": 1910}, {"Word": "ran", "OffsetStartMs": 1960, "OffsetEndMs": 2360}, {"Word": "and", "OffsetStartMs": 2830, "OffsetEndMs": 3230}, {"Word": "decreased", "OffsetStartMs": 3460, "OffsetEndMs": 3915}, {"Word": "the", "OffsetStartMs": 3915, "OffsetEndMs": 4110}, {"Word": "probability", "OffsetStartMs": 4110, "OffsetEndMs": 4560}, {"Word": "of", "OffsetStartMs": 4560, "OffsetEndMs": 4770}, {"Word": "actions", "OffsetStartMs": 4770, "OffsetEndMs": 5030}, {"Word": "that", "OffsetStartMs": 5590, "OffsetEndMs": 5990}, {"Word": "resulted", "OffsetStartMs": 6010, "OffsetEndMs": 6410}, {"Word": "in", "OffsetStartMs": 6610, "OffsetEndMs": 6930}, {"Word": "low", "OffsetStartMs": 6930, "OffsetEndMs": 7155}, {"Word": "rewards", "OffsetStartMs": 7155, "OffsetEndMs": 7575}, {"Word": "Now", "OffsetStartMs": 7575, "OffsetEndMs": 7970}, {"Word": "because", "OffsetStartMs": 8170, "OffsetEndMs": 8520}, {"Word": "the", "OffsetStartMs": 8520, "OffsetEndMs": 8730}, {"Word": "vehicle", "OffsetStartMs": 8730, "OffsetEndMs": 8970}, {"Word": "we", "OffsetStartMs": 8970, "OffsetEndMs": 9240}, {"Word": "know", "OffsetStartMs": 9240, "OffsetEndMs": 9435}, {"Word": "the", "OffsetStartMs": 9435, "OffsetEndMs": 9585}, {"Word": "vehicle", "OffsetStartMs": 9585, "OffsetEndMs": 9830}, {"Word": "terminated", "OffsetStartMs": 9850, "OffsetEndMs": 10460}, {"Word": "we", "OffsetStartMs": 10990, "OffsetEndMs": 11265}, {"Word": "can", "OffsetStartMs": 11265, "OffsetEndMs": 11540}, {"Word": "assume", "OffsetStartMs": 11740, "OffsetEndMs": 12140}, {"Word": "that", "OffsetStartMs": 12160, "OffsetEndMs": 12495}, {"Word": "all", "OffsetStartMs": 12495, "OffsetEndMs": 12735}, {"Word": "of", "OffsetStartMs": 12735, "OffsetEndMs": 12930}, {"Word": "the", "OffsetStartMs": 12930, "OffsetEndMs": 13065}, {"Word": "actions", "OffsetStartMs": 13065, "OffsetEndMs": 13310}, {"Word": "that", "OffsetStartMs": 14110, "OffsetEndMs": 14510}, {"Word": "occurred", "OffsetStartMs": 14560, "OffsetEndMs": 14865}, {"Word": "in", "OffsetStartMs": 14865, "OffsetEndMs": 15030}, {"Word": "the", "OffsetStartMs": 15030, "OffsetEndMs": 15180}, {"Word": "later", "OffsetStartMs": 15180, "OffsetEndMs": 15450}, {"Word": "half", "OffsetStartMs": 15450, "OffsetEndMs": 15750}, {"Word": "of", "OffsetStartMs": 15750, "OffsetEndMs": 15945}, {"Word": "this", "OffsetStartMs": 15945, "OffsetEndMs": 16125}, {"Word": "trajectory", "OffsetStartMs": 16125, "OffsetEndMs": 16695}, {"Word": "were", "OffsetStartMs": 16695, "OffsetEndMs": 16890}, {"Word": "probably", "OffsetStartMs": 16890, "OffsetEndMs": 17180}, {"Word": "not", "OffsetStartMs": 17500, "OffsetEndMs": 17805}, {"Word": "very", "OffsetStartMs": 17805, "OffsetEndMs": 18045}, {"Word": "good", "OffsetStartMs": 18045, "OffsetEndMs": 18270}, {"Word": "actions", "OffsetStartMs": 18270, "OffsetEndMs": 18560}, {"Word": "because", "OffsetStartMs": 18700, "OffsetEndMs": 18960}, {"Word": "they", "OffsetStartMs": 18960, "OffsetEndMs": 19095}, {"Word": "came", "OffsetStartMs": 19095, "OffsetEndMs": 19260}, {"Word": "very", "OffsetStartMs": 19260, "OffsetEndMs": 19485}, {"Word": "close", "OffsetStartMs": 19485, "OffsetEndMs": 19725}, {"Word": "to", "OffsetStartMs": 19725, "OffsetEndMs": 19905}, {"Word": "termination", "OffsetStartMs": 19905, "OffsetEndMs": 20390}, {"Word": "So", "OffsetStartMs": 20950, "OffsetEndMs": 21195}, {"Word": "let's", "OffsetStartMs": 21195, "OffsetEndMs": 21525}, {"Word": "decrease", "OffsetStartMs": 21525, "OffsetEndMs": 21795}, {"Word": "the", "OffsetStartMs": 21795, "OffsetEndMs": 21960}, {"Word": "probability", "OffsetStartMs": 21960, "OffsetEndMs": 22320}, {"Word": "of", "OffsetStartMs": 22320, "OffsetEndMs": 22530}, {"Word": "all", "OffsetStartMs": 22530, "OffsetEndMs": 22710}, {"Word": "of", "OffsetStartMs": 22710, "OffsetEndMs": 22875}, {"Word": "those", "OffsetStartMs": 22875, "OffsetEndMs": 23070}, {"Word": "things", "OffsetStartMs": 23070, "OffsetEndMs": 23310}, {"Word": "happening", "OffsetStartMs": 23310, "OffsetEndMs": 23630}, {"Word": "again", "OffsetStartMs": 23710, "OffsetEndMs": 23970}, {"Word": "in", "OffsetStartMs": 23970, "OffsetEndMs": 24090}, {"Word": "the", "OffsetStartMs": 24090, "OffsetEndMs": 24225}, {"Word": "future", "OffsetStartMs": 24225, "OffsetEndMs": 24500}, {"Word": "and", "OffsetStartMs": 24790, "OffsetEndMs": 25065}, {"Word": "we'll", "OffsetStartMs": 25065, "OffsetEndMs": 25245}, {"Word": "take", "OffsetStartMs": 25245, "OffsetEndMs": 25410}, {"Word": "all", "OffsetStartMs": 25410, "OffsetEndMs": 25590}, {"Word": "of", "OffsetStartMs": 25590, "OffsetEndMs": 25710}, {"Word": "the", "OffsetStartMs": 25710, "OffsetEndMs": 25845}, {"Word": "things", "OffsetStartMs": 25845, "OffsetEndMs": 26010}, {"Word": "that", "OffsetStartMs": 26010, "OffsetEndMs": 26160}, {"Word": "happen", "OffsetStartMs": 26160, "OffsetEndMs": 26355}, {"Word": "in", "OffsetStartMs": 26355, "OffsetEndMs": 26550}, {"Word": "the", "OffsetStartMs": 26550, "OffsetEndMs": 26715}, {"Word": "beginning", "OffsetStartMs": 26715, "OffsetEndMs": 26970}, {"Word": "half", "OffsetStartMs": 26970, "OffsetEndMs": 27320}, {"Word": "of", "OffsetStartMs": 27550, "OffsetEndMs": 27825}, {"Word": "our", "OffsetStartMs": 27825, "OffsetEndMs": 28020}, {"Word": "training", "OffsetStartMs": 28020, "OffsetEndMs": 28340}, {"Word": "episode", "OffsetStartMs": 28480, "OffsetEndMs": 28880}], "SpeechSpeed": 17.2}, {"FinalSentence": "And we will increase their probabilities. Now, again, there's no reason why there shouldn't necessarily be a good action that we took in the first half of this trajectory and a bad action in the later half. But it's simply because actions that are in the later half were closer to a failure and closer determination that we can assume, for example, that these were probably suboptimal actions. But it's very possible that these are noisy rewards as well, because it's such a sparse signal, it's very possible that you had some good actions at the end and you were actually trying to recover your car, but you were just too late.", "SliceSentence": "And we will increase their probabilities Now again there's no reason why there shouldn't necessarily be a good action that we took in the first half of this trajectory and a bad action in the later half But it's simply because actions that are in the later half were closer to a failure and closer determination that we can assume for example that these were probably suboptimal actions But it's very possible that these are noisy rewards as well because it's such a sparse signal it's very possible that you had some good actions at the end and you were actually trying to recover your car but you were just too late", "StartMs": 2566620, "EndMs": 2602340, "WordsNum": 112, "Words": [{"Word": "And", "OffsetStartMs": 0, "OffsetEndMs": 380}, {"Word": "we", "OffsetStartMs": 580, "OffsetEndMs": 840}, {"Word": "will", "OffsetStartMs": 840, "OffsetEndMs": 1065}, {"Word": "increase", "OffsetStartMs": 1065, "OffsetEndMs": 1335}, {"Word": "their", "OffsetStartMs": 1335, "OffsetEndMs": 1530}, {"Word": "probabilities", "OffsetStartMs": 1530, "OffsetEndMs": 2060}, {"Word": "Now", "OffsetStartMs": 2350, "OffsetEndMs": 2670}, {"Word": "again", "OffsetStartMs": 2670, "OffsetEndMs": 2970}, {"Word": "there's", "OffsetStartMs": 2970, "OffsetEndMs": 3390}, {"Word": "no", "OffsetStartMs": 3390, "OffsetEndMs": 3710}, {"Word": "reason", "OffsetStartMs": 3880, "OffsetEndMs": 4280}, {"Word": "why", "OffsetStartMs": 4390, "OffsetEndMs": 4790}, {"Word": "there", "OffsetStartMs": 5680, "OffsetEndMs": 6080}, {"Word": "shouldn't", "OffsetStartMs": 6130, "OffsetEndMs": 6680}, {"Word": "necessarily", "OffsetStartMs": 6760, "OffsetEndMs": 7140}, {"Word": "be", "OffsetStartMs": 7140, "OffsetEndMs": 7455}, {"Word": "a", "OffsetStartMs": 7455, "OffsetEndMs": 7725}, {"Word": "good", "OffsetStartMs": 7725, "OffsetEndMs": 7980}, {"Word": "action", "OffsetStartMs": 7980, "OffsetEndMs": 8300}, {"Word": "that", "OffsetStartMs": 8350, "OffsetEndMs": 8625}, {"Word": "we", "OffsetStartMs": 8625, "OffsetEndMs": 8790}, {"Word": "took", "OffsetStartMs": 8790, "OffsetEndMs": 9060}, {"Word": "in", "OffsetStartMs": 9060, "OffsetEndMs": 9315}, {"Word": "the", "OffsetStartMs": 9315, "OffsetEndMs": 9465}, {"Word": "first", "OffsetStartMs": 9465, "OffsetEndMs": 9660}, {"Word": "half", "OffsetStartMs": 9660, "OffsetEndMs": 9900}, {"Word": "of", "OffsetStartMs": 9900, "OffsetEndMs": 10110}, {"Word": "this", "OffsetStartMs": 10110, "OffsetEndMs": 10350}, {"Word": "trajectory", "OffsetStartMs": 10350, "OffsetEndMs": 10890}, {"Word": "and", "OffsetStartMs": 10890, "OffsetEndMs": 10980}, {"Word": "a", "OffsetStartMs": 10980, "OffsetEndMs": 11070}, {"Word": "bad", "OffsetStartMs": 11070, "OffsetEndMs": 11220}, {"Word": "action", "OffsetStartMs": 11220, "OffsetEndMs": 11460}, {"Word": "in", "OffsetStartMs": 11460, "OffsetEndMs": 11670}, {"Word": "the", "OffsetStartMs": 11670, "OffsetEndMs": 11775}, {"Word": "later", "OffsetStartMs": 11775, "OffsetEndMs": 11940}, {"Word": "half", "OffsetStartMs": 11940, "OffsetEndMs": 12260}, {"Word": "But", "OffsetStartMs": 12460, "OffsetEndMs": 12705}, {"Word": "it's", "OffsetStartMs": 12705, "OffsetEndMs": 12885}, {"Word": "simply", "OffsetStartMs": 12885, "OffsetEndMs": 13130}, {"Word": "because", "OffsetStartMs": 13360, "OffsetEndMs": 13760}, {"Word": "actions", "OffsetStartMs": 14230, "OffsetEndMs": 14630}, {"Word": "that", "OffsetStartMs": 14680, "OffsetEndMs": 14940}, {"Word": "are", "OffsetStartMs": 14940, "OffsetEndMs": 15120}, {"Word": "in", "OffsetStartMs": 15120, "OffsetEndMs": 15360}, {"Word": "the", "OffsetStartMs": 15360, "OffsetEndMs": 15600}, {"Word": "later", "OffsetStartMs": 15600, "OffsetEndMs": 15885}, {"Word": "half", "OffsetStartMs": 15885, "OffsetEndMs": 16250}, {"Word": "were", "OffsetStartMs": 16270, "OffsetEndMs": 16620}, {"Word": "closer", "OffsetStartMs": 16620, "OffsetEndMs": 16970}, {"Word": "to", "OffsetStartMs": 17050, "OffsetEndMs": 17325}, {"Word": "a", "OffsetStartMs": 17325, "OffsetEndMs": 17475}, {"Word": "failure", "OffsetStartMs": 17475, "OffsetEndMs": 17750}, {"Word": "and", "OffsetStartMs": 17890, "OffsetEndMs": 18225}, {"Word": "closer", "OffsetStartMs": 18225, "OffsetEndMs": 18560}, {"Word": "determination", "OffsetStartMs": 18580, "OffsetEndMs": 19140}, {"Word": "that", "OffsetStartMs": 19140, "OffsetEndMs": 19350}, {"Word": "we", "OffsetStartMs": 19350, "OffsetEndMs": 19485}, {"Word": "can", "OffsetStartMs": 19485, "OffsetEndMs": 19760}, {"Word": "assume", "OffsetStartMs": 20050, "OffsetEndMs": 20450}, {"Word": "for", "OffsetStartMs": 20530, "OffsetEndMs": 20835}, {"Word": "example", "OffsetStartMs": 20835, "OffsetEndMs": 21140}, {"Word": "that", "OffsetStartMs": 21430, "OffsetEndMs": 21780}, {"Word": "these", "OffsetStartMs": 21780, "OffsetEndMs": 22035}, {"Word": "were", "OffsetStartMs": 22035, "OffsetEndMs": 22245}, {"Word": "probably", "OffsetStartMs": 22245, "OffsetEndMs": 22550}, {"Word": "suboptimal", "OffsetStartMs": 22750, "OffsetEndMs": 23520}, {"Word": "actions", "OffsetStartMs": 23520, "OffsetEndMs": 23810}, {"Word": "But", "OffsetStartMs": 24250, "OffsetEndMs": 24495}, {"Word": "it's", "OffsetStartMs": 24495, "OffsetEndMs": 24660}, {"Word": "very", "OffsetStartMs": 24660, "OffsetEndMs": 24840}, {"Word": "possible", "OffsetStartMs": 24840, "OffsetEndMs": 25160}, {"Word": "that", "OffsetStartMs": 25300, "OffsetEndMs": 25560}, {"Word": "these", "OffsetStartMs": 25560, "OffsetEndMs": 25695}, {"Word": "are", "OffsetStartMs": 25695, "OffsetEndMs": 25860}, {"Word": "noisy", "OffsetStartMs": 25860, "OffsetEndMs": 26450}, {"Word": "rewards", "OffsetStartMs": 26560, "OffsetEndMs": 27090}, {"Word": "as", "OffsetStartMs": 27090, "OffsetEndMs": 27375}, {"Word": "well", "OffsetStartMs": 27375, "OffsetEndMs": 27675}, {"Word": "because", "OffsetStartMs": 27675, "OffsetEndMs": 27960}, {"Word": "it's", "OffsetStartMs": 27960, "OffsetEndMs": 28185}, {"Word": "such", "OffsetStartMs": 28185, "OffsetEndMs": 28305}, {"Word": "a", "OffsetStartMs": 28305, "OffsetEndMs": 28470}, {"Word": "sparse", "OffsetStartMs": 28470, "OffsetEndMs": 28785}, {"Word": "signal", "OffsetStartMs": 28785, "OffsetEndMs": 29060}, {"Word": "it's", "OffsetStartMs": 29380, "OffsetEndMs": 29760}, {"Word": "very", "OffsetStartMs": 29760, "OffsetEndMs": 29985}, {"Word": "possible", "OffsetStartMs": 29985, "OffsetEndMs": 30300}, {"Word": "that", "OffsetStartMs": 30300, "OffsetEndMs": 30540}, {"Word": "you", "OffsetStartMs": 30540, "OffsetEndMs": 30675}, {"Word": "had", "OffsetStartMs": 30675, "OffsetEndMs": 30870}, {"Word": "some", "OffsetStartMs": 30870, "OffsetEndMs": 31080}, {"Word": "good", "OffsetStartMs": 31080, "OffsetEndMs": 31245}, {"Word": "actions", "OffsetStartMs": 31245, "OffsetEndMs": 31515}, {"Word": "at", "OffsetStartMs": 31515, "OffsetEndMs": 31785}, {"Word": "the", "OffsetStartMs": 31785, "OffsetEndMs": 31920}, {"Word": "end", "OffsetStartMs": 31920, "OffsetEndMs": 32070}, {"Word": "and", "OffsetStartMs": 32070, "OffsetEndMs": 32205}, {"Word": "you", "OffsetStartMs": 32205, "OffsetEndMs": 32310}, {"Word": "were", "OffsetStartMs": 32310, "OffsetEndMs": 32505}, {"Word": "actually", "OffsetStartMs": 32505, "OffsetEndMs": 32715}, {"Word": "trying", "OffsetStartMs": 32715, "OffsetEndMs": 32880}, {"Word": "to", "OffsetStartMs": 32880, "OffsetEndMs": 33105}, {"Word": "recover", "OffsetStartMs": 33105, "OffsetEndMs": 33360}, {"Word": "your", "OffsetStartMs": 33360, "OffsetEndMs": 33570}, {"Word": "car", "OffsetStartMs": 33570, "OffsetEndMs": 33860}, {"Word": "but", "OffsetStartMs": 33880, "OffsetEndMs": 34125}, {"Word": "you", "OffsetStartMs": 34125, "OffsetEndMs": 34215}, {"Word": "were", "OffsetStartMs": 34215, "OffsetEndMs": 34335}, {"Word": "just", "OffsetStartMs": 34335, "OffsetEndMs": 34610}, {"Word": "too", "OffsetStartMs": 34720, "OffsetEndMs": 34995}, {"Word": "late", "OffsetStartMs": 34995, "OffsetEndMs": 35270}], "SpeechSpeed": 17.3}, {"FinalSentence": "Now repeat this process again. Re-initialize the agent one more time and run it until completion. Now the agent goes a bit farther right because you've decreased the probabilities at the ends, increased the probabilities at the future, and you keep repeating this over and over again until you notice that the agent learns to perform better and better every time until it finally converges. And at the end the agent is able to basically follow lanes, usually swerving a bit side to side while it does that.", "SliceSentence": "Now repeat this process again Re -initialize the agent one more time and run it until completion Now the agent goes a bit farther right because you've decreased the probabilities at the ends increased the probabilities at the future and you keep repeating this over and over again until you notice that the agent learns to perform better and better every time until it finally converges And at the end the agent is able to basically follow lanes usually swerving a bit side to side while it does that", "StartMs": 2604080, "EndMs": 2633520, "WordsNum": 89, "Words": [{"Word": "Now", "OffsetStartMs": 100, "OffsetEndMs": 495}, {"Word": "repeat", "OffsetStartMs": 495, "OffsetEndMs": 750}, {"Word": "this", "OffsetStartMs": 750, "OffsetEndMs": 900}, {"Word": "process", "OffsetStartMs": 900, "OffsetEndMs": 1190}, {"Word": "again", "OffsetStartMs": 1480, "OffsetEndMs": 1880}, {"Word": "Re", "OffsetStartMs": 1930, "OffsetEndMs": 2220}, {"Word": "-initialize", "OffsetStartMs": 2220, "OffsetEndMs": 2670}, {"Word": "the", "OffsetStartMs": 2670, "OffsetEndMs": 2835}, {"Word": "agent", "OffsetStartMs": 2835, "OffsetEndMs": 3045}, {"Word": "one", "OffsetStartMs": 3045, "OffsetEndMs": 3285}, {"Word": "more", "OffsetStartMs": 3285, "OffsetEndMs": 3465}, {"Word": "time", "OffsetStartMs": 3465, "OffsetEndMs": 3770}, {"Word": "and", "OffsetStartMs": 4150, "OffsetEndMs": 4455}, {"Word": "run", "OffsetStartMs": 4455, "OffsetEndMs": 4650}, {"Word": "it", "OffsetStartMs": 4650, "OffsetEndMs": 4860}, {"Word": "until", "OffsetStartMs": 4860, "OffsetEndMs": 5145}, {"Word": "completion", "OffsetStartMs": 5145, "OffsetEndMs": 5505}, {"Word": "Now", "OffsetStartMs": 5505, "OffsetEndMs": 5820}, {"Word": "the", "OffsetStartMs": 5820, "OffsetEndMs": 5985}, {"Word": "agent", "OffsetStartMs": 5985, "OffsetEndMs": 6180}, {"Word": "goes", "OffsetStartMs": 6180, "OffsetEndMs": 6405}, {"Word": "a", "OffsetStartMs": 6405, "OffsetEndMs": 6540}, {"Word": "bit", "OffsetStartMs": 6540, "OffsetEndMs": 6705}, {"Word": "farther", "OffsetStartMs": 6705, "OffsetEndMs": 7200}, {"Word": "right", "OffsetStartMs": 7200, "OffsetEndMs": 7500}, {"Word": "because", "OffsetStartMs": 7500, "OffsetEndMs": 7725}, {"Word": "you've", "OffsetStartMs": 7725, "OffsetEndMs": 8055}, {"Word": "decreased", "OffsetStartMs": 8055, "OffsetEndMs": 8340}, {"Word": "the", "OffsetStartMs": 8340, "OffsetEndMs": 8475}, {"Word": "probabilities", "OffsetStartMs": 8475, "OffsetEndMs": 8880}, {"Word": "at", "OffsetStartMs": 8880, "OffsetEndMs": 9105}, {"Word": "the", "OffsetStartMs": 9105, "OffsetEndMs": 9210}, {"Word": "ends", "OffsetStartMs": 9210, "OffsetEndMs": 9440}, {"Word": "increased", "OffsetStartMs": 9490, "OffsetEndMs": 9765}, {"Word": "the", "OffsetStartMs": 9765, "OffsetEndMs": 9915}, {"Word": "probabilities", "OffsetStartMs": 9915, "OffsetEndMs": 10335}, {"Word": "at", "OffsetStartMs": 10335, "OffsetEndMs": 10575}, {"Word": "the", "OffsetStartMs": 10575, "OffsetEndMs": 10710}, {"Word": "future", "OffsetStartMs": 10710, "OffsetEndMs": 10970}, {"Word": "and", "OffsetStartMs": 11350, "OffsetEndMs": 11750}, {"Word": "you", "OffsetStartMs": 11800, "OffsetEndMs": 12120}, {"Word": "keep", "OffsetStartMs": 12120, "OffsetEndMs": 12390}, {"Word": "repeating", "OffsetStartMs": 12390, "OffsetEndMs": 12720}, {"Word": "this", "OffsetStartMs": 12720, "OffsetEndMs": 12930}, {"Word": "over", "OffsetStartMs": 12930, "OffsetEndMs": 13245}, {"Word": "and", "OffsetStartMs": 13245, "OffsetEndMs": 13455}, {"Word": "over", "OffsetStartMs": 13455, "OffsetEndMs": 13700}, {"Word": "again", "OffsetStartMs": 13720, "OffsetEndMs": 14120}, {"Word": "until", "OffsetStartMs": 14380, "OffsetEndMs": 14730}, {"Word": "you", "OffsetStartMs": 14730, "OffsetEndMs": 14955}, {"Word": "notice", "OffsetStartMs": 14955, "OffsetEndMs": 15180}, {"Word": "that", "OffsetStartMs": 15180, "OffsetEndMs": 15450}, {"Word": "the", "OffsetStartMs": 15450, "OffsetEndMs": 15645}, {"Word": "agent", "OffsetStartMs": 15645, "OffsetEndMs": 15920}, {"Word": "learns", "OffsetStartMs": 16030, "OffsetEndMs": 16590}, {"Word": "to", "OffsetStartMs": 16590, "OffsetEndMs": 16830}, {"Word": "perform", "OffsetStartMs": 16830, "OffsetEndMs": 17115}, {"Word": "better", "OffsetStartMs": 17115, "OffsetEndMs": 17385}, {"Word": "and", "OffsetStartMs": 17385, "OffsetEndMs": 17580}, {"Word": "better", "OffsetStartMs": 17580, "OffsetEndMs": 17870}, {"Word": "every", "OffsetStartMs": 18190, "OffsetEndMs": 18570}, {"Word": "time", "OffsetStartMs": 18570, "OffsetEndMs": 18950}, {"Word": "until", "OffsetStartMs": 19030, "OffsetEndMs": 19275}, {"Word": "it", "OffsetStartMs": 19275, "OffsetEndMs": 19395}, {"Word": "finally", "OffsetStartMs": 19395, "OffsetEndMs": 19670}, {"Word": "converges", "OffsetStartMs": 19810, "OffsetEndMs": 20355}, {"Word": "And", "OffsetStartMs": 20355, "OffsetEndMs": 20690}, {"Word": "at", "OffsetStartMs": 20770, "OffsetEndMs": 21060}, {"Word": "the", "OffsetStartMs": 21060, "OffsetEndMs": 21195}, {"Word": "end", "OffsetStartMs": 21195, "OffsetEndMs": 21440}, {"Word": "the", "OffsetStartMs": 22270, "OffsetEndMs": 22670}, {"Word": "agent", "OffsetStartMs": 23020, "OffsetEndMs": 23420}, {"Word": "is", "OffsetStartMs": 23650, "OffsetEndMs": 23910}, {"Word": "able", "OffsetStartMs": 23910, "OffsetEndMs": 24165}, {"Word": "to", "OffsetStartMs": 24165, "OffsetEndMs": 24450}, {"Word": "basically", "OffsetStartMs": 24450, "OffsetEndMs": 24740}, {"Word": "follow", "OffsetStartMs": 24760, "OffsetEndMs": 25110}, {"Word": "lanes", "OffsetStartMs": 25110, "OffsetEndMs": 25490}, {"Word": "usually", "OffsetStartMs": 25990, "OffsetEndMs": 26390}, {"Word": "swerving", "OffsetStartMs": 26590, "OffsetEndMs": 27045}, {"Word": "a", "OffsetStartMs": 27045, "OffsetEndMs": 27150}, {"Word": "bit", "OffsetStartMs": 27150, "OffsetEndMs": 27315}, {"Word": "side", "OffsetStartMs": 27315, "OffsetEndMs": 27525}, {"Word": "to", "OffsetStartMs": 27525, "OffsetEndMs": 27705}, {"Word": "side", "OffsetStartMs": 27705, "OffsetEndMs": 27960}, {"Word": "while", "OffsetStartMs": 27960, "OffsetEndMs": 28200}, {"Word": "it", "OffsetStartMs": 28200, "OffsetEndMs": 28335}, {"Word": "does", "OffsetStartMs": 28335, "OffsetEndMs": 28545}, {"Word": "that", "OffsetStartMs": 28545, "OffsetEndMs": 28880}], "SpeechSpeed": 16.9}, {"FinalSentence": "Without crashing. And this is actually really fascinating because this is a self driving car that we never taught anything about. What a Lane marker means or what are the rules of the road, anything about that, right? This was a car that learned entirely just by going out, crashing a lot and, you know, trying to figure out what to do to not keep doing that in the future.", "SliceSentence": "Without crashing And this is actually really fascinating because this is a self driving car that we never taught anything about What a Lane marker means or what are the rules of the road anything about that right This was a car that learned entirely just by going out crashing a lot and you know trying to figure out what to do to not keep doing that in the future", "StartMs": 2633520, "EndMs": 2655880, "WordsNum": 70, "Words": [{"Word": "Without", "OffsetStartMs": 190, "OffsetEndMs": 570}, {"Word": "crashing", "OffsetStartMs": 570, "OffsetEndMs": 1155}, {"Word": "And", "OffsetStartMs": 1155, "OffsetEndMs": 1395}, {"Word": "this", "OffsetStartMs": 1395, "OffsetEndMs": 1530}, {"Word": "is", "OffsetStartMs": 1530, "OffsetEndMs": 1790}, {"Word": "actually", "OffsetStartMs": 1990, "OffsetEndMs": 2340}, {"Word": "really", "OffsetStartMs": 2340, "OffsetEndMs": 2690}, {"Word": "fascinating", "OffsetStartMs": 2980, "OffsetEndMs": 3380}, {"Word": "because", "OffsetStartMs": 3640, "OffsetEndMs": 4040}, {"Word": "this", "OffsetStartMs": 4480, "OffsetEndMs": 4755}, {"Word": "is", "OffsetStartMs": 4755, "OffsetEndMs": 4890}, {"Word": "a", "OffsetStartMs": 4890, "OffsetEndMs": 5010}, {"Word": "self", "OffsetStartMs": 5010, "OffsetEndMs": 5175}, {"Word": "driving", "OffsetStartMs": 5175, "OffsetEndMs": 5460}, {"Word": "car", "OffsetStartMs": 5460, "OffsetEndMs": 5820}, {"Word": "that", "OffsetStartMs": 5820, "OffsetEndMs": 6075}, {"Word": "we", "OffsetStartMs": 6075, "OffsetEndMs": 6240}, {"Word": "never", "OffsetStartMs": 6240, "OffsetEndMs": 6510}, {"Word": "taught", "OffsetStartMs": 6510, "OffsetEndMs": 6890}, {"Word": "anything", "OffsetStartMs": 7120, "OffsetEndMs": 7520}, {"Word": "about", "OffsetStartMs": 7600, "OffsetEndMs": 7965}, {"Word": "What", "OffsetStartMs": 7965, "OffsetEndMs": 8190}, {"Word": "a", "OffsetStartMs": 8190, "OffsetEndMs": 8325}, {"Word": "Lane", "OffsetStartMs": 8325, "OffsetEndMs": 8520}, {"Word": "marker", "OffsetStartMs": 8520, "OffsetEndMs": 8985}, {"Word": "means", "OffsetStartMs": 8985, "OffsetEndMs": 9320}, {"Word": "or", "OffsetStartMs": 9370, "OffsetEndMs": 9645}, {"Word": "what", "OffsetStartMs": 9645, "OffsetEndMs": 9780}, {"Word": "are", "OffsetStartMs": 9780, "OffsetEndMs": 9900}, {"Word": "the", "OffsetStartMs": 9900, "OffsetEndMs": 10035}, {"Word": "rules", "OffsetStartMs": 10035, "OffsetEndMs": 10230}, {"Word": "of", "OffsetStartMs": 10230, "OffsetEndMs": 10425}, {"Word": "the", "OffsetStartMs": 10425, "OffsetEndMs": 10560}, {"Word": "road", "OffsetStartMs": 10560, "OffsetEndMs": 10820}, {"Word": "anything", "OffsetStartMs": 11380, "OffsetEndMs": 11670}, {"Word": "about", "OffsetStartMs": 11670, "OffsetEndMs": 11865}, {"Word": "that", "OffsetStartMs": 11865, "OffsetEndMs": 12090}, {"Word": "right", "OffsetStartMs": 12090, "OffsetEndMs": 12410}, {"Word": "This", "OffsetStartMs": 12430, "OffsetEndMs": 12705}, {"Word": "was", "OffsetStartMs": 12705, "OffsetEndMs": 12855}, {"Word": "a", "OffsetStartMs": 12855, "OffsetEndMs": 13020}, {"Word": "car", "OffsetStartMs": 13020, "OffsetEndMs": 13245}, {"Word": "that", "OffsetStartMs": 13245, "OffsetEndMs": 13485}, {"Word": "learned", "OffsetStartMs": 13485, "OffsetEndMs": 13790}, {"Word": "entirely", "OffsetStartMs": 13960, "OffsetEndMs": 14360}, {"Word": "just", "OffsetStartMs": 14740, "OffsetEndMs": 15015}, {"Word": "by", "OffsetStartMs": 15015, "OffsetEndMs": 15195}, {"Word": "going", "OffsetStartMs": 15195, "OffsetEndMs": 15435}, {"Word": "out", "OffsetStartMs": 15435, "OffsetEndMs": 15765}, {"Word": "crashing", "OffsetStartMs": 15765, "OffsetEndMs": 16260}, {"Word": "a", "OffsetStartMs": 16260, "OffsetEndMs": 16365}, {"Word": "lot", "OffsetStartMs": 16365, "OffsetEndMs": 16610}, {"Word": "and", "OffsetStartMs": 17050, "OffsetEndMs": 17445}, {"Word": "you", "OffsetStartMs": 17445, "OffsetEndMs": 17700}, {"Word": "know", "OffsetStartMs": 17700, "OffsetEndMs": 17925}, {"Word": "trying", "OffsetStartMs": 17925, "OffsetEndMs": 18210}, {"Word": "to", "OffsetStartMs": 18210, "OffsetEndMs": 18390}, {"Word": "figure", "OffsetStartMs": 18390, "OffsetEndMs": 18525}, {"Word": "out", "OffsetStartMs": 18525, "OffsetEndMs": 18720}, {"Word": "what", "OffsetStartMs": 18720, "OffsetEndMs": 18960}, {"Word": "to", "OffsetStartMs": 18960, "OffsetEndMs": 19170}, {"Word": "do", "OffsetStartMs": 19170, "OffsetEndMs": 19455}, {"Word": "to", "OffsetStartMs": 19455, "OffsetEndMs": 19740}, {"Word": "not", "OffsetStartMs": 19740, "OffsetEndMs": 20030}, {"Word": "keep", "OffsetStartMs": 20080, "OffsetEndMs": 20385}, {"Word": "doing", "OffsetStartMs": 20385, "OffsetEndMs": 20625}, {"Word": "that", "OffsetStartMs": 20625, "OffsetEndMs": 20960}, {"Word": "in", "OffsetStartMs": 21130, "OffsetEndMs": 21405}, {"Word": "the", "OffsetStartMs": 21405, "OffsetEndMs": 21540}, {"Word": "future", "OffsetStartMs": 21540, "OffsetEndMs": 21800}], "SpeechSpeed": 16.3}, {"FinalSentence": "And the remaining question is actually how we can update, you know, that policy as part of this algorithm that I'm showing you on the right and the left hand side, right? Like how can we basically formulate that same algorithm? And specifically the update equations, steps four and five right here. These are the two really important steps of how we can use those two steps to train our policy and decrease the probability of bad events while promoting these likelihoods of all these good events.", "SliceSentence": "And the remaining question is actually how we can update you know that policy as part of this algorithm that I'm showing you on the right and the left hand side right Like how can we basically formulate that same algorithm And specifically the update equations steps four and five right here These are the two really important steps of how we can use those two steps to train our policy and decrease the probability of bad events while promoting these likelihoods of all these good events", "StartMs": 2655880, "EndMs": 2683600, "WordsNum": 87, "Words": [{"Word": "And", "OffsetStartMs": 190, "OffsetEndMs": 465}, {"Word": "the", "OffsetStartMs": 465, "OffsetEndMs": 645}, {"Word": "remaining", "OffsetStartMs": 645, "OffsetEndMs": 885}, {"Word": "question", "OffsetStartMs": 885, "OffsetEndMs": 1170}, {"Word": "is", "OffsetStartMs": 1170, "OffsetEndMs": 1520}, {"Word": "actually", "OffsetStartMs": 1570, "OffsetEndMs": 1860}, {"Word": "how", "OffsetStartMs": 1860, "OffsetEndMs": 2010}, {"Word": "we", "OffsetStartMs": 2010, "OffsetEndMs": 2145}, {"Word": "can", "OffsetStartMs": 2145, "OffsetEndMs": 2420}, {"Word": "update", "OffsetStartMs": 2440, "OffsetEndMs": 2840}, {"Word": "you", "OffsetStartMs": 3280, "OffsetEndMs": 3495}, {"Word": "know", "OffsetStartMs": 3495, "OffsetEndMs": 3710}, {"Word": "that", "OffsetStartMs": 3730, "OffsetEndMs": 4035}, {"Word": "policy", "OffsetStartMs": 4035, "OffsetEndMs": 4340}, {"Word": "as", "OffsetStartMs": 4570, "OffsetEndMs": 4890}, {"Word": "part", "OffsetStartMs": 4890, "OffsetEndMs": 5085}, {"Word": "of", "OffsetStartMs": 5085, "OffsetEndMs": 5220}, {"Word": "this", "OffsetStartMs": 5220, "OffsetEndMs": 5480}, {"Word": "algorithm", "OffsetStartMs": 5500, "OffsetEndMs": 5895}, {"Word": "that", "OffsetStartMs": 5895, "OffsetEndMs": 6030}, {"Word": "I'm", "OffsetStartMs": 6030, "OffsetEndMs": 6240}, {"Word": "showing", "OffsetStartMs": 6240, "OffsetEndMs": 6420}, {"Word": "you", "OffsetStartMs": 6420, "OffsetEndMs": 6615}, {"Word": "on", "OffsetStartMs": 6615, "OffsetEndMs": 6750}, {"Word": "the", "OffsetStartMs": 6750, "OffsetEndMs": 6855}, {"Word": "right", "OffsetStartMs": 6855, "OffsetEndMs": 7065}, {"Word": "and", "OffsetStartMs": 7065, "OffsetEndMs": 7290}, {"Word": "the", "OffsetStartMs": 7290, "OffsetEndMs": 7410}, {"Word": "left", "OffsetStartMs": 7410, "OffsetEndMs": 7575}, {"Word": "hand", "OffsetStartMs": 7575, "OffsetEndMs": 7800}, {"Word": "side", "OffsetStartMs": 7800, "OffsetEndMs": 8085}, {"Word": "right", "OffsetStartMs": 8085, "OffsetEndMs": 8450}, {"Word": "Like", "OffsetStartMs": 8680, "OffsetEndMs": 9080}, {"Word": "how", "OffsetStartMs": 9190, "OffsetEndMs": 9495}, {"Word": "can", "OffsetStartMs": 9495, "OffsetEndMs": 9690}, {"Word": "we", "OffsetStartMs": 9690, "OffsetEndMs": 9930}, {"Word": "basically", "OffsetStartMs": 9930, "OffsetEndMs": 10280}, {"Word": "formulate", "OffsetStartMs": 10570, "OffsetEndMs": 11190}, {"Word": "that", "OffsetStartMs": 11190, "OffsetEndMs": 11445}, {"Word": "same", "OffsetStartMs": 11445, "OffsetEndMs": 11780}, {"Word": "algorithm", "OffsetStartMs": 11890, "OffsetEndMs": 12440}, {"Word": "And", "OffsetStartMs": 12640, "OffsetEndMs": 12960}, {"Word": "specifically", "OffsetStartMs": 12960, "OffsetEndMs": 13280}, {"Word": "the", "OffsetStartMs": 13540, "OffsetEndMs": 13920}, {"Word": "update", "OffsetStartMs": 13920, "OffsetEndMs": 14265}, {"Word": "equations", "OffsetStartMs": 14265, "OffsetEndMs": 14660}, {"Word": "steps", "OffsetStartMs": 14710, "OffsetEndMs": 15075}, {"Word": "four", "OffsetStartMs": 15075, "OffsetEndMs": 15345}, {"Word": "and", "OffsetStartMs": 15345, "OffsetEndMs": 15570}, {"Word": "five", "OffsetStartMs": 15570, "OffsetEndMs": 15890}, {"Word": "right", "OffsetStartMs": 16030, "OffsetEndMs": 16365}, {"Word": "here", "OffsetStartMs": 16365, "OffsetEndMs": 16700}, {"Word": "These", "OffsetStartMs": 16840, "OffsetEndMs": 17130}, {"Word": "are", "OffsetStartMs": 17130, "OffsetEndMs": 17280}, {"Word": "the", "OffsetStartMs": 17280, "OffsetEndMs": 17430}, {"Word": "two", "OffsetStartMs": 17430, "OffsetEndMs": 17595}, {"Word": "really", "OffsetStartMs": 17595, "OffsetEndMs": 17835}, {"Word": "important", "OffsetStartMs": 17835, "OffsetEndMs": 18200}, {"Word": "steps", "OffsetStartMs": 18220, "OffsetEndMs": 18620}, {"Word": "of", "OffsetStartMs": 18940, "OffsetEndMs": 19230}, {"Word": "how", "OffsetStartMs": 19230, "OffsetEndMs": 19395}, {"Word": "we", "OffsetStartMs": 19395, "OffsetEndMs": 19545}, {"Word": "can", "OffsetStartMs": 19545, "OffsetEndMs": 19820}, {"Word": "use", "OffsetStartMs": 19900, "OffsetEndMs": 20235}, {"Word": "those", "OffsetStartMs": 20235, "OffsetEndMs": 20520}, {"Word": "two", "OffsetStartMs": 20520, "OffsetEndMs": 20760}, {"Word": "steps", "OffsetStartMs": 20760, "OffsetEndMs": 20985}, {"Word": "to", "OffsetStartMs": 20985, "OffsetEndMs": 21225}, {"Word": "train", "OffsetStartMs": 21225, "OffsetEndMs": 21435}, {"Word": "our", "OffsetStartMs": 21435, "OffsetEndMs": 21645}, {"Word": "policy", "OffsetStartMs": 21645, "OffsetEndMs": 21950}, {"Word": "and", "OffsetStartMs": 22390, "OffsetEndMs": 22790}, {"Word": "decrease", "OffsetStartMs": 22840, "OffsetEndMs": 23175}, {"Word": "the", "OffsetStartMs": 23175, "OffsetEndMs": 23370}, {"Word": "probability", "OffsetStartMs": 23370, "OffsetEndMs": 23700}, {"Word": "of", "OffsetStartMs": 23700, "OffsetEndMs": 23865}, {"Word": "bad", "OffsetStartMs": 23865, "OffsetEndMs": 24045}, {"Word": "events", "OffsetStartMs": 24045, "OffsetEndMs": 24300}, {"Word": "while", "OffsetStartMs": 24300, "OffsetEndMs": 24620}, {"Word": "promoting", "OffsetStartMs": 24700, "OffsetEndMs": 25200}, {"Word": "these", "OffsetStartMs": 25200, "OffsetEndMs": 25425}, {"Word": "likelihoods", "OffsetStartMs": 25425, "OffsetEndMs": 26115}, {"Word": "of", "OffsetStartMs": 26115, "OffsetEndMs": 26250}, {"Word": "all", "OffsetStartMs": 26250, "OffsetEndMs": 26400}, {"Word": "these", "OffsetStartMs": 26400, "OffsetEndMs": 26610}, {"Word": "good", "OffsetStartMs": 26610, "OffsetEndMs": 26850}, {"Word": "events", "OffsetStartMs": 26850, "OffsetEndMs": 27170}], "SpeechSpeed": 17.6}, {"FinalSentence": "So let's assume the let's look at the loss function. First of all, the loss function for a policy gradient neural network looks like this. And then we'll start by dissecting it to understand why this works the way it does. So here we can see that the loss consists of two terms. The first term is this term in green.", "SliceSentence": "So let's assume the let's look at the loss function First of all the loss function for a policy gradient neural network looks like this And then we'll start by dissecting it to understand why this works the way it does So here we can see that the loss consists of two terms The first term is this term in green", "StartMs": 2684740, "EndMs": 2704620, "WordsNum": 61, "Words": [{"Word": "So", "OffsetStartMs": 130, "OffsetEndMs": 530}, {"Word": "let's", "OffsetStartMs": 580, "OffsetEndMs": 975}, {"Word": "assume", "OffsetStartMs": 975, "OffsetEndMs": 1200}, {"Word": "the", "OffsetStartMs": 1200, "OffsetEndMs": 1520}, {"Word": "let's", "OffsetStartMs": 1600, "OffsetEndMs": 2625}, {"Word": "look", "OffsetStartMs": 2625, "OffsetEndMs": 2715}, {"Word": "at", "OffsetStartMs": 2715, "OffsetEndMs": 2820}, {"Word": "the", "OffsetStartMs": 2820, "OffsetEndMs": 2925}, {"Word": "loss", "OffsetStartMs": 2925, "OffsetEndMs": 3090}, {"Word": "function", "OffsetStartMs": 3090, "OffsetEndMs": 3410}, {"Word": "First", "OffsetStartMs": 3550, "OffsetEndMs": 3855}, {"Word": "of", "OffsetStartMs": 3855, "OffsetEndMs": 3990}, {"Word": "all", "OffsetStartMs": 3990, "OffsetEndMs": 4155}, {"Word": "the", "OffsetStartMs": 4155, "OffsetEndMs": 4365}, {"Word": "loss", "OffsetStartMs": 4365, "OffsetEndMs": 4575}, {"Word": "function", "OffsetStartMs": 4575, "OffsetEndMs": 4910}, {"Word": "for", "OffsetStartMs": 4930, "OffsetEndMs": 5175}, {"Word": "a", "OffsetStartMs": 5175, "OffsetEndMs": 5295}, {"Word": "policy", "OffsetStartMs": 5295, "OffsetEndMs": 5570}, {"Word": "gradient", "OffsetStartMs": 5590, "OffsetEndMs": 6170}, {"Word": "neural", "OffsetStartMs": 6370, "OffsetEndMs": 6750}, {"Word": "network", "OffsetStartMs": 6750, "OffsetEndMs": 7010}, {"Word": "looks", "OffsetStartMs": 7840, "OffsetEndMs": 8145}, {"Word": "like", "OffsetStartMs": 8145, "OffsetEndMs": 8415}, {"Word": "this", "OffsetStartMs": 8415, "OffsetEndMs": 8700}, {"Word": "And", "OffsetStartMs": 8700, "OffsetEndMs": 8865}, {"Word": "then", "OffsetStartMs": 8865, "OffsetEndMs": 8985}, {"Word": "we'll", "OffsetStartMs": 8985, "OffsetEndMs": 9255}, {"Word": "start", "OffsetStartMs": 9255, "OffsetEndMs": 9495}, {"Word": "by", "OffsetStartMs": 9495, "OffsetEndMs": 9735}, {"Word": "dissecting", "OffsetStartMs": 9735, "OffsetEndMs": 10380}, {"Word": "it", "OffsetStartMs": 10380, "OffsetEndMs": 10640}, {"Word": "to", "OffsetStartMs": 10870, "OffsetEndMs": 11250}, {"Word": "understand", "OffsetStartMs": 11250, "OffsetEndMs": 11610}, {"Word": "why", "OffsetStartMs": 11610, "OffsetEndMs": 11990}, {"Word": "this", "OffsetStartMs": 12370, "OffsetEndMs": 12705}, {"Word": "works", "OffsetStartMs": 12705, "OffsetEndMs": 13040}, {"Word": "the", "OffsetStartMs": 13060, "OffsetEndMs": 13305}, {"Word": "way", "OffsetStartMs": 13305, "OffsetEndMs": 13410}, {"Word": "it", "OffsetStartMs": 13410, "OffsetEndMs": 13545}, {"Word": "does", "OffsetStartMs": 13545, "OffsetEndMs": 13820}, {"Word": "So", "OffsetStartMs": 14440, "OffsetEndMs": 14730}, {"Word": "here", "OffsetStartMs": 14730, "OffsetEndMs": 14910}, {"Word": "we", "OffsetStartMs": 14910, "OffsetEndMs": 15045}, {"Word": "can", "OffsetStartMs": 15045, "OffsetEndMs": 15180}, {"Word": "see", "OffsetStartMs": 15180, "OffsetEndMs": 15330}, {"Word": "that", "OffsetStartMs": 15330, "OffsetEndMs": 15450}, {"Word": "the", "OffsetStartMs": 15450, "OffsetEndMs": 15570}, {"Word": "loss", "OffsetStartMs": 15570, "OffsetEndMs": 15830}, {"Word": "consists", "OffsetStartMs": 15910, "OffsetEndMs": 16215}, {"Word": "of", "OffsetStartMs": 16215, "OffsetEndMs": 16520}, {"Word": "two", "OffsetStartMs": 16540, "OffsetEndMs": 16860}, {"Word": "terms", "OffsetStartMs": 16860, "OffsetEndMs": 17175}, {"Word": "The", "OffsetStartMs": 17175, "OffsetEndMs": 17430}, {"Word": "first", "OffsetStartMs": 17430, "OffsetEndMs": 17625}, {"Word": "term", "OffsetStartMs": 17625, "OffsetEndMs": 17960}, {"Word": "is", "OffsetStartMs": 18010, "OffsetEndMs": 18330}, {"Word": "this", "OffsetStartMs": 18330, "OffsetEndMs": 18555}, {"Word": "term", "OffsetStartMs": 18555, "OffsetEndMs": 18750}, {"Word": "in", "OffsetStartMs": 18750, "OffsetEndMs": 18960}, {"Word": "green", "OffsetStartMs": 18960, "OffsetEndMs": 19280}], "SpeechSpeed": 15.6}, {"FinalSentence": "Just called the log likelihood of selecting a particular action the second term is something that all of you are very familiar with already. This is simply the return at a specific time, so that's the expected return on rewards that you would get after this time point.", "SliceSentence": "Just called the log likelihood of selecting a particular action the second term is something that all of you are very familiar with already This is simply the return at a specific time so that's the expected return on rewards that you would get after this time point", "StartMs": 2704620, "EndMs": 2721200, "WordsNum": 48, "Words": [{"Word": "Just", "OffsetStartMs": 0, "OffsetEndMs": 210}, {"Word": "called", "OffsetStartMs": 210, "OffsetEndMs": 465}, {"Word": "the", "OffsetStartMs": 465, "OffsetEndMs": 830}, {"Word": "log", "OffsetStartMs": 1090, "OffsetEndMs": 1485}, {"Word": "likelihood", "OffsetStartMs": 1485, "OffsetEndMs": 2210}, {"Word": "of", "OffsetStartMs": 2230, "OffsetEndMs": 2610}, {"Word": "selecting", "OffsetStartMs": 2610, "OffsetEndMs": 3120}, {"Word": "a", "OffsetStartMs": 3120, "OffsetEndMs": 3420}, {"Word": "particular", "OffsetStartMs": 3420, "OffsetEndMs": 3750}, {"Word": "action", "OffsetStartMs": 3750, "OffsetEndMs": 4130}, {"Word": "the", "OffsetStartMs": 4720, "OffsetEndMs": 4980}, {"Word": "second", "OffsetStartMs": 4980, "OffsetEndMs": 5205}, {"Word": "term", "OffsetStartMs": 5205, "OffsetEndMs": 5460}, {"Word": "is", "OffsetStartMs": 5460, "OffsetEndMs": 5625}, {"Word": "something", "OffsetStartMs": 5625, "OffsetEndMs": 5850}, {"Word": "that", "OffsetStartMs": 5850, "OffsetEndMs": 6075}, {"Word": "all", "OffsetStartMs": 6075, "OffsetEndMs": 6210}, {"Word": "of", "OffsetStartMs": 6210, "OffsetEndMs": 6330}, {"Word": "you", "OffsetStartMs": 6330, "OffsetEndMs": 6450}, {"Word": "are", "OffsetStartMs": 6450, "OffsetEndMs": 6585}, {"Word": "very", "OffsetStartMs": 6585, "OffsetEndMs": 6780}, {"Word": "familiar", "OffsetStartMs": 6780, "OffsetEndMs": 7065}, {"Word": "with", "OffsetStartMs": 7065, "OffsetEndMs": 7380}, {"Word": "already", "OffsetStartMs": 7380, "OffsetEndMs": 7665}, {"Word": "This", "OffsetStartMs": 7665, "OffsetEndMs": 7860}, {"Word": "is", "OffsetStartMs": 7860, "OffsetEndMs": 8040}, {"Word": "simply", "OffsetStartMs": 8040, "OffsetEndMs": 8325}, {"Word": "the", "OffsetStartMs": 8325, "OffsetEndMs": 8690}, {"Word": "return", "OffsetStartMs": 9160, "OffsetEndMs": 9560}, {"Word": "at", "OffsetStartMs": 9850, "OffsetEndMs": 10155}, {"Word": "a", "OffsetStartMs": 10155, "OffsetEndMs": 10365}, {"Word": "specific", "OffsetStartMs": 10365, "OffsetEndMs": 10670}, {"Word": "time", "OffsetStartMs": 10720, "OffsetEndMs": 11120}, {"Word": "so", "OffsetStartMs": 11560, "OffsetEndMs": 11835}, {"Word": "that's", "OffsetStartMs": 11835, "OffsetEndMs": 12135}, {"Word": "the", "OffsetStartMs": 12135, "OffsetEndMs": 12435}, {"Word": "expected", "OffsetStartMs": 12435, "OffsetEndMs": 12830}, {"Word": "return", "OffsetStartMs": 12910, "OffsetEndMs": 13200}, {"Word": "on", "OffsetStartMs": 13200, "OffsetEndMs": 13365}, {"Word": "rewards", "OffsetStartMs": 13365, "OffsetEndMs": 13710}, {"Word": "that", "OffsetStartMs": 13710, "OffsetEndMs": 13935}, {"Word": "you", "OffsetStartMs": 13935, "OffsetEndMs": 14085}, {"Word": "would", "OffsetStartMs": 14085, "OffsetEndMs": 14250}, {"Word": "get", "OffsetStartMs": 14250, "OffsetEndMs": 14475}, {"Word": "after", "OffsetStartMs": 14475, "OffsetEndMs": 14760}, {"Word": "this", "OffsetStartMs": 14760, "OffsetEndMs": 15030}, {"Word": "time", "OffsetStartMs": 15030, "OffsetEndMs": 15255}, {"Word": "point", "OffsetStartMs": 15255, "OffsetEndMs": 15560}], "SpeechSpeed": 16.0}, {"FinalSentence": "Now, let's assume that we got a lot of reward for a particular action that had a high log probability or high probability. If we got a lot of reward for a particular action that had high probability, that means that we want to increase that probability even further. So we do it even more or even more likelihood, we sampled that action again into the future.", "SliceSentence": "Now let's assume that we got a lot of reward for a particular action that had a high log probability or high probability If we got a lot of reward for a particular action that had high probability that means that we want to increase that probability even further So we do it even more or even more likelihood we sampled that action again into the future", "StartMs": 2721200, "EndMs": 2744580, "WordsNum": 67, "Words": [{"Word": "Now", "OffsetStartMs": 0, "OffsetEndMs": 290}, {"Word": "let's", "OffsetStartMs": 790, "OffsetEndMs": 1200}, {"Word": "assume", "OffsetStartMs": 1200, "OffsetEndMs": 1440}, {"Word": "that", "OffsetStartMs": 1440, "OffsetEndMs": 1620}, {"Word": "we", "OffsetStartMs": 1620, "OffsetEndMs": 1740}, {"Word": "got", "OffsetStartMs": 1740, "OffsetEndMs": 1905}, {"Word": "a", "OffsetStartMs": 1905, "OffsetEndMs": 2115}, {"Word": "lot", "OffsetStartMs": 2115, "OffsetEndMs": 2310}, {"Word": "of", "OffsetStartMs": 2310, "OffsetEndMs": 2550}, {"Word": "reward", "OffsetStartMs": 2550, "OffsetEndMs": 2900}, {"Word": "for", "OffsetStartMs": 3130, "OffsetEndMs": 3420}, {"Word": "a", "OffsetStartMs": 3420, "OffsetEndMs": 3705}, {"Word": "particular", "OffsetStartMs": 3705, "OffsetEndMs": 4100}, {"Word": "action", "OffsetStartMs": 4150, "OffsetEndMs": 4550}, {"Word": "that", "OffsetStartMs": 4930, "OffsetEndMs": 5250}, {"Word": "had", "OffsetStartMs": 5250, "OffsetEndMs": 5570}, {"Word": "a", "OffsetStartMs": 5650, "OffsetEndMs": 6030}, {"Word": "high", "OffsetStartMs": 6030, "OffsetEndMs": 6410}, {"Word": "log", "OffsetStartMs": 6700, "OffsetEndMs": 7100}, {"Word": "probability", "OffsetStartMs": 7120, "OffsetEndMs": 7790}, {"Word": "or", "OffsetStartMs": 7930, "OffsetEndMs": 8265}, {"Word": "high", "OffsetStartMs": 8265, "OffsetEndMs": 8535}, {"Word": "probability", "OffsetStartMs": 8535, "OffsetEndMs": 9110}, {"Word": "If", "OffsetStartMs": 9730, "OffsetEndMs": 9990}, {"Word": "we", "OffsetStartMs": 9990, "OffsetEndMs": 10110}, {"Word": "got", "OffsetStartMs": 10110, "OffsetEndMs": 10245}, {"Word": "a", "OffsetStartMs": 10245, "OffsetEndMs": 10395}, {"Word": "lot", "OffsetStartMs": 10395, "OffsetEndMs": 10545}, {"Word": "of", "OffsetStartMs": 10545, "OffsetEndMs": 10755}, {"Word": "reward", "OffsetStartMs": 10755, "OffsetEndMs": 11090}, {"Word": "for", "OffsetStartMs": 11200, "OffsetEndMs": 11430}, {"Word": "a", "OffsetStartMs": 11430, "OffsetEndMs": 11610}, {"Word": "particular", "OffsetStartMs": 11610, "OffsetEndMs": 11955}, {"Word": "action", "OffsetStartMs": 11955, "OffsetEndMs": 12350}, {"Word": "that", "OffsetStartMs": 12460, "OffsetEndMs": 12735}, {"Word": "had", "OffsetStartMs": 12735, "OffsetEndMs": 12915}, {"Word": "high", "OffsetStartMs": 12915, "OffsetEndMs": 13125}, {"Word": "probability", "OffsetStartMs": 13125, "OffsetEndMs": 13700}, {"Word": "that", "OffsetStartMs": 14140, "OffsetEndMs": 14415}, {"Word": "means", "OffsetStartMs": 14415, "OffsetEndMs": 14580}, {"Word": "that", "OffsetStartMs": 14580, "OffsetEndMs": 14730}, {"Word": "we", "OffsetStartMs": 14730, "OffsetEndMs": 14835}, {"Word": "want", "OffsetStartMs": 14835, "OffsetEndMs": 14985}, {"Word": "to", "OffsetStartMs": 14985, "OffsetEndMs": 15270}, {"Word": "increase", "OffsetStartMs": 15270, "OffsetEndMs": 15650}, {"Word": "that", "OffsetStartMs": 15760, "OffsetEndMs": 16095}, {"Word": "probability", "OffsetStartMs": 16095, "OffsetEndMs": 16590}, {"Word": "even", "OffsetStartMs": 16590, "OffsetEndMs": 16890}, {"Word": "further", "OffsetStartMs": 16890, "OffsetEndMs": 17220}, {"Word": "So", "OffsetStartMs": 17220, "OffsetEndMs": 17475}, {"Word": "we", "OffsetStartMs": 17475, "OffsetEndMs": 17750}, {"Word": "do", "OffsetStartMs": 17860, "OffsetEndMs": 18105}, {"Word": "it", "OffsetStartMs": 18105, "OffsetEndMs": 18270}, {"Word": "even", "OffsetStartMs": 18270, "OffsetEndMs": 18555}, {"Word": "more", "OffsetStartMs": 18555, "OffsetEndMs": 18915}, {"Word": "or", "OffsetStartMs": 18915, "OffsetEndMs": 19245}, {"Word": "even", "OffsetStartMs": 19245, "OffsetEndMs": 19530}, {"Word": "more", "OffsetStartMs": 19530, "OffsetEndMs": 19800}, {"Word": "likelihood", "OffsetStartMs": 19800, "OffsetEndMs": 20415}, {"Word": "we", "OffsetStartMs": 20415, "OffsetEndMs": 20625}, {"Word": "sampled", "OffsetStartMs": 20625, "OffsetEndMs": 21015}, {"Word": "that", "OffsetStartMs": 21015, "OffsetEndMs": 21210}, {"Word": "action", "OffsetStartMs": 21210, "OffsetEndMs": 21530}, {"Word": "again", "OffsetStartMs": 21730, "OffsetEndMs": 22050}, {"Word": "into", "OffsetStartMs": 22050, "OffsetEndMs": 22320}, {"Word": "the", "OffsetStartMs": 22320, "OffsetEndMs": 22530}, {"Word": "future", "OffsetStartMs": 22530, "OffsetEndMs": 22790}], "SpeechSpeed": 15.1}, {"FinalSentence": "On the other hand, if we selected or let's say if we obtained a reward that was very low for an action that had high likelihood, we want the inverse effect. We never want to sample that action again in the future because it resulted in a low reward, right? And you'll notice that this loss function right here, by including this negative, we're going to minimize the likelihood of achieving any action that had low rewards in this trajectory now in our simplified example on.", "SliceSentence": "On the other hand if we selected or let's say if we obtained a reward that was very low for an action that had high likelihood we want the inverse effect We never want to sample that action again in the future because it resulted in a low reward right And you'll notice that this loss function right here by including this negative we're going to minimize the likelihood of achieving any action that had low rewards in this trajectory now in our simplified example on", "StartMs": 2744960, "EndMs": 2777320, "WordsNum": 86, "Words": [{"Word": "On", "OffsetStartMs": 100, "OffsetEndMs": 375}, {"Word": "the", "OffsetStartMs": 375, "OffsetEndMs": 480}, {"Word": "other", "OffsetStartMs": 480, "OffsetEndMs": 615}, {"Word": "hand", "OffsetStartMs": 615, "OffsetEndMs": 920}, {"Word": "if", "OffsetStartMs": 1270, "OffsetEndMs": 1575}, {"Word": "we", "OffsetStartMs": 1575, "OffsetEndMs": 1880}, {"Word": "selected", "OffsetStartMs": 2110, "OffsetEndMs": 2510}, {"Word": "or", "OffsetStartMs": 2920, "OffsetEndMs": 3225}, {"Word": "let's", "OffsetStartMs": 3225, "OffsetEndMs": 3450}, {"Word": "say", "OffsetStartMs": 3450, "OffsetEndMs": 3570}, {"Word": "if", "OffsetStartMs": 3570, "OffsetEndMs": 3735}, {"Word": "we", "OffsetStartMs": 3735, "OffsetEndMs": 3930}, {"Word": "obtained", "OffsetStartMs": 3930, "OffsetEndMs": 4520}, {"Word": "a", "OffsetStartMs": 4870, "OffsetEndMs": 5235}, {"Word": "reward", "OffsetStartMs": 5235, "OffsetEndMs": 5600}, {"Word": "that", "OffsetStartMs": 5980, "OffsetEndMs": 6285}, {"Word": "was", "OffsetStartMs": 6285, "OffsetEndMs": 6555}, {"Word": "very", "OffsetStartMs": 6555, "OffsetEndMs": 6870}, {"Word": "low", "OffsetStartMs": 6870, "OffsetEndMs": 7185}, {"Word": "for", "OffsetStartMs": 7185, "OffsetEndMs": 7410}, {"Word": "an", "OffsetStartMs": 7410, "OffsetEndMs": 7545}, {"Word": "action", "OffsetStartMs": 7545, "OffsetEndMs": 7815}, {"Word": "that", "OffsetStartMs": 7815, "OffsetEndMs": 8085}, {"Word": "had", "OffsetStartMs": 8085, "OffsetEndMs": 8265}, {"Word": "high", "OffsetStartMs": 8265, "OffsetEndMs": 8475}, {"Word": "likelihood", "OffsetStartMs": 8475, "OffsetEndMs": 9110}, {"Word": "we", "OffsetStartMs": 9250, "OffsetEndMs": 9510}, {"Word": "want", "OffsetStartMs": 9510, "OffsetEndMs": 9660}, {"Word": "the", "OffsetStartMs": 9660, "OffsetEndMs": 9840}, {"Word": "inverse", "OffsetStartMs": 9840, "OffsetEndMs": 10260}, {"Word": "effect", "OffsetStartMs": 10260, "OffsetEndMs": 10610}, {"Word": "We", "OffsetStartMs": 11080, "OffsetEndMs": 11355}, {"Word": "never", "OffsetStartMs": 11355, "OffsetEndMs": 11580}, {"Word": "want", "OffsetStartMs": 11580, "OffsetEndMs": 11835}, {"Word": "to", "OffsetStartMs": 11835, "OffsetEndMs": 12015}, {"Word": "sample", "OffsetStartMs": 12015, "OffsetEndMs": 12285}, {"Word": "that", "OffsetStartMs": 12285, "OffsetEndMs": 12555}, {"Word": "action", "OffsetStartMs": 12555, "OffsetEndMs": 12830}, {"Word": "again", "OffsetStartMs": 12910, "OffsetEndMs": 13170}, {"Word": "in", "OffsetStartMs": 13170, "OffsetEndMs": 13290}, {"Word": "the", "OffsetStartMs": 13290, "OffsetEndMs": 13410}, {"Word": "future", "OffsetStartMs": 13410, "OffsetEndMs": 13650}, {"Word": "because", "OffsetStartMs": 13650, "OffsetEndMs": 13905}, {"Word": "it", "OffsetStartMs": 13905, "OffsetEndMs": 14130}, {"Word": "resulted", "OffsetStartMs": 14130, "OffsetEndMs": 14460}, {"Word": "in", "OffsetStartMs": 14460, "OffsetEndMs": 14685}, {"Word": "a", "OffsetStartMs": 14685, "OffsetEndMs": 14790}, {"Word": "low", "OffsetStartMs": 14790, "OffsetEndMs": 15015}, {"Word": "reward", "OffsetStartMs": 15015, "OffsetEndMs": 15380}, {"Word": "right", "OffsetStartMs": 16030, "OffsetEndMs": 16350}, {"Word": "And", "OffsetStartMs": 16350, "OffsetEndMs": 16560}, {"Word": "you'll", "OffsetStartMs": 16560, "OffsetEndMs": 16785}, {"Word": "notice", "OffsetStartMs": 16785, "OffsetEndMs": 17030}, {"Word": "that", "OffsetStartMs": 17080, "OffsetEndMs": 17370}, {"Word": "this", "OffsetStartMs": 17370, "OffsetEndMs": 17660}, {"Word": "loss", "OffsetStartMs": 17890, "OffsetEndMs": 18240}, {"Word": "function", "OffsetStartMs": 18240, "OffsetEndMs": 18590}, {"Word": "right", "OffsetStartMs": 18670, "OffsetEndMs": 19005}, {"Word": "here", "OffsetStartMs": 19005, "OffsetEndMs": 19340}, {"Word": "by", "OffsetStartMs": 19630, "OffsetEndMs": 19995}, {"Word": "including", "OffsetStartMs": 19995, "OffsetEndMs": 20310}, {"Word": "this", "OffsetStartMs": 20310, "OffsetEndMs": 20580}, {"Word": "negative", "OffsetStartMs": 20580, "OffsetEndMs": 20900}, {"Word": "we're", "OffsetStartMs": 21280, "OffsetEndMs": 21615}, {"Word": "going", "OffsetStartMs": 21615, "OffsetEndMs": 21765}, {"Word": "to", "OffsetStartMs": 21765, "OffsetEndMs": 21945}, {"Word": "minimize", "OffsetStartMs": 21945, "OffsetEndMs": 22460}, {"Word": "the", "OffsetStartMs": 22960, "OffsetEndMs": 23235}, {"Word": "likelihood", "OffsetStartMs": 23235, "OffsetEndMs": 23930}, {"Word": "of", "OffsetStartMs": 23980, "OffsetEndMs": 24375}, {"Word": "achieving", "OffsetStartMs": 24375, "OffsetEndMs": 24900}, {"Word": "any", "OffsetStartMs": 24900, "OffsetEndMs": 25245}, {"Word": "action", "OffsetStartMs": 25245, "OffsetEndMs": 25640}, {"Word": "that", "OffsetStartMs": 25780, "OffsetEndMs": 26055}, {"Word": "had", "OffsetStartMs": 26055, "OffsetEndMs": 26330}, {"Word": "low", "OffsetStartMs": 26500, "OffsetEndMs": 26805}, {"Word": "rewards", "OffsetStartMs": 26805, "OffsetEndMs": 27260}, {"Word": "in", "OffsetStartMs": 27460, "OffsetEndMs": 27765}, {"Word": "this", "OffsetStartMs": 27765, "OffsetEndMs": 28070}, {"Word": "trajectory", "OffsetStartMs": 28120, "OffsetEndMs": 28880}, {"Word": "now", "OffsetStartMs": 29350, "OffsetEndMs": 29685}, {"Word": "in", "OffsetStartMs": 29685, "OffsetEndMs": 29880}, {"Word": "our", "OffsetStartMs": 29880, "OffsetEndMs": 30140}, {"Word": "simplified", "OffsetStartMs": 30220, "OffsetEndMs": 30885}, {"Word": "example", "OffsetStartMs": 30885, "OffsetEndMs": 31245}, {"Word": "on", "OffsetStartMs": 31245, "OffsetEndMs": 31640}], "SpeechSpeed": 14.4}, {"FinalSentence": "The car example, all the things that had low rewards were exactly those actions that came closest to the termination part of the of the vehicle. All the things that had high rewards were the things that came in the beginning. That's just the assumption that we make when defining our reward structure.", "SliceSentence": "The car example all the things that had low rewards were exactly those actions that came closest to the termination part of the of the vehicle All the things that had high rewards were the things that came in the beginning That's just the assumption that we make when defining our reward structure", "StartMs": 2777320, "EndMs": 2793740, "WordsNum": 53, "Words": [{"Word": "The", "OffsetStartMs": 0, "OffsetEndMs": 240}, {"Word": "car", "OffsetStartMs": 240, "OffsetEndMs": 495}, {"Word": "example", "OffsetStartMs": 495, "OffsetEndMs": 860}, {"Word": "all", "OffsetStartMs": 1270, "OffsetEndMs": 1605}, {"Word": "the", "OffsetStartMs": 1605, "OffsetEndMs": 1800}, {"Word": "things", "OffsetStartMs": 1800, "OffsetEndMs": 1965}, {"Word": "that", "OffsetStartMs": 1965, "OffsetEndMs": 2145}, {"Word": "had", "OffsetStartMs": 2145, "OffsetEndMs": 2355}, {"Word": "low", "OffsetStartMs": 2355, "OffsetEndMs": 2595}, {"Word": "rewards", "OffsetStartMs": 2595, "OffsetEndMs": 3045}, {"Word": "were", "OffsetStartMs": 3045, "OffsetEndMs": 3360}, {"Word": "exactly", "OffsetStartMs": 3360, "OffsetEndMs": 3680}, {"Word": "those", "OffsetStartMs": 3760, "OffsetEndMs": 4140}, {"Word": "actions", "OffsetStartMs": 4140, "OffsetEndMs": 4520}, {"Word": "that", "OffsetStartMs": 4660, "OffsetEndMs": 4965}, {"Word": "came", "OffsetStartMs": 4965, "OffsetEndMs": 5235}, {"Word": "closest", "OffsetStartMs": 5235, "OffsetEndMs": 5870}, {"Word": "to", "OffsetStartMs": 6100, "OffsetEndMs": 6375}, {"Word": "the", "OffsetStartMs": 6375, "OffsetEndMs": 6600}, {"Word": "termination", "OffsetStartMs": 6600, "OffsetEndMs": 7160}, {"Word": "part", "OffsetStartMs": 7300, "OffsetEndMs": 7635}, {"Word": "of", "OffsetStartMs": 7635, "OffsetEndMs": 7920}, {"Word": "the", "OffsetStartMs": 7920, "OffsetEndMs": 8265}, {"Word": "of", "OffsetStartMs": 8265, "OffsetEndMs": 8565}, {"Word": "the", "OffsetStartMs": 8565, "OffsetEndMs": 8870}, {"Word": "vehicle", "OffsetStartMs": 8920, "OffsetEndMs": 9320}, {"Word": "All", "OffsetStartMs": 9670, "OffsetEndMs": 9930}, {"Word": "the", "OffsetStartMs": 9930, "OffsetEndMs": 10035}, {"Word": "things", "OffsetStartMs": 10035, "OffsetEndMs": 10170}, {"Word": "that", "OffsetStartMs": 10170, "OffsetEndMs": 10320}, {"Word": "had", "OffsetStartMs": 10320, "OffsetEndMs": 10455}, {"Word": "high", "OffsetStartMs": 10455, "OffsetEndMs": 10635}, {"Word": "rewards", "OffsetStartMs": 10635, "OffsetEndMs": 10965}, {"Word": "were", "OffsetStartMs": 10965, "OffsetEndMs": 11130}, {"Word": "the", "OffsetStartMs": 11130, "OffsetEndMs": 11235}, {"Word": "things", "OffsetStartMs": 11235, "OffsetEndMs": 11370}, {"Word": "that", "OffsetStartMs": 11370, "OffsetEndMs": 11535}, {"Word": "came", "OffsetStartMs": 11535, "OffsetEndMs": 11670}, {"Word": "in", "OffsetStartMs": 11670, "OffsetEndMs": 11790}, {"Word": "the", "OffsetStartMs": 11790, "OffsetEndMs": 11955}, {"Word": "beginning", "OffsetStartMs": 11955, "OffsetEndMs": 12260}, {"Word": "That's", "OffsetStartMs": 12610, "OffsetEndMs": 12990}, {"Word": "just", "OffsetStartMs": 12990, "OffsetEndMs": 13140}, {"Word": "the", "OffsetStartMs": 13140, "OffsetEndMs": 13320}, {"Word": "assumption", "OffsetStartMs": 13320, "OffsetEndMs": 13680}, {"Word": "that", "OffsetStartMs": 13680, "OffsetEndMs": 13800}, {"Word": "we", "OffsetStartMs": 13800, "OffsetEndMs": 13920}, {"Word": "make", "OffsetStartMs": 13920, "OffsetEndMs": 14100}, {"Word": "when", "OffsetStartMs": 14100, "OffsetEndMs": 14415}, {"Word": "defining", "OffsetStartMs": 14415, "OffsetEndMs": 14880}, {"Word": "our", "OffsetStartMs": 14880, "OffsetEndMs": 15090}, {"Word": "reward", "OffsetStartMs": 15090, "OffsetEndMs": 15390}, {"Word": "structure", "OffsetStartMs": 15390, "OffsetEndMs": 15740}], "SpeechSpeed": 18.1}, {"FinalSentence": "Now we can plug this into the the loss of gradient descent algorithm to train our neural network. When we see, you know, this policy gradient algorithm which you can see highlighted here. This gradient is exactly of the policy part of the neural network. That's the probability of selecting an action, even a specific state. And if you remember before when we defined, you know, what does it mean to be a policy function? That's exactly what it means, right? Given a particular state that you find yourself in, what is the probability of selecting a particular action with the highest likelihood.", "SliceSentence": "Now we can plug this into the the loss of gradient descent algorithm to train our neural network When we see you know this policy gradient algorithm which you can see highlighted here This gradient is exactly of the policy part of the neural network That's the probability of selecting an action even a specific state And if you remember before when we defined you know what does it mean to be a policy function That's exactly what it means right Given a particular state that you find yourself in what is the probability of selecting a particular action with the highest likelihood", "StartMs": 2794000, "EndMs": 2829460, "WordsNum": 103, "Words": [{"Word": "Now", "OffsetStartMs": 130, "OffsetEndMs": 495}, {"Word": "we", "OffsetStartMs": 495, "OffsetEndMs": 705}, {"Word": "can", "OffsetStartMs": 705, "OffsetEndMs": 855}, {"Word": "plug", "OffsetStartMs": 855, "OffsetEndMs": 1080}, {"Word": "this", "OffsetStartMs": 1080, "OffsetEndMs": 1400}, {"Word": "into", "OffsetStartMs": 1480, "OffsetEndMs": 1880}, {"Word": "the", "OffsetStartMs": 2200, "OffsetEndMs": 2600}, {"Word": "the", "OffsetStartMs": 3130, "OffsetEndMs": 3420}, {"Word": "loss", "OffsetStartMs": 3420, "OffsetEndMs": 3710}, {"Word": "of", "OffsetStartMs": 4090, "OffsetEndMs": 4490}, {"Word": "gradient", "OffsetStartMs": 4510, "OffsetEndMs": 4965}, {"Word": "descent", "OffsetStartMs": 4965, "OffsetEndMs": 5420}, {"Word": "algorithm", "OffsetStartMs": 6010, "OffsetEndMs": 6405}, {"Word": "to", "OffsetStartMs": 6405, "OffsetEndMs": 6615}, {"Word": "train", "OffsetStartMs": 6615, "OffsetEndMs": 6795}, {"Word": "our", "OffsetStartMs": 6795, "OffsetEndMs": 6960}, {"Word": "neural", "OffsetStartMs": 6960, "OffsetEndMs": 7185}, {"Word": "network", "OffsetStartMs": 7185, "OffsetEndMs": 7440}, {"Word": "When", "OffsetStartMs": 7440, "OffsetEndMs": 7710}, {"Word": "we", "OffsetStartMs": 7710, "OffsetEndMs": 7905}, {"Word": "see", "OffsetStartMs": 7905, "OffsetEndMs": 8210}, {"Word": "you", "OffsetStartMs": 8410, "OffsetEndMs": 8640}, {"Word": "know", "OffsetStartMs": 8640, "OffsetEndMs": 8760}, {"Word": "this", "OffsetStartMs": 8760, "OffsetEndMs": 9000}, {"Word": "policy", "OffsetStartMs": 9000, "OffsetEndMs": 9350}, {"Word": "gradient", "OffsetStartMs": 9430, "OffsetEndMs": 10040}, {"Word": "algorithm", "OffsetStartMs": 10120, "OffsetEndMs": 10575}, {"Word": "which", "OffsetStartMs": 10575, "OffsetEndMs": 10845}, {"Word": "you", "OffsetStartMs": 10845, "OffsetEndMs": 11040}, {"Word": "can", "OffsetStartMs": 11040, "OffsetEndMs": 11175}, {"Word": "see", "OffsetStartMs": 11175, "OffsetEndMs": 11340}, {"Word": "highlighted", "OffsetStartMs": 11340, "OffsetEndMs": 11805}, {"Word": "here", "OffsetStartMs": 11805, "OffsetEndMs": 12015}, {"Word": "This", "OffsetStartMs": 12015, "OffsetEndMs": 12345}, {"Word": "gradient", "OffsetStartMs": 12345, "OffsetEndMs": 12980}, {"Word": "is", "OffsetStartMs": 13180, "OffsetEndMs": 13580}, {"Word": "exactly", "OffsetStartMs": 13900, "OffsetEndMs": 14300}, {"Word": "of", "OffsetStartMs": 14440, "OffsetEndMs": 14840}, {"Word": "the", "OffsetStartMs": 15100, "OffsetEndMs": 15390}, {"Word": "policy", "OffsetStartMs": 15390, "OffsetEndMs": 15680}, {"Word": "part", "OffsetStartMs": 16000, "OffsetEndMs": 16380}, {"Word": "of", "OffsetStartMs": 16380, "OffsetEndMs": 16635}, {"Word": "the", "OffsetStartMs": 16635, "OffsetEndMs": 16755}, {"Word": "neural", "OffsetStartMs": 16755, "OffsetEndMs": 16950}, {"Word": "network", "OffsetStartMs": 16950, "OffsetEndMs": 17160}, {"Word": "That's", "OffsetStartMs": 17160, "OffsetEndMs": 17475}, {"Word": "the", "OffsetStartMs": 17475, "OffsetEndMs": 17610}, {"Word": "probability", "OffsetStartMs": 17610, "OffsetEndMs": 18120}, {"Word": "of", "OffsetStartMs": 18120, "OffsetEndMs": 18435}, {"Word": "selecting", "OffsetStartMs": 18435, "OffsetEndMs": 18855}, {"Word": "an", "OffsetStartMs": 18855, "OffsetEndMs": 18960}, {"Word": "action", "OffsetStartMs": 18960, "OffsetEndMs": 19220}, {"Word": "even", "OffsetStartMs": 19630, "OffsetEndMs": 20010}, {"Word": "a", "OffsetStartMs": 20010, "OffsetEndMs": 20295}, {"Word": "specific", "OffsetStartMs": 20295, "OffsetEndMs": 20600}, {"Word": "state", "OffsetStartMs": 20800, "OffsetEndMs": 21150}, {"Word": "And", "OffsetStartMs": 21150, "OffsetEndMs": 21330}, {"Word": "if", "OffsetStartMs": 21330, "OffsetEndMs": 21435}, {"Word": "you", "OffsetStartMs": 21435, "OffsetEndMs": 21585}, {"Word": "remember", "OffsetStartMs": 21585, "OffsetEndMs": 21825}, {"Word": "before", "OffsetStartMs": 21825, "OffsetEndMs": 22155}, {"Word": "when", "OffsetStartMs": 22155, "OffsetEndMs": 22380}, {"Word": "we", "OffsetStartMs": 22380, "OffsetEndMs": 22620}, {"Word": "defined", "OffsetStartMs": 22620, "OffsetEndMs": 22950}, {"Word": "you", "OffsetStartMs": 22950, "OffsetEndMs": 23145}, {"Word": "know", "OffsetStartMs": 23145, "OffsetEndMs": 23265}, {"Word": "what", "OffsetStartMs": 23265, "OffsetEndMs": 23460}, {"Word": "does", "OffsetStartMs": 23460, "OffsetEndMs": 23640}, {"Word": "it", "OffsetStartMs": 23640, "OffsetEndMs": 23790}, {"Word": "mean", "OffsetStartMs": 23790, "OffsetEndMs": 24080}, {"Word": "to", "OffsetStartMs": 24400, "OffsetEndMs": 24675}, {"Word": "be", "OffsetStartMs": 24675, "OffsetEndMs": 24870}, {"Word": "a", "OffsetStartMs": 24870, "OffsetEndMs": 25065}, {"Word": "policy", "OffsetStartMs": 25065, "OffsetEndMs": 25335}, {"Word": "function", "OffsetStartMs": 25335, "OffsetEndMs": 25725}, {"Word": "That's", "OffsetStartMs": 25725, "OffsetEndMs": 26145}, {"Word": "exactly", "OffsetStartMs": 26145, "OffsetEndMs": 26430}, {"Word": "what", "OffsetStartMs": 26430, "OffsetEndMs": 26670}, {"Word": "it", "OffsetStartMs": 26670, "OffsetEndMs": 26835}, {"Word": "means", "OffsetStartMs": 26835, "OffsetEndMs": 27105}, {"Word": "right", "OffsetStartMs": 27105, "OffsetEndMs": 27420}, {"Word": "Given", "OffsetStartMs": 27420, "OffsetEndMs": 27770}, {"Word": "a", "OffsetStartMs": 27970, "OffsetEndMs": 28305}, {"Word": "particular", "OffsetStartMs": 28305, "OffsetEndMs": 28640}, {"Word": "state", "OffsetStartMs": 28720, "OffsetEndMs": 29055}, {"Word": "that", "OffsetStartMs": 29055, "OffsetEndMs": 29250}, {"Word": "you", "OffsetStartMs": 29250, "OffsetEndMs": 29400}, {"Word": "find", "OffsetStartMs": 29400, "OffsetEndMs": 29670}, {"Word": "yourself", "OffsetStartMs": 29670, "OffsetEndMs": 29955}, {"Word": "in", "OffsetStartMs": 29955, "OffsetEndMs": 30260}, {"Word": "what", "OffsetStartMs": 30580, "OffsetEndMs": 30870}, {"Word": "is", "OffsetStartMs": 30870, "OffsetEndMs": 31125}, {"Word": "the", "OffsetStartMs": 31125, "OffsetEndMs": 31490}, {"Word": "probability", "OffsetStartMs": 31720, "OffsetEndMs": 32325}, {"Word": "of", "OffsetStartMs": 32325, "OffsetEndMs": 32625}, {"Word": "selecting", "OffsetStartMs": 32625, "OffsetEndMs": 33030}, {"Word": "a", "OffsetStartMs": 33030, "OffsetEndMs": 33240}, {"Word": "particular", "OffsetStartMs": 33240, "OffsetEndMs": 33555}, {"Word": "action", "OffsetStartMs": 33555, "OffsetEndMs": 33885}, {"Word": "with", "OffsetStartMs": 33885, "OffsetEndMs": 34155}, {"Word": "the", "OffsetStartMs": 34155, "OffsetEndMs": 34320}, {"Word": "highest", "OffsetStartMs": 34320, "OffsetEndMs": 34530}, {"Word": "likelihood", "OffsetStartMs": 34530, "OffsetEndMs": 35180}], "SpeechSpeed": 16.4}, {"FinalSentence": "And that's, you know, exactly where this method gets its name from this policy gradient piece here that you can see here.", "SliceSentence": "And that's you know exactly where this method gets its name from this policy gradient piece here that you can see here", "StartMs": 2829460, "EndMs": 2837320, "WordsNum": 22, "Words": [{"Word": "And", "OffsetStartMs": 190, "OffsetEndMs": 450}, {"Word": "that's", "OffsetStartMs": 450, "OffsetEndMs": 750}, {"Word": "you", "OffsetStartMs": 750, "OffsetEndMs": 915}, {"Word": "know", "OffsetStartMs": 915, "OffsetEndMs": 1080}, {"Word": "exactly", "OffsetStartMs": 1080, "OffsetEndMs": 1365}, {"Word": "where", "OffsetStartMs": 1365, "OffsetEndMs": 1635}, {"Word": "this", "OffsetStartMs": 1635, "OffsetEndMs": 1845}, {"Word": "method", "OffsetStartMs": 1845, "OffsetEndMs": 2115}, {"Word": "gets", "OffsetStartMs": 2115, "OffsetEndMs": 2370}, {"Word": "its", "OffsetStartMs": 2370, "OffsetEndMs": 2565}, {"Word": "name", "OffsetStartMs": 2565, "OffsetEndMs": 2850}, {"Word": "from", "OffsetStartMs": 2850, "OffsetEndMs": 3120}, {"Word": "this", "OffsetStartMs": 3120, "OffsetEndMs": 3315}, {"Word": "policy", "OffsetStartMs": 3315, "OffsetEndMs": 3620}, {"Word": "gradient", "OffsetStartMs": 3640, "OffsetEndMs": 4220}, {"Word": "piece", "OffsetStartMs": 5050, "OffsetEndMs": 5450}, {"Word": "here", "OffsetStartMs": 5620, "OffsetEndMs": 5925}, {"Word": "that", "OffsetStartMs": 5925, "OffsetEndMs": 6075}, {"Word": "you", "OffsetStartMs": 6075, "OffsetEndMs": 6180}, {"Word": "can", "OffsetStartMs": 6180, "OffsetEndMs": 6330}, {"Word": "see", "OffsetStartMs": 6330, "OffsetEndMs": 6495}, {"Word": "here", "OffsetStartMs": 6495, "OffsetEndMs": 6770}], "SpeechSpeed": 15.0}, {"FinalSentence": "Now, I want to take maybe just a very brief second towards the end of the class here just to talk about, you know, some of the challenges and keeping in line with the first lecture today, some of the challenges of deploying these types of algorithms in the context of the real world, right?", "SliceSentence": "Now I want to take maybe just a very brief second towards the end of the class here just to talk about you know some of the challenges and keeping in line with the first lecture today some of the challenges of deploying these types of algorithms in the context of the real world right", "StartMs": 2837640, "EndMs": 2855060, "WordsNum": 55, "Words": [{"Word": "Now", "OffsetStartMs": 400, "OffsetEndMs": 800}, {"Word": "I", "OffsetStartMs": 1090, "OffsetEndMs": 1350}, {"Word": "want", "OffsetStartMs": 1350, "OffsetEndMs": 1470}, {"Word": "to", "OffsetStartMs": 1470, "OffsetEndMs": 1590}, {"Word": "take", "OffsetStartMs": 1590, "OffsetEndMs": 1850}, {"Word": "maybe", "OffsetStartMs": 1960, "OffsetEndMs": 2340}, {"Word": "just", "OffsetStartMs": 2340, "OffsetEndMs": 2595}, {"Word": "a", "OffsetStartMs": 2595, "OffsetEndMs": 2775}, {"Word": "very", "OffsetStartMs": 2775, "OffsetEndMs": 3015}, {"Word": "brief", "OffsetStartMs": 3015, "OffsetEndMs": 3270}, {"Word": "second", "OffsetStartMs": 3270, "OffsetEndMs": 3590}, {"Word": "towards", "OffsetStartMs": 3610, "OffsetEndMs": 3930}, {"Word": "the", "OffsetStartMs": 3930, "OffsetEndMs": 4080}, {"Word": "end", "OffsetStartMs": 4080, "OffsetEndMs": 4185}, {"Word": "of", "OffsetStartMs": 4185, "OffsetEndMs": 4320}, {"Word": "the", "OffsetStartMs": 4320, "OffsetEndMs": 4455}, {"Word": "class", "OffsetStartMs": 4455, "OffsetEndMs": 4665}, {"Word": "here", "OffsetStartMs": 4665, "OffsetEndMs": 4965}, {"Word": "just", "OffsetStartMs": 4965, "OffsetEndMs": 5235}, {"Word": "to", "OffsetStartMs": 5235, "OffsetEndMs": 5415}, {"Word": "talk", "OffsetStartMs": 5415, "OffsetEndMs": 5625}, {"Word": "about", "OffsetStartMs": 5625, "OffsetEndMs": 5960}, {"Word": "you", "OffsetStartMs": 6310, "OffsetEndMs": 6525}, {"Word": "know", "OffsetStartMs": 6525, "OffsetEndMs": 6660}, {"Word": "some", "OffsetStartMs": 6660, "OffsetEndMs": 6840}, {"Word": "of", "OffsetStartMs": 6840, "OffsetEndMs": 6990}, {"Word": "the", "OffsetStartMs": 6990, "OffsetEndMs": 7280}, {"Word": "challenges", "OffsetStartMs": 7480, "OffsetEndMs": 7880}, {"Word": "and", "OffsetStartMs": 8380, "OffsetEndMs": 8715}, {"Word": "keeping", "OffsetStartMs": 8715, "OffsetEndMs": 8955}, {"Word": "in", "OffsetStartMs": 8955, "OffsetEndMs": 9150}, {"Word": "line", "OffsetStartMs": 9150, "OffsetEndMs": 9360}, {"Word": "with", "OffsetStartMs": 9360, "OffsetEndMs": 9555}, {"Word": "the", "OffsetStartMs": 9555, "OffsetEndMs": 9690}, {"Word": "first", "OffsetStartMs": 9690, "OffsetEndMs": 9855}, {"Word": "lecture", "OffsetStartMs": 9855, "OffsetEndMs": 10160}, {"Word": "today", "OffsetStartMs": 10180, "OffsetEndMs": 10515}, {"Word": "some", "OffsetStartMs": 10515, "OffsetEndMs": 10710}, {"Word": "of", "OffsetStartMs": 10710, "OffsetEndMs": 10830}, {"Word": "the", "OffsetStartMs": 10830, "OffsetEndMs": 10995}, {"Word": "challenges", "OffsetStartMs": 10995, "OffsetEndMs": 11300}, {"Word": "of", "OffsetStartMs": 11530, "OffsetEndMs": 11930}, {"Word": "deploying", "OffsetStartMs": 12100, "OffsetEndMs": 12540}, {"Word": "these", "OffsetStartMs": 12540, "OffsetEndMs": 12735}, {"Word": "types", "OffsetStartMs": 12735, "OffsetEndMs": 12945}, {"Word": "of", "OffsetStartMs": 12945, "OffsetEndMs": 13215}, {"Word": "algorithms", "OffsetStartMs": 13215, "OffsetEndMs": 13730}, {"Word": "in", "OffsetStartMs": 13960, "OffsetEndMs": 14235}, {"Word": "the", "OffsetStartMs": 14235, "OffsetEndMs": 14400}, {"Word": "context", "OffsetStartMs": 14400, "OffsetEndMs": 14690}, {"Word": "of", "OffsetStartMs": 14800, "OffsetEndMs": 15195}, {"Word": "the", "OffsetStartMs": 15195, "OffsetEndMs": 15450}, {"Word": "real", "OffsetStartMs": 15450, "OffsetEndMs": 15630}, {"Word": "world", "OffsetStartMs": 15630, "OffsetEndMs": 15950}, {"Word": "right", "OffsetStartMs": 16480, "OffsetEndMs": 16880}], "SpeechSpeed": 16.3}, {"FinalSentence": "What do you think when you look at this training algorithm that you can see here? What do you think are the shortcomings of this training algorithm and which step, I guess, specifically if we wanted to deploy this approach into reality?", "SliceSentence": "What do you think when you look at this training algorithm that you can see here What do you think are the shortcomings of this training algorithm and which step I guess specifically if we wanted to deploy this approach into reality", "StartMs": 2855060, "EndMs": 2869140, "WordsNum": 42, "Words": [{"Word": "What", "OffsetStartMs": 0, "OffsetEndMs": 255}, {"Word": "do", "OffsetStartMs": 255, "OffsetEndMs": 360}, {"Word": "you", "OffsetStartMs": 360, "OffsetEndMs": 450}, {"Word": "think", "OffsetStartMs": 450, "OffsetEndMs": 710}, {"Word": "when", "OffsetStartMs": 790, "OffsetEndMs": 1065}, {"Word": "you", "OffsetStartMs": 1065, "OffsetEndMs": 1245}, {"Word": "look", "OffsetStartMs": 1245, "OffsetEndMs": 1440}, {"Word": "at", "OffsetStartMs": 1440, "OffsetEndMs": 1620}, {"Word": "this", "OffsetStartMs": 1620, "OffsetEndMs": 1830}, {"Word": "training", "OffsetStartMs": 1830, "OffsetEndMs": 2150}, {"Word": "algorithm", "OffsetStartMs": 2230, "OffsetEndMs": 2580}, {"Word": "that", "OffsetStartMs": 2580, "OffsetEndMs": 2715}, {"Word": "you", "OffsetStartMs": 2715, "OffsetEndMs": 2850}, {"Word": "can", "OffsetStartMs": 2850, "OffsetEndMs": 3000}, {"Word": "see", "OffsetStartMs": 3000, "OffsetEndMs": 3195}, {"Word": "here", "OffsetStartMs": 3195, "OffsetEndMs": 3500}, {"Word": "What", "OffsetStartMs": 3970, "OffsetEndMs": 4260}, {"Word": "do", "OffsetStartMs": 4260, "OffsetEndMs": 4380}, {"Word": "you", "OffsetStartMs": 4380, "OffsetEndMs": 4485}, {"Word": "think", "OffsetStartMs": 4485, "OffsetEndMs": 4635}, {"Word": "are", "OffsetStartMs": 4635, "OffsetEndMs": 4770}, {"Word": "the", "OffsetStartMs": 4770, "OffsetEndMs": 4935}, {"Word": "shortcomings", "OffsetStartMs": 4935, "OffsetEndMs": 5625}, {"Word": "of", "OffsetStartMs": 5625, "OffsetEndMs": 5925}, {"Word": "this", "OffsetStartMs": 5925, "OffsetEndMs": 6165}, {"Word": "training", "OffsetStartMs": 6165, "OffsetEndMs": 6500}, {"Word": "algorithm", "OffsetStartMs": 6610, "OffsetEndMs": 7130}, {"Word": "and", "OffsetStartMs": 7480, "OffsetEndMs": 7815}, {"Word": "which", "OffsetStartMs": 7815, "OffsetEndMs": 8145}, {"Word": "step", "OffsetStartMs": 8145, "OffsetEndMs": 8490}, {"Word": "I", "OffsetStartMs": 8490, "OffsetEndMs": 8700}, {"Word": "guess", "OffsetStartMs": 8700, "OffsetEndMs": 8895}, {"Word": "specifically", "OffsetStartMs": 8895, "OffsetEndMs": 9230}, {"Word": "if", "OffsetStartMs": 9400, "OffsetEndMs": 9660}, {"Word": "we", "OffsetStartMs": 9660, "OffsetEndMs": 9795}, {"Word": "wanted", "OffsetStartMs": 9795, "OffsetEndMs": 10005}, {"Word": "to", "OffsetStartMs": 10005, "OffsetEndMs": 10290}, {"Word": "deploy", "OffsetStartMs": 10290, "OffsetEndMs": 10590}, {"Word": "this", "OffsetStartMs": 10590, "OffsetEndMs": 10940}, {"Word": "approach", "OffsetStartMs": 11620, "OffsetEndMs": 12020}, {"Word": "into", "OffsetStartMs": 12130, "OffsetEndMs": 12495}, {"Word": "reality", "OffsetStartMs": 12495, "OffsetEndMs": 12860}], "SpeechSpeed": 16.5}, {"FinalSentence": "Yeah, exactly. So it's step two, right? If you wanted to do this in reality, right, that essentially means that you want to go out, collect your car, crashing it a bunch of times just to learn how to not crash it, right? And that's, you know, that's simply not feasible. Right? Number one, it's also, you know, very dangerous. Number two, so there are ways around this, right? The number one way around this is that people try to train these types of models in simulation, right? Simulation is very safe because you know we're not going to actually be damaging anything real. It's still very inefficient because we have to run these algorithms a bunch of times and crash them a bunch of times. Just learn not to crash, but at least now at least from a safety point of view.", "SliceSentence": "Yeah exactly So it's step two right If you wanted to do this in reality right that essentially means that you want to go out collect your car crashing it a bunch of times just to learn how to not crash it right And that's you know that's simply not feasible Right Number one it's also you know very dangerous Number two so there are ways around this right The number one way around this is that people try to train these types of models in simulation right Simulation is very safe because you know we're not going to actually be damaging anything real It's still very inefficient because we have to run these algorithms a bunch of times and crash them a bunch of times Just learn not to crash but at least now at least from a safety point of view", "StartMs": 2872780, "EndMs": 2920100, "WordsNum": 143, "Words": [{"Word": "Yeah", "OffsetStartMs": 130, "OffsetEndMs": 530}, {"Word": "exactly", "OffsetStartMs": 670, "OffsetEndMs": 1050}, {"Word": "So", "OffsetStartMs": 1050, "OffsetEndMs": 1350}, {"Word": "it's", "OffsetStartMs": 1350, "OffsetEndMs": 1680}, {"Word": "step", "OffsetStartMs": 1680, "OffsetEndMs": 1950}, {"Word": "two", "OffsetStartMs": 1950, "OffsetEndMs": 2325}, {"Word": "right", "OffsetStartMs": 2325, "OffsetEndMs": 2720}, {"Word": "If", "OffsetStartMs": 3070, "OffsetEndMs": 3360}, {"Word": "you", "OffsetStartMs": 3360, "OffsetEndMs": 3510}, {"Word": "wanted", "OffsetStartMs": 3510, "OffsetEndMs": 3705}, {"Word": "to", "OffsetStartMs": 3705, "OffsetEndMs": 3900}, {"Word": "do", "OffsetStartMs": 3900, "OffsetEndMs": 4050}, {"Word": "this", "OffsetStartMs": 4050, "OffsetEndMs": 4340}, {"Word": "in", "OffsetStartMs": 4450, "OffsetEndMs": 4740}, {"Word": "reality", "OffsetStartMs": 4740, "OffsetEndMs": 5030}, {"Word": "right", "OffsetStartMs": 5710, "OffsetEndMs": 6060}, {"Word": "that", "OffsetStartMs": 6060, "OffsetEndMs": 6360}, {"Word": "essentially", "OffsetStartMs": 6360, "OffsetEndMs": 6675}, {"Word": "means", "OffsetStartMs": 6675, "OffsetEndMs": 6960}, {"Word": "that", "OffsetStartMs": 6960, "OffsetEndMs": 7200}, {"Word": "you", "OffsetStartMs": 7200, "OffsetEndMs": 7395}, {"Word": "want", "OffsetStartMs": 7395, "OffsetEndMs": 7635}, {"Word": "to", "OffsetStartMs": 7635, "OffsetEndMs": 7980}, {"Word": "go", "OffsetStartMs": 7980, "OffsetEndMs": 8235}, {"Word": "out", "OffsetStartMs": 8235, "OffsetEndMs": 8510}, {"Word": "collect", "OffsetStartMs": 8530, "OffsetEndMs": 8820}, {"Word": "your", "OffsetStartMs": 8820, "OffsetEndMs": 9000}, {"Word": "car", "OffsetStartMs": 9000, "OffsetEndMs": 9290}, {"Word": "crashing", "OffsetStartMs": 9550, "OffsetEndMs": 10080}, {"Word": "it", "OffsetStartMs": 10080, "OffsetEndMs": 10230}, {"Word": "a", "OffsetStartMs": 10230, "OffsetEndMs": 10395}, {"Word": "bunch", "OffsetStartMs": 10395, "OffsetEndMs": 10560}, {"Word": "of", "OffsetStartMs": 10560, "OffsetEndMs": 10755}, {"Word": "times", "OffsetStartMs": 10755, "OffsetEndMs": 11060}, {"Word": "just", "OffsetStartMs": 11110, "OffsetEndMs": 11475}, {"Word": "to", "OffsetStartMs": 11475, "OffsetEndMs": 11760}, {"Word": "learn", "OffsetStartMs": 11760, "OffsetEndMs": 12080}, {"Word": "how", "OffsetStartMs": 12490, "OffsetEndMs": 12825}, {"Word": "to", "OffsetStartMs": 12825, "OffsetEndMs": 13035}, {"Word": "not", "OffsetStartMs": 13035, "OffsetEndMs": 13245}, {"Word": "crash", "OffsetStartMs": 13245, "OffsetEndMs": 13530}, {"Word": "it", "OffsetStartMs": 13530, "OffsetEndMs": 13880}, {"Word": "right", "OffsetStartMs": 14260, "OffsetEndMs": 14595}, {"Word": "And", "OffsetStartMs": 14595, "OffsetEndMs": 14820}, {"Word": "that's", "OffsetStartMs": 14820, "OffsetEndMs": 15260}, {"Word": "you", "OffsetStartMs": 15400, "OffsetEndMs": 15660}, {"Word": "know", "OffsetStartMs": 15660, "OffsetEndMs": 15920}, {"Word": "that's", "OffsetStartMs": 15940, "OffsetEndMs": 16320}, {"Word": "simply", "OffsetStartMs": 16320, "OffsetEndMs": 16530}, {"Word": "not", "OffsetStartMs": 16530, "OffsetEndMs": 16800}, {"Word": "feasible", "OffsetStartMs": 16800, "OffsetEndMs": 17420}, {"Word": "Right", "OffsetStartMs": 17470, "OffsetEndMs": 17790}, {"Word": "Number", "OffsetStartMs": 17790, "OffsetEndMs": 18060}, {"Word": "one", "OffsetStartMs": 18060, "OffsetEndMs": 18345}, {"Word": "it's", "OffsetStartMs": 18345, "OffsetEndMs": 18705}, {"Word": "also", "OffsetStartMs": 18705, "OffsetEndMs": 19005}, {"Word": "you", "OffsetStartMs": 19005, "OffsetEndMs": 19230}, {"Word": "know", "OffsetStartMs": 19230, "OffsetEndMs": 19490}, {"Word": "very", "OffsetStartMs": 19750, "OffsetEndMs": 20040}, {"Word": "dangerous", "OffsetStartMs": 20040, "OffsetEndMs": 20330}, {"Word": "Number", "OffsetStartMs": 20440, "OffsetEndMs": 20805}, {"Word": "two", "OffsetStartMs": 20805, "OffsetEndMs": 21170}, {"Word": "so", "OffsetStartMs": 22660, "OffsetEndMs": 23060}, {"Word": "there", "OffsetStartMs": 23440, "OffsetEndMs": 23745}, {"Word": "are", "OffsetStartMs": 23745, "OffsetEndMs": 23940}, {"Word": "ways", "OffsetStartMs": 23940, "OffsetEndMs": 24195}, {"Word": "around", "OffsetStartMs": 24195, "OffsetEndMs": 24510}, {"Word": "this", "OffsetStartMs": 24510, "OffsetEndMs": 24860}, {"Word": "right", "OffsetStartMs": 24940, "OffsetEndMs": 25335}, {"Word": "The", "OffsetStartMs": 25335, "OffsetEndMs": 25620}, {"Word": "number", "OffsetStartMs": 25620, "OffsetEndMs": 25890}, {"Word": "one", "OffsetStartMs": 25890, "OffsetEndMs": 26220}, {"Word": "way", "OffsetStartMs": 26220, "OffsetEndMs": 26550}, {"Word": "around", "OffsetStartMs": 26550, "OffsetEndMs": 26865}, {"Word": "this", "OffsetStartMs": 26865, "OffsetEndMs": 27135}, {"Word": "is", "OffsetStartMs": 27135, "OffsetEndMs": 27390}, {"Word": "that", "OffsetStartMs": 27390, "OffsetEndMs": 27600}, {"Word": "people", "OffsetStartMs": 27600, "OffsetEndMs": 27890}, {"Word": "try", "OffsetStartMs": 27940, "OffsetEndMs": 28290}, {"Word": "to", "OffsetStartMs": 28290, "OffsetEndMs": 28635}, {"Word": "train", "OffsetStartMs": 28635, "OffsetEndMs": 28980}, {"Word": "these", "OffsetStartMs": 28980, "OffsetEndMs": 29235}, {"Word": "types", "OffsetStartMs": 29235, "OffsetEndMs": 29445}, {"Word": "of", "OffsetStartMs": 29445, "OffsetEndMs": 29610}, {"Word": "models", "OffsetStartMs": 29610, "OffsetEndMs": 29870}, {"Word": "in", "OffsetStartMs": 30280, "OffsetEndMs": 30675}, {"Word": "simulation", "OffsetStartMs": 30675, "OffsetEndMs": 31280}, {"Word": "right", "OffsetStartMs": 31540, "OffsetEndMs": 31940}, {"Word": "Simulation", "OffsetStartMs": 32020, "OffsetEndMs": 32610}, {"Word": "is", "OffsetStartMs": 32610, "OffsetEndMs": 32940}, {"Word": "very", "OffsetStartMs": 32940, "OffsetEndMs": 33225}, {"Word": "safe", "OffsetStartMs": 33225, "OffsetEndMs": 33560}, {"Word": "because", "OffsetStartMs": 33730, "OffsetEndMs": 34130}, {"Word": "you", "OffsetStartMs": 34360, "OffsetEndMs": 34590}, {"Word": "know", "OffsetStartMs": 34590, "OffsetEndMs": 34725}, {"Word": "we're", "OffsetStartMs": 34725, "OffsetEndMs": 34950}, {"Word": "not", "OffsetStartMs": 34950, "OffsetEndMs": 35070}, {"Word": "going", "OffsetStartMs": 35070, "OffsetEndMs": 35235}, {"Word": "to", "OffsetStartMs": 35235, "OffsetEndMs": 35430}, {"Word": "actually", "OffsetStartMs": 35430, "OffsetEndMs": 35625}, {"Word": "be", "OffsetStartMs": 35625, "OffsetEndMs": 35760}, {"Word": "damaging", "OffsetStartMs": 35760, "OffsetEndMs": 36320}, {"Word": "anything", "OffsetStartMs": 36430, "OffsetEndMs": 36765}, {"Word": "real", "OffsetStartMs": 36765, "OffsetEndMs": 37100}, {"Word": "It's", "OffsetStartMs": 37480, "OffsetEndMs": 38000}, {"Word": "still", "OffsetStartMs": 38080, "OffsetEndMs": 38370}, {"Word": "very", "OffsetStartMs": 38370, "OffsetEndMs": 38550}, {"Word": "inefficient", "OffsetStartMs": 38550, "OffsetEndMs": 39180}, {"Word": "because", "OffsetStartMs": 39180, "OffsetEndMs": 39375}, {"Word": "we", "OffsetStartMs": 39375, "OffsetEndMs": 39480}, {"Word": "have", "OffsetStartMs": 39480, "OffsetEndMs": 39555}, {"Word": "to", "OffsetStartMs": 39555, "OffsetEndMs": 39660}, {"Word": "run", "OffsetStartMs": 39660, "OffsetEndMs": 39810}, {"Word": "these", "OffsetStartMs": 39810, "OffsetEndMs": 40050}, {"Word": "algorithms", "OffsetStartMs": 40050, "OffsetEndMs": 40410}, {"Word": "a", "OffsetStartMs": 40410, "OffsetEndMs": 40515}, {"Word": "bunch", "OffsetStartMs": 40515, "OffsetEndMs": 40650}, {"Word": "of", "OffsetStartMs": 40650, "OffsetEndMs": 40800}, {"Word": "times", "OffsetStartMs": 40800, "OffsetEndMs": 41060}, {"Word": "and", "OffsetStartMs": 41350, "OffsetEndMs": 41750}, {"Word": "crash", "OffsetStartMs": 41770, "OffsetEndMs": 42090}, {"Word": "them", "OffsetStartMs": 42090, "OffsetEndMs": 42270}, {"Word": "a", "OffsetStartMs": 42270, "OffsetEndMs": 42390}, {"Word": "bunch", "OffsetStartMs": 42390, "OffsetEndMs": 42525}, {"Word": "of", "OffsetStartMs": 42525, "OffsetEndMs": 42660}, {"Word": "times", "OffsetStartMs": 42660, "OffsetEndMs": 42825}, {"Word": "Just", "OffsetStartMs": 42825, "OffsetEndMs": 43050}, {"Word": "learn", "OffsetStartMs": 43050, "OffsetEndMs": 43365}, {"Word": "not", "OffsetStartMs": 43365, "OffsetEndMs": 43650}, {"Word": "to", "OffsetStartMs": 43650, "OffsetEndMs": 43815}, {"Word": "crash", "OffsetStartMs": 43815, "OffsetEndMs": 44090}, {"Word": "but", "OffsetStartMs": 44320, "OffsetEndMs": 44565}, {"Word": "at", "OffsetStartMs": 44565, "OffsetEndMs": 44685}, {"Word": "least", "OffsetStartMs": 44685, "OffsetEndMs": 44880}, {"Word": "now", "OffsetStartMs": 44880, "OffsetEndMs": 45150}, {"Word": "at", "OffsetStartMs": 45150, "OffsetEndMs": 45375}, {"Word": "least", "OffsetStartMs": 45375, "OffsetEndMs": 45540}, {"Word": "from", "OffsetStartMs": 45540, "OffsetEndMs": 45690}, {"Word": "a", "OffsetStartMs": 45690, "OffsetEndMs": 45915}, {"Word": "safety", "OffsetStartMs": 45915, "OffsetEndMs": 46275}, {"Word": "point", "OffsetStartMs": 46275, "OffsetEndMs": 46560}, {"Word": "of", "OffsetStartMs": 46560, "OffsetEndMs": 46710}, {"Word": "view", "OffsetStartMs": 46710, "OffsetEndMs": 46970}], "SpeechSpeed": 15.8}, {"FinalSentence": "It's much safer.", "SliceSentence": "It's much safer", "StartMs": 2920100, "EndMs": 2921880, "WordsNum": 3, "Words": [{"Word": "It's", "OffsetStartMs": 120, "OffsetEndMs": 225}, {"Word": "much", "OffsetStartMs": 225, "OffsetEndMs": 405}, {"Word": "safer", "OffsetStartMs": 405, "OffsetEndMs": 920}], "SpeechSpeed": 8.4}, {"FinalSentence": "But, you know, the problem is that modern simulation engines for reinforcement learning and generally, very broadly speaking, modern simators for vision specifically, do not at all capture reality very accurately. In fact, there's a very famous notion called the simoral gap, which is a gap that exists when you train algorithms in simulation, and they don't extend to a lot of the phenomena that we see and the patterns that we see in reality.", "SliceSentence": "But you know the problem is that modern simulation engines for reinforcement learning and generally very broadly speaking modern simators for vision specifically do not at all capture reality very accurately In fact there's a very famous notion called the simoral gap which is a gap that exists when you train algorithms in simulation and they don't extend to a lot of the phenomena that we see and the patterns that we see in reality", "StartMs": 2921880, "EndMs": 2953720, "WordsNum": 75, "Words": [{"Word": "But", "OffsetStartMs": 70, "OffsetEndMs": 390}, {"Word": "you", "OffsetStartMs": 390, "OffsetEndMs": 570}, {"Word": "know", "OffsetStartMs": 570, "OffsetEndMs": 705}, {"Word": "the", "OffsetStartMs": 705, "OffsetEndMs": 855}, {"Word": "problem", "OffsetStartMs": 855, "OffsetEndMs": 1130}, {"Word": "is", "OffsetStartMs": 1540, "OffsetEndMs": 1830}, {"Word": "that", "OffsetStartMs": 1830, "OffsetEndMs": 2085}, {"Word": "modern", "OffsetStartMs": 2085, "OffsetEndMs": 2450}, {"Word": "simulation", "OffsetStartMs": 2530, "OffsetEndMs": 3120}, {"Word": "engines", "OffsetStartMs": 3120, "OffsetEndMs": 3500}, {"Word": "for", "OffsetStartMs": 4030, "OffsetEndMs": 4430}, {"Word": "reinforcement", "OffsetStartMs": 4480, "OffsetEndMs": 5160}, {"Word": "learning", "OffsetStartMs": 5160, "OffsetEndMs": 5340}, {"Word": "and", "OffsetStartMs": 5340, "OffsetEndMs": 5565}, {"Word": "generally", "OffsetStartMs": 5565, "OffsetEndMs": 5870}, {"Word": "very", "OffsetStartMs": 6190, "OffsetEndMs": 6525}, {"Word": "broadly", "OffsetStartMs": 6525, "OffsetEndMs": 7020}, {"Word": "speaking", "OffsetStartMs": 7020, "OffsetEndMs": 7340}, {"Word": "modern", "OffsetStartMs": 7810, "OffsetEndMs": 8190}, {"Word": "simators", "OffsetStartMs": 8190, "OffsetEndMs": 8780}, {"Word": "for", "OffsetStartMs": 9310, "OffsetEndMs": 9710}, {"Word": "vision", "OffsetStartMs": 9760, "OffsetEndMs": 10160}, {"Word": "specifically", "OffsetStartMs": 10540, "OffsetEndMs": 10940}, {"Word": "do", "OffsetStartMs": 11200, "OffsetEndMs": 11505}, {"Word": "not", "OffsetStartMs": 11505, "OffsetEndMs": 11730}, {"Word": "at", "OffsetStartMs": 11730, "OffsetEndMs": 11910}, {"Word": "all", "OffsetStartMs": 11910, "OffsetEndMs": 12120}, {"Word": "capture", "OffsetStartMs": 12120, "OffsetEndMs": 12470}, {"Word": "reality", "OffsetStartMs": 13030, "OffsetEndMs": 13430}, {"Word": "very", "OffsetStartMs": 13750, "OffsetEndMs": 14150}, {"Word": "accurately", "OffsetStartMs": 14230, "OffsetEndMs": 14805}, {"Word": "In", "OffsetStartMs": 14805, "OffsetEndMs": 15060}, {"Word": "fact", "OffsetStartMs": 15060, "OffsetEndMs": 15320}, {"Word": "there's", "OffsetStartMs": 16660, "OffsetEndMs": 16995}, {"Word": "a", "OffsetStartMs": 16995, "OffsetEndMs": 17130}, {"Word": "very", "OffsetStartMs": 17130, "OffsetEndMs": 17400}, {"Word": "famous", "OffsetStartMs": 17400, "OffsetEndMs": 17780}, {"Word": "notion", "OffsetStartMs": 18970, "OffsetEndMs": 19370}, {"Word": "called", "OffsetStartMs": 19480, "OffsetEndMs": 19770}, {"Word": "the", "OffsetStartMs": 19770, "OffsetEndMs": 19950}, {"Word": "simoral", "OffsetStartMs": 19950, "OffsetEndMs": 20535}, {"Word": "gap", "OffsetStartMs": 20535, "OffsetEndMs": 20870}, {"Word": "which", "OffsetStartMs": 21130, "OffsetEndMs": 21390}, {"Word": "is", "OffsetStartMs": 21390, "OffsetEndMs": 21525}, {"Word": "a", "OffsetStartMs": 21525, "OffsetEndMs": 21690}, {"Word": "gap", "OffsetStartMs": 21690, "OffsetEndMs": 21960}, {"Word": "that", "OffsetStartMs": 21960, "OffsetEndMs": 22305}, {"Word": "exists", "OffsetStartMs": 22305, "OffsetEndMs": 22670}, {"Word": "when", "OffsetStartMs": 22690, "OffsetEndMs": 22965}, {"Word": "you", "OffsetStartMs": 22965, "OffsetEndMs": 23160}, {"Word": "train", "OffsetStartMs": 23160, "OffsetEndMs": 23480}, {"Word": "algorithms", "OffsetStartMs": 23560, "OffsetEndMs": 24080}, {"Word": "in", "OffsetStartMs": 24100, "OffsetEndMs": 24420}, {"Word": "simulation", "OffsetStartMs": 24420, "OffsetEndMs": 24950}, {"Word": "and", "OffsetStartMs": 25300, "OffsetEndMs": 25575}, {"Word": "they", "OffsetStartMs": 25575, "OffsetEndMs": 25770}, {"Word": "don't", "OffsetStartMs": 25770, "OffsetEndMs": 26235}, {"Word": "extend", "OffsetStartMs": 26235, "OffsetEndMs": 26630}, {"Word": "to", "OffsetStartMs": 26950, "OffsetEndMs": 27255}, {"Word": "a", "OffsetStartMs": 27255, "OffsetEndMs": 27420}, {"Word": "lot", "OffsetStartMs": 27420, "OffsetEndMs": 27540}, {"Word": "of", "OffsetStartMs": 27540, "OffsetEndMs": 27675}, {"Word": "the", "OffsetStartMs": 27675, "OffsetEndMs": 27810}, {"Word": "phenomena", "OffsetStartMs": 27810, "OffsetEndMs": 28260}, {"Word": "that", "OffsetStartMs": 28260, "OffsetEndMs": 28425}, {"Word": "we", "OffsetStartMs": 28425, "OffsetEndMs": 28605}, {"Word": "see", "OffsetStartMs": 28605, "OffsetEndMs": 28845}, {"Word": "and", "OffsetStartMs": 28845, "OffsetEndMs": 29040}, {"Word": "the", "OffsetStartMs": 29040, "OffsetEndMs": 29175}, {"Word": "patterns", "OffsetStartMs": 29175, "OffsetEndMs": 29430}, {"Word": "that", "OffsetStartMs": 29430, "OffsetEndMs": 29670}, {"Word": "we", "OffsetStartMs": 29670, "OffsetEndMs": 29835}, {"Word": "see", "OffsetStartMs": 29835, "OffsetEndMs": 30140}, {"Word": "in", "OffsetStartMs": 30400, "OffsetEndMs": 30765}, {"Word": "reality", "OffsetStartMs": 30765, "OffsetEndMs": 31130}], "SpeechSpeed": 13.6}, {"FinalSentence": "And one really cool result that I want to just highlight here is that when we're training reinforcement learning algorithms, we ultimately want them to be, you know, not operating in simulation. We want them to be in reality. And as part of our lab here at MIT, we've been developing this very, very cool brand new photo, realistic simulation engine that goes beyond basically the paradigm of how simulators work today, which is basically defining a model of their environment and trying to, you know, synthesize that that model. Essentially these simulators are like glorified game engines, right? They all look very game like when you look at them. But one thing that we've done is taken a data driven approach using real data of the real world. Can we build up synthetic environments that are super photo realistic and look like this, right? So this is a cool result that we created here at MIT developing this photo realistic simulation engine. This is actually an autonomous agent, not a real car driving through.", "SliceSentence": "And one really cool result that I want to just highlight here is that when we're training reinforcement learning algorithms we ultimately want them to be you know not operating in simulation We want them to be in reality And as part of our lab here at MIT we've been developing this very very cool brand new photo realistic simulation engine that goes beyond basically the paradigm of how simulators work today which is basically defining a model of their environment and trying to you know synthesize that that model Essentially these simulators are like glorified game engines right They all look very game like when you look at them But one thing that we've done is taken a data driven approach using real data of the real world Can we build up synthetic environments that are super photo realistic and look like this right So this is a cool result that we created here at MIT developing this photo realistic simulation engine This is actually an autonomous agent not a real car driving through", "StartMs": 2953720, "EndMs": 3014080, "WordsNum": 175, "Words": [{"Word": "And", "OffsetStartMs": 0, "OffsetEndMs": 345}, {"Word": "one", "OffsetStartMs": 345, "OffsetEndMs": 615}, {"Word": "really", "OffsetStartMs": 615, "OffsetEndMs": 870}, {"Word": "cool", "OffsetStartMs": 870, "OffsetEndMs": 1170}, {"Word": "result", "OffsetStartMs": 1170, "OffsetEndMs": 1425}, {"Word": "that", "OffsetStartMs": 1425, "OffsetEndMs": 1575}, {"Word": "I", "OffsetStartMs": 1575, "OffsetEndMs": 1680}, {"Word": "want", "OffsetStartMs": 1680, "OffsetEndMs": 1830}, {"Word": "to", "OffsetStartMs": 1830, "OffsetEndMs": 1980}, {"Word": "just", "OffsetStartMs": 1980, "OffsetEndMs": 2175}, {"Word": "highlight", "OffsetStartMs": 2175, "OffsetEndMs": 2505}, {"Word": "here", "OffsetStartMs": 2505, "OffsetEndMs": 2805}, {"Word": "is", "OffsetStartMs": 2805, "OffsetEndMs": 2985}, {"Word": "that", "OffsetStartMs": 2985, "OffsetEndMs": 3150}, {"Word": "when", "OffsetStartMs": 3150, "OffsetEndMs": 3330}, {"Word": "we're", "OffsetStartMs": 3330, "OffsetEndMs": 3570}, {"Word": "training", "OffsetStartMs": 3570, "OffsetEndMs": 3825}, {"Word": "reinforcement", "OffsetStartMs": 3825, "OffsetEndMs": 4470}, {"Word": "learning", "OffsetStartMs": 4470, "OffsetEndMs": 4730}, {"Word": "algorithms", "OffsetStartMs": 4780, "OffsetEndMs": 5250}, {"Word": "we", "OffsetStartMs": 5250, "OffsetEndMs": 5535}, {"Word": "ultimately", "OffsetStartMs": 5535, "OffsetEndMs": 5865}, {"Word": "want", "OffsetStartMs": 5865, "OffsetEndMs": 6165}, {"Word": "them", "OffsetStartMs": 6165, "OffsetEndMs": 6435}, {"Word": "to", "OffsetStartMs": 6435, "OffsetEndMs": 6630}, {"Word": "be", "OffsetStartMs": 6630, "OffsetEndMs": 6890}, {"Word": "you", "OffsetStartMs": 7030, "OffsetEndMs": 7275}, {"Word": "know", "OffsetStartMs": 7275, "OffsetEndMs": 7455}, {"Word": "not", "OffsetStartMs": 7455, "OffsetEndMs": 7790}, {"Word": "operating", "OffsetStartMs": 7840, "OffsetEndMs": 8175}, {"Word": "in", "OffsetStartMs": 8175, "OffsetEndMs": 8385}, {"Word": "simulation", "OffsetStartMs": 8385, "OffsetEndMs": 8775}, {"Word": "We", "OffsetStartMs": 8775, "OffsetEndMs": 8985}, {"Word": "want", "OffsetStartMs": 8985, "OffsetEndMs": 9180}, {"Word": "them", "OffsetStartMs": 9180, "OffsetEndMs": 9390}, {"Word": "to", "OffsetStartMs": 9390, "OffsetEndMs": 9525}, {"Word": "be", "OffsetStartMs": 9525, "OffsetEndMs": 9630}, {"Word": "in", "OffsetStartMs": 9630, "OffsetEndMs": 9870}, {"Word": "reality", "OffsetStartMs": 9870, "OffsetEndMs": 10250}, {"Word": "And", "OffsetStartMs": 10930, "OffsetEndMs": 11330}, {"Word": "as", "OffsetStartMs": 12100, "OffsetEndMs": 12435}, {"Word": "part", "OffsetStartMs": 12435, "OffsetEndMs": 12660}, {"Word": "of", "OffsetStartMs": 12660, "OffsetEndMs": 12950}, {"Word": "our", "OffsetStartMs": 13000, "OffsetEndMs": 13320}, {"Word": "lab", "OffsetStartMs": 13320, "OffsetEndMs": 13575}, {"Word": "here", "OffsetStartMs": 13575, "OffsetEndMs": 13785}, {"Word": "at", "OffsetStartMs": 13785, "OffsetEndMs": 13965}, {"Word": "MIT", "OffsetStartMs": 13965, "OffsetEndMs": 14250}, {"Word": "we've", "OffsetStartMs": 14250, "OffsetEndMs": 14625}, {"Word": "been", "OffsetStartMs": 14625, "OffsetEndMs": 14880}, {"Word": "developing", "OffsetStartMs": 14880, "OffsetEndMs": 15225}, {"Word": "this", "OffsetStartMs": 15225, "OffsetEndMs": 15620}, {"Word": "very", "OffsetStartMs": 15670, "OffsetEndMs": 16070}, {"Word": "very", "OffsetStartMs": 16270, "OffsetEndMs": 16665}, {"Word": "cool", "OffsetStartMs": 16665, "OffsetEndMs": 17040}, {"Word": "brand", "OffsetStartMs": 17040, "OffsetEndMs": 17340}, {"Word": "new", "OffsetStartMs": 17340, "OffsetEndMs": 17550}, {"Word": "photo", "OffsetStartMs": 17550, "OffsetEndMs": 17760}, {"Word": "realistic", "OffsetStartMs": 17760, "OffsetEndMs": 18300}, {"Word": "simulation", "OffsetStartMs": 18300, "OffsetEndMs": 18825}, {"Word": "engine", "OffsetStartMs": 18825, "OffsetEndMs": 19220}, {"Word": "that", "OffsetStartMs": 19360, "OffsetEndMs": 19665}, {"Word": "goes", "OffsetStartMs": 19665, "OffsetEndMs": 19965}, {"Word": "beyond", "OffsetStartMs": 19965, "OffsetEndMs": 20360}, {"Word": "basically", "OffsetStartMs": 20560, "OffsetEndMs": 20960}, {"Word": "the", "OffsetStartMs": 21040, "OffsetEndMs": 21345}, {"Word": "paradigm", "OffsetStartMs": 21345, "OffsetEndMs": 21975}, {"Word": "of", "OffsetStartMs": 21975, "OffsetEndMs": 22170}, {"Word": "how", "OffsetStartMs": 22170, "OffsetEndMs": 22490}, {"Word": "simulators", "OffsetStartMs": 22540, "OffsetEndMs": 23150}, {"Word": "work", "OffsetStartMs": 23200, "OffsetEndMs": 23600}, {"Word": "today", "OffsetStartMs": 23620, "OffsetEndMs": 24020}, {"Word": "which", "OffsetStartMs": 24040, "OffsetEndMs": 24300}, {"Word": "is", "OffsetStartMs": 24300, "OffsetEndMs": 24560}, {"Word": "basically", "OffsetStartMs": 24640, "OffsetEndMs": 25040}, {"Word": "defining", "OffsetStartMs": 25150, "OffsetEndMs": 25605}, {"Word": "a", "OffsetStartMs": 25605, "OffsetEndMs": 25725}, {"Word": "model", "OffsetStartMs": 25725, "OffsetEndMs": 25950}, {"Word": "of", "OffsetStartMs": 25950, "OffsetEndMs": 26175}, {"Word": "their", "OffsetStartMs": 26175, "OffsetEndMs": 26385}, {"Word": "environment", "OffsetStartMs": 26385, "OffsetEndMs": 26720}, {"Word": "and", "OffsetStartMs": 27190, "OffsetEndMs": 27570}, {"Word": "trying", "OffsetStartMs": 27570, "OffsetEndMs": 27885}, {"Word": "to", "OffsetStartMs": 27885, "OffsetEndMs": 28185}, {"Word": "you", "OffsetStartMs": 28185, "OffsetEndMs": 28395}, {"Word": "know", "OffsetStartMs": 28395, "OffsetEndMs": 28590}, {"Word": "synthesize", "OffsetStartMs": 28590, "OffsetEndMs": 29205}, {"Word": "that", "OffsetStartMs": 29205, "OffsetEndMs": 29570}, {"Word": "that", "OffsetStartMs": 29590, "OffsetEndMs": 29895}, {"Word": "model", "OffsetStartMs": 29895, "OffsetEndMs": 30200}, {"Word": "Essentially", "OffsetStartMs": 30550, "OffsetEndMs": 30945}, {"Word": "these", "OffsetStartMs": 30945, "OffsetEndMs": 31340}, {"Word": "simulators", "OffsetStartMs": 31360, "OffsetEndMs": 31905}, {"Word": "are", "OffsetStartMs": 31905, "OffsetEndMs": 32115}, {"Word": "like", "OffsetStartMs": 32115, "OffsetEndMs": 32370}, {"Word": "glorified", "OffsetStartMs": 32370, "OffsetEndMs": 32910}, {"Word": "game", "OffsetStartMs": 32910, "OffsetEndMs": 33135}, {"Word": "engines", "OffsetStartMs": 33135, "OffsetEndMs": 33440}, {"Word": "right", "OffsetStartMs": 33580, "OffsetEndMs": 33900}, {"Word": "They", "OffsetStartMs": 33900, "OffsetEndMs": 34110}, {"Word": "all", "OffsetStartMs": 34110, "OffsetEndMs": 34320}, {"Word": "look", "OffsetStartMs": 34320, "OffsetEndMs": 34560}, {"Word": "very", "OffsetStartMs": 34560, "OffsetEndMs": 34830}, {"Word": "game", "OffsetStartMs": 34830, "OffsetEndMs": 35115}, {"Word": "like", "OffsetStartMs": 35115, "OffsetEndMs": 35450}, {"Word": "when", "OffsetStartMs": 35650, "OffsetEndMs": 35910}, {"Word": "you", "OffsetStartMs": 35910, "OffsetEndMs": 36030}, {"Word": "look", "OffsetStartMs": 36030, "OffsetEndMs": 36165}, {"Word": "at", "OffsetStartMs": 36165, "OffsetEndMs": 36300}, {"Word": "them", "OffsetStartMs": 36300, "OffsetEndMs": 36560}, {"Word": "But", "OffsetStartMs": 36940, "OffsetEndMs": 37340}, {"Word": "one", "OffsetStartMs": 37360, "OffsetEndMs": 37650}, {"Word": "thing", "OffsetStartMs": 37650, "OffsetEndMs": 37815}, {"Word": "that", "OffsetStartMs": 37815, "OffsetEndMs": 37965}, {"Word": "we've", "OffsetStartMs": 37965, "OffsetEndMs": 38310}, {"Word": "done", "OffsetStartMs": 38310, "OffsetEndMs": 38660}, {"Word": "is", "OffsetStartMs": 38740, "OffsetEndMs": 39140}, {"Word": "taken", "OffsetStartMs": 39520, "OffsetEndMs": 39855}, {"Word": "a", "OffsetStartMs": 39855, "OffsetEndMs": 40080}, {"Word": "data", "OffsetStartMs": 40080, "OffsetEndMs": 40305}, {"Word": "driven", "OffsetStartMs": 40305, "OffsetEndMs": 40620}, {"Word": "approach", "OffsetStartMs": 40620, "OffsetEndMs": 41000}, {"Word": "using", "OffsetStartMs": 41020, "OffsetEndMs": 41420}, {"Word": "real", "OffsetStartMs": 41470, "OffsetEndMs": 41805}, {"Word": "data", "OffsetStartMs": 41805, "OffsetEndMs": 42090}, {"Word": "of", "OffsetStartMs": 42090, "OffsetEndMs": 42330}, {"Word": "the", "OffsetStartMs": 42330, "OffsetEndMs": 42510}, {"Word": "real", "OffsetStartMs": 42510, "OffsetEndMs": 42720}, {"Word": "world", "OffsetStartMs": 42720, "OffsetEndMs": 43040}, {"Word": "Can", "OffsetStartMs": 43330, "OffsetEndMs": 43620}, {"Word": "we", "OffsetStartMs": 43620, "OffsetEndMs": 43800}, {"Word": "build", "OffsetStartMs": 43800, "OffsetEndMs": 43995}, {"Word": "up", "OffsetStartMs": 43995, "OffsetEndMs": 44300}, {"Word": "synthetic", "OffsetStartMs": 44320, "OffsetEndMs": 44930}, {"Word": "environments", "OffsetStartMs": 44950, "OffsetEndMs": 45650}, {"Word": "that", "OffsetStartMs": 45880, "OffsetEndMs": 46230}, {"Word": "are", "OffsetStartMs": 46230, "OffsetEndMs": 46580}, {"Word": "super", "OffsetStartMs": 46630, "OffsetEndMs": 47010}, {"Word": "photo", "OffsetStartMs": 47010, "OffsetEndMs": 47310}, {"Word": "realistic", "OffsetStartMs": 47310, "OffsetEndMs": 47910}, {"Word": "and", "OffsetStartMs": 47910, "OffsetEndMs": 48090}, {"Word": "look", "OffsetStartMs": 48090, "OffsetEndMs": 48255}, {"Word": "like", "OffsetStartMs": 48255, "OffsetEndMs": 48450}, {"Word": "this", "OffsetStartMs": 48450, "OffsetEndMs": 48770}, {"Word": "right", "OffsetStartMs": 48940, "OffsetEndMs": 49245}, {"Word": "So", "OffsetStartMs": 49245, "OffsetEndMs": 49395}, {"Word": "this", "OffsetStartMs": 49395, "OffsetEndMs": 49515}, {"Word": "is", "OffsetStartMs": 49515, "OffsetEndMs": 49790}, {"Word": "a", "OffsetStartMs": 49840, "OffsetEndMs": 50130}, {"Word": "cool", "OffsetStartMs": 50130, "OffsetEndMs": 50370}, {"Word": "result", "OffsetStartMs": 50370, "OffsetEndMs": 50610}, {"Word": "that", "OffsetStartMs": 50610, "OffsetEndMs": 50760}, {"Word": "we", "OffsetStartMs": 50760, "OffsetEndMs": 50925}, {"Word": "created", "OffsetStartMs": 50925, "OffsetEndMs": 51230}, {"Word": "here", "OffsetStartMs": 51910, "OffsetEndMs": 52200}, {"Word": "at", "OffsetStartMs": 52200, "OffsetEndMs": 52440}, {"Word": "MIT", "OffsetStartMs": 52440, "OffsetEndMs": 52790}, {"Word": "developing", "OffsetStartMs": 53410, "OffsetEndMs": 53790}, {"Word": "this", "OffsetStartMs": 53790, "OffsetEndMs": 54120}, {"Word": "photo", "OffsetStartMs": 54120, "OffsetEndMs": 54405}, {"Word": "realistic", "OffsetStartMs": 54405, "OffsetEndMs": 55035}, {"Word": "simulation", "OffsetStartMs": 55035, "OffsetEndMs": 55530}, {"Word": "engine", "OffsetStartMs": 55530, "OffsetEndMs": 55800}, {"Word": "This", "OffsetStartMs": 55800, "OffsetEndMs": 56025}, {"Word": "is", "OffsetStartMs": 56025, "OffsetEndMs": 56280}, {"Word": "actually", "OffsetStartMs": 56280, "OffsetEndMs": 56505}, {"Word": "an", "OffsetStartMs": 56505, "OffsetEndMs": 56595}, {"Word": "autonomous", "OffsetStartMs": 56595, "OffsetEndMs": 57120}, {"Word": "agent", "OffsetStartMs": 57120, "OffsetEndMs": 57380}, {"Word": "not", "OffsetStartMs": 57880, "OffsetEndMs": 58170}, {"Word": "a", "OffsetStartMs": 58170, "OffsetEndMs": 58320}, {"Word": "real", "OffsetStartMs": 58320, "OffsetEndMs": 58515}, {"Word": "car", "OffsetStartMs": 58515, "OffsetEndMs": 58850}, {"Word": "driving", "OffsetStartMs": 59170, "OffsetEndMs": 59570}, {"Word": "through", "OffsetStartMs": 59770, "OffsetEndMs": 60170}], "SpeechSpeed": 16.5}, {"FinalSentence": "Our virtual simulator and a bunch of different types of different scenarios. So this simulator is called vista, allows us to basically use real data that we do collect in the real world, but then re-simulate those same real roads. So for example, let's say you take your car, you drive out on mass, have you collect data of mass have you can now drop a virtual agent into that same simulated environment, observing new viewpoints of what that scene might have looked like from different types of perturbations or, or types of angles that it might be exposed to.", "SliceSentence": "Our virtual simulator and a bunch of different types of different scenarios So this simulator is called vista allows us to basically use real data that we do collect in the real world but then re -simulate those same real roads So for example let's say you take your car you drive out on mass have you collect data of mass have you can now drop a virtual agent into that same simulated environment observing new viewpoints of what that scene might have looked like from different types of perturbations or or types of angles that it might be exposed to", "StartMs": 3014080, "EndMs": 3047760, "WordsNum": 101, "Words": [{"Word": "Our", "OffsetStartMs": 190, "OffsetEndMs": 510}, {"Word": "virtual", "OffsetStartMs": 510, "OffsetEndMs": 830}, {"Word": "simulator", "OffsetStartMs": 850, "OffsetEndMs": 1380}, {"Word": "and", "OffsetStartMs": 1380, "OffsetEndMs": 1500}, {"Word": "a", "OffsetStartMs": 1500, "OffsetEndMs": 1605}, {"Word": "bunch", "OffsetStartMs": 1605, "OffsetEndMs": 1800}, {"Word": "of", "OffsetStartMs": 1800, "OffsetEndMs": 1980}, {"Word": "different", "OffsetStartMs": 1980, "OffsetEndMs": 2205}, {"Word": "types", "OffsetStartMs": 2205, "OffsetEndMs": 2520}, {"Word": "of", "OffsetStartMs": 2520, "OffsetEndMs": 2805}, {"Word": "different", "OffsetStartMs": 2805, "OffsetEndMs": 3135}, {"Word": "scenarios", "OffsetStartMs": 3135, "OffsetEndMs": 3830}, {"Word": "So", "OffsetStartMs": 4150, "OffsetEndMs": 4410}, {"Word": "this", "OffsetStartMs": 4410, "OffsetEndMs": 4575}, {"Word": "simulator", "OffsetStartMs": 4575, "OffsetEndMs": 4980}, {"Word": "is", "OffsetStartMs": 4980, "OffsetEndMs": 5145}, {"Word": "called", "OffsetStartMs": 5145, "OffsetEndMs": 5325}, {"Word": "vista", "OffsetStartMs": 5325, "OffsetEndMs": 5745}, {"Word": "allows", "OffsetStartMs": 5745, "OffsetEndMs": 5985}, {"Word": "us", "OffsetStartMs": 5985, "OffsetEndMs": 6195}, {"Word": "to", "OffsetStartMs": 6195, "OffsetEndMs": 6330}, {"Word": "basically", "OffsetStartMs": 6330, "OffsetEndMs": 6590}, {"Word": "use", "OffsetStartMs": 6730, "OffsetEndMs": 7130}, {"Word": "real", "OffsetStartMs": 7240, "OffsetEndMs": 7575}, {"Word": "data", "OffsetStartMs": 7575, "OffsetEndMs": 7910}, {"Word": "that", "OffsetStartMs": 7930, "OffsetEndMs": 8190}, {"Word": "we", "OffsetStartMs": 8190, "OffsetEndMs": 8355}, {"Word": "do", "OffsetStartMs": 8355, "OffsetEndMs": 8625}, {"Word": "collect", "OffsetStartMs": 8625, "OffsetEndMs": 8880}, {"Word": "in", "OffsetStartMs": 8880, "OffsetEndMs": 9030}, {"Word": "the", "OffsetStartMs": 9030, "OffsetEndMs": 9150}, {"Word": "real", "OffsetStartMs": 9150, "OffsetEndMs": 9330}, {"Word": "world", "OffsetStartMs": 9330, "OffsetEndMs": 9650}, {"Word": "but", "OffsetStartMs": 9970, "OffsetEndMs": 10245}, {"Word": "then", "OffsetStartMs": 10245, "OffsetEndMs": 10455}, {"Word": "re", "OffsetStartMs": 10455, "OffsetEndMs": 10740}, {"Word": "-simulate", "OffsetStartMs": 10740, "OffsetEndMs": 11390}, {"Word": "those", "OffsetStartMs": 11410, "OffsetEndMs": 11790}, {"Word": "same", "OffsetStartMs": 11790, "OffsetEndMs": 12165}, {"Word": "real", "OffsetStartMs": 12165, "OffsetEndMs": 12510}, {"Word": "roads", "OffsetStartMs": 12510, "OffsetEndMs": 12860}, {"Word": "So", "OffsetStartMs": 12940, "OffsetEndMs": 13260}, {"Word": "for", "OffsetStartMs": 13260, "OffsetEndMs": 13470}, {"Word": "example", "OffsetStartMs": 13470, "OffsetEndMs": 13695}, {"Word": "let's", "OffsetStartMs": 13695, "OffsetEndMs": 13950}, {"Word": "say", "OffsetStartMs": 13950, "OffsetEndMs": 14055}, {"Word": "you", "OffsetStartMs": 14055, "OffsetEndMs": 14220}, {"Word": "take", "OffsetStartMs": 14220, "OffsetEndMs": 14370}, {"Word": "your", "OffsetStartMs": 14370, "OffsetEndMs": 14505}, {"Word": "car", "OffsetStartMs": 14505, "OffsetEndMs": 14655}, {"Word": "you", "OffsetStartMs": 14655, "OffsetEndMs": 14805}, {"Word": "drive", "OffsetStartMs": 14805, "OffsetEndMs": 14985}, {"Word": "out", "OffsetStartMs": 14985, "OffsetEndMs": 15165}, {"Word": "on", "OffsetStartMs": 15165, "OffsetEndMs": 15330}, {"Word": "mass", "OffsetStartMs": 15330, "OffsetEndMs": 15540}, {"Word": "have", "OffsetStartMs": 15540, "OffsetEndMs": 15860}, {"Word": "you", "OffsetStartMs": 16090, "OffsetEndMs": 16410}, {"Word": "collect", "OffsetStartMs": 16410, "OffsetEndMs": 16635}, {"Word": "data", "OffsetStartMs": 16635, "OffsetEndMs": 16845}, {"Word": "of", "OffsetStartMs": 16845, "OffsetEndMs": 17040}, {"Word": "mass", "OffsetStartMs": 17040, "OffsetEndMs": 17265}, {"Word": "have", "OffsetStartMs": 17265, "OffsetEndMs": 17600}, {"Word": "you", "OffsetStartMs": 17860, "OffsetEndMs": 18135}, {"Word": "can", "OffsetStartMs": 18135, "OffsetEndMs": 18270}, {"Word": "now", "OffsetStartMs": 18270, "OffsetEndMs": 18530}, {"Word": "drop", "OffsetStartMs": 18610, "OffsetEndMs": 19005}, {"Word": "a", "OffsetStartMs": 19005, "OffsetEndMs": 19320}, {"Word": "virtual", "OffsetStartMs": 19320, "OffsetEndMs": 19635}, {"Word": "agent", "OffsetStartMs": 19635, "OffsetEndMs": 20030}, {"Word": "into", "OffsetStartMs": 20290, "OffsetEndMs": 20690}, {"Word": "that", "OffsetStartMs": 20770, "OffsetEndMs": 21120}, {"Word": "same", "OffsetStartMs": 21120, "OffsetEndMs": 21470}, {"Word": "simulated", "OffsetStartMs": 21490, "OffsetEndMs": 22125}, {"Word": "environment", "OffsetStartMs": 22125, "OffsetEndMs": 22520}, {"Word": "observing", "OffsetStartMs": 23140, "OffsetEndMs": 23540}, {"Word": "new", "OffsetStartMs": 23740, "OffsetEndMs": 24090}, {"Word": "viewpoints", "OffsetStartMs": 24090, "OffsetEndMs": 24890}, {"Word": "of", "OffsetStartMs": 25000, "OffsetEndMs": 25320}, {"Word": "what", "OffsetStartMs": 25320, "OffsetEndMs": 25545}, {"Word": "that", "OffsetStartMs": 25545, "OffsetEndMs": 25800}, {"Word": "scene", "OffsetStartMs": 25800, "OffsetEndMs": 26055}, {"Word": "might", "OffsetStartMs": 26055, "OffsetEndMs": 26220}, {"Word": "have", "OffsetStartMs": 26220, "OffsetEndMs": 26370}, {"Word": "looked", "OffsetStartMs": 26370, "OffsetEndMs": 26580}, {"Word": "like", "OffsetStartMs": 26580, "OffsetEndMs": 26820}, {"Word": "from", "OffsetStartMs": 26820, "OffsetEndMs": 27060}, {"Word": "different", "OffsetStartMs": 27060, "OffsetEndMs": 27360}, {"Word": "types", "OffsetStartMs": 27360, "OffsetEndMs": 27675}, {"Word": "of", "OffsetStartMs": 27675, "OffsetEndMs": 28010}, {"Word": "perturbations", "OffsetStartMs": 28540, "OffsetEndMs": 29150}, {"Word": "or", "OffsetStartMs": 29320, "OffsetEndMs": 29720}, {"Word": "or", "OffsetStartMs": 29800, "OffsetEndMs": 30150}, {"Word": "types", "OffsetStartMs": 30150, "OffsetEndMs": 30420}, {"Word": "of", "OffsetStartMs": 30420, "OffsetEndMs": 30740}, {"Word": "angles", "OffsetStartMs": 31180, "OffsetEndMs": 31800}, {"Word": "that", "OffsetStartMs": 31800, "OffsetEndMs": 32040}, {"Word": "it", "OffsetStartMs": 32040, "OffsetEndMs": 32160}, {"Word": "might", "OffsetStartMs": 32160, "OffsetEndMs": 32310}, {"Word": "be", "OffsetStartMs": 32310, "OffsetEndMs": 32595}, {"Word": "exposed", "OffsetStartMs": 32595, "OffsetEndMs": 32955}, {"Word": "to", "OffsetStartMs": 32955, "OffsetEndMs": 33320}], "SpeechSpeed": 16.4}, {"FinalSentence": "And that allows us to train these agents now entirely using reinforcement learning, no human labels, but importantly allowed them to be transferred into reality because there's no SIM to real gap anymore. So in fact, we did exactly this. We placed agents into our simulator, we trained them using the exact algorithms that you learned about in today's lecture, these policy gradient algorithms and all of the training was done entirely in simulation. Then we took these policies and we deployed them on board our full scale autonomous vehicle. This is now in the real world, no longer in simulation, and on the left hand side you can see.", "SliceSentence": "And that allows us to train these agents now entirely using reinforcement learning no human labels but importantly allowed them to be transferred into reality because there's no SIM to real gap anymore So in fact we did exactly this We placed agents into our simulator we trained them using the exact algorithms that you learned about in today's lecture these policy gradient algorithms and all of the training was done entirely in simulation Then we took these policies and we deployed them on board our full scale autonomous vehicle This is now in the real world no longer in simulation and on the left hand side you can see", "StartMs": 3047760, "EndMs": 3086620, "WordsNum": 110, "Words": [{"Word": "And", "OffsetStartMs": 40, "OffsetEndMs": 405}, {"Word": "that", "OffsetStartMs": 405, "OffsetEndMs": 690}, {"Word": "allows", "OffsetStartMs": 690, "OffsetEndMs": 930}, {"Word": "us", "OffsetStartMs": 930, "OffsetEndMs": 1170}, {"Word": "to", "OffsetStartMs": 1170, "OffsetEndMs": 1395}, {"Word": "train", "OffsetStartMs": 1395, "OffsetEndMs": 1635}, {"Word": "these", "OffsetStartMs": 1635, "OffsetEndMs": 1845}, {"Word": "agents", "OffsetStartMs": 1845, "OffsetEndMs": 2120}, {"Word": "now", "OffsetStartMs": 2170, "OffsetEndMs": 2570}, {"Word": "entirely", "OffsetStartMs": 2680, "OffsetEndMs": 3080}, {"Word": "using", "OffsetStartMs": 3310, "OffsetEndMs": 3675}, {"Word": "reinforcement", "OffsetStartMs": 3675, "OffsetEndMs": 4410}, {"Word": "learning", "OffsetStartMs": 4410, "OffsetEndMs": 4670}, {"Word": "no", "OffsetStartMs": 4870, "OffsetEndMs": 5205}, {"Word": "human", "OffsetStartMs": 5205, "OffsetEndMs": 5490}, {"Word": "labels", "OffsetStartMs": 5490, "OffsetEndMs": 6050}, {"Word": "but", "OffsetStartMs": 6670, "OffsetEndMs": 7070}, {"Word": "importantly", "OffsetStartMs": 7240, "OffsetEndMs": 7640}, {"Word": "allowed", "OffsetStartMs": 7810, "OffsetEndMs": 8145}, {"Word": "them", "OffsetStartMs": 8145, "OffsetEndMs": 8475}, {"Word": "to", "OffsetStartMs": 8475, "OffsetEndMs": 8715}, {"Word": "be", "OffsetStartMs": 8715, "OffsetEndMs": 8895}, {"Word": "transferred", "OffsetStartMs": 8895, "OffsetEndMs": 9435}, {"Word": "into", "OffsetStartMs": 9435, "OffsetEndMs": 9720}, {"Word": "reality", "OffsetStartMs": 9720, "OffsetEndMs": 10070}, {"Word": "because", "OffsetStartMs": 10180, "OffsetEndMs": 10470}, {"Word": "there's", "OffsetStartMs": 10470, "OffsetEndMs": 10830}, {"Word": "no", "OffsetStartMs": 10830, "OffsetEndMs": 11145}, {"Word": "SIM", "OffsetStartMs": 11145, "OffsetEndMs": 11415}, {"Word": "to", "OffsetStartMs": 11415, "OffsetEndMs": 11580}, {"Word": "real", "OffsetStartMs": 11580, "OffsetEndMs": 11760}, {"Word": "gap", "OffsetStartMs": 11760, "OffsetEndMs": 12080}, {"Word": "anymore", "OffsetStartMs": 12460, "OffsetEndMs": 12860}, {"Word": "So", "OffsetStartMs": 13030, "OffsetEndMs": 13260}, {"Word": "in", "OffsetStartMs": 13260, "OffsetEndMs": 13350}, {"Word": "fact", "OffsetStartMs": 13350, "OffsetEndMs": 13530}, {"Word": "we", "OffsetStartMs": 13530, "OffsetEndMs": 13850}, {"Word": "did", "OffsetStartMs": 14260, "OffsetEndMs": 14640}, {"Word": "exactly", "OffsetStartMs": 14640, "OffsetEndMs": 15000}, {"Word": "this", "OffsetStartMs": 15000, "OffsetEndMs": 15380}, {"Word": "We", "OffsetStartMs": 15520, "OffsetEndMs": 15840}, {"Word": "placed", "OffsetStartMs": 15840, "OffsetEndMs": 16160}, {"Word": "agents", "OffsetStartMs": 16180, "OffsetEndMs": 16580}, {"Word": "into", "OffsetStartMs": 17140, "OffsetEndMs": 17460}, {"Word": "our", "OffsetStartMs": 17460, "OffsetEndMs": 17685}, {"Word": "simulator", "OffsetStartMs": 17685, "OffsetEndMs": 18135}, {"Word": "we", "OffsetStartMs": 18135, "OffsetEndMs": 18360}, {"Word": "trained", "OffsetStartMs": 18360, "OffsetEndMs": 18600}, {"Word": "them", "OffsetStartMs": 18600, "OffsetEndMs": 18810}, {"Word": "using", "OffsetStartMs": 18810, "OffsetEndMs": 19100}, {"Word": "the", "OffsetStartMs": 19300, "OffsetEndMs": 19650}, {"Word": "exact", "OffsetStartMs": 19650, "OffsetEndMs": 20000}, {"Word": "algorithms", "OffsetStartMs": 20230, "OffsetEndMs": 20750}, {"Word": "that", "OffsetStartMs": 20920, "OffsetEndMs": 21180}, {"Word": "you", "OffsetStartMs": 21180, "OffsetEndMs": 21330}, {"Word": "learned", "OffsetStartMs": 21330, "OffsetEndMs": 21555}, {"Word": "about", "OffsetStartMs": 21555, "OffsetEndMs": 21780}, {"Word": "in", "OffsetStartMs": 21780, "OffsetEndMs": 21945}, {"Word": "today's", "OffsetStartMs": 21945, "OffsetEndMs": 22320}, {"Word": "lecture", "OffsetStartMs": 22320, "OffsetEndMs": 22590}, {"Word": "these", "OffsetStartMs": 22590, "OffsetEndMs": 22875}, {"Word": "policy", "OffsetStartMs": 22875, "OffsetEndMs": 23175}, {"Word": "gradient", "OffsetStartMs": 23175, "OffsetEndMs": 23730}, {"Word": "algorithms", "OffsetStartMs": 23730, "OffsetEndMs": 24230}, {"Word": "and", "OffsetStartMs": 24490, "OffsetEndMs": 24795}, {"Word": "all", "OffsetStartMs": 24795, "OffsetEndMs": 24990}, {"Word": "of", "OffsetStartMs": 24990, "OffsetEndMs": 25155}, {"Word": "the", "OffsetStartMs": 25155, "OffsetEndMs": 25320}, {"Word": "training", "OffsetStartMs": 25320, "OffsetEndMs": 25575}, {"Word": "was", "OffsetStartMs": 25575, "OffsetEndMs": 25830}, {"Word": "done", "OffsetStartMs": 25830, "OffsetEndMs": 26120}, {"Word": "entirely", "OffsetStartMs": 26140, "OffsetEndMs": 26540}, {"Word": "in", "OffsetStartMs": 26770, "OffsetEndMs": 27105}, {"Word": "simulation", "OffsetStartMs": 27105, "OffsetEndMs": 27680}, {"Word": "Then", "OffsetStartMs": 28150, "OffsetEndMs": 28500}, {"Word": "we", "OffsetStartMs": 28500, "OffsetEndMs": 28725}, {"Word": "took", "OffsetStartMs": 28725, "OffsetEndMs": 28890}, {"Word": "these", "OffsetStartMs": 28890, "OffsetEndMs": 29085}, {"Word": "policies", "OffsetStartMs": 29085, "OffsetEndMs": 29390}, {"Word": "and", "OffsetStartMs": 29500, "OffsetEndMs": 29775}, {"Word": "we", "OffsetStartMs": 29775, "OffsetEndMs": 30000}, {"Word": "deployed", "OffsetStartMs": 30000, "OffsetEndMs": 30330}, {"Word": "them", "OffsetStartMs": 30330, "OffsetEndMs": 30540}, {"Word": "on", "OffsetStartMs": 30540, "OffsetEndMs": 30825}, {"Word": "board", "OffsetStartMs": 30825, "OffsetEndMs": 31155}, {"Word": "our", "OffsetStartMs": 31155, "OffsetEndMs": 31500}, {"Word": "full", "OffsetStartMs": 31500, "OffsetEndMs": 31785}, {"Word": "scale", "OffsetStartMs": 31785, "OffsetEndMs": 32040}, {"Word": "autonomous", "OffsetStartMs": 32040, "OffsetEndMs": 32595}, {"Word": "vehicle", "OffsetStartMs": 32595, "OffsetEndMs": 32870}, {"Word": "This", "OffsetStartMs": 32980, "OffsetEndMs": 33240}, {"Word": "is", "OffsetStartMs": 33240, "OffsetEndMs": 33390}, {"Word": "now", "OffsetStartMs": 33390, "OffsetEndMs": 33570}, {"Word": "in", "OffsetStartMs": 33570, "OffsetEndMs": 33735}, {"Word": "the", "OffsetStartMs": 33735, "OffsetEndMs": 33870}, {"Word": "real", "OffsetStartMs": 33870, "OffsetEndMs": 34035}, {"Word": "world", "OffsetStartMs": 34035, "OffsetEndMs": 34340}, {"Word": "no", "OffsetStartMs": 34360, "OffsetEndMs": 34635}, {"Word": "longer", "OffsetStartMs": 34635, "OffsetEndMs": 34845}, {"Word": "in", "OffsetStartMs": 34845, "OffsetEndMs": 35070}, {"Word": "simulation", "OffsetStartMs": 35070, "OffsetEndMs": 35570}, {"Word": "and", "OffsetStartMs": 36100, "OffsetEndMs": 36500}, {"Word": "on", "OffsetStartMs": 36610, "OffsetEndMs": 36900}, {"Word": "the", "OffsetStartMs": 36900, "OffsetEndMs": 37035}, {"Word": "left", "OffsetStartMs": 37035, "OffsetEndMs": 37200}, {"Word": "hand", "OffsetStartMs": 37200, "OffsetEndMs": 37410}, {"Word": "side", "OffsetStartMs": 37410, "OffsetEndMs": 37590}, {"Word": "you", "OffsetStartMs": 37590, "OffsetEndMs": 37740}, {"Word": "can", "OffsetStartMs": 37740, "OffsetEndMs": 37905}, {"Word": "see", "OffsetStartMs": 37905, "OffsetEndMs": 38210}], "SpeechSpeed": 16.1}, {"FinalSentence": "Basically this car driving through this environment completely autonomous in the real world, no transfer learning is is done here. There is no augmentation of data from real world data. This is entirely trained using simulation and this represented actually the first time ever that reinforcement learning was used to train a policy end to end. We're an autonomous vehicle that could be deployed in reality. So that was something really cool that uh we we created here at MIT. But now that we covered, you know, all of these foundations of reinforcement learning and policy learning, I want to touch on some other maybe very exciting applications that we're seeing. And one very popular application that a lot of people will tell you about and talk about is the game of go.", "SliceSentence": "Basically this car driving through this environment completely autonomous in the real world no transfer learning is is done here There is no augmentation of data from real world data This is entirely trained using simulation and this represented actually the first time ever that reinforcement learning was used to train a policy end to end We're an autonomous vehicle that could be deployed in reality So that was something really cool that uh we we created here at MIT But now that we covered you know all of these foundations of reinforcement learning and policy learning I want to touch on some other maybe very exciting applications that we're seeing And one very popular application that a lot of people will tell you about and talk about is the game of go", "StartMs": 3086780, "EndMs": 3132900, "WordsNum": 133, "Words": [{"Word": "Basically", "OffsetStartMs": 70, "OffsetEndMs": 465}, {"Word": "this", "OffsetStartMs": 465, "OffsetEndMs": 780}, {"Word": "car", "OffsetStartMs": 780, "OffsetEndMs": 1100}, {"Word": "driving", "OffsetStartMs": 1450, "OffsetEndMs": 1850}, {"Word": "through", "OffsetStartMs": 1870, "OffsetEndMs": 2270}, {"Word": "this", "OffsetStartMs": 2320, "OffsetEndMs": 2670}, {"Word": "environment", "OffsetStartMs": 2670, "OffsetEndMs": 3020}, {"Word": "completely", "OffsetStartMs": 3400, "OffsetEndMs": 3765}, {"Word": "autonomous", "OffsetStartMs": 3765, "OffsetEndMs": 4500}, {"Word": "in", "OffsetStartMs": 4500, "OffsetEndMs": 4755}, {"Word": "the", "OffsetStartMs": 4755, "OffsetEndMs": 4890}, {"Word": "real", "OffsetStartMs": 4890, "OffsetEndMs": 5070}, {"Word": "world", "OffsetStartMs": 5070, "OffsetEndMs": 5390}, {"Word": "no", "OffsetStartMs": 5440, "OffsetEndMs": 5775}, {"Word": "transfer", "OffsetStartMs": 5775, "OffsetEndMs": 6105}, {"Word": "learning", "OffsetStartMs": 6105, "OffsetEndMs": 6450}, {"Word": "is", "OffsetStartMs": 6450, "OffsetEndMs": 6780}, {"Word": "is", "OffsetStartMs": 6780, "OffsetEndMs": 7080}, {"Word": "done", "OffsetStartMs": 7080, "OffsetEndMs": 7320}, {"Word": "here", "OffsetStartMs": 7320, "OffsetEndMs": 7640}, {"Word": "There", "OffsetStartMs": 7720, "OffsetEndMs": 7965}, {"Word": "is", "OffsetStartMs": 7965, "OffsetEndMs": 8145}, {"Word": "no", "OffsetStartMs": 8145, "OffsetEndMs": 8480}, {"Word": "augmentation", "OffsetStartMs": 9010, "OffsetEndMs": 9795}, {"Word": "of", "OffsetStartMs": 9795, "OffsetEndMs": 10035}, {"Word": "data", "OffsetStartMs": 10035, "OffsetEndMs": 10310}, {"Word": "from", "OffsetStartMs": 10420, "OffsetEndMs": 10725}, {"Word": "real", "OffsetStartMs": 10725, "OffsetEndMs": 10935}, {"Word": "world", "OffsetStartMs": 10935, "OffsetEndMs": 11175}, {"Word": "data", "OffsetStartMs": 11175, "OffsetEndMs": 11445}, {"Word": "This", "OffsetStartMs": 11445, "OffsetEndMs": 11655}, {"Word": "is", "OffsetStartMs": 11655, "OffsetEndMs": 11910}, {"Word": "entirely", "OffsetStartMs": 11910, "OffsetEndMs": 12290}, {"Word": "trained", "OffsetStartMs": 12310, "OffsetEndMs": 12710}, {"Word": "using", "OffsetStartMs": 12970, "OffsetEndMs": 13365}, {"Word": "simulation", "OffsetStartMs": 13365, "OffsetEndMs": 13935}, {"Word": "and", "OffsetStartMs": 13935, "OffsetEndMs": 14175}, {"Word": "this", "OffsetStartMs": 14175, "OffsetEndMs": 14340}, {"Word": "represented", "OffsetStartMs": 14340, "OffsetEndMs": 14630}, {"Word": "actually", "OffsetStartMs": 15040, "OffsetEndMs": 15315}, {"Word": "the", "OffsetStartMs": 15315, "OffsetEndMs": 15465}, {"Word": "first", "OffsetStartMs": 15465, "OffsetEndMs": 15675}, {"Word": "time", "OffsetStartMs": 15675, "OffsetEndMs": 15930}, {"Word": "ever", "OffsetStartMs": 15930, "OffsetEndMs": 16250}, {"Word": "that", "OffsetStartMs": 16630, "OffsetEndMs": 16935}, {"Word": "reinforcement", "OffsetStartMs": 16935, "OffsetEndMs": 17640}, {"Word": "learning", "OffsetStartMs": 17640, "OffsetEndMs": 17930}, {"Word": "was", "OffsetStartMs": 18040, "OffsetEndMs": 18360}, {"Word": "used", "OffsetStartMs": 18360, "OffsetEndMs": 18645}, {"Word": "to", "OffsetStartMs": 18645, "OffsetEndMs": 18930}, {"Word": "train", "OffsetStartMs": 18930, "OffsetEndMs": 19200}, {"Word": "a", "OffsetStartMs": 19200, "OffsetEndMs": 19440}, {"Word": "policy", "OffsetStartMs": 19440, "OffsetEndMs": 19730}, {"Word": "end", "OffsetStartMs": 19810, "OffsetEndMs": 20130}, {"Word": "to", "OffsetStartMs": 20130, "OffsetEndMs": 20295}, {"Word": "end", "OffsetStartMs": 20295, "OffsetEndMs": 20540}, {"Word": "We're", "OffsetStartMs": 20980, "OffsetEndMs": 21270}, {"Word": "an", "OffsetStartMs": 21270, "OffsetEndMs": 21330}, {"Word": "autonomous", "OffsetStartMs": 21330, "OffsetEndMs": 21765}, {"Word": "vehicle", "OffsetStartMs": 21765, "OffsetEndMs": 22005}, {"Word": "that", "OffsetStartMs": 22005, "OffsetEndMs": 22230}, {"Word": "could", "OffsetStartMs": 22230, "OffsetEndMs": 22350}, {"Word": "be", "OffsetStartMs": 22350, "OffsetEndMs": 22560}, {"Word": "deployed", "OffsetStartMs": 22560, "OffsetEndMs": 23090}, {"Word": "in", "OffsetStartMs": 23230, "OffsetEndMs": 23550}, {"Word": "reality", "OffsetStartMs": 23550, "OffsetEndMs": 23870}, {"Word": "So", "OffsetStartMs": 24010, "OffsetEndMs": 24255}, {"Word": "that", "OffsetStartMs": 24255, "OffsetEndMs": 24360}, {"Word": "was", "OffsetStartMs": 24360, "OffsetEndMs": 24480}, {"Word": "something", "OffsetStartMs": 24480, "OffsetEndMs": 24705}, {"Word": "really", "OffsetStartMs": 24705, "OffsetEndMs": 25020}, {"Word": "cool", "OffsetStartMs": 25020, "OffsetEndMs": 25275}, {"Word": "that", "OffsetStartMs": 25275, "OffsetEndMs": 25580}, {"Word": "uh", "OffsetStartMs": 25840, "OffsetEndMs": 26240}, {"Word": "we", "OffsetStartMs": 26290, "OffsetEndMs": 26655}, {"Word": "we", "OffsetStartMs": 26655, "OffsetEndMs": 26925}, {"Word": "created", "OffsetStartMs": 26925, "OffsetEndMs": 27195}, {"Word": "here", "OffsetStartMs": 27195, "OffsetEndMs": 27420}, {"Word": "at", "OffsetStartMs": 27420, "OffsetEndMs": 27600}, {"Word": "MIT", "OffsetStartMs": 27600, "OffsetEndMs": 27920}, {"Word": "But", "OffsetStartMs": 28090, "OffsetEndMs": 28395}, {"Word": "now", "OffsetStartMs": 28395, "OffsetEndMs": 28590}, {"Word": "that", "OffsetStartMs": 28590, "OffsetEndMs": 28740}, {"Word": "we", "OffsetStartMs": 28740, "OffsetEndMs": 28935}, {"Word": "covered", "OffsetStartMs": 28935, "OffsetEndMs": 29270}, {"Word": "you", "OffsetStartMs": 29560, "OffsetEndMs": 29805}, {"Word": "know", "OffsetStartMs": 29805, "OffsetEndMs": 29985}, {"Word": "all", "OffsetStartMs": 29985, "OffsetEndMs": 30225}, {"Word": "of", "OffsetStartMs": 30225, "OffsetEndMs": 30390}, {"Word": "these", "OffsetStartMs": 30390, "OffsetEndMs": 30555}, {"Word": "foundations", "OffsetStartMs": 30555, "OffsetEndMs": 31070}, {"Word": "of", "OffsetStartMs": 31390, "OffsetEndMs": 31785}, {"Word": "reinforcement", "OffsetStartMs": 31785, "OffsetEndMs": 32550}, {"Word": "learning", "OffsetStartMs": 32550, "OffsetEndMs": 32840}, {"Word": "and", "OffsetStartMs": 32980, "OffsetEndMs": 33285}, {"Word": "policy", "OffsetStartMs": 33285, "OffsetEndMs": 33590}, {"Word": "learning", "OffsetStartMs": 33610, "OffsetEndMs": 34010}, {"Word": "I", "OffsetStartMs": 34660, "OffsetEndMs": 34935}, {"Word": "want", "OffsetStartMs": 34935, "OffsetEndMs": 35085}, {"Word": "to", "OffsetStartMs": 35085, "OffsetEndMs": 35310}, {"Word": "touch", "OffsetStartMs": 35310, "OffsetEndMs": 35550}, {"Word": "on", "OffsetStartMs": 35550, "OffsetEndMs": 35730}, {"Word": "some", "OffsetStartMs": 35730, "OffsetEndMs": 35865}, {"Word": "other", "OffsetStartMs": 35865, "OffsetEndMs": 36110}, {"Word": "maybe", "OffsetStartMs": 36130, "OffsetEndMs": 36465}, {"Word": "very", "OffsetStartMs": 36465, "OffsetEndMs": 36765}, {"Word": "exciting", "OffsetStartMs": 36765, "OffsetEndMs": 37130}, {"Word": "applications", "OffsetStartMs": 37390, "OffsetEndMs": 37790}, {"Word": "that", "OffsetStartMs": 38170, "OffsetEndMs": 38570}, {"Word": "we're", "OffsetStartMs": 38710, "OffsetEndMs": 39090}, {"Word": "seeing", "OffsetStartMs": 39090, "OffsetEndMs": 39380}, {"Word": "And", "OffsetStartMs": 39730, "OffsetEndMs": 40130}, {"Word": "one", "OffsetStartMs": 40180, "OffsetEndMs": 40530}, {"Word": "very", "OffsetStartMs": 40530, "OffsetEndMs": 40880}, {"Word": "popular", "OffsetStartMs": 40990, "OffsetEndMs": 41390}, {"Word": "application", "OffsetStartMs": 41710, "OffsetEndMs": 42060}, {"Word": "that", "OffsetStartMs": 42060, "OffsetEndMs": 42255}, {"Word": "a", "OffsetStartMs": 42255, "OffsetEndMs": 42360}, {"Word": "lot", "OffsetStartMs": 42360, "OffsetEndMs": 42495}, {"Word": "of", "OffsetStartMs": 42495, "OffsetEndMs": 42630}, {"Word": "people", "OffsetStartMs": 42630, "OffsetEndMs": 42890}, {"Word": "will", "OffsetStartMs": 42910, "OffsetEndMs": 43230}, {"Word": "tell", "OffsetStartMs": 43230, "OffsetEndMs": 43440}, {"Word": "you", "OffsetStartMs": 43440, "OffsetEndMs": 43605}, {"Word": "about", "OffsetStartMs": 43605, "OffsetEndMs": 43755}, {"Word": "and", "OffsetStartMs": 43755, "OffsetEndMs": 43905}, {"Word": "talk", "OffsetStartMs": 43905, "OffsetEndMs": 44115}, {"Word": "about", "OffsetStartMs": 44115, "OffsetEndMs": 44370}, {"Word": "is", "OffsetStartMs": 44370, "OffsetEndMs": 44625}, {"Word": "the", "OffsetStartMs": 44625, "OffsetEndMs": 44835}, {"Word": "game", "OffsetStartMs": 44835, "OffsetEndMs": 45015}, {"Word": "of", "OffsetStartMs": 45015, "OffsetEndMs": 45240}, {"Word": "go", "OffsetStartMs": 45240, "OffsetEndMs": 45560}], "SpeechSpeed": 16.5}, {"FinalSentence": "So here reinforcement learning agents could be actually tried to put against the test against you know, grand master level go players and you know at the time achieved incredibly impressive results. So for those of you who are not familiar with the game of go go game of go is played on a nineteen by nineteen board. The rough objective of go is to claim basically more board pieces than your opponent, right? And through the grid of sorry through the grid that you can see here this nineteen by nineteen grid.", "SliceSentence": "So here reinforcement learning agents could be actually tried to put against the test against you know grand master level go players and you know at the time achieved incredibly impressive results So for those of you who are not familiar with the game of go go game of go is played on a nineteen by nineteen board The rough objective of go is to claim basically more board pieces than your opponent right And through the grid of sorry through the grid that you can see here this nineteen by nineteen grid", "StartMs": 3132900, "EndMs": 3166140, "WordsNum": 93, "Words": [{"Word": "So", "OffsetStartMs": 40, "OffsetEndMs": 345}, {"Word": "here", "OffsetStartMs": 345, "OffsetEndMs": 650}, {"Word": "reinforcement", "OffsetStartMs": 820, "OffsetEndMs": 1500}, {"Word": "learning", "OffsetStartMs": 1500, "OffsetEndMs": 1695}, {"Word": "agents", "OffsetStartMs": 1695, "OffsetEndMs": 2030}, {"Word": "could", "OffsetStartMs": 2230, "OffsetEndMs": 2505}, {"Word": "be", "OffsetStartMs": 2505, "OffsetEndMs": 2715}, {"Word": "actually", "OffsetStartMs": 2715, "OffsetEndMs": 3000}, {"Word": "tried", "OffsetStartMs": 3000, "OffsetEndMs": 3350}, {"Word": "to", "OffsetStartMs": 3760, "OffsetEndMs": 4160}, {"Word": "put", "OffsetStartMs": 4510, "OffsetEndMs": 4845}, {"Word": "against", "OffsetStartMs": 4845, "OffsetEndMs": 5100}, {"Word": "the", "OffsetStartMs": 5100, "OffsetEndMs": 5340}, {"Word": "test", "OffsetStartMs": 5340, "OffsetEndMs": 5660}, {"Word": "against", "OffsetStartMs": 5680, "OffsetEndMs": 6030}, {"Word": "you", "OffsetStartMs": 6030, "OffsetEndMs": 6225}, {"Word": "know", "OffsetStartMs": 6225, "OffsetEndMs": 6405}, {"Word": "grand", "OffsetStartMs": 6405, "OffsetEndMs": 6690}, {"Word": "master", "OffsetStartMs": 6690, "OffsetEndMs": 7040}, {"Word": "level", "OffsetStartMs": 7240, "OffsetEndMs": 7640}, {"Word": "go", "OffsetStartMs": 7990, "OffsetEndMs": 8325}, {"Word": "players", "OffsetStartMs": 8325, "OffsetEndMs": 8660}, {"Word": "and", "OffsetStartMs": 9280, "OffsetEndMs": 9680}, {"Word": "you", "OffsetStartMs": 9880, "OffsetEndMs": 10110}, {"Word": "know", "OffsetStartMs": 10110, "OffsetEndMs": 10305}, {"Word": "at", "OffsetStartMs": 10305, "OffsetEndMs": 10545}, {"Word": "the", "OffsetStartMs": 10545, "OffsetEndMs": 10725}, {"Word": "time", "OffsetStartMs": 10725, "OffsetEndMs": 11030}, {"Word": "achieved", "OffsetStartMs": 11140, "OffsetEndMs": 11540}, {"Word": "incredibly", "OffsetStartMs": 11650, "OffsetEndMs": 12050}, {"Word": "impressive", "OffsetStartMs": 12340, "OffsetEndMs": 12740}, {"Word": "results", "OffsetStartMs": 12910, "OffsetEndMs": 13245}, {"Word": "So", "OffsetStartMs": 13245, "OffsetEndMs": 13470}, {"Word": "for", "OffsetStartMs": 13470, "OffsetEndMs": 13620}, {"Word": "those", "OffsetStartMs": 13620, "OffsetEndMs": 13755}, {"Word": "of", "OffsetStartMs": 13755, "OffsetEndMs": 13875}, {"Word": "you", "OffsetStartMs": 13875, "OffsetEndMs": 14010}, {"Word": "who", "OffsetStartMs": 14010, "OffsetEndMs": 14145}, {"Word": "are", "OffsetStartMs": 14145, "OffsetEndMs": 14250}, {"Word": "not", "OffsetStartMs": 14250, "OffsetEndMs": 14510}, {"Word": "familiar", "OffsetStartMs": 14740, "OffsetEndMs": 15140}, {"Word": "with", "OffsetStartMs": 15160, "OffsetEndMs": 15435}, {"Word": "the", "OffsetStartMs": 15435, "OffsetEndMs": 15555}, {"Word": "game", "OffsetStartMs": 15555, "OffsetEndMs": 15675}, {"Word": "of", "OffsetStartMs": 15675, "OffsetEndMs": 15840}, {"Word": "go", "OffsetStartMs": 15840, "OffsetEndMs": 16095}, {"Word": "go", "OffsetStartMs": 16095, "OffsetEndMs": 16460}, {"Word": "game", "OffsetStartMs": 16480, "OffsetEndMs": 16770}, {"Word": "of", "OffsetStartMs": 16770, "OffsetEndMs": 16950}, {"Word": "go", "OffsetStartMs": 16950, "OffsetEndMs": 17240}, {"Word": "is", "OffsetStartMs": 17290, "OffsetEndMs": 17595}, {"Word": "played", "OffsetStartMs": 17595, "OffsetEndMs": 17775}, {"Word": "on", "OffsetStartMs": 17775, "OffsetEndMs": 17910}, {"Word": "a", "OffsetStartMs": 17910, "OffsetEndMs": 18060}, {"Word": "nineteen", "OffsetStartMs": 18060, "OffsetEndMs": 18350}, {"Word": "by", "OffsetStartMs": 18610, "OffsetEndMs": 18915}, {"Word": "nineteen", "OffsetStartMs": 18915, "OffsetEndMs": 19220}, {"Word": "board", "OffsetStartMs": 19450, "OffsetEndMs": 19850}, {"Word": "The", "OffsetStartMs": 20230, "OffsetEndMs": 20580}, {"Word": "rough", "OffsetStartMs": 20580, "OffsetEndMs": 20930}, {"Word": "objective", "OffsetStartMs": 20950, "OffsetEndMs": 21350}, {"Word": "of", "OffsetStartMs": 21430, "OffsetEndMs": 21750}, {"Word": "go", "OffsetStartMs": 21750, "OffsetEndMs": 22070}, {"Word": "is", "OffsetStartMs": 22330, "OffsetEndMs": 22665}, {"Word": "to", "OffsetStartMs": 22665, "OffsetEndMs": 22890}, {"Word": "claim", "OffsetStartMs": 22890, "OffsetEndMs": 23100}, {"Word": "basically", "OffsetStartMs": 23100, "OffsetEndMs": 23420}, {"Word": "more", "OffsetStartMs": 23560, "OffsetEndMs": 23960}, {"Word": "board", "OffsetStartMs": 23980, "OffsetEndMs": 24345}, {"Word": "pieces", "OffsetStartMs": 24345, "OffsetEndMs": 24710}, {"Word": "than", "OffsetStartMs": 24820, "OffsetEndMs": 25110}, {"Word": "your", "OffsetStartMs": 25110, "OffsetEndMs": 25400}, {"Word": "opponent", "OffsetStartMs": 25420, "OffsetEndMs": 26000}, {"Word": "right", "OffsetStartMs": 26020, "OffsetEndMs": 26325}, {"Word": "And", "OffsetStartMs": 26325, "OffsetEndMs": 26565}, {"Word": "through", "OffsetStartMs": 26565, "OffsetEndMs": 26805}, {"Word": "the", "OffsetStartMs": 26805, "OffsetEndMs": 27110}, {"Word": "grid", "OffsetStartMs": 27430, "OffsetEndMs": 27860}, {"Word": "of", "OffsetStartMs": 27970, "OffsetEndMs": 28370}, {"Word": "sorry", "OffsetStartMs": 29170, "OffsetEndMs": 29565}, {"Word": "through", "OffsetStartMs": 29565, "OffsetEndMs": 29850}, {"Word": "the", "OffsetStartMs": 29850, "OffsetEndMs": 30060}, {"Word": "grid", "OffsetStartMs": 30060, "OffsetEndMs": 30345}, {"Word": "that", "OffsetStartMs": 30345, "OffsetEndMs": 30540}, {"Word": "you", "OffsetStartMs": 30540, "OffsetEndMs": 30660}, {"Word": "can", "OffsetStartMs": 30660, "OffsetEndMs": 30810}, {"Word": "see", "OffsetStartMs": 30810, "OffsetEndMs": 30975}, {"Word": "here", "OffsetStartMs": 30975, "OffsetEndMs": 31140}, {"Word": "this", "OffsetStartMs": 31140, "OffsetEndMs": 31320}, {"Word": "nineteen", "OffsetStartMs": 31320, "OffsetEndMs": 31575}, {"Word": "by", "OffsetStartMs": 31575, "OffsetEndMs": 31830}, {"Word": "nineteen", "OffsetStartMs": 31830, "OffsetEndMs": 32120}, {"Word": "grid", "OffsetStartMs": 32260, "OffsetEndMs": 32690}], "SpeechSpeed": 15.2}, {"FinalSentence": "And while the game itself, the the logical rules, are actually quite simple, the number of possible action spaces and possible states that this board could be placed into is greater than the number of atoms in the universe. So this game, even though the rules are very simple in their logical definitions, is an extraordinarily complex game for an artificial algorithm to try and master.", "SliceSentence": "And while the game itself the the logical rules are actually quite simple the number of possible action spaces and possible states that this board could be placed into is greater than the number of atoms in the universe So this game even though the rules are very simple in their logical definitions is an extraordinarily complex game for an artificial algorithm to try and master", "StartMs": 3166140, "EndMs": 3191860, "WordsNum": 66, "Words": [{"Word": "And", "OffsetStartMs": 0, "OffsetEndMs": 290}, {"Word": "while", "OffsetStartMs": 640, "OffsetEndMs": 945}, {"Word": "the", "OffsetStartMs": 945, "OffsetEndMs": 1140}, {"Word": "game", "OffsetStartMs": 1140, "OffsetEndMs": 1430}, {"Word": "itself", "OffsetStartMs": 1480, "OffsetEndMs": 1880}, {"Word": "the", "OffsetStartMs": 2020, "OffsetEndMs": 2420}, {"Word": "the", "OffsetStartMs": 2440, "OffsetEndMs": 2700}, {"Word": "logical", "OffsetStartMs": 2700, "OffsetEndMs": 3165}, {"Word": "rules", "OffsetStartMs": 3165, "OffsetEndMs": 3465}, {"Word": "are", "OffsetStartMs": 3465, "OffsetEndMs": 3795}, {"Word": "actually", "OffsetStartMs": 3795, "OffsetEndMs": 4020}, {"Word": "quite", "OffsetStartMs": 4020, "OffsetEndMs": 4245}, {"Word": "simple", "OffsetStartMs": 4245, "OffsetEndMs": 4580}, {"Word": "the", "OffsetStartMs": 4870, "OffsetEndMs": 5160}, {"Word": "number", "OffsetStartMs": 5160, "OffsetEndMs": 5415}, {"Word": "of", "OffsetStartMs": 5415, "OffsetEndMs": 5685}, {"Word": "possible", "OffsetStartMs": 5685, "OffsetEndMs": 5990}, {"Word": "action", "OffsetStartMs": 6520, "OffsetEndMs": 6920}, {"Word": "spaces", "OffsetStartMs": 7210, "OffsetEndMs": 7610}, {"Word": "and", "OffsetStartMs": 8080, "OffsetEndMs": 8415}, {"Word": "possible", "OffsetStartMs": 8415, "OffsetEndMs": 8750}, {"Word": "states", "OffsetStartMs": 8800, "OffsetEndMs": 9200}, {"Word": "that", "OffsetStartMs": 9370, "OffsetEndMs": 9675}, {"Word": "this", "OffsetStartMs": 9675, "OffsetEndMs": 9900}, {"Word": "board", "OffsetStartMs": 9900, "OffsetEndMs": 10155}, {"Word": "could", "OffsetStartMs": 10155, "OffsetEndMs": 10350}, {"Word": "be", "OffsetStartMs": 10350, "OffsetEndMs": 10500}, {"Word": "placed", "OffsetStartMs": 10500, "OffsetEndMs": 10725}, {"Word": "into", "OffsetStartMs": 10725, "OffsetEndMs": 11060}, {"Word": "is", "OffsetStartMs": 11350, "OffsetEndMs": 11655}, {"Word": "greater", "OffsetStartMs": 11655, "OffsetEndMs": 11955}, {"Word": "than", "OffsetStartMs": 11955, "OffsetEndMs": 12225}, {"Word": "the", "OffsetStartMs": 12225, "OffsetEndMs": 12345}, {"Word": "number", "OffsetStartMs": 12345, "OffsetEndMs": 12495}, {"Word": "of", "OffsetStartMs": 12495, "OffsetEndMs": 12660}, {"Word": "atoms", "OffsetStartMs": 12660, "OffsetEndMs": 13095}, {"Word": "in", "OffsetStartMs": 13095, "OffsetEndMs": 13335}, {"Word": "the", "OffsetStartMs": 13335, "OffsetEndMs": 13590}, {"Word": "universe", "OffsetStartMs": 13590, "OffsetEndMs": 13970}, {"Word": "So", "OffsetStartMs": 14140, "OffsetEndMs": 14400}, {"Word": "this", "OffsetStartMs": 14400, "OffsetEndMs": 14660}, {"Word": "game", "OffsetStartMs": 15220, "OffsetEndMs": 15600}, {"Word": "even", "OffsetStartMs": 15600, "OffsetEndMs": 15915}, {"Word": "though", "OffsetStartMs": 15915, "OffsetEndMs": 16110}, {"Word": "the", "OffsetStartMs": 16110, "OffsetEndMs": 16245}, {"Word": "rules", "OffsetStartMs": 16245, "OffsetEndMs": 16455}, {"Word": "are", "OffsetStartMs": 16455, "OffsetEndMs": 16680}, {"Word": "very", "OffsetStartMs": 16680, "OffsetEndMs": 16970}, {"Word": "simple", "OffsetStartMs": 17170, "OffsetEndMs": 17570}, {"Word": "in", "OffsetStartMs": 17590, "OffsetEndMs": 17880}, {"Word": "their", "OffsetStartMs": 17880, "OffsetEndMs": 18075}, {"Word": "logical", "OffsetStartMs": 18075, "OffsetEndMs": 18525}, {"Word": "definitions", "OffsetStartMs": 18525, "OffsetEndMs": 19040}, {"Word": "is", "OffsetStartMs": 19690, "OffsetEndMs": 20040}, {"Word": "an", "OffsetStartMs": 20040, "OffsetEndMs": 20370}, {"Word": "extraordinarily", "OffsetStartMs": 20370, "OffsetEndMs": 20960}, {"Word": "complex", "OffsetStartMs": 21250, "OffsetEndMs": 21615}, {"Word": "game", "OffsetStartMs": 21615, "OffsetEndMs": 21980}, {"Word": "for", "OffsetStartMs": 22180, "OffsetEndMs": 22500}, {"Word": "an", "OffsetStartMs": 22500, "OffsetEndMs": 22815}, {"Word": "artificial", "OffsetStartMs": 22815, "OffsetEndMs": 23210}, {"Word": "algorithm", "OffsetStartMs": 23260, "OffsetEndMs": 23715}, {"Word": "to", "OffsetStartMs": 23715, "OffsetEndMs": 23940}, {"Word": "try", "OffsetStartMs": 23940, "OffsetEndMs": 24120}, {"Word": "and", "OffsetStartMs": 24120, "OffsetEndMs": 24410}, {"Word": "master", "OffsetStartMs": 24640, "OffsetEndMs": 25040}], "SpeechSpeed": 14.8}, {"FinalSentence": "So the objective here was to build a reinforcement learning algorithm to master the game of go, not only beating, you know, these gold standard softwareares, but also what was at the time like an amazing result was to beat the grand master level players. So the number one player in the world of go was a human human champion, obviously.", "SliceSentence": "So the objective here was to build a reinforcement learning algorithm to master the game of go not only beating you know these gold standard softwareares but also what was at the time like an amazing result was to beat the grand master level players So the number one player in the world of go was a human human champion obviously", "StartMs": 3191860, "EndMs": 3213000, "WordsNum": 61, "Words": [{"Word": "So", "OffsetStartMs": 0, "OffsetEndMs": 180}, {"Word": "the", "OffsetStartMs": 180, "OffsetEndMs": 345}, {"Word": "objective", "OffsetStartMs": 345, "OffsetEndMs": 615}, {"Word": "here", "OffsetStartMs": 615, "OffsetEndMs": 885}, {"Word": "was", "OffsetStartMs": 885, "OffsetEndMs": 1110}, {"Word": "to", "OffsetStartMs": 1110, "OffsetEndMs": 1430}, {"Word": "build", "OffsetStartMs": 1570, "OffsetEndMs": 1970}, {"Word": "a", "OffsetStartMs": 2080, "OffsetEndMs": 2355}, {"Word": "reinforcement", "OffsetStartMs": 2355, "OffsetEndMs": 2985}, {"Word": "learning", "OffsetStartMs": 2985, "OffsetEndMs": 3260}, {"Word": "algorithm", "OffsetStartMs": 3340, "OffsetEndMs": 3870}, {"Word": "to", "OffsetStartMs": 3870, "OffsetEndMs": 4125}, {"Word": "master", "OffsetStartMs": 4125, "OffsetEndMs": 4400}, {"Word": "the", "OffsetStartMs": 4450, "OffsetEndMs": 4710}, {"Word": "game", "OffsetStartMs": 4710, "OffsetEndMs": 4860}, {"Word": "of", "OffsetStartMs": 4860, "OffsetEndMs": 5040}, {"Word": "go", "OffsetStartMs": 5040, "OffsetEndMs": 5330}, {"Word": "not", "OffsetStartMs": 5380, "OffsetEndMs": 5685}, {"Word": "only", "OffsetStartMs": 5685, "OffsetEndMs": 5990}, {"Word": "beating", "OffsetStartMs": 6040, "OffsetEndMs": 6440}, {"Word": "you", "OffsetStartMs": 6760, "OffsetEndMs": 7020}, {"Word": "know", "OffsetStartMs": 7020, "OffsetEndMs": 7185}, {"Word": "these", "OffsetStartMs": 7185, "OffsetEndMs": 7490}, {"Word": "gold", "OffsetStartMs": 7510, "OffsetEndMs": 7910}, {"Word": "standard", "OffsetStartMs": 7930, "OffsetEndMs": 8330}, {"Word": "softwareares", "OffsetStartMs": 8800, "OffsetEndMs": 9435}, {"Word": "but", "OffsetStartMs": 9435, "OffsetEndMs": 9800}, {"Word": "also", "OffsetStartMs": 9820, "OffsetEndMs": 10220}, {"Word": "what", "OffsetStartMs": 10330, "OffsetEndMs": 10605}, {"Word": "was", "OffsetStartMs": 10605, "OffsetEndMs": 10755}, {"Word": "at", "OffsetStartMs": 10755, "OffsetEndMs": 10905}, {"Word": "the", "OffsetStartMs": 10905, "OffsetEndMs": 11055}, {"Word": "time", "OffsetStartMs": 11055, "OffsetEndMs": 11265}, {"Word": "like", "OffsetStartMs": 11265, "OffsetEndMs": 11460}, {"Word": "an", "OffsetStartMs": 11460, "OffsetEndMs": 11640}, {"Word": "amazing", "OffsetStartMs": 11640, "OffsetEndMs": 11960}, {"Word": "result", "OffsetStartMs": 12100, "OffsetEndMs": 12500}, {"Word": "was", "OffsetStartMs": 12700, "OffsetEndMs": 13005}, {"Word": "to", "OffsetStartMs": 13005, "OffsetEndMs": 13200}, {"Word": "beat", "OffsetStartMs": 13200, "OffsetEndMs": 13425}, {"Word": "the", "OffsetStartMs": 13425, "OffsetEndMs": 13650}, {"Word": "grand", "OffsetStartMs": 13650, "OffsetEndMs": 13905}, {"Word": "master", "OffsetStartMs": 13905, "OffsetEndMs": 14270}, {"Word": "level", "OffsetStartMs": 14290, "OffsetEndMs": 14690}, {"Word": "players", "OffsetStartMs": 14920, "OffsetEndMs": 15270}, {"Word": "So", "OffsetStartMs": 15270, "OffsetEndMs": 15465}, {"Word": "the", "OffsetStartMs": 15465, "OffsetEndMs": 15585}, {"Word": "number", "OffsetStartMs": 15585, "OffsetEndMs": 15780}, {"Word": "one", "OffsetStartMs": 15780, "OffsetEndMs": 16005}, {"Word": "player", "OffsetStartMs": 16005, "OffsetEndMs": 16200}, {"Word": "in", "OffsetStartMs": 16200, "OffsetEndMs": 16350}, {"Word": "the", "OffsetStartMs": 16350, "OffsetEndMs": 16485}, {"Word": "world", "OffsetStartMs": 16485, "OffsetEndMs": 16760}, {"Word": "of", "OffsetStartMs": 16810, "OffsetEndMs": 17115}, {"Word": "go", "OffsetStartMs": 17115, "OffsetEndMs": 17420}, {"Word": "was", "OffsetStartMs": 17770, "OffsetEndMs": 18060}, {"Word": "a", "OffsetStartMs": 18060, "OffsetEndMs": 18225}, {"Word": "human", "OffsetStartMs": 18225, "OffsetEndMs": 18500}, {"Word": "human", "OffsetStartMs": 19210, "OffsetEndMs": 19545}, {"Word": "champion", "OffsetStartMs": 19545, "OffsetEndMs": 19880}, {"Word": "obviously", "OffsetStartMs": 20080, "OffsetEndMs": 20480}], "SpeechSpeed": 15.6}, {"FinalSentence": "So Google deepmind Rose to this challenge they created a couple years ago developing this solution, which is very much based in the exact same algorithms that you learned about in today's lecture, combining both the value part of this network with residual layers, which we'll cover in the next lecture tomorrow. And using reinforcement learning pipeline, they were able to defeat the grand champion human players and the idea that its core was actually very simple, the first step is that you train a neural network to basically watch human level experts. So this is not using reinforcement learning, using supervised learning, using the techniques that we covered in lectures one, two and three.", "SliceSentence": "So Google deepmind Rose to this challenge they created a couple years ago developing this solution which is very much based in the exact same algorithms that you learned about in today's lecture combining both the value part of this network with residual layers which we'll cover in the next lecture tomorrow And using reinforcement learning pipeline they were able to defeat the grand champion human players and the idea that its core was actually very simple the first step is that you train a neural network to basically watch human level experts So this is not using reinforcement learning using supervised learning using the techniques that we covered in lectures one two and three", "StartMs": 3213000, "EndMs": 3257460, "WordsNum": 115, "Words": [{"Word": "So", "OffsetStartMs": 10, "OffsetEndMs": 390}, {"Word": "Google", "OffsetStartMs": 390, "OffsetEndMs": 720}, {"Word": "deepmind", "OffsetStartMs": 720, "OffsetEndMs": 1260}, {"Word": "Rose", "OffsetStartMs": 1260, "OffsetEndMs": 1590}, {"Word": "to", "OffsetStartMs": 1590, "OffsetEndMs": 1800}, {"Word": "this", "OffsetStartMs": 1800, "OffsetEndMs": 1980}, {"Word": "challenge", "OffsetStartMs": 1980, "OffsetEndMs": 2300}, {"Word": "they", "OffsetStartMs": 2950, "OffsetEndMs": 3350}, {"Word": "created", "OffsetStartMs": 3400, "OffsetEndMs": 3800}, {"Word": "a", "OffsetStartMs": 3940, "OffsetEndMs": 4340}, {"Word": "couple", "OffsetStartMs": 4630, "OffsetEndMs": 4950}, {"Word": "years", "OffsetStartMs": 4950, "OffsetEndMs": 5205}, {"Word": "ago", "OffsetStartMs": 5205, "OffsetEndMs": 5540}, {"Word": "developing", "OffsetStartMs": 5650, "OffsetEndMs": 6050}, {"Word": "this", "OffsetStartMs": 6100, "OffsetEndMs": 6500}, {"Word": "solution", "OffsetStartMs": 6520, "OffsetEndMs": 6920}, {"Word": "which", "OffsetStartMs": 7240, "OffsetEndMs": 7640}, {"Word": "is", "OffsetStartMs": 7780, "OffsetEndMs": 8180}, {"Word": "very", "OffsetStartMs": 8410, "OffsetEndMs": 8805}, {"Word": "much", "OffsetStartMs": 8805, "OffsetEndMs": 9200}, {"Word": "based", "OffsetStartMs": 9790, "OffsetEndMs": 10190}, {"Word": "in", "OffsetStartMs": 10330, "OffsetEndMs": 10620}, {"Word": "the", "OffsetStartMs": 10620, "OffsetEndMs": 10845}, {"Word": "exact", "OffsetStartMs": 10845, "OffsetEndMs": 11115}, {"Word": "same", "OffsetStartMs": 11115, "OffsetEndMs": 11415}, {"Word": "algorithms", "OffsetStartMs": 11415, "OffsetEndMs": 11775}, {"Word": "that", "OffsetStartMs": 11775, "OffsetEndMs": 11895}, {"Word": "you", "OffsetStartMs": 11895, "OffsetEndMs": 12015}, {"Word": "learned", "OffsetStartMs": 12015, "OffsetEndMs": 12225}, {"Word": "about", "OffsetStartMs": 12225, "OffsetEndMs": 12465}, {"Word": "in", "OffsetStartMs": 12465, "OffsetEndMs": 12645}, {"Word": "today's", "OffsetStartMs": 12645, "OffsetEndMs": 12990}, {"Word": "lecture", "OffsetStartMs": 12990, "OffsetEndMs": 13250}, {"Word": "combining", "OffsetStartMs": 13690, "OffsetEndMs": 14240}, {"Word": "both", "OffsetStartMs": 14350, "OffsetEndMs": 14750}, {"Word": "the", "OffsetStartMs": 14770, "OffsetEndMs": 15045}, {"Word": "value", "OffsetStartMs": 15045, "OffsetEndMs": 15320}, {"Word": "part", "OffsetStartMs": 16090, "OffsetEndMs": 16380}, {"Word": "of", "OffsetStartMs": 16380, "OffsetEndMs": 16530}, {"Word": "this", "OffsetStartMs": 16530, "OffsetEndMs": 16695}, {"Word": "network", "OffsetStartMs": 16695, "OffsetEndMs": 16995}, {"Word": "with", "OffsetStartMs": 16995, "OffsetEndMs": 17295}, {"Word": "residual", "OffsetStartMs": 17295, "OffsetEndMs": 17960}, {"Word": "layers", "OffsetStartMs": 17980, "OffsetEndMs": 18560}, {"Word": "which", "OffsetStartMs": 18910, "OffsetEndMs": 19230}, {"Word": "we'll", "OffsetStartMs": 19230, "OffsetEndMs": 19455}, {"Word": "cover", "OffsetStartMs": 19455, "OffsetEndMs": 19700}, {"Word": "in", "OffsetStartMs": 19720, "OffsetEndMs": 20120}, {"Word": "the", "OffsetStartMs": 20170, "OffsetEndMs": 20430}, {"Word": "next", "OffsetStartMs": 20430, "OffsetEndMs": 20610}, {"Word": "lecture", "OffsetStartMs": 20610, "OffsetEndMs": 20930}, {"Word": "tomorrow", "OffsetStartMs": 21010, "OffsetEndMs": 21410}, {"Word": "And", "OffsetStartMs": 22390, "OffsetEndMs": 22785}, {"Word": "using", "OffsetStartMs": 22785, "OffsetEndMs": 23175}, {"Word": "reinforcement", "OffsetStartMs": 23175, "OffsetEndMs": 23865}, {"Word": "learning", "OffsetStartMs": 23865, "OffsetEndMs": 24090}, {"Word": "pipeline", "OffsetStartMs": 24090, "OffsetEndMs": 24440}, {"Word": "they", "OffsetStartMs": 25090, "OffsetEndMs": 25395}, {"Word": "were", "OffsetStartMs": 25395, "OffsetEndMs": 25560}, {"Word": "able", "OffsetStartMs": 25560, "OffsetEndMs": 25800}, {"Word": "to", "OffsetStartMs": 25800, "OffsetEndMs": 26055}, {"Word": "defeat", "OffsetStartMs": 26055, "OffsetEndMs": 26480}, {"Word": "the", "OffsetStartMs": 26650, "OffsetEndMs": 26925}, {"Word": "grand", "OffsetStartMs": 26925, "OffsetEndMs": 27180}, {"Word": "champion", "OffsetStartMs": 27180, "OffsetEndMs": 27560}, {"Word": "human", "OffsetStartMs": 27730, "OffsetEndMs": 28080}, {"Word": "players", "OffsetStartMs": 28080, "OffsetEndMs": 28380}, {"Word": "and", "OffsetStartMs": 28380, "OffsetEndMs": 28590}, {"Word": "the", "OffsetStartMs": 28590, "OffsetEndMs": 28770}, {"Word": "idea", "OffsetStartMs": 28770, "OffsetEndMs": 28980}, {"Word": "that", "OffsetStartMs": 28980, "OffsetEndMs": 29115}, {"Word": "its", "OffsetStartMs": 29115, "OffsetEndMs": 29280}, {"Word": "core", "OffsetStartMs": 29280, "OffsetEndMs": 29490}, {"Word": "was", "OffsetStartMs": 29490, "OffsetEndMs": 29745}, {"Word": "actually", "OffsetStartMs": 29745, "OffsetEndMs": 30110}, {"Word": "very", "OffsetStartMs": 30250, "OffsetEndMs": 30600}, {"Word": "simple", "OffsetStartMs": 30600, "OffsetEndMs": 30950}, {"Word": "the", "OffsetStartMs": 31030, "OffsetEndMs": 31305}, {"Word": "first", "OffsetStartMs": 31305, "OffsetEndMs": 31530}, {"Word": "step", "OffsetStartMs": 31530, "OffsetEndMs": 31880}, {"Word": "is", "OffsetStartMs": 31900, "OffsetEndMs": 32175}, {"Word": "that", "OffsetStartMs": 32175, "OffsetEndMs": 32325}, {"Word": "you", "OffsetStartMs": 32325, "OffsetEndMs": 32520}, {"Word": "train", "OffsetStartMs": 32520, "OffsetEndMs": 32840}, {"Word": "a", "OffsetStartMs": 33100, "OffsetEndMs": 33375}, {"Word": "neural", "OffsetStartMs": 33375, "OffsetEndMs": 33600}, {"Word": "network", "OffsetStartMs": 33600, "OffsetEndMs": 33855}, {"Word": "to", "OffsetStartMs": 33855, "OffsetEndMs": 34140}, {"Word": "basically", "OffsetStartMs": 34140, "OffsetEndMs": 34430}, {"Word": "watch", "OffsetStartMs": 34570, "OffsetEndMs": 34970}, {"Word": "human", "OffsetStartMs": 35230, "OffsetEndMs": 35630}, {"Word": "level", "OffsetStartMs": 35770, "OffsetEndMs": 36170}, {"Word": "experts", "OffsetStartMs": 36430, "OffsetEndMs": 36830}, {"Word": "So", "OffsetStartMs": 37420, "OffsetEndMs": 37665}, {"Word": "this", "OffsetStartMs": 37665, "OffsetEndMs": 37770}, {"Word": "is", "OffsetStartMs": 37770, "OffsetEndMs": 37980}, {"Word": "not", "OffsetStartMs": 37980, "OffsetEndMs": 38220}, {"Word": "using", "OffsetStartMs": 38220, "OffsetEndMs": 38460}, {"Word": "reinforcement", "OffsetStartMs": 38460, "OffsetEndMs": 39090}, {"Word": "learning", "OffsetStartMs": 39090, "OffsetEndMs": 39350}, {"Word": "using", "OffsetStartMs": 39490, "OffsetEndMs": 39890}, {"Word": "supervised", "OffsetStartMs": 40150, "OffsetEndMs": 40530}, {"Word": "learning", "OffsetStartMs": 40530, "OffsetEndMs": 40880}, {"Word": "using", "OffsetStartMs": 41140, "OffsetEndMs": 41505}, {"Word": "the", "OffsetStartMs": 41505, "OffsetEndMs": 41745}, {"Word": "techniques", "OffsetStartMs": 41745, "OffsetEndMs": 42000}, {"Word": "that", "OffsetStartMs": 42000, "OffsetEndMs": 42240}, {"Word": "we", "OffsetStartMs": 42240, "OffsetEndMs": 42360}, {"Word": "covered", "OffsetStartMs": 42360, "OffsetEndMs": 42540}, {"Word": "in", "OffsetStartMs": 42540, "OffsetEndMs": 42720}, {"Word": "lectures", "OffsetStartMs": 42720, "OffsetEndMs": 43050}, {"Word": "one", "OffsetStartMs": 43050, "OffsetEndMs": 43275}, {"Word": "two", "OffsetStartMs": 43275, "OffsetEndMs": 43455}, {"Word": "and", "OffsetStartMs": 43455, "OffsetEndMs": 43605}, {"Word": "three", "OffsetStartMs": 43605, "OffsetEndMs": 43910}], "SpeechSpeed": 15.4}, {"FinalSentence": "And from this first step, the goal is to build like a policy that would imitate some of the rough patterns that a human type of player or a human grandmaster would take based on a given board, state the type of actions that they might execute. But then given this pre trained model, essentially you could use it to bootstrap and reinforcement learning algorithm that would play against itself.", "SliceSentence": "And from this first step the goal is to build like a policy that would imitate some of the rough patterns that a human type of player or a human grandmaster would take based on a given board state the type of actions that they might execute But then given this pre trained model essentially you could use it to bootstrap and reinforcement learning algorithm that would play against itself", "StartMs": 3257460, "EndMs": 3281000, "WordsNum": 70, "Words": [{"Word": "And", "OffsetStartMs": 0, "OffsetEndMs": 380}, {"Word": "from", "OffsetStartMs": 610, "OffsetEndMs": 930}, {"Word": "this", "OffsetStartMs": 930, "OffsetEndMs": 1155}, {"Word": "first", "OffsetStartMs": 1155, "OffsetEndMs": 1410}, {"Word": "step", "OffsetStartMs": 1410, "OffsetEndMs": 1740}, {"Word": "the", "OffsetStartMs": 1740, "OffsetEndMs": 1980}, {"Word": "goal", "OffsetStartMs": 1980, "OffsetEndMs": 2130}, {"Word": "is", "OffsetStartMs": 2130, "OffsetEndMs": 2310}, {"Word": "to", "OffsetStartMs": 2310, "OffsetEndMs": 2460}, {"Word": "build", "OffsetStartMs": 2460, "OffsetEndMs": 2720}, {"Word": "like", "OffsetStartMs": 2800, "OffsetEndMs": 3060}, {"Word": "a", "OffsetStartMs": 3060, "OffsetEndMs": 3210}, {"Word": "policy", "OffsetStartMs": 3210, "OffsetEndMs": 3500}, {"Word": "that", "OffsetStartMs": 3670, "OffsetEndMs": 3930}, {"Word": "would", "OffsetStartMs": 3930, "OffsetEndMs": 4065}, {"Word": "imitate", "OffsetStartMs": 4065, "OffsetEndMs": 4640}, {"Word": "some", "OffsetStartMs": 4660, "OffsetEndMs": 4920}, {"Word": "of", "OffsetStartMs": 4920, "OffsetEndMs": 5070}, {"Word": "the", "OffsetStartMs": 5070, "OffsetEndMs": 5250}, {"Word": "rough", "OffsetStartMs": 5250, "OffsetEndMs": 5505}, {"Word": "patterns", "OffsetStartMs": 5505, "OffsetEndMs": 5870}, {"Word": "that", "OffsetStartMs": 6280, "OffsetEndMs": 6525}, {"Word": "a", "OffsetStartMs": 6525, "OffsetEndMs": 6675}, {"Word": "human", "OffsetStartMs": 6675, "OffsetEndMs": 6960}, {"Word": "type", "OffsetStartMs": 6960, "OffsetEndMs": 7245}, {"Word": "of", "OffsetStartMs": 7245, "OffsetEndMs": 7455}, {"Word": "player", "OffsetStartMs": 7455, "OffsetEndMs": 7740}, {"Word": "or", "OffsetStartMs": 7740, "OffsetEndMs": 7965}, {"Word": "a", "OffsetStartMs": 7965, "OffsetEndMs": 8070}, {"Word": "human", "OffsetStartMs": 8070, "OffsetEndMs": 8280}, {"Word": "grandmaster", "OffsetStartMs": 8280, "OffsetEndMs": 8840}, {"Word": "would", "OffsetStartMs": 8890, "OffsetEndMs": 9195}, {"Word": "take", "OffsetStartMs": 9195, "OffsetEndMs": 9500}, {"Word": "based", "OffsetStartMs": 9730, "OffsetEndMs": 10050}, {"Word": "on", "OffsetStartMs": 10050, "OffsetEndMs": 10215}, {"Word": "a", "OffsetStartMs": 10215, "OffsetEndMs": 10320}, {"Word": "given", "OffsetStartMs": 10320, "OffsetEndMs": 10515}, {"Word": "board", "OffsetStartMs": 10515, "OffsetEndMs": 10815}, {"Word": "state", "OffsetStartMs": 10815, "OffsetEndMs": 11130}, {"Word": "the", "OffsetStartMs": 11130, "OffsetEndMs": 11340}, {"Word": "type", "OffsetStartMs": 11340, "OffsetEndMs": 11475}, {"Word": "of", "OffsetStartMs": 11475, "OffsetEndMs": 11595}, {"Word": "actions", "OffsetStartMs": 11595, "OffsetEndMs": 11840}, {"Word": "that", "OffsetStartMs": 11890, "OffsetEndMs": 12165}, {"Word": "they", "OffsetStartMs": 12165, "OffsetEndMs": 12315}, {"Word": "might", "OffsetStartMs": 12315, "OffsetEndMs": 12590}, {"Word": "execute", "OffsetStartMs": 12790, "OffsetEndMs": 13190}, {"Word": "But", "OffsetStartMs": 13660, "OffsetEndMs": 13905}, {"Word": "then", "OffsetStartMs": 13905, "OffsetEndMs": 14040}, {"Word": "given", "OffsetStartMs": 14040, "OffsetEndMs": 14310}, {"Word": "this", "OffsetStartMs": 14310, "OffsetEndMs": 14690}, {"Word": "pre", "OffsetStartMs": 14830, "OffsetEndMs": 15165}, {"Word": "trained", "OffsetStartMs": 15165, "OffsetEndMs": 15465}, {"Word": "model", "OffsetStartMs": 15465, "OffsetEndMs": 15830}, {"Word": "essentially", "OffsetStartMs": 15880, "OffsetEndMs": 16280}, {"Word": "you", "OffsetStartMs": 16630, "OffsetEndMs": 16890}, {"Word": "could", "OffsetStartMs": 16890, "OffsetEndMs": 17025}, {"Word": "use", "OffsetStartMs": 17025, "OffsetEndMs": 17205}, {"Word": "it", "OffsetStartMs": 17205, "OffsetEndMs": 17385}, {"Word": "to", "OffsetStartMs": 17385, "OffsetEndMs": 17550}, {"Word": "bootstrap", "OffsetStartMs": 17550, "OffsetEndMs": 18140}, {"Word": "and", "OffsetStartMs": 18280, "OffsetEndMs": 18680}, {"Word": "reinforcement", "OffsetStartMs": 18880, "OffsetEndMs": 19620}, {"Word": "learning", "OffsetStartMs": 19620, "OffsetEndMs": 19880}, {"Word": "algorithm", "OffsetStartMs": 20020, "OffsetEndMs": 20540}, {"Word": "that", "OffsetStartMs": 20710, "OffsetEndMs": 21000}, {"Word": "would", "OffsetStartMs": 21000, "OffsetEndMs": 21290}, {"Word": "play", "OffsetStartMs": 21430, "OffsetEndMs": 21830}, {"Word": "against", "OffsetStartMs": 21940, "OffsetEndMs": 22340}, {"Word": "itself", "OffsetStartMs": 22540, "OffsetEndMs": 22940}], "SpeechSpeed": 16.5}, {"FinalSentence": "In order to learn how to improve even beyond the human levels, right. So it would take its human understandings, try to imitate the humans first of all, but then from that imitation they would pin these two neural networks against themselves, play a game against themselves and the winners would be receiving a reward. The losers would try to negate all of the actions that they may have acquired from their human counterparts and try to actually learn new types of rules and new types of actions basically that might be very beneficial to achieving superhuman performance. And one of the very important auxiliary tricks that brought this idea to be possible was the usage of this second network, this auxiliary network which took as input the state of the board and tried to predict, you know, what are all of the different possible board states that might emerge from this particular state and what would their values be? What would their potential returns and their outcomes be? So this network was an auxiliary.", "SliceSentence": "In order to learn how to improve even beyond the human levels right So it would take its human understandings try to imitate the humans first of all but then from that imitation they would pin these two neural networks against themselves play a game against themselves and the winners would be receiving a reward The losers would try to negate all of the actions that they may have acquired from their human counterparts and try to actually learn new types of rules and new types of actions basically that might be very beneficial to achieving superhuman performance And one of the very important auxiliary tricks that brought this idea to be possible was the usage of this second network this auxiliary network which took as input the state of the board and tried to predict you know what are all of the different possible board states that might emerge from this particular state and what would their values be What would their potential returns and their outcomes be So this network was an auxiliary", "StartMs": 3281000, "EndMs": 3341320, "WordsNum": 175, "Words": [{"Word": "In", "OffsetStartMs": 130, "OffsetEndMs": 435}, {"Word": "order", "OffsetStartMs": 435, "OffsetEndMs": 740}, {"Word": "to", "OffsetStartMs": 910, "OffsetEndMs": 1185}, {"Word": "learn", "OffsetStartMs": 1185, "OffsetEndMs": 1395}, {"Word": "how", "OffsetStartMs": 1395, "OffsetEndMs": 1635}, {"Word": "to", "OffsetStartMs": 1635, "OffsetEndMs": 1860}, {"Word": "improve", "OffsetStartMs": 1860, "OffsetEndMs": 2115}, {"Word": "even", "OffsetStartMs": 2115, "OffsetEndMs": 2450}, {"Word": "beyond", "OffsetStartMs": 2530, "OffsetEndMs": 2930}, {"Word": "the", "OffsetStartMs": 3100, "OffsetEndMs": 3375}, {"Word": "human", "OffsetStartMs": 3375, "OffsetEndMs": 3585}, {"Word": "levels", "OffsetStartMs": 3585, "OffsetEndMs": 3920}, {"Word": "right", "OffsetStartMs": 4540, "OffsetEndMs": 4875}, {"Word": "So", "OffsetStartMs": 4875, "OffsetEndMs": 5100}, {"Word": "it", "OffsetStartMs": 5100, "OffsetEndMs": 5250}, {"Word": "would", "OffsetStartMs": 5250, "OffsetEndMs": 5430}, {"Word": "take", "OffsetStartMs": 5430, "OffsetEndMs": 5700}, {"Word": "its", "OffsetStartMs": 5700, "OffsetEndMs": 5940}, {"Word": "human", "OffsetStartMs": 5940, "OffsetEndMs": 6230}, {"Word": "understandings", "OffsetStartMs": 6340, "OffsetEndMs": 6825}, {"Word": "try", "OffsetStartMs": 6825, "OffsetEndMs": 7050}, {"Word": "to", "OffsetStartMs": 7050, "OffsetEndMs": 7185}, {"Word": "imitate", "OffsetStartMs": 7185, "OffsetEndMs": 7605}, {"Word": "the", "OffsetStartMs": 7605, "OffsetEndMs": 7770}, {"Word": "humans", "OffsetStartMs": 7770, "OffsetEndMs": 8025}, {"Word": "first", "OffsetStartMs": 8025, "OffsetEndMs": 8325}, {"Word": "of", "OffsetStartMs": 8325, "OffsetEndMs": 8475}, {"Word": "all", "OffsetStartMs": 8475, "OffsetEndMs": 8625}, {"Word": "but", "OffsetStartMs": 8625, "OffsetEndMs": 8775}, {"Word": "then", "OffsetStartMs": 8775, "OffsetEndMs": 8925}, {"Word": "from", "OffsetStartMs": 8925, "OffsetEndMs": 9120}, {"Word": "that", "OffsetStartMs": 9120, "OffsetEndMs": 9285}, {"Word": "imitation", "OffsetStartMs": 9285, "OffsetEndMs": 9770}, {"Word": "they", "OffsetStartMs": 10390, "OffsetEndMs": 10665}, {"Word": "would", "OffsetStartMs": 10665, "OffsetEndMs": 10875}, {"Word": "pin", "OffsetStartMs": 10875, "OffsetEndMs": 11130}, {"Word": "these", "OffsetStartMs": 11130, "OffsetEndMs": 11370}, {"Word": "two", "OffsetStartMs": 11370, "OffsetEndMs": 11565}, {"Word": "neural", "OffsetStartMs": 11565, "OffsetEndMs": 11790}, {"Word": "networks", "OffsetStartMs": 11790, "OffsetEndMs": 12050}, {"Word": "against", "OffsetStartMs": 12100, "OffsetEndMs": 12500}, {"Word": "themselves", "OffsetStartMs": 12520, "OffsetEndMs": 12920}, {"Word": "play", "OffsetStartMs": 13180, "OffsetEndMs": 13440}, {"Word": "a", "OffsetStartMs": 13440, "OffsetEndMs": 13560}, {"Word": "game", "OffsetStartMs": 13560, "OffsetEndMs": 13740}, {"Word": "against", "OffsetStartMs": 13740, "OffsetEndMs": 14055}, {"Word": "themselves", "OffsetStartMs": 14055, "OffsetEndMs": 14370}, {"Word": "and", "OffsetStartMs": 14370, "OffsetEndMs": 14550}, {"Word": "the", "OffsetStartMs": 14550, "OffsetEndMs": 14685}, {"Word": "winners", "OffsetStartMs": 14685, "OffsetEndMs": 15080}, {"Word": "would", "OffsetStartMs": 15310, "OffsetEndMs": 15600}, {"Word": "be", "OffsetStartMs": 15600, "OffsetEndMs": 15890}, {"Word": "receiving", "OffsetStartMs": 16180, "OffsetEndMs": 16485}, {"Word": "a", "OffsetStartMs": 16485, "OffsetEndMs": 16710}, {"Word": "reward", "OffsetStartMs": 16710, "OffsetEndMs": 16950}, {"Word": "The", "OffsetStartMs": 16950, "OffsetEndMs": 17130}, {"Word": "losers", "OffsetStartMs": 17130, "OffsetEndMs": 17535}, {"Word": "would", "OffsetStartMs": 17535, "OffsetEndMs": 17760}, {"Word": "try", "OffsetStartMs": 17760, "OffsetEndMs": 17970}, {"Word": "to", "OffsetStartMs": 17970, "OffsetEndMs": 18150}, {"Word": "negate", "OffsetStartMs": 18150, "OffsetEndMs": 18530}, {"Word": "all", "OffsetStartMs": 18610, "OffsetEndMs": 18870}, {"Word": "of", "OffsetStartMs": 18870, "OffsetEndMs": 18990}, {"Word": "the", "OffsetStartMs": 18990, "OffsetEndMs": 19095}, {"Word": "actions", "OffsetStartMs": 19095, "OffsetEndMs": 19340}, {"Word": "that", "OffsetStartMs": 19450, "OffsetEndMs": 19850}, {"Word": "they", "OffsetStartMs": 19960, "OffsetEndMs": 20280}, {"Word": "may", "OffsetStartMs": 20280, "OffsetEndMs": 20460}, {"Word": "have", "OffsetStartMs": 20460, "OffsetEndMs": 20720}, {"Word": "acquired", "OffsetStartMs": 20890, "OffsetEndMs": 21285}, {"Word": "from", "OffsetStartMs": 21285, "OffsetEndMs": 21585}, {"Word": "their", "OffsetStartMs": 21585, "OffsetEndMs": 21810}, {"Word": "human", "OffsetStartMs": 21810, "OffsetEndMs": 22130}, {"Word": "counterparts", "OffsetStartMs": 22330, "OffsetEndMs": 23210}, {"Word": "and", "OffsetStartMs": 23410, "OffsetEndMs": 23810}, {"Word": "try", "OffsetStartMs": 23920, "OffsetEndMs": 24195}, {"Word": "to", "OffsetStartMs": 24195, "OffsetEndMs": 24435}, {"Word": "actually", "OffsetStartMs": 24435, "OffsetEndMs": 24705}, {"Word": "learn", "OffsetStartMs": 24705, "OffsetEndMs": 25010}, {"Word": "new", "OffsetStartMs": 25060, "OffsetEndMs": 25395}, {"Word": "types", "OffsetStartMs": 25395, "OffsetEndMs": 25635}, {"Word": "of", "OffsetStartMs": 25635, "OffsetEndMs": 25830}, {"Word": "rules", "OffsetStartMs": 25830, "OffsetEndMs": 26100}, {"Word": "and", "OffsetStartMs": 26100, "OffsetEndMs": 26340}, {"Word": "new", "OffsetStartMs": 26340, "OffsetEndMs": 26490}, {"Word": "types", "OffsetStartMs": 26490, "OffsetEndMs": 26670}, {"Word": "of", "OffsetStartMs": 26670, "OffsetEndMs": 26805}, {"Word": "actions", "OffsetStartMs": 26805, "OffsetEndMs": 27050}, {"Word": "basically", "OffsetStartMs": 27250, "OffsetEndMs": 27650}, {"Word": "that", "OffsetStartMs": 27880, "OffsetEndMs": 28200}, {"Word": "might", "OffsetStartMs": 28200, "OffsetEndMs": 28410}, {"Word": "be", "OffsetStartMs": 28410, "OffsetEndMs": 28575}, {"Word": "very", "OffsetStartMs": 28575, "OffsetEndMs": 28740}, {"Word": "beneficial", "OffsetStartMs": 28740, "OffsetEndMs": 29270}, {"Word": "to", "OffsetStartMs": 29920, "OffsetEndMs": 30240}, {"Word": "achieving", "OffsetStartMs": 30240, "OffsetEndMs": 30750}, {"Word": "superhuman", "OffsetStartMs": 30750, "OffsetEndMs": 31515}, {"Word": "performance", "OffsetStartMs": 31515, "OffsetEndMs": 31880}, {"Word": "And", "OffsetStartMs": 31900, "OffsetEndMs": 32190}, {"Word": "one", "OffsetStartMs": 32190, "OffsetEndMs": 32340}, {"Word": "of", "OffsetStartMs": 32340, "OffsetEndMs": 32490}, {"Word": "the", "OffsetStartMs": 32490, "OffsetEndMs": 32780}, {"Word": "very", "OffsetStartMs": 32830, "OffsetEndMs": 33210}, {"Word": "important", "OffsetStartMs": 33210, "OffsetEndMs": 33510}, {"Word": "auxiliary", "OffsetStartMs": 33510, "OffsetEndMs": 34350}, {"Word": "tricks", "OffsetStartMs": 34350, "OffsetEndMs": 34910}, {"Word": "that", "OffsetStartMs": 35050, "OffsetEndMs": 35430}, {"Word": "brought", "OffsetStartMs": 35430, "OffsetEndMs": 35745}, {"Word": "this", "OffsetStartMs": 35745, "OffsetEndMs": 36080}, {"Word": "idea", "OffsetStartMs": 36760, "OffsetEndMs": 37160}, {"Word": "to", "OffsetStartMs": 37330, "OffsetEndMs": 37575}, {"Word": "be", "OffsetStartMs": 37575, "OffsetEndMs": 37740}, {"Word": "possible", "OffsetStartMs": 37740, "OffsetEndMs": 38060}, {"Word": "was", "OffsetStartMs": 38500, "OffsetEndMs": 38790}, {"Word": "the", "OffsetStartMs": 38790, "OffsetEndMs": 38940}, {"Word": "usage", "OffsetStartMs": 38940, "OffsetEndMs": 39300}, {"Word": "of", "OffsetStartMs": 39300, "OffsetEndMs": 39510}, {"Word": "this", "OffsetStartMs": 39510, "OffsetEndMs": 39720}, {"Word": "second", "OffsetStartMs": 39720, "OffsetEndMs": 40020}, {"Word": "network", "OffsetStartMs": 40020, "OffsetEndMs": 40400}, {"Word": "this", "OffsetStartMs": 40420, "OffsetEndMs": 40710}, {"Word": "auxiliary", "OffsetStartMs": 40710, "OffsetEndMs": 41340}, {"Word": "network", "OffsetStartMs": 41340, "OffsetEndMs": 41630}, {"Word": "which", "OffsetStartMs": 41980, "OffsetEndMs": 42380}, {"Word": "took", "OffsetStartMs": 42430, "OffsetEndMs": 42750}, {"Word": "as", "OffsetStartMs": 42750, "OffsetEndMs": 43070}, {"Word": "input", "OffsetStartMs": 43120, "OffsetEndMs": 43500}, {"Word": "the", "OffsetStartMs": 43500, "OffsetEndMs": 43800}, {"Word": "state", "OffsetStartMs": 43800, "OffsetEndMs": 44010}, {"Word": "of", "OffsetStartMs": 44010, "OffsetEndMs": 44175}, {"Word": "the", "OffsetStartMs": 44175, "OffsetEndMs": 44310}, {"Word": "board", "OffsetStartMs": 44310, "OffsetEndMs": 44570}, {"Word": "and", "OffsetStartMs": 44830, "OffsetEndMs": 45150}, {"Word": "tried", "OffsetStartMs": 45150, "OffsetEndMs": 45360}, {"Word": "to", "OffsetStartMs": 45360, "OffsetEndMs": 45525}, {"Word": "predict", "OffsetStartMs": 45525, "OffsetEndMs": 45800}, {"Word": "you", "OffsetStartMs": 46180, "OffsetEndMs": 46425}, {"Word": "know", "OffsetStartMs": 46425, "OffsetEndMs": 46670}, {"Word": "what", "OffsetStartMs": 47560, "OffsetEndMs": 47895}, {"Word": "are", "OffsetStartMs": 47895, "OffsetEndMs": 48165}, {"Word": "all", "OffsetStartMs": 48165, "OffsetEndMs": 48405}, {"Word": "of", "OffsetStartMs": 48405, "OffsetEndMs": 48585}, {"Word": "the", "OffsetStartMs": 48585, "OffsetEndMs": 48705}, {"Word": "different", "OffsetStartMs": 48705, "OffsetEndMs": 48930}, {"Word": "possible", "OffsetStartMs": 48930, "OffsetEndMs": 49310}, {"Word": "board", "OffsetStartMs": 50470, "OffsetEndMs": 50820}, {"Word": "states", "OffsetStartMs": 50820, "OffsetEndMs": 51060}, {"Word": "that", "OffsetStartMs": 51060, "OffsetEndMs": 51240}, {"Word": "might", "OffsetStartMs": 51240, "OffsetEndMs": 51510}, {"Word": "emerge", "OffsetStartMs": 51510, "OffsetEndMs": 51960}, {"Word": "from", "OffsetStartMs": 51960, "OffsetEndMs": 52155}, {"Word": "this", "OffsetStartMs": 52155, "OffsetEndMs": 52460}, {"Word": "particular", "OffsetStartMs": 53320, "OffsetEndMs": 53720}, {"Word": "state", "OffsetStartMs": 53770, "OffsetEndMs": 54090}, {"Word": "and", "OffsetStartMs": 54090, "OffsetEndMs": 54300}, {"Word": "what", "OffsetStartMs": 54300, "OffsetEndMs": 54480}, {"Word": "would", "OffsetStartMs": 54480, "OffsetEndMs": 54660}, {"Word": "their", "OffsetStartMs": 54660, "OffsetEndMs": 54855}, {"Word": "values", "OffsetStartMs": 54855, "OffsetEndMs": 55160}, {"Word": "be", "OffsetStartMs": 55570, "OffsetEndMs": 55875}, {"Word": "What", "OffsetStartMs": 55875, "OffsetEndMs": 56055}, {"Word": "would", "OffsetStartMs": 56055, "OffsetEndMs": 56190}, {"Word": "their", "OffsetStartMs": 56190, "OffsetEndMs": 56415}, {"Word": "potential", "OffsetStartMs": 56415, "OffsetEndMs": 56780}, {"Word": "returns", "OffsetStartMs": 56830, "OffsetEndMs": 57180}, {"Word": "and", "OffsetStartMs": 57180, "OffsetEndMs": 57390}, {"Word": "their", "OffsetStartMs": 57390, "OffsetEndMs": 57645}, {"Word": "outcomes", "OffsetStartMs": 57645, "OffsetEndMs": 58040}, {"Word": "be", "OffsetStartMs": 58300, "OffsetEndMs": 58620}, {"Word": "So", "OffsetStartMs": 58620, "OffsetEndMs": 58815}, {"Word": "this", "OffsetStartMs": 58815, "OffsetEndMs": 59010}, {"Word": "network", "OffsetStartMs": 59010, "OffsetEndMs": 59330}, {"Word": "was", "OffsetStartMs": 59440, "OffsetEndMs": 59715}, {"Word": "an", "OffsetStartMs": 59715, "OffsetEndMs": 59850}, {"Word": "auxiliary", "OffsetStartMs": 59850, "OffsetEndMs": 60270}], "SpeechSpeed": 16.6}, {"FinalSentence": "Network that was almost hallucinating, right? Different board states that it could take from this particular state and using those predicted values to guide its planning of, you know, what action should it take into the future? And finally, very much more recently, they extended this algorithm and showed that they could not even use the human grand masters in the beginning to imitate from in the beginning. And bootstrap these algorithms. What if they just started entirely from scratch and just had two neural networks never trained before they start pinning themselves against each other and you could actually see that you could without any human supervision at all.", "SliceSentence": "Network that was almost hallucinating right Different board states that it could take from this particular state and using those predicted values to guide its planning of you know what action should it take into the future And finally very much more recently they extended this algorithm and showed that they could not even use the human grand masters in the beginning to imitate from in the beginning And bootstrap these algorithms What if they just started entirely from scratch and just had two neural networks never trained before they start pinning themselves against each other and you could actually see that you could without any human supervision at all", "StartMs": 3341320, "EndMs": 3378300, "WordsNum": 110, "Words": [{"Word": "Network", "OffsetStartMs": 40, "OffsetEndMs": 440}, {"Word": "that", "OffsetStartMs": 760, "OffsetEndMs": 1020}, {"Word": "was", "OffsetStartMs": 1020, "OffsetEndMs": 1185}, {"Word": "almost", "OffsetStartMs": 1185, "OffsetEndMs": 1395}, {"Word": "hallucinating", "OffsetStartMs": 1395, "OffsetEndMs": 2120}, {"Word": "right", "OffsetStartMs": 2230, "OffsetEndMs": 2630}, {"Word": "Different", "OffsetStartMs": 3010, "OffsetEndMs": 3405}, {"Word": "board", "OffsetStartMs": 3405, "OffsetEndMs": 3780}, {"Word": "states", "OffsetStartMs": 3780, "OffsetEndMs": 4155}, {"Word": "that", "OffsetStartMs": 4155, "OffsetEndMs": 4455}, {"Word": "it", "OffsetStartMs": 4455, "OffsetEndMs": 4650}, {"Word": "could", "OffsetStartMs": 4650, "OffsetEndMs": 4845}, {"Word": "take", "OffsetStartMs": 4845, "OffsetEndMs": 5085}, {"Word": "from", "OffsetStartMs": 5085, "OffsetEndMs": 5295}, {"Word": "this", "OffsetStartMs": 5295, "OffsetEndMs": 5570}, {"Word": "particular", "OffsetStartMs": 5620, "OffsetEndMs": 6020}, {"Word": "state", "OffsetStartMs": 6160, "OffsetEndMs": 6560}, {"Word": "and", "OffsetStartMs": 6940, "OffsetEndMs": 7340}, {"Word": "using", "OffsetStartMs": 7420, "OffsetEndMs": 7815}, {"Word": "those", "OffsetStartMs": 7815, "OffsetEndMs": 8130}, {"Word": "predicted", "OffsetStartMs": 8130, "OffsetEndMs": 8595}, {"Word": "values", "OffsetStartMs": 8595, "OffsetEndMs": 8870}, {"Word": "to", "OffsetStartMs": 9010, "OffsetEndMs": 9300}, {"Word": "guide", "OffsetStartMs": 9300, "OffsetEndMs": 9590}, {"Word": "its", "OffsetStartMs": 9970, "OffsetEndMs": 10350}, {"Word": "planning", "OffsetStartMs": 10350, "OffsetEndMs": 10730}, {"Word": "of", "OffsetStartMs": 11020, "OffsetEndMs": 11420}, {"Word": "you", "OffsetStartMs": 11560, "OffsetEndMs": 11805}, {"Word": "know", "OffsetStartMs": 11805, "OffsetEndMs": 12050}, {"Word": "what", "OffsetStartMs": 12130, "OffsetEndMs": 12435}, {"Word": "action", "OffsetStartMs": 12435, "OffsetEndMs": 12735}, {"Word": "should", "OffsetStartMs": 12735, "OffsetEndMs": 12975}, {"Word": "it", "OffsetStartMs": 12975, "OffsetEndMs": 13110}, {"Word": "take", "OffsetStartMs": 13110, "OffsetEndMs": 13305}, {"Word": "into", "OffsetStartMs": 13305, "OffsetEndMs": 13545}, {"Word": "the", "OffsetStartMs": 13545, "OffsetEndMs": 13740}, {"Word": "future", "OffsetStartMs": 13740, "OffsetEndMs": 14000}, {"Word": "And", "OffsetStartMs": 14470, "OffsetEndMs": 14760}, {"Word": "finally", "OffsetStartMs": 14760, "OffsetEndMs": 15050}, {"Word": "very", "OffsetStartMs": 15280, "OffsetEndMs": 15680}, {"Word": "much", "OffsetStartMs": 15910, "OffsetEndMs": 16215}, {"Word": "more", "OffsetStartMs": 16215, "OffsetEndMs": 16410}, {"Word": "recently", "OffsetStartMs": 16410, "OffsetEndMs": 16700}, {"Word": "they", "OffsetStartMs": 17080, "OffsetEndMs": 17445}, {"Word": "extended", "OffsetStartMs": 17445, "OffsetEndMs": 17760}, {"Word": "this", "OffsetStartMs": 17760, "OffsetEndMs": 18090}, {"Word": "algorithm", "OffsetStartMs": 18090, "OffsetEndMs": 18420}, {"Word": "and", "OffsetStartMs": 18420, "OffsetEndMs": 18570}, {"Word": "showed", "OffsetStartMs": 18570, "OffsetEndMs": 18735}, {"Word": "that", "OffsetStartMs": 18735, "OffsetEndMs": 18885}, {"Word": "they", "OffsetStartMs": 18885, "OffsetEndMs": 19035}, {"Word": "could", "OffsetStartMs": 19035, "OffsetEndMs": 19200}, {"Word": "not", "OffsetStartMs": 19200, "OffsetEndMs": 19410}, {"Word": "even", "OffsetStartMs": 19410, "OffsetEndMs": 19695}, {"Word": "use", "OffsetStartMs": 19695, "OffsetEndMs": 20060}, {"Word": "the", "OffsetStartMs": 20410, "OffsetEndMs": 20685}, {"Word": "human", "OffsetStartMs": 20685, "OffsetEndMs": 20940}, {"Word": "grand", "OffsetStartMs": 20940, "OffsetEndMs": 21240}, {"Word": "masters", "OffsetStartMs": 21240, "OffsetEndMs": 21660}, {"Word": "in", "OffsetStartMs": 21660, "OffsetEndMs": 21795}, {"Word": "the", "OffsetStartMs": 21795, "OffsetEndMs": 21930}, {"Word": "beginning", "OffsetStartMs": 21930, "OffsetEndMs": 22140}, {"Word": "to", "OffsetStartMs": 22140, "OffsetEndMs": 22305}, {"Word": "imitate", "OffsetStartMs": 22305, "OffsetEndMs": 22850}, {"Word": "from", "OffsetStartMs": 22960, "OffsetEndMs": 23340}, {"Word": "in", "OffsetStartMs": 23340, "OffsetEndMs": 23580}, {"Word": "the", "OffsetStartMs": 23580, "OffsetEndMs": 23730}, {"Word": "beginning", "OffsetStartMs": 23730, "OffsetEndMs": 23910}, {"Word": "And", "OffsetStartMs": 23910, "OffsetEndMs": 24075}, {"Word": "bootstrap", "OffsetStartMs": 24075, "OffsetEndMs": 24465}, {"Word": "these", "OffsetStartMs": 24465, "OffsetEndMs": 24705}, {"Word": "algorithms", "OffsetStartMs": 24705, "OffsetEndMs": 25095}, {"Word": "What", "OffsetStartMs": 25095, "OffsetEndMs": 25245}, {"Word": "if", "OffsetStartMs": 25245, "OffsetEndMs": 25350}, {"Word": "they", "OffsetStartMs": 25350, "OffsetEndMs": 25485}, {"Word": "just", "OffsetStartMs": 25485, "OffsetEndMs": 25665}, {"Word": "started", "OffsetStartMs": 25665, "OffsetEndMs": 25970}, {"Word": "entirely", "OffsetStartMs": 26290, "OffsetEndMs": 26670}, {"Word": "from", "OffsetStartMs": 26670, "OffsetEndMs": 26970}, {"Word": "scratch", "OffsetStartMs": 26970, "OffsetEndMs": 27270}, {"Word": "and", "OffsetStartMs": 27270, "OffsetEndMs": 27510}, {"Word": "just", "OffsetStartMs": 27510, "OffsetEndMs": 27675}, {"Word": "had", "OffsetStartMs": 27675, "OffsetEndMs": 27900}, {"Word": "two", "OffsetStartMs": 27900, "OffsetEndMs": 28095}, {"Word": "neural", "OffsetStartMs": 28095, "OffsetEndMs": 28320}, {"Word": "networks", "OffsetStartMs": 28320, "OffsetEndMs": 28580}, {"Word": "never", "OffsetStartMs": 28990, "OffsetEndMs": 29340}, {"Word": "trained", "OffsetStartMs": 29340, "OffsetEndMs": 29595}, {"Word": "before", "OffsetStartMs": 29595, "OffsetEndMs": 29900}, {"Word": "they", "OffsetStartMs": 30280, "OffsetEndMs": 30660}, {"Word": "start", "OffsetStartMs": 30660, "OffsetEndMs": 30975}, {"Word": "pinning", "OffsetStartMs": 30975, "OffsetEndMs": 31350}, {"Word": "themselves", "OffsetStartMs": 31350, "OffsetEndMs": 31665}, {"Word": "against", "OffsetStartMs": 31665, "OffsetEndMs": 31935}, {"Word": "each", "OffsetStartMs": 31935, "OffsetEndMs": 32130}, {"Word": "other", "OffsetStartMs": 32130, "OffsetEndMs": 32420}, {"Word": "and", "OffsetStartMs": 32650, "OffsetEndMs": 32925}, {"Word": "you", "OffsetStartMs": 32925, "OffsetEndMs": 33060}, {"Word": "could", "OffsetStartMs": 33060, "OffsetEndMs": 33270}, {"Word": "actually", "OffsetStartMs": 33270, "OffsetEndMs": 33525}, {"Word": "see", "OffsetStartMs": 33525, "OffsetEndMs": 33705}, {"Word": "that", "OffsetStartMs": 33705, "OffsetEndMs": 33855}, {"Word": "you", "OffsetStartMs": 33855, "OffsetEndMs": 34020}, {"Word": "could", "OffsetStartMs": 34020, "OffsetEndMs": 34310}, {"Word": "without", "OffsetStartMs": 34480, "OffsetEndMs": 34845}, {"Word": "any", "OffsetStartMs": 34845, "OffsetEndMs": 35145}, {"Word": "human", "OffsetStartMs": 35145, "OffsetEndMs": 35480}, {"Word": "supervision", "OffsetStartMs": 35620, "OffsetEndMs": 35970}, {"Word": "at", "OffsetStartMs": 35970, "OffsetEndMs": 36135}, {"Word": "all", "OffsetStartMs": 36135, "OffsetEndMs": 36380}], "SpeechSpeed": 17.9}, {"FinalSentence": "Have a neural network learn to not only outperform the solution that outperform the humans, but also outperform the solution that was created, which was bootstrapped by humans as well.", "SliceSentence": "Have a neural network learn to not only outperform the solution that outperform the humans but also outperform the solution that was created which was bootstrapped by humans as well", "StartMs": 3378300, "EndMs": 3393400, "WordsNum": 30, "Words": [{"Word": "Have", "OffsetStartMs": 160, "OffsetEndMs": 540}, {"Word": "a", "OffsetStartMs": 540, "OffsetEndMs": 810}, {"Word": "neural", "OffsetStartMs": 810, "OffsetEndMs": 1050}, {"Word": "network", "OffsetStartMs": 1050, "OffsetEndMs": 1310}, {"Word": "learn", "OffsetStartMs": 1540, "OffsetEndMs": 1920}, {"Word": "to", "OffsetStartMs": 1920, "OffsetEndMs": 2300}, {"Word": "not", "OffsetStartMs": 2440, "OffsetEndMs": 2730}, {"Word": "only", "OffsetStartMs": 2730, "OffsetEndMs": 3000}, {"Word": "outperform", "OffsetStartMs": 3000, "OffsetEndMs": 3770}, {"Word": "the", "OffsetStartMs": 4030, "OffsetEndMs": 4320}, {"Word": "solution", "OffsetStartMs": 4320, "OffsetEndMs": 4610}, {"Word": "that", "OffsetStartMs": 5200, "OffsetEndMs": 5600}, {"Word": "outperform", "OffsetStartMs": 6910, "OffsetEndMs": 7590}, {"Word": "the", "OffsetStartMs": 7590, "OffsetEndMs": 7755}, {"Word": "humans", "OffsetStartMs": 7755, "OffsetEndMs": 8030}, {"Word": "but", "OffsetStartMs": 8500, "OffsetEndMs": 8895}, {"Word": "also", "OffsetStartMs": 8895, "OffsetEndMs": 9150}, {"Word": "outperform", "OffsetStartMs": 9150, "OffsetEndMs": 9800}, {"Word": "the", "OffsetStartMs": 9940, "OffsetEndMs": 10215}, {"Word": "solution", "OffsetStartMs": 10215, "OffsetEndMs": 10485}, {"Word": "that", "OffsetStartMs": 10485, "OffsetEndMs": 10740}, {"Word": "was", "OffsetStartMs": 10740, "OffsetEndMs": 10905}, {"Word": "created", "OffsetStartMs": 10905, "OffsetEndMs": 11210}, {"Word": "which", "OffsetStartMs": 11260, "OffsetEndMs": 11535}, {"Word": "was", "OffsetStartMs": 11535, "OffsetEndMs": 11730}, {"Word": "bootstrapped", "OffsetStartMs": 11730, "OffsetEndMs": 12465}, {"Word": "by", "OffsetStartMs": 12465, "OffsetEndMs": 12765}, {"Word": "humans", "OffsetStartMs": 12765, "OffsetEndMs": 13070}, {"Word": "as", "OffsetStartMs": 13360, "OffsetEndMs": 13680}, {"Word": "well", "OffsetStartMs": 13680, "OffsetEndMs": 14000}], "SpeechSpeed": 12.0}, {"FinalSentence": "So with that, I'll summarize very quickly what we've learned today and and conclude for the day. So we've talked a lot about really the foundational algorithms underlying reinforcement learning. We saw two different types of reinforcement learning approaches of how we can optimize these solutions. First being q, learning, where we're trying to actually estimate, given a state, you know, what is the value that we might expect for any possible action in the second way was to take a much more end to end approach and say how, given the state that we see ourselves in, what is the likelihood that I should take any given action to maximize the potential that I I have in this particular state.", "SliceSentence": "So with that I'll summarize very quickly what we've learned today and and conclude for the day So we've talked a lot about really the foundational algorithms underlying reinforcement learning We saw two different types of reinforcement learning approaches of how we can optimize these solutions First being q learning where we're trying to actually estimate given a state you know what is the value that we might expect for any possible action in the second way was to take a much more end to end approach and say how given the state that we see ourselves in what is the likelihood that I should take any given action to maximize the potential that I I have in this particular state", "StartMs": 3394300, "EndMs": 3431940, "WordsNum": 121, "Words": [{"Word": "So", "OffsetStartMs": 160, "OffsetEndMs": 560}, {"Word": "with", "OffsetStartMs": 700, "OffsetEndMs": 975}, {"Word": "that", "OffsetStartMs": 975, "OffsetEndMs": 1170}, {"Word": "I'll", "OffsetStartMs": 1170, "OffsetEndMs": 1700}, {"Word": "summarize", "OffsetStartMs": 1960, "OffsetEndMs": 2430}, {"Word": "very", "OffsetStartMs": 2430, "OffsetEndMs": 2640}, {"Word": "quickly", "OffsetStartMs": 2640, "OffsetEndMs": 2940}, {"Word": "what", "OffsetStartMs": 2940, "OffsetEndMs": 3180}, {"Word": "we've", "OffsetStartMs": 3180, "OffsetEndMs": 3390}, {"Word": "learned", "OffsetStartMs": 3390, "OffsetEndMs": 3585}, {"Word": "today", "OffsetStartMs": 3585, "OffsetEndMs": 3840}, {"Word": "and", "OffsetStartMs": 3840, "OffsetEndMs": 4125}, {"Word": "and", "OffsetStartMs": 4125, "OffsetEndMs": 4490}, {"Word": "conclude", "OffsetStartMs": 4510, "OffsetEndMs": 4860}, {"Word": "for", "OffsetStartMs": 4860, "OffsetEndMs": 4980}, {"Word": "the", "OffsetStartMs": 4980, "OffsetEndMs": 5100}, {"Word": "day", "OffsetStartMs": 5100, "OffsetEndMs": 5360}, {"Word": "So", "OffsetStartMs": 5860, "OffsetEndMs": 6135}, {"Word": "we've", "OffsetStartMs": 6135, "OffsetEndMs": 6480}, {"Word": "talked", "OffsetStartMs": 6480, "OffsetEndMs": 6690}, {"Word": "a", "OffsetStartMs": 6690, "OffsetEndMs": 6855}, {"Word": "lot", "OffsetStartMs": 6855, "OffsetEndMs": 7065}, {"Word": "about", "OffsetStartMs": 7065, "OffsetEndMs": 7335}, {"Word": "really", "OffsetStartMs": 7335, "OffsetEndMs": 7590}, {"Word": "the", "OffsetStartMs": 7590, "OffsetEndMs": 7770}, {"Word": "foundational", "OffsetStartMs": 7770, "OffsetEndMs": 8240}, {"Word": "algorithms", "OffsetStartMs": 8590, "OffsetEndMs": 9110}, {"Word": "underlying", "OffsetStartMs": 9250, "OffsetEndMs": 9650}, {"Word": "reinforcement", "OffsetStartMs": 9910, "OffsetEndMs": 10635}, {"Word": "learning", "OffsetStartMs": 10635, "OffsetEndMs": 10860}, {"Word": "We", "OffsetStartMs": 10860, "OffsetEndMs": 11100}, {"Word": "saw", "OffsetStartMs": 11100, "OffsetEndMs": 11355}, {"Word": "two", "OffsetStartMs": 11355, "OffsetEndMs": 11595}, {"Word": "different", "OffsetStartMs": 11595, "OffsetEndMs": 11870}, {"Word": "types", "OffsetStartMs": 11890, "OffsetEndMs": 12270}, {"Word": "of", "OffsetStartMs": 12270, "OffsetEndMs": 12510}, {"Word": "reinforcement", "OffsetStartMs": 12510, "OffsetEndMs": 13155}, {"Word": "learning", "OffsetStartMs": 13155, "OffsetEndMs": 13430}, {"Word": "approaches", "OffsetStartMs": 13630, "OffsetEndMs": 14030}, {"Word": "of", "OffsetStartMs": 14050, "OffsetEndMs": 14310}, {"Word": "how", "OffsetStartMs": 14310, "OffsetEndMs": 14445}, {"Word": "we", "OffsetStartMs": 14445, "OffsetEndMs": 14565}, {"Word": "can", "OffsetStartMs": 14565, "OffsetEndMs": 14790}, {"Word": "optimize", "OffsetStartMs": 14790, "OffsetEndMs": 15180}, {"Word": "these", "OffsetStartMs": 15180, "OffsetEndMs": 15435}, {"Word": "solutions", "OffsetStartMs": 15435, "OffsetEndMs": 15770}, {"Word": "First", "OffsetStartMs": 16360, "OffsetEndMs": 16695}, {"Word": "being", "OffsetStartMs": 16695, "OffsetEndMs": 16980}, {"Word": "q", "OffsetStartMs": 16980, "OffsetEndMs": 17220}, {"Word": "learning", "OffsetStartMs": 17220, "OffsetEndMs": 17510}, {"Word": "where", "OffsetStartMs": 17530, "OffsetEndMs": 17805}, {"Word": "we're", "OffsetStartMs": 17805, "OffsetEndMs": 17985}, {"Word": "trying", "OffsetStartMs": 17985, "OffsetEndMs": 18165}, {"Word": "to", "OffsetStartMs": 18165, "OffsetEndMs": 18450}, {"Word": "actually", "OffsetStartMs": 18450, "OffsetEndMs": 18800}, {"Word": "estimate", "OffsetStartMs": 19180, "OffsetEndMs": 19545}, {"Word": "given", "OffsetStartMs": 19545, "OffsetEndMs": 19815}, {"Word": "a", "OffsetStartMs": 19815, "OffsetEndMs": 20025}, {"Word": "state", "OffsetStartMs": 20025, "OffsetEndMs": 20310}, {"Word": "you", "OffsetStartMs": 20310, "OffsetEndMs": 20535}, {"Word": "know", "OffsetStartMs": 20535, "OffsetEndMs": 20780}, {"Word": "what", "OffsetStartMs": 20830, "OffsetEndMs": 21090}, {"Word": "is", "OffsetStartMs": 21090, "OffsetEndMs": 21255}, {"Word": "the", "OffsetStartMs": 21255, "OffsetEndMs": 21420}, {"Word": "value", "OffsetStartMs": 21420, "OffsetEndMs": 21680}, {"Word": "that", "OffsetStartMs": 21730, "OffsetEndMs": 21990}, {"Word": "we", "OffsetStartMs": 21990, "OffsetEndMs": 22125}, {"Word": "might", "OffsetStartMs": 22125, "OffsetEndMs": 22395}, {"Word": "expect", "OffsetStartMs": 22395, "OffsetEndMs": 22790}, {"Word": "for", "OffsetStartMs": 23020, "OffsetEndMs": 23280}, {"Word": "any", "OffsetStartMs": 23280, "OffsetEndMs": 23445}, {"Word": "possible", "OffsetStartMs": 23445, "OffsetEndMs": 23715}, {"Word": "action", "OffsetStartMs": 23715, "OffsetEndMs": 24045}, {"Word": "in", "OffsetStartMs": 24045, "OffsetEndMs": 24285}, {"Word": "the", "OffsetStartMs": 24285, "OffsetEndMs": 24435}, {"Word": "second", "OffsetStartMs": 24435, "OffsetEndMs": 24645}, {"Word": "way", "OffsetStartMs": 24645, "OffsetEndMs": 24980}, {"Word": "was", "OffsetStartMs": 25150, "OffsetEndMs": 25440}, {"Word": "to", "OffsetStartMs": 25440, "OffsetEndMs": 25590}, {"Word": "take", "OffsetStartMs": 25590, "OffsetEndMs": 25710}, {"Word": "a", "OffsetStartMs": 25710, "OffsetEndMs": 25815}, {"Word": "much", "OffsetStartMs": 25815, "OffsetEndMs": 25950}, {"Word": "more", "OffsetStartMs": 25950, "OffsetEndMs": 26100}, {"Word": "end", "OffsetStartMs": 26100, "OffsetEndMs": 26265}, {"Word": "to", "OffsetStartMs": 26265, "OffsetEndMs": 26400}, {"Word": "end", "OffsetStartMs": 26400, "OffsetEndMs": 26595}, {"Word": "approach", "OffsetStartMs": 26595, "OffsetEndMs": 26960}, {"Word": "and", "OffsetStartMs": 27280, "OffsetEndMs": 27585}, {"Word": "say", "OffsetStartMs": 27585, "OffsetEndMs": 27885}, {"Word": "how", "OffsetStartMs": 27885, "OffsetEndMs": 28280}, {"Word": "given", "OffsetStartMs": 28390, "OffsetEndMs": 28710}, {"Word": "the", "OffsetStartMs": 28710, "OffsetEndMs": 28920}, {"Word": "state", "OffsetStartMs": 28920, "OffsetEndMs": 29085}, {"Word": "that", "OffsetStartMs": 29085, "OffsetEndMs": 29220}, {"Word": "we", "OffsetStartMs": 29220, "OffsetEndMs": 29370}, {"Word": "see", "OffsetStartMs": 29370, "OffsetEndMs": 29625}, {"Word": "ourselves", "OffsetStartMs": 29625, "OffsetEndMs": 29910}, {"Word": "in", "OffsetStartMs": 29910, "OffsetEndMs": 30180}, {"Word": "what", "OffsetStartMs": 30180, "OffsetEndMs": 30390}, {"Word": "is", "OffsetStartMs": 30390, "OffsetEndMs": 30525}, {"Word": "the", "OffsetStartMs": 30525, "OffsetEndMs": 30660}, {"Word": "likelihood", "OffsetStartMs": 30660, "OffsetEndMs": 31095}, {"Word": "that", "OffsetStartMs": 31095, "OffsetEndMs": 31215}, {"Word": "I", "OffsetStartMs": 31215, "OffsetEndMs": 31335}, {"Word": "should", "OffsetStartMs": 31335, "OffsetEndMs": 31470}, {"Word": "take", "OffsetStartMs": 31470, "OffsetEndMs": 31605}, {"Word": "any", "OffsetStartMs": 31605, "OffsetEndMs": 31785}, {"Word": "given", "OffsetStartMs": 31785, "OffsetEndMs": 31995}, {"Word": "action", "OffsetStartMs": 31995, "OffsetEndMs": 32300}, {"Word": "to", "OffsetStartMs": 32860, "OffsetEndMs": 33135}, {"Word": "maximize", "OffsetStartMs": 33135, "OffsetEndMs": 33720}, {"Word": "the", "OffsetStartMs": 33720, "OffsetEndMs": 34005}, {"Word": "potential", "OffsetStartMs": 34005, "OffsetEndMs": 34340}, {"Word": "that", "OffsetStartMs": 34630, "OffsetEndMs": 34890}, {"Word": "I", "OffsetStartMs": 34890, "OffsetEndMs": 35150}, {"Word": "I", "OffsetStartMs": 35320, "OffsetEndMs": 35625}, {"Word": "have", "OffsetStartMs": 35625, "OffsetEndMs": 35930}, {"Word": "in", "OffsetStartMs": 35980, "OffsetEndMs": 36255}, {"Word": "this", "OffsetStartMs": 36255, "OffsetEndMs": 36480}, {"Word": "particular", "OffsetStartMs": 36480, "OffsetEndMs": 36830}, {"Word": "state", "OffsetStartMs": 36910, "OffsetEndMs": 37310}], "SpeechSpeed": 18.1}, {"FinalSentence": "And I hope that all of this was very exciting to you today. We have a very exciting lab and kick off for the competition and the deadline for these competitions will be well. It was originally set to be thursday, which is tomorrow at eleven PM. Thank you.", "SliceSentence": "And I hope that all of this was very exciting to you today We have a very exciting lab and kick off for the competition and the deadline for these competitions will be well It was originally set to be thursday which is tomorrow at eleven PM Thank you", "StartMs": 3431940, "EndMs": 3449740, "WordsNum": 49, "Words": [{"Word": "And", "OffsetStartMs": 70, "OffsetEndMs": 420}, {"Word": "I", "OffsetStartMs": 420, "OffsetEndMs": 630}, {"Word": "hope", "OffsetStartMs": 630, "OffsetEndMs": 795}, {"Word": "that", "OffsetStartMs": 795, "OffsetEndMs": 1100}, {"Word": "all", "OffsetStartMs": 1150, "OffsetEndMs": 1410}, {"Word": "of", "OffsetStartMs": 1410, "OffsetEndMs": 1545}, {"Word": "this", "OffsetStartMs": 1545, "OffsetEndMs": 1695}, {"Word": "was", "OffsetStartMs": 1695, "OffsetEndMs": 1860}, {"Word": "very", "OffsetStartMs": 1860, "OffsetEndMs": 2115}, {"Word": "exciting", "OffsetStartMs": 2115, "OffsetEndMs": 2475}, {"Word": "to", "OffsetStartMs": 2475, "OffsetEndMs": 2685}, {"Word": "you", "OffsetStartMs": 2685, "OffsetEndMs": 2865}, {"Word": "today", "OffsetStartMs": 2865, "OffsetEndMs": 3150}, {"Word": "We", "OffsetStartMs": 3150, "OffsetEndMs": 3300}, {"Word": "have", "OffsetStartMs": 3300, "OffsetEndMs": 3405}, {"Word": "a", "OffsetStartMs": 3405, "OffsetEndMs": 3680}, {"Word": "very", "OffsetStartMs": 3700, "OffsetEndMs": 4095}, {"Word": "exciting", "OffsetStartMs": 4095, "OffsetEndMs": 4485}, {"Word": "lab", "OffsetStartMs": 4485, "OffsetEndMs": 4880}, {"Word": "and", "OffsetStartMs": 4960, "OffsetEndMs": 5360}, {"Word": "kick", "OffsetStartMs": 5500, "OffsetEndMs": 5775}, {"Word": "off", "OffsetStartMs": 5775, "OffsetEndMs": 6000}, {"Word": "for", "OffsetStartMs": 6000, "OffsetEndMs": 6210}, {"Word": "the", "OffsetStartMs": 6210, "OffsetEndMs": 6465}, {"Word": "competition", "OffsetStartMs": 6465, "OffsetEndMs": 6860}, {"Word": "and", "OffsetStartMs": 7570, "OffsetEndMs": 7920}, {"Word": "the", "OffsetStartMs": 7920, "OffsetEndMs": 8145}, {"Word": "deadline", "OffsetStartMs": 8145, "OffsetEndMs": 8550}, {"Word": "for", "OffsetStartMs": 8550, "OffsetEndMs": 8715}, {"Word": "these", "OffsetStartMs": 8715, "OffsetEndMs": 8865}, {"Word": "competitions", "OffsetStartMs": 8865, "OffsetEndMs": 9440}, {"Word": "will", "OffsetStartMs": 9520, "OffsetEndMs": 9810}, {"Word": "be", "OffsetStartMs": 9810, "OffsetEndMs": 10100}, {"Word": "well", "OffsetStartMs": 10840, "OffsetEndMs": 11130}, {"Word": "It", "OffsetStartMs": 11130, "OffsetEndMs": 11280}, {"Word": "was", "OffsetStartMs": 11280, "OffsetEndMs": 11460}, {"Word": "originally", "OffsetStartMs": 11460, "OffsetEndMs": 11780}, {"Word": "set", "OffsetStartMs": 11890, "OffsetEndMs": 12270}, {"Word": "to", "OffsetStartMs": 12270, "OffsetEndMs": 12495}, {"Word": "be", "OffsetStartMs": 12495, "OffsetEndMs": 12720}, {"Word": "thursday", "OffsetStartMs": 12720, "OffsetEndMs": 13100}, {"Word": "which", "OffsetStartMs": 13570, "OffsetEndMs": 13845}, {"Word": "is", "OffsetStartMs": 13845, "OffsetEndMs": 14120}, {"Word": "tomorrow", "OffsetStartMs": 14470, "OffsetEndMs": 14870}, {"Word": "at", "OffsetStartMs": 14980, "OffsetEndMs": 15300}, {"Word": "eleven", "OffsetStartMs": 15300, "OffsetEndMs": 15570}, {"Word": "PM", "OffsetStartMs": 15570, "OffsetEndMs": 16010}, {"Word": "Thank", "OffsetStartMs": 16150, "OffsetEndMs": 16440}, {"Word": "you", "OffsetStartMs": 16440, "OffsetEndMs": 16730}], "SpeechSpeed": 14.0}]}, "RequestId": "a4e2bdcb-1404-4952-9f89-02179606d4b6"}