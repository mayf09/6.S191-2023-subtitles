1
00:00:09,660 --> 00:00:11,240
0,320 320,515 515,880 900,1300 1320,1580
I'm really excited especially for

2
00:00:11,240 --> 00:00:12,275
0,180 180,500 520,780 780,915 915,1035
this lecture, which is a

3
00:00:12,275 --> 00:00:13,985
0,245 385,735 735,1065 1065,1395 1395,1710
very special lecture on robust

4
00:00:13,985 --> 00:00:15,755
0,255 255,810 810,990 990,1295 1435,1770
and trustworthy deep learning by

5
00:00:15,755 --> 00:00:17,405
0,195 195,315 315,575 925,1455 1455,1650
one of our sponsors of

6
00:00:17,405 --> 00:00:19,150
0,195 195,495 495,870 870,1380 1380,1745
this amazing course, themeis AI.

7
00:00:19,800 --> 00:00:21,070
0,365 365,620 620,845 845,980 980,1270
{And,as -} you'll see today,

8
00:00:21,240 --> 00:00:24,310
0,515 515,880 990,1390 1890,2290 2460,3070
themeis AI is a startup

9
00:00:24,510 --> 00:00:26,015
0,275 275,710 710,995 995,1265 1265,1505
actually locally based here in

10
00:00:26,015 --> 00:00:27,890
0,575 865,1155 1155,1380 1380,1620 1620,1875
{Cambridge.,Our -} mission is to

11
00:00:27,890 --> 00:00:30,500
0,350 670,1070 1180,1560 1560,1940 2320,2610
design, advance and deploy the

12
00:00:30,500 --> 00:00:32,870
0,290 340,740 940,1340 1390,1725 1725,2370
future of AI {and,trustworthy. -}

13
00:00:32,870 --> 00:00:35,320
0,240 240,560 1180,1680 1680,2055 2055,2450
I specifically, I'm especially excited

14
00:00:35,340 --> 00:00:37,865
0,350 350,970 1050,1450 1800,2200 2220,2525
about today's lecture because I

15
00:00:37,865 --> 00:00:39,575
0,195 195,485 565,1145 1165,1470 1470,1710
Co founded themis right here

16
00:00:39,575 --> 00:00:41,210
0,300 300,665 1105,1395 1395,1530 1530,1635
at MIT right here in

17
00:00:41,210 --> 00:00:42,370
0,165 165,375 375,615 615,855 855,1160
{this,very -} building. In fact,

18
00:00:42,930 --> 00:00:44,525
0,305 305,560 560,935 935,1210 1230,1595
this all stemmed from really

19
00:00:44,525 --> 00:00:47,105
0,300 300,635 835,1235 1735,2135 2245,2580
the incredible scientific innovation and

20
00:00:47,105 --> 00:00:48,755
0,540 540,765 765,960 960,1265 1345,1650
advances that we created right

21
00:00:48,755 --> 00:00:49,930
0,225 225,405 405,540 540,735 735,1175
here just a few floors

22
00:00:50,100 --> 00:00:51,245
0,335 335,530 530,665 665,905 905,1145
higher than {where,you're -} sitting

23
00:00:51,245 --> 00:00:53,510
0,365 1135,1535 1705,1995 1995,2130 2130,2265
today. And because of our

24
00:00:53,510 --> 00:00:55,570
0,290 610,990 990,1365 1365,1710 1710,2060
background in really cutting edge

25
00:00:55,770 --> 00:00:58,780
0,400 990,1390 2010,2480 2480,2690 2690,3010
scientific innovation stemming from MIT,

26
00:00:58,830 --> 00:01:00,940
0,425 425,635 635,970 1080,1690 1710,2110
themus is very rooted deeply

27
00:01:01,380 --> 00:01:03,320
0,400 450,850 1140,1520 1520,1775 1775,1940
in science and like I

28
00:01:03,320 --> 00:01:05,520
0,290 400,800
said, innovation.|

29
00:01:05,520 --> 00:01:07,490
0,195 195,470 550,950 1210,1590 1590,1970
We really aim to advance

30
00:01:07,540 --> 00:01:08,810
0,275 275,515 515,770 770,965 965,1270
the future of deep learning

31
00:01:09,010 --> 00:01:10,395
0,400 420,800 800,1070 1070,1250 1250,1385
and AI and much of

32
00:01:10,395 --> 00:01:12,350
0,135 135,425 625,1025 1045,1445 1555,1955
our technology has already grown

33
00:01:12,400 --> 00:01:15,140
0,320 320,605 605,970 1680,2080 2160,2740
from published research that we've

34
00:01:15,580 --> 00:01:18,195
0,400 930,1280 1280,1595 1595,2020 2220,2615
published at top tier peer

35
00:01:18,195 --> 00:01:20,060
0,270 270,1025 1045,1320 1320,1530 1530,1865
review conferences in the AI

36
00:01:20,380 --> 00:01:22,065
0,580 660,950 950,1100 1100,1360 1440,1685
venues around the world and

37
00:01:22,065 --> 00:01:23,115
0,180 180,420 420,615 615,795 795,1050
our work has been covered

38
00:01:23,115 --> 00:01:25,440
0,365 445,845 895,1295 1495,1895 2005,2325
by high profile international media

39
00:01:25,440 --> 00:01:28,725
0,500 1480,1880 1900,2300 2530,2930 2980,3285
outlets. {This,scientific -} innovation with

40
00:01:28,725 --> 00:01:31,095
0,195 195,485 685,1085 1315,1895 2125,2370
this scientific innovation themeis we

41
00:01:31,095 --> 00:01:33,015
0,165 165,785 1285,1560 1560,1695 1695,1920
are tackling some of the

42
00:01:33,015 --> 00:01:35,330
0,365 415,815 1255,1620 1620,1950 1950,2315
biggest challenges in safety critical

43
00:01:35,500 --> 00:01:37,260
0,400 420,755 755,1040 1040,1385 1385,1760
AI that exists {today.,And -}

44
00:01:37,260 --> 00:01:38,925
0,300 300,570 570,930 930,1190 1330,1665
really that stems from the

45
00:01:38,925 --> 00:01:39,810
0,240 240,405 405,540 540,705 705,885
fact that we want to

46
00:01:39,810 --> 00:01:40,850
0,210 210,405 405,540 540,720 720,1040
take all of these amazing

47
00:01:40,870 --> 00:01:42,015
0,470 470,605 605,785 785,950 950,1145
advances that you're learning as

48
00:01:42,015 --> 00:01:43,340
0,120 120,225 225,405 405,725 925,1325
part of this course and

49
00:01:43,360 --> 00:01:44,780
0,380 380,665 665,905 905,1130 1130,1420
actually achieve them in reality

50
00:01:45,160 --> 00:01:46,140
0,320 320,500 500,605 605,740 740,980
as part of our daily

51
00:01:46,140 --> 00:01:47,835
0,350 670,945 945,1125 1125,1365 1365,1695
lives and we're working together

52
00:01:47,835 --> 00:01:49,580
0,285 285,615 615,995 1195,1470 1470,1745
with leading global industry partners

53
00:01:49,690 --> 00:01:51,855
0,400 630,950 950,1205 1205,1760 1760,2165
across many different disciplines ranging

54
00:01:51,855 --> 00:01:54,105
0,240 240,755 1045,1755 1755,2010 2010,2250
from robotics, autonomy, health care

55
00:01:54,105 --> 00:01:55,275
0,180 180,450 450,765 765,990 990,1170
and more to develop a

56
00:01:55,275 --> 00:01:57,090
0,210 210,450 450,755 1375,1650 1650,1815
line of products that will

57
00:01:57,090 --> 00:01:59,060
0,290 460,810 810,1050 1050,1650 1650,1970
guarantee safe and trustworthy AI

58
00:01:59,440 --> 00:02:01,430
0,305 305,545 545,860 860,1240 1590,1990
and we drive this really

59
00:02:01,630 --> 00:02:03,500
0,400 420,820 1110,1385 1385,1565 1565,1870
eh deeply with our technical

60
00:02:03,670 --> 00:02:05,450
0,400 540,875 875,1100 1100,1385 1385,1780
engineering and machine learning team.|

61
00:02:05,900 --> 00:02:08,005
0,400 480,800 800,1120 1440,1790 1790,2105
And our focus is very

62
00:02:08,005 --> 00:02:10,135
0,365 595,870 870,1125 1125,1505 1765,2130
much on the engineering, very

63
00:02:10,135 --> 00:02:12,570
0,365 565,840 840,1065 1065,1655 2035,2435
flexible and very modular platforms

64
00:02:13,010 --> 00:02:14,940
0,305 305,610 660,1085 1085,1420 1530,1930
to scale algorithms towards robust

65
00:02:15,200 --> 00:02:17,650
0,400 450,1190 1190,1540 2010,2270 2270,2450
and trustworthy AI. {This,really -}

66
00:02:17,650 --> 00:02:20,575
0,440 640,1035 1035,1640 2140,2540 2590,2925
enables this deployment towards grand

67
00:02:20,575 --> 00:02:22,440
0,335 415,720 720,1025 1105,1485 1485,1865
challenges that our society faces

68
00:02:22,460 --> 00:02:24,670
0,365 365,665 665,1000 1350,1750 1920,2210
with AI {today.,Specifically -} the

69
00:02:24,670 --> 00:02:26,305
0,285 285,615 615,870 870,1190 1300,1635
ability for AI solutions today

70
00:02:26,305 --> 00:02:27,760
0,270 270,525 525,780 780,1350 1350,1455
are not very trustworthy at

71
00:02:27,760 --> 00:02:29,245
0,260 430,830 880,1170 1170,1335 1335,1485
all, even if they may

72
00:02:29,245 --> 00:02:30,400
0,150 150,330 330,600 600,915 915,1155
be very high performance on

73
00:02:30,400 --> 00:02:31,270
0,135 135,225 225,360 360,630 630,870
some of the tasks that

74
00:02:31,270 --> 00:02:32,080
0,165 165,360 360,540 540,690 690,810
we study as part of

75
00:02:32,080 --> 00:02:34,000
0,195 195,530 1030,1410 1410,1710 1710,1920
{this,course. -} So it's an

76
00:02:34,000 --> 00:02:36,715
0,380 550,945 945,1340 1750,2150 2200,2715
incredibly exciting time for themis

77
00:02:36,715 --> 00:02:38,455
0,285 285,600 600,900 900,1205 1435,1740
and specific right now where

78
00:02:38,455 --> 00:02:40,375
0,390 390,900 900,1335 1335,1620 1620,1920
VC {backed,we're -} located. Our

79
00:02:40,375 --> 00:02:41,485
0,300 300,540 540,765 765,945 945,1110
offices are right here in

80
00:02:41,485 --> 00:02:43,390
0,510 510,750 750,930 930,1175 1645,1905
Cambridge so we're local and

81
00:02:43,390 --> 00:02:44,740
0,120 120,345 345,660 660,1010 1030,1350
we have just closed around

82
00:02:44,740 --> 00:02:46,990
0,195 195,470 1180,1545 1545,1965 1965,2250
the funding so we're actively

83
00:02:46,990 --> 00:02:48,310
0,320 370,660 660,915 915,1155 1155,1320
hiring the best and the

84
00:02:48,310 --> 00:02:49,930
0,470 520,920 1000,1305 1305,1485 1485,1620
brightest engineers like all of

85
00:02:49,930 --> 00:02:51,820
0,260 910,1230 1230,1470 1470,1650 1650,1890
you to realize the future

86
00:02:51,820 --> 00:02:53,485
0,270 270,510 510,750 750,1335 1335,1665
of safe and trustworthy AI

87
00:02:53,485 --> 00:02:54,730
0,255 255,375 375,570 570,900 900,1245
and we hope that really

88
00:02:54,730 --> 00:02:56,970
0,435 435,630 630,1215 1215,1610 1840,2240
today's lecture inspires you to

89
00:02:56,990 --> 00:02:58,470
0,305 305,590 590,875 875,1130 1130,1480
join us on this mission

90
00:02:58,550 --> 00:02:59,665
0,275 275,485 485,680 680,860 860,1115
to build {the,future -} of

91
00:02:59,665 --> 00:03:01,420
0,255 255,435 435,585 585,875 1375,1755
AI. And with that it's

92
00:03:01,420 --> 00:03:02,965
0,150 150,375 375,710 910,1275 1275,1545
my {great,pleasure -} to introduce

93
00:03:02,965 --> 00:03:04,810
0,515 865,1350 1350,1455 1455,1635 1635,1845
SOA. SOA is a machine

94
00:03:04,810 --> 00:03:05,840
0,240 240,590
learning scientist.|

95
00:03:05,840 --> 00:03:08,570
0,120 120,560 1240,1790 2020,2420 2440,2730
At themis, she's also the

96
00:03:08,570 --> 00:03:10,060
0,240 240,590 670,945 945,1155 1155,1490
lead ta of this course,

97
00:03:10,170 --> 00:03:11,510
0,410 410,530 530,680 680,970 990,1340
intro to deep learning at

98
00:03:11,510 --> 00:03:13,430
0,350 700,975 975,1245 1245,1545 1545,1920
MIT. {Her,research -} at themis

99
00:03:13,430 --> 00:03:15,620
0,555 555,890 970,1275 1275,1580 1930,2190
focuses specifically on how we

100
00:03:15,620 --> 00:03:17,045
0,135 135,360 360,690 690,1215 1215,1425
can build very modular and

101
00:03:17,045 --> 00:03:19,430
0,305 385,785 1255,1655 1795,2145 2145,2385
flexible methods for AI and

102
00:03:19,430 --> 00:03:20,900
0,290 610,870 870,1080 1080,1305 1305,1470
building what we call a

103
00:03:20,900 --> 00:03:22,880
0,180 180,360 360,1005 1005,1370 1690,1980
safe and trustworthy {AI.,And -}

104
00:03:22,880 --> 00:03:23,900
0,240 240,480 480,585 585,780 780,1020
today she'll be teaching us

105
00:03:23,900 --> 00:03:25,955
0,255 255,590 730,1130 1300,1590 1590,2055
more about specifically the bias

106
00:03:25,955 --> 00:03:28,090
0,240 240,450 450,785 805,1445 1735,2135
and the uncertainty realms of

107
00:03:28,320 --> 00:03:30,410
0,400 420,940 1470,1730 1730,1865 1865,2090
AI algorithms, which are really

108
00:03:30,410 --> 00:03:32,500
0,350 490,885 885,1185 1185,1490 1690,2090
two key or critical components

109
00:03:32,550 --> 00:03:34,145
0,400 420,860 860,1085 1085,1370 1370,1595
towards achieving this mission or

110
00:03:34,145 --> 00:03:35,930
0,180 180,485 715,1115 1195,1545 1545,1785
this vision of safe and

111
00:03:35,930 --> 00:03:38,360
0,680 760,1340 1450,1800 1800,2130 2130,2430
trustworthy deployment of AI all

112
00:03:38,360 --> 00:03:40,220
0,225 225,530 1060,1440 1440,1710 1710,1860
{around,us. -} So thank you

113
00:03:40,220 --> 00:03:41,855
0,195 195,530 640,900 900,1160 1330,1635
and please give a big,

114
00:03:41,855 --> 00:03:43,370
0,305 535,810 810,975 975,1215 1215,1515
warm round of applause for

115
00:03:43,370 --> 00:03:44,860
0,380
s.|

116
00:03:48,040 --> 00:03:49,140
0,260 260,395 395,530 530,785 785,1100
Thank you so much, Alexander,

117
00:03:49,140 --> 00:03:51,540
0,165 165,240 240,470 1660,2040 2040,2400
for the introduction. {Hi,everyone. -}

118
00:03:51,540 --> 00:03:53,025
0,375 375,840 840,1110 1110,1275 1275,1485
I'm salina, I'm a machine

119
00:03:53,025 --> 00:03:54,840
0,225 225,575 865,1185 1185,1410 1410,1815
learning scientist here at themis

120
00:03:54,840 --> 00:03:56,715
0,350 730,1130 1210,1470 1470,1650 1650,1875
AI and the lead ta

121
00:03:56,715 --> 00:03:57,710
0,165 165,300 300,510 510,720 720,995
of the course this {year.,And

122
00:03:57,910 --> 00:03:59,385
0,275 275,545 545,920 920,1160 1160,1475
-} today I'm super excited

123
00:03:59,385 --> 00:04:00,290
0,210 210,390 390,540 540,645 645,905
to talk to you all

124
00:04:00,340 --> 00:04:02,415
0,400 600,980 980,1265 1265,1880 1880,2075
about robust and trustworthy deep

125
00:04:02,415 --> 00:04:04,010
0,305 355,690 690,960 960,1170 1170,1595
learning on behalf of themis.|

126
00:04:06,230 --> 00:04:07,830
0,400 480,815 815,1025 1025,1250 1250,1600
So over the past decade,

127
00:04:07,850 --> 00:04:09,595
0,395 395,650 650,950 950,1270 1380,1745
we've seen some tremendous growth

128
00:04:09,595 --> 00:04:11,635
0,345 345,690 690,1055 1315,1695 1695,2040
in artificial intelligence, across safety,

129
00:04:11,635 --> 00:04:13,825
0,315 315,785 1375,1650 1650,1815 1815,2190
critical domains, in the spheres

130
00:04:13,825 --> 00:04:15,820
0,180 180,780 780,975 975,1445 1705,1995
of autonomy and robotics. {We,now

131
00:04:15,820 --> 00:04:17,275
0,270 270,650 760,1110 1110,1320 1320,1455
-} have models that can

132
00:04:17,275 --> 00:04:18,670
0,195 195,515 535,930 930,1215 1215,1395
make critical decisions about things

133
00:04:18,670 --> 00:04:19,915
0,195 195,405 405,710 850,1110 1110,1245
like self driving at a

134
00:04:19,915 --> 00:04:21,610
0,405 405,665 1105,1380 1380,1530 1530,1695
second's notice, and these are

135
00:04:21,610 --> 00:04:22,750
0,330 330,450 450,660 660,915 915,1140
paving the way for fully

136
00:04:22,750 --> 00:04:25,285
0,570 570,860 910,1200 1200,1610 2260,2535
autonomous vehicles and robots, and

137
00:04:25,285 --> 00:04:26,370
0,225 225,360 360,555 555,765 765,1085
that's not where this stops

138
00:04:26,480 --> 00:04:27,780
0,260 260,410 410,800 800,1010 1010,1300
in the spheres of medicine

139
00:04:27,830 --> 00:04:29,740
0,275 275,550 1020,1505 1505,1685 1685,1910
and {healthcare.,Robots -} are now

140
00:04:29,740 --> 00:04:31,300
0,330 330,540 540,800 880,1230 1230,1560
equipped to conduct life {saving,surgery.

141
00:04:31,300 --> 00:04:33,400
0,380 880,1155 1155,1430 1450,1890 1890,2100
-} We have algorithms that

142
00:04:33,400 --> 00:04:35,130
0,270 270,855 855,1050 1050,1335 1335,1730
generate predictions for critical drugs

143
00:04:35,150 --> 00:04:36,535
0,275 275,485 485,770 770,1115 1115,1385
that may cure diseases that

144
00:04:36,535 --> 00:04:38,250
0,180 180,485 565,870 870,1035 1035,1715
we previously {thought,were -} incurable.

145
00:04:38,750 --> 00:04:40,075
0,395 395,650 650,800 800,1070 1070,1325
And we have models that

146
00:04:40,075 --> 00:04:42,295
0,275 325,725 745,1425 1425,1805 1855,2220
can automatically diagnose diseases without

147
00:04:42,295 --> 00:04:43,900
0,615 615,870 870,1080 1080,1350 1350,1605
intervention from any health {care,professionals

148
00:04:43,900 --> 00:04:46,615
0,510 510,690 690,950 1870,2235 2235,2715
-} at all. These advances

149
00:04:46,615 --> 00:04:48,160
0,180 180,960 960,1230 1230,1380 1380,1545
are revolutionary, and they have

150
00:04:48,160 --> 00:04:49,315
0,210 210,480 480,690 690,870 870,1155
the potential to change life

151
00:04:49,315 --> 00:04:50,190
0,240 240,375 375,480 480,600 600,875
as we know it today.|

152
00:04:51,550 --> 00:04:52,890
0,350 350,680 680,860 860,1130 1130,1340
But there's another question that

153
00:04:52,890 --> 00:04:53,895
0,120 120,270 270,405 405,650 730,1005
we need to ask, which

154
00:04:53,895 --> 00:04:55,485
0,275 565,885 885,1125 1125,1335 1335,1590
is where are these models

155
00:04:55,485 --> 00:04:57,045
0,240 240,420 420,725 1135,1410 1410,1560
in real life? A lot

156
00:04:57,045 --> 00:04:58,545
0,150 150,330 330,635 865,1110 1110,1500
of these technologies were innovated

157
00:04:58,545 --> 00:05:00,225
0,360 360,660 660,945 945,1325 1405,1680
five, ten years ago, but

158
00:05:00,225 --> 00:05:01,305
0,135 135,285 285,555 555,930 930,1080
you and I don't see

159
00:05:01,305 --> 00:05:02,300
0,165 165,300 300,435 435,660 660,995
them in our daily lives.

160
00:05:02,950 --> 00:05:04,500
0,400 570,860 860,1100 1100,1430 1430,1550
{So,what -} is, what's the

161
00:05:04,500 --> 00:05:06,240
0,210 210,540 540,915 915,1310 1360,1740
gap here between innovation and

162
00:05:06,240 --> 00:05:07,480
0,500
deployment?|

163
00:05:09,270 --> 00:05:10,340
0,260 260,485 485,785 785,965 965,1070
The reason why you and

164
00:05:10,340 --> 00:05:11,390
0,195 195,480 480,600 600,810 810,1050
I can't go by self

165
00:05:11,390 --> 00:05:13,210
0,285 285,650 730,1020 1020,1380 1380,1820
driving cars or robots don't

166
00:05:13,470 --> 00:05:15,280
0,400 540,875 875,1175 1175,1475 1475,1810
typically assist in operating rooms

167
00:05:15,330 --> 00:05:17,435
0,305 305,610 1320,1670 1670,1910 1910,2105
is this. {These,are -} some

168
00:05:17,435 --> 00:05:18,830
0,435 435,690 690,825 825,1185 1185,1395
headlines about the failures of

169
00:05:18,830 --> 00:05:20,015
0,315 315,570 570,675 675,915 915,1185
AI from the last few

170
00:05:20,015 --> 00:05:22,340
0,225 225,575 1435,1755 1755,2070 2070,2325
years {alone.,In -} addition to

171
00:05:22,340 --> 00:05:25,160
0,260 400,800 1510,2130 2130,2565 2565,2820
these incredible advances, we've also

172
00:05:25,160 --> 00:05:27,520
0,290 310,1125 1125,1640 1750,2055 2055,2360
seen catastrophic failures in every

173
00:05:27,540 --> 00:05:28,730
0,350 350,635 635,830 830,965 965,1190
single one of the safety

174
00:05:28,730 --> 00:05:30,160
0,285 285,690 690,930 930,1125 1125,1430
critical domains I {just,mentioned. -}

175
00:05:31,140 --> 00:05:32,975
0,335 335,670 720,1100 1100,1415 1415,1835
These problems range from crashing

176
00:05:32,975 --> 00:05:34,835
0,465 465,755 1105,1365 1365,1560 1560,1860
autonomous vehicles to health care

177
00:05:34,835 --> 00:05:36,395
0,435 435,615 615,990 990,1305 1305,1560
algorithms that don't actually work

178
00:05:36,395 --> 00:05:38,060
0,335 355,755 835,1170 1170,1380 1380,1665
for everyone, even though they're

179
00:05:38,060 --> 00:05:39,005
0,315 315,495 495,660 660,780 780,945
deployed out in the real

180
00:05:39,005 --> 00:05:40,295
0,305 355,720 720,975 975,1125 1125,1290
world so everyone can use

181
00:05:40,295 --> 00:05:41,000
0,305
them.|

182
00:05:41,790 --> 00:05:43,180
0,400 450,710 710,830 830,1040 1040,1390
Now, at a first glance,

183
00:05:43,380 --> 00:05:45,710
0,290 290,560 560,860 860,1480 1980,2330
this seems really demoralizing. {If,these

184
00:05:45,710 --> 00:05:46,520
0,225 225,390 390,570 570,705 705,810
-} are all of the

185
00:05:46,520 --> 00:05:47,950
0,180 180,435 435,735 735,1065 1065,1430
things wrong with artificial intelligence,

186
00:05:48,330 --> 00:05:49,340
0,275 275,410 410,560 560,785 785,1010
how are we ever going

187
00:05:49,340 --> 00:05:50,600
0,225 225,465 465,690 690,990 990,1260
to achieve that vision of

188
00:05:50,600 --> 00:05:52,370
0,290 310,690 690,1070 1180,1515 1515,1770
having our AI integrated into

189
00:05:52,370 --> 00:05:53,465
0,180 180,420 420,660 660,825 825,1095
the fabric of our daily

190
00:05:53,465 --> 00:05:55,145
0,365 625,945 945,1215 1215,1455 1455,1680
lives in terms of safety,

191
00:05:55,145 --> 00:05:58,490
0,335 355,905 2305,2655 2655,2910 2910,3345
critical deployment? But at themis,

192
00:05:58,490 --> 00:05:59,645
0,240 240,450 450,765 765,1005 1005,1155
this is exactly the type

193
00:05:59,645 --> 00:06:00,640
0,150 150,360 360,570 570,720 720,995
of problem that we {solve.,We

194
00:06:01,200 --> 00:06:02,540
0,380 380,710 710,920 920,1100 1100,1340
-} want to bring these

195
00:06:02,540 --> 00:06:03,770
0,480 480,645 645,765 765,945 945,1230
advances to the real world,

196
00:06:03,770 --> 00:06:04,610
0,255 255,375 375,525 525,705 705,840
and the way we do

197
00:06:04,610 --> 00:06:05,810
0,165 165,345 345,510 510,990 990,1200
this is by innovating in

198
00:06:05,810 --> 00:06:07,085
0,150 150,525 525,750 750,1020 1020,1275
the spheres of safe and

199
00:06:07,085 --> 00:06:09,380
0,675 675,1035 1035,1415 1765,2055 2055,2295
trustworthy artificial intelligence in order

200
00:06:09,380 --> 00:06:10,625
0,210 210,470 640,900 900,1065 1065,1245
to bring the things that

201
00:06:10,625 --> 00:06:11,825
0,165 165,390 390,585 585,825 825,1200
were developed in research labs

202
00:06:11,825 --> 00:06:13,060
0,180 180,345 345,605 685,960 960,1235
around the world to customers

203
00:06:13,350 --> 00:06:14,500
0,305 305,455 455,575 575,850
like you and me.|

204
00:06:16,450 --> 00:06:17,930
0,365 365,605 605,755 755,1030 1080,1480
And we do this by

205
00:06:18,100 --> 00:06:19,560
0,320 320,530 530,1145 1145,1295 1295,1460
our core ideology, is that

206
00:06:19,560 --> 00:06:20,670
0,225 225,480 480,720 720,945 945,1110
we believe that all of

207
00:06:20,670 --> 00:06:21,800
0,135 135,390 390,645 645,825 825,1130
the problems on this slide

208
00:06:21,820 --> 00:06:23,985
0,400 570,1175 1175,1445 1445,1810 1830,2165
are underlaid by two key

209
00:06:23,985 --> 00:06:26,270
0,545 775,1050 1050,1325 1465,1785 1785,2285
notions. {The,first -} is bias.|

210
00:06:27,110 --> 00:06:28,735
0,530 530,740 740,890 890,1150 1230,1625
Bias is what happens when

211
00:06:28,735 --> 00:06:30,040
0,255 255,435 435,755 775,1050 1050,1305
machine learning models do better

212
00:06:30,040 --> 00:06:31,650
0,300 300,510 510,1155 1155,1350 1350,1610
on some demographics than others.

213
00:06:32,390 --> 00:06:33,760
0,365 365,635 635,830 830,1070 1070,1370
{This,results -} in things like

214
00:06:33,760 --> 00:06:35,410
0,435 435,795 795,1070 1180,1485 1485,1650
facial detection systems, not being

215
00:06:35,410 --> 00:06:36,720
0,210 210,480 480,735 735,990 990,1310
able to detect certain faces

216
00:06:36,890 --> 00:06:39,325
0,380 380,755 755,1420 1800,2255 2255,2435
with high accuracy, Siri not

217
00:06:39,325 --> 00:06:40,620
0,165 165,345 345,525 525,785 895,1295
being able to recognize voices

218
00:06:40,640 --> 00:06:42,595
0,275 275,820 1020,1415 1415,1820 1820,1955
with accents, or algorithms that

219
00:06:42,595 --> 00:06:44,065
0,150 150,390 390,630 630,1215 1215,1470
are trained on imbalanced data

220
00:06:44,065 --> 00:06:45,670
0,335 445,720 720,885 885,1170 1170,1605
{sets.,So -} what the algorithm

221
00:06:45,670 --> 00:06:47,010
0,315 315,570 570,750 750,1005 1005,1340
believes is a good solution

222
00:06:47,450 --> 00:06:49,105
0,530 530,815 815,1055 1055,1370 1370,1655
doesn't actually work for everyone

223
00:06:49,105 --> 00:06:50,740
0,165 165,270 270,435 435,755
in the real world.|

224
00:06:52,030 --> 00:06:53,160
0,275 275,410 410,605 605,905 905,1130
And the second notion that

225
00:06:53,160 --> 00:06:54,165
0,405 405,555 555,675 675,825 825,1005
underlies a lot of these

226
00:06:54,165 --> 00:06:56,460
0,285 285,665 805,1200 1200,2025 2025,2295
problems today is unmitigated and

227
00:06:56,460 --> 00:06:59,370
0,860 1000,1400 2290,2565 2565,2715 2715,2910
uncommunicated uncertainty. {This,is -} when

228
00:06:59,370 --> 00:07:00,990
0,320 400,825 825,1100 1120,1410 1410,1620
models don't know when they

229
00:07:00,990 --> 00:07:02,450
0,300 300,615 615,975 975,1155 1155,1460
can or can't be {trusted.,And

230
00:07:03,160 --> 00:07:04,785
0,290 290,545 545,830 830,1040 1040,1625
-} this results in scenarios

231
00:07:04,785 --> 00:07:06,020
0,210 210,345 345,555 555,855 855,1235
such as self driving cars

232
00:07:06,190 --> 00:07:08,700
0,365 365,695 695,1010 1010,1360 1950,2510
continuing to operate in environments

233
00:07:08,700 --> 00:07:09,870
0,195 195,390 390,555 555,885 885,1170
when {they're,not - -} 100%

234
00:07:09,870 --> 00:07:11,550
0,350 640,885 885,1005 1005,1280 1360,1680
confident instead of giving control

235
00:07:11,550 --> 00:07:14,180
0,180 180,440 1270,1670 1750,2280 2280,2630
to users, or robots being

236
00:07:14,380 --> 00:07:15,870
0,365 365,635 635,875 875,1340 1340,1490
moving around in environments that

237
00:07:15,870 --> 00:07:16,790
0,180 180,345 345,540 540,660 660,920
they've never been in before

238
00:07:16,810 --> 00:07:18,590
0,260 260,455 455,695 695,1520 1520,1780
and have high unfamiliarity with.|

239
00:07:21,160 --> 00:07:22,125
0,350 350,560 560,695 695,830 830,965
And a lot of the

240
00:07:22,125 --> 00:07:24,180
0,275 505,905 985,1365 1365,1725 1725,2055
problems in modern day AI

241
00:07:24,180 --> 00:07:25,215
0,240 240,450 450,690 690,870 870,1035
are the result of a

242
00:07:25,215 --> 00:07:27,495
0,305 565,840 840,1485 1485,1965 1965,2280
combination of unmitigated bias and

243
00:07:27,495 --> 00:07:29,200
0,365
uncertainty.|

244
00:07:30,980 --> 00:07:32,550
0,395 395,790 840,1115 1115,1280 1280,1570
So today in this lecture,

245
00:07:32,750 --> 00:07:33,880
0,320 320,440 440,575 575,800 800,1130
we're going to focus on

246
00:07:33,880 --> 00:07:35,620
0,585 585,795 795,1020 1020,1370 1420,1740
investigating the root causes of

247
00:07:35,620 --> 00:07:37,120
0,210 210,375 375,555 555,860 1120,1500
all of these problems, these

248
00:07:37,120 --> 00:07:38,950
0,345 345,660 660,1010 1210,1530 1530,1830
two big challenges to robust

249
00:07:38,950 --> 00:07:41,050
0,270 270,560 1270,1680 1680,1890 1890,2100
deep learning. We'll also talk

250
00:07:41,050 --> 00:07:42,295
0,225 225,530 610,870 870,1050 1050,1245
about solutions for them that

251
00:07:42,295 --> 00:07:43,660
0,210 210,465 465,705 705,1185 1185,1365
can improve the robustness and

252
00:07:43,660 --> 00:07:45,000
0,290 460,750 750,930 930,1080 1080,1340
safety of all of these

253
00:07:45,050 --> 00:07:47,365
0,515 515,875 875,1270 1800,2090 2090,2315
algorithms for everyone. {And,we'll -}

254
00:07:47,365 --> 00:07:48,900
0,195 195,405 405,695 745,1035 1035,1535
start by talking about bias.|

255
00:07:50,280 --> 00:07:51,320
0,425 425,560 560,680 680,860 860,1040
Bias is a word that

256
00:07:51,320 --> 00:07:52,610
0,210 210,435 435,800 910,1170 1170,1290
we've all heard outside the

257
00:07:52,610 --> 00:07:54,125
0,255 255,525 525,690 690,980 1240,1515
context of deep learning, but

258
00:07:54,125 --> 00:07:55,250
0,150 150,300 300,570 570,900 900,1125
in the context of machine

259
00:07:55,250 --> 00:07:56,885
0,290 430,705 705,840 840,1020 1020,1635
learning, it can be quantified

260
00:07:56,885 --> 00:07:59,060
0,240 240,785 835,1235
and mathematically defined.|

261
00:07:59,130 --> 00:08:00,170
0,320 320,560 560,710 710,905 905,1040
Today we'll talk about how

262
00:08:00,170 --> 00:08:01,295
0,135 135,270 270,530 550,855 855,1125
to do this and methods

263
00:08:01,295 --> 00:08:02,950
0,240 240,735 735,1005 1005,1200 1200,1655
for mitigation of this bias

264
00:08:02,970 --> 00:08:05,030
0,910 990,1280 1280,1505 1505,1880 1880,2060
algorithmically and how themus is

265
00:08:05,030 --> 00:08:06,455
0,465 465,660 660,810 810,1100 1180,1425
innovating in these areas in

266
00:08:06,455 --> 00:08:07,760
0,165 165,330 330,495 495,815 895,1305
order to bring new algorithms

267
00:08:07,760 --> 00:08:10,445
0,135 135,330 330,680 880,1280 2350,2685
in this space to industries

268
00:08:10,445 --> 00:08:12,200
0,225 225,375 375,635
around the world.|

269
00:08:12,240 --> 00:08:14,080
0,400 630,935 935,1115 1115,1445 1445,1840
Afterwards, we'll talk about uncertainty,

270
00:08:14,460 --> 00:08:15,800
0,275 275,550 690,965 965,1145 1145,1340
which is can we teach

271
00:08:15,800 --> 00:08:17,015
0,165 165,435 435,750 750,960 960,1215
a model when it does

272
00:08:17,015 --> 00:08:18,190
0,240 240,570 570,765 765,915 915,1175
or doesn't know the answer

273
00:08:18,300 --> 00:08:19,750
0,400 510,740 740,860 860,1100 1100,1450
to to its given task?

274
00:08:20,100 --> 00:08:21,095
0,260 260,425 425,590 590,800 800,995
And we'll talk about the

275
00:08:21,095 --> 00:08:22,940
0,675 675,915 915,1175 1375,1650 1650,1845
ramifications for this for real

276
00:08:22,940 --> 00:08:24,780
0,320 370,770
world AI.|

277
00:08:27,900 --> 00:08:29,900
0,400 630,980 980,1325 1325,1610 1610,2000
So what exactly does bias

278
00:08:29,900 --> 00:08:31,295
0,320 580,885 885,1095 1095,1260 1260,1395
mean, and where is it

279
00:08:31,295 --> 00:08:32,645
0,240 240,465 465,675 675,990 990,1350
present in the artificial intelligence

280
00:08:32,645 --> 00:08:34,860
0,785
lifecycle?|

281
00:08:34,860 --> 00:08:36,165
0,135 135,300 300,915 915,1125 1125,1305
The most intuitive form of

282
00:08:36,165 --> 00:08:38,535
0,455 505,870 870,1140 1140,1445 2095,2370
bias comes from data. {We,have

283
00:08:38,535 --> 00:08:39,780
0,240 240,495 495,780 780,1050 1050,1245
-} two different two main

284
00:08:39,780 --> 00:08:41,205
0,225 225,390 390,705 705,1010 1150,1425
types of bias {here.,The -}

285
00:08:41,205 --> 00:08:43,290
0,275 325,660 660,1125 1125,1595 1825,2085
first is sampling bias, which

286
00:08:43,290 --> 00:08:44,535
0,150 150,375 375,600 600,870 870,1245
is when we over sample

287
00:08:44,535 --> 00:08:45,840
0,300 300,525 525,840 840,1080 1080,1305
from some regions of our

288
00:08:45,840 --> 00:08:47,700
0,255 255,530 550,950 1330,1620 1620,1860
input, data distribution and under

289
00:08:47,700 --> 00:08:49,500
0,330 330,585 585,860 1360,1620 1620,1800
sample {from,others. -} A good

290
00:08:49,500 --> 00:08:50,505
0,255 255,450 450,675 675,900 900,1005
example of this is a

291
00:08:50,505 --> 00:08:51,710
0,120 120,285 285,555 555,870 870,1205
lot of clinical data sets,

292
00:08:51,940 --> 00:08:53,835
0,400 600,890 890,1180 1260,1580 1580,1895
where they often contain fewer

293
00:08:53,835 --> 00:08:56,145
0,395 505,905 1135,1605 1605,1955 2035,2310
examples of diseased patients than

294
00:08:56,145 --> 00:08:57,585
0,240 240,605 745,1005 1005,1230 1230,1440
healthy patients because it's much

295
00:08:57,585 --> 00:08:59,265
0,330 330,630 630,915 915,1265 1435,1680
easier to acquire data for

296
00:08:59,265 --> 00:09:00,600
0,195 195,545 625,900 900,1095 1095,1335
healthy patients than their disease

297
00:09:00,600 --> 00:09:02,040
0,680
counterparts.|

298
00:09:02,610 --> 00:09:04,130
0,305 305,610 720,1070 1070,1280 1280,1520
In addition, we also have

299
00:09:04,130 --> 00:09:05,540
0,360 360,840 840,1065 1065,1200 1200,1410
selection bias at the data

300
00:09:05,540 --> 00:09:06,755
0,350 370,630 630,810 810,1020 1020,1215
portion of the AI life

301
00:09:06,755 --> 00:09:09,340
0,305 1105,1425 1425,1680 1680,2295 2295,2585
cycle. {Think,about -} Apple's series

302
00:09:09,390 --> 00:09:12,220
0,320 320,640 960,1540 2190,2510 2510,2830
voice recognition {algorithm.,This -} model

303
00:09:12,540 --> 00:09:14,420
0,320 320,590 590,940 1020,1385 1385,1880
is trained largely on flawless

304
00:09:14,420 --> 00:09:16,535
0,350 460,860 1180,1485 1485,1800 1800,2115
American English, but it's deployed

305
00:09:16,535 --> 00:09:17,675
0,225 225,420 420,615 615,915 915,1140
across the real world to

306
00:09:17,675 --> 00:09:18,880
0,90 90,255 255,420 420,665 805,1205
be able to recognize voices

307
00:09:18,900 --> 00:09:20,345
0,290 290,785 785,995 995,1190 1190,1445
with accents from all over

308
00:09:20,345 --> 00:09:21,260
0,180 180,425
the world.|

309
00:09:21,850 --> 00:09:23,505
0,365 365,730 870,1145 1145,1280 1280,1655
The distribution of the model's

310
00:09:23,505 --> 00:09:25,320
0,210 210,545 625,1095 1095,1415 1435,1815
training data doesn't match the

311
00:09:25,320 --> 00:09:26,630
0,380 430,705 705,870 870,1035 1035,1310
distribution of this type of

312
00:09:27,070 --> 00:09:28,250
0,350 350,545 545,665 665,860 860,1180
language in the real world,

313
00:09:28,570 --> 00:09:30,195
0,350 350,700 780,1100 1100,1340 1340,1625
because American English is highly

314
00:09:30,195 --> 00:09:32,040
0,845 985,1320 1320,1560 1560,1695 1695,1845
overrepresented, as opposed to other

315
00:09:32,040 --> 00:09:33,900
0,740
demographics.|

316
00:09:35,070 --> 00:09:36,920
0,320 320,620 620,800 800,1120 1500,1850
But that's not where, that's

317
00:09:36,920 --> 00:09:37,955
0,105 105,270 270,630 630,780 780,1035
not where bias and data

318
00:09:37,955 --> 00:09:40,745
0,395 1045,1365 1365,2010 2010,2375 2485,2790
stops. {These,biases -} can be

319
00:09:40,745 --> 00:09:42,875
0,570 570,900 900,1265 1285,1635 1635,2130
propagated towards models, training cycles

320
00:09:42,875 --> 00:09:44,105
0,395 565,825 825,945 945,1065 1065,1230
themselves, which is what we'll

321
00:09:44,105 --> 00:09:45,035
0,195 195,450 450,600 600,720 720,930
focus on in the second

322
00:09:45,035 --> 00:09:47,140
0,270 270,465 465,600 600,875
half of this lecture.|

323
00:09:48,130 --> 00:09:49,440
0,260 260,520 600,935 935,1130 1130,1310
And then once the model

324
00:09:49,440 --> 00:09:51,195
0,320 400,800 850,1320 1320,1545 1545,1755
is actually deployed, which means

325
00:09:51,195 --> 00:09:52,350
0,330 330,600 600,780 780,960 960,1155
it's actually put out into

326
00:09:52,350 --> 00:09:53,450
0,165 165,345 345,585 585,810 810,1100
the real world and customers

327
00:09:53,590 --> 00:09:55,245
0,275 275,550 570,950 950,1330 1350,1655
or users can actually get

328
00:09:55,245 --> 00:09:56,835
0,165 165,555 555,720 720,995 1315,1590
the predictions from it, we

329
00:09:56,835 --> 00:09:59,805
0,240 240,605 1435,1770 1770,2295 2295,2970
may see further biases perpetuated

330
00:09:59,805 --> 00:10:00,980
0,240 240,390 390,690 690,885 885,1175
that we haven't seen before.

331
00:10:01,630 --> 00:10:02,805
0,260 260,440 440,620 620,830 830,1175
{The,first -} of these is

332
00:10:02,805 --> 00:10:05,055
0,395 475,1055 1525,1905 1905,2070 2070,2250
distribution shifts. Let's say I

333
00:10:05,055 --> 00:10:06,270
0,135 135,255 255,515 565,930 930,1215
have a model that I

334
00:10:06,270 --> 00:10:07,560
0,270 270,585 585,825 825,1050 1050,1290
trained on the past twenty

335
00:10:07,560 --> 00:10:08,985
0,195 195,360 360,620 970,1245 1245,1425
years of data, and then

336
00:10:08,985 --> 00:10:09,900
0,240 240,450 450,585 585,750 750,915
I deploy it into the

337
00:10:09,900 --> 00:10:11,990
0,150 150,440 910,1215 1215,1740 1740,2090
real world {{in,-} -} 2023.

338
00:10:12,100 --> 00:10:13,410
0,290 290,500 500,695 695,970 1020,1310
This model will probably do

339
00:10:13,410 --> 00:10:14,895
0,290 430,690 690,810 810,1070 1120,1485
fine because the data input

340
00:10:14,895 --> 00:10:16,605
0,365 445,765 765,1035 1035,1385 1465,1710
distribution is quite similar to

341
00:10:16,605 --> 00:10:17,900
0,210 210,480 480,645 645,900 900,1295
data in the training distribution.|

342
00:10:18,900 --> 00:10:20,025
0,320 340,615 615,750 750,945 945,1125
But what would happen to

343
00:10:20,025 --> 00:10:22,650
0,135 135,405 405,735 735,2370 2370,2625
this model in {2033,it,} it

344
00:10:22,650 --> 00:10:24,360
0,290 310,600 600,890 1000,1395 1395,1710
probably would not work as

345
00:10:24,360 --> 00:10:26,250
0,320 700,1020 1020,1290 1290,1635 1635,1890
well because the distribution that

346
00:10:26,250 --> 00:10:27,150
0,105 105,255 255,450 450,675 675,900
the data is coming from

347
00:10:27,150 --> 00:10:29,355
0,210 210,530 550,950 1630,1965 1965,2205
would shift significantly across this

348
00:10:29,355 --> 00:10:30,705
0,305 565,825 825,945 945,1065 1065,1350
decade. {And,if -} we don't

349
00:10:30,705 --> 00:10:31,875
0,240 240,525 525,735 735,885 885,1170
continue to update our models

350
00:10:31,875 --> 00:10:33,405
0,255 255,515 925,1230 1230,1395 1395,1530
with this input stream of

351
00:10:33,405 --> 00:10:34,545
0,275 475,780 780,870 870,990 990,1140
data, we're going to have

352
00:10:34,545 --> 00:10:37,480
0,630 630,855 855,1365 1365,1985
obsolete and incorrect predictions.|

353
00:10:38,510 --> 00:10:40,690
0,290 290,580 780,1180 1290,1805 1805,2180
And finally, after deployment there,

354
00:10:40,690 --> 00:10:43,390
0,195 195,800 1000,1400 1780,2180 2380,2700
the evaluation aspect. {So,think -}

355
00:10:43,390 --> 00:10:44,920
0,300 300,600 600,840 840,1125 1125,1530
back to the Apple Siri

356
00:10:44,920 --> 00:10:45,985
0,255 255,450 450,645 645,780 780,1065
example that we've been talking

357
00:10:45,985 --> 00:10:48,715
0,395 835,1235 1645,1980 1980,2205 2205,2730
{about.,EM, -} if the evaluation

358
00:10:48,715 --> 00:10:50,290
0,495 495,720 720,870 870,1275 1275,1575
metric or the evaluation data

359
00:10:50,290 --> 00:10:51,685
0,240 240,450 450,780 780,945 945,1395
set that Siri was evaluated

360
00:10:51,685 --> 00:10:53,725
0,305 475,875 925,1215 1215,1500 1500,2040
on was also mostly comprised

361
00:10:53,725 --> 00:10:56,610
0,360 360,725 805,1205 1525,1925 2485,2885
of American English, then to

362
00:10:56,630 --> 00:10:57,955
0,380 380,650 650,935 935,1190 1190,1325
anybody this model will look

363
00:10:57,955 --> 00:10:59,160
0,135 135,255 255,495 495,840 840,1205
like it does extremely well,

364
00:10:59,330 --> 00:11:00,790
0,290 290,440 440,650 650,1000 1200,1460
right? It can detect, it,

365
00:11:00,790 --> 00:11:02,440
0,165 165,470 700,1095 1095,1380 1380,1650
can recognize American English voices

366
00:11:02,440 --> 00:11:04,495
0,345 345,660 660,1005 1005,1610 1690,2055
with extremely high accuracy and

367
00:11:04,495 --> 00:11:05,650
0,255 255,495 495,825 825,990 990,1155
therefore is deployed into the

368
00:11:05,650 --> 00:11:07,300
0,165 165,470 940,1200 1200,1365 1365,1650
{real,world. -} But what about

369
00:11:07,300 --> 00:11:09,340
0,375 375,855 855,1050 1050,1710 1710,2040
its accuracy on subgroups, on

370
00:11:09,340 --> 00:11:11,400
0,570 570,920 1060,1395 1395,1695 1695,2060
accented voices, on people who

371
00:11:11,780 --> 00:11:12,790
0,275 275,500 500,725 725,860 860,1010
for whom English is not

372
00:11:12,790 --> 00:11:14,320
0,165 165,345 345,650 1090,1365 1365,1530
their first language? If we

373
00:11:14,320 --> 00:11:15,985
0,405 405,705 705,945 945,1170 1170,1665
don't also test on subgroups

374
00:11:15,985 --> 00:11:17,680
0,120 120,270 270,795 795,1145 1405,1695
in our evaluation metrics, we're

375
00:11:17,680 --> 00:11:20,340
0,120 120,270 270,1125 1125,1640
going to faceation bias.|

376
00:11:20,640 --> 00:11:22,115
0,260 260,520 690,1055 1055,1235 1235,1475
So now let's talk about

377
00:11:22,115 --> 00:11:23,240
0,270 270,615 615,855 855,960 960,1125
another example in the real

378
00:11:23,240 --> 00:11:24,530
0,300 300,570 570,765 765,1125 1125,1290
world of how bias can

379
00:11:24,530 --> 00:11:26,120
0,615 615,900 900,1125 1125,1365 1365,1590
perpetuate throughout the course of

380
00:11:26,120 --> 00:11:27,640
0,240 240,585 585,930 930,1215 1215,1520
this artificial intelligence life cycle.|

381
00:11:30,310 --> 00:11:32,240
0,395 395,845 845,1220 1220,1510 1530,1930
Commercial facial detection systems are

382
00:11:32,320 --> 00:11:34,095
0,400 570,970 1080,1370 1370,1565 1565,1775
everywhere. {You,actually -} played around

383
00:11:34,095 --> 00:11:35,150
0,195 195,360 360,495 495,705 705,1055
with some of them in

384
00:11:35,410 --> 00:11:36,795
0,365 365,680 680,875 875,1085 1085,1385
lab two when you trained

385
00:11:36,795 --> 00:11:38,580
0,225 225,515 865,1200 1200,1425 1425,1785
your v on a facial

386
00:11:38,580 --> 00:11:40,520
0,330 330,525 525,860
detection data set.|

387
00:11:40,520 --> 00:11:41,690
0,165 165,470 490,795 795,945 945,1170
In addition to the lock

388
00:11:41,690 --> 00:11:42,820
0,300 300,450 450,615 615,825 825,1130
screens on your cell phones,

389
00:11:44,040 --> 00:11:45,695
0,455 455,785 785,1040 1040,1400 1400,1655
facial detection systems are also

390
00:11:45,695 --> 00:11:47,350
0,255 255,510 510,780 780,1110 1110,1655
present in the automatic filters

391
00:11:47,370 --> 00:11:48,650
0,260 260,395 395,590 590,910 930,1280
that your phone cameras apply

392
00:11:48,650 --> 00:11:49,445
0,240 240,420 420,570 570,690 690,795
whenever you try to take

393
00:11:49,445 --> 00:11:51,140
0,105 105,365 985,1335 1335,1515 1515,1695
a picture, and {they're -}

394
00:11:51,140 --> 00:11:52,840
0,225 225,435 435,690 690,1005 1005,1700
also used in criminal investigations.|

395
00:11:54,120 --> 00:11:55,985
0,365 365,680 680,1025 1025,1400 1400,1865
These are three commercial facial

396
00:11:55,985 --> 00:11:57,700
0,345 345,635 655,930 930,1170 1170,1715
detection systems that were deployed,

397
00:11:57,780 --> 00:12:00,215
0,400 1110,1445 1445,1835 1835,1985 1985,2435
and we'll analyze the biases

398
00:12:00,215 --> 00:12:01,010
0,150 150,285 285,405 405,555 555,795
that might have been present

399
00:12:01,010 --> 00:12:02,510
0,225 225,390 390,555 555,830 1150,1500
in all of them for

400
00:12:02,510 --> 00:12:03,670
0,330 330,555 555,720 720,900 900,1160
in the next few minutes.|

401
00:12:05,730 --> 00:12:06,770
0,350 350,560 560,725 725,905 905,1040
So the first thing you

402
00:12:06,770 --> 00:12:07,775
0,135 135,390 390,645 645,825 825,1005
may notice is that there

403
00:12:07,775 --> 00:12:09,700
0,150 150,420 420,815 1165,1665 1665,1925
is a huge accuracy gap

404
00:12:09,900 --> 00:12:11,885
0,350 350,605 605,860 860,1600 1710,1985
between two different demographics in

405
00:12:11,885 --> 00:12:14,520
0,275 1135,1535
this plot.|

406
00:12:14,520 --> 00:12:16,050
0,380 430,885 885,1080 1080,1320 1320,1530
This accuracy gap can get

407
00:12:16,050 --> 00:12:18,255
0,240 240,480 480,1095 1095,1400 1930,2205
up to {{34%.,-} -} Keep

408
00:12:18,255 --> 00:12:20,145
0,150 150,425 445,845 865,1265 1435,1890
in mind that this facial

409
00:12:20,145 --> 00:12:21,770
0,360 360,495 495,645 645,1050 1050,1625
detection is a {binary,classification -}

410
00:12:21,820 --> 00:12:23,400
0,400 900,1145 1145,1265 1265,1430 1430,1580
task. Everything is either a

411
00:12:23,400 --> 00:12:24,390
0,260 280,540 540,720 720,855 855,990
face or {it's,not -} a

412
00:12:24,390 --> 00:12:26,220
0,260 850,1155 1155,1395 1395,1620 1620,1830
face. This means that a

413
00:12:26,220 --> 00:12:28,260
0,570 570,1035 1035,1370 1570,1830 1830,2040
randomly initialized model would be

414
00:12:28,260 --> 00:12:29,730
0,270 270,450 450,675 675,1020 1020,1470
expected {to,have -} an accuracy

415
00:12:29,730 --> 00:12:31,815
0,180 180,800 1540,1800 1800,1965 1965,2085
of 50% because it's going

416
00:12:31,815 --> 00:12:33,015
0,120 120,585 585,825 825,1050 1050,1200
to randomly assign whether or

417
00:12:33,015 --> 00:12:33,825
0,150 150,375 375,525 525,615 615,810
not something is a face

418
00:12:33,825 --> 00:12:34,860
0,195 195,455
or not.|

419
00:12:35,150 --> 00:12:36,415
0,275 275,410 410,560 560,920 920,1265
Some of these facial detection

420
00:12:36,415 --> 00:12:38,680
0,545 745,1065 1065,1385 1465,1865 1915,2265
classifiers do only barely better

421
00:12:38,680 --> 00:12:40,890
0,255 255,560 610,1010 1150,1425 1425,2210
than random on these underrepresented

422
00:12:41,420 --> 00:12:43,435
0,400 450,710 710,830 830,1490 1490,2015
data on these underrepresented samples

423
00:12:43,435 --> 00:12:46,520
0,365 955,1245 1245,1535
in this population.|

424
00:12:46,850 --> 00:12:48,240
0,400 540,815 815,950 950,1100 1100,1390
So how did this happen?

425
00:12:48,620 --> 00:12:49,600
0,320 320,515 515,680 680,830 830,980
Why is there such a

426
00:12:49,600 --> 00:12:51,535
0,360 360,540 540,810 810,1430 1660,1935
blatant gap in accuracy between

427
00:12:51,535 --> 00:12:53,515
0,150 150,360 360,1005 1005,1295 1675,1980
these different demographic groups? And

428
00:12:53,515 --> 00:12:55,075
0,180 180,300 300,545 835,1230 1230,1560
how did these models ever

429
00:12:55,075 --> 00:12:56,140
0,285 285,645 645,780 780,870 870,1065
get deployed in the first

430
00:12:56,140 --> 00:12:58,270
0,350 820,1155 1155,1410 1410,1590 1590,2130
place? What types of biases

431
00:12:58,270 --> 00:12:59,610
0,270 270,560 640,900 900,1050 1050,1340
were present in these models?|

432
00:13:01,310 --> 00:13:02,755
0,400 570,830 830,950 950,1070 1070,1445
So a lot of facial

433
00:13:02,755 --> 00:13:04,825
0,360 360,635 925,1365 1365,1680 1680,2070
detection systems exhibit very clear

434
00:13:04,825 --> 00:13:06,940
0,375 375,935 1225,1530 1530,1830 1830,2115
selection bias. {This,model -} was

435
00:13:06,940 --> 00:13:08,695
0,285 285,660 660,1040 1120,1410 1410,1755
likely trained mostly on lighter

436
00:13:08,695 --> 00:13:10,900
0,210 210,515 865,1265 1315,1715 1855,2205
skin faces and therefore EM

437
00:13:10,900 --> 00:13:12,240
0,300 300,600 600,855 855,1050 1050,1340
learned those much more effectively

438
00:13:12,290 --> 00:13:13,405
0,230 230,335 335,500 500,650 650,1115
than it learned to classify

439
00:13:13,405 --> 00:13:15,505
0,345 345,525 525,815 1615,1875 1875,2100
darker skin {faces.,But -} that's

440
00:13:15,505 --> 00:13:16,480
0,150 150,300 300,480 480,840 840,975
not the only bias that

441
00:13:16,480 --> 00:13:18,460
0,150 150,440 1120,1380 1380,1590 1590,1980
{was,present. -} The second bias

442
00:13:18,460 --> 00:13:21,220
0,225 225,470 550,950 2080,2445 2445,2760
that's often EM very present

443
00:13:21,220 --> 00:13:22,945
0,300 300,705 705,1035 1035,1310 1390,1725
in facial detection systems is

444
00:13:22,945 --> 00:13:26,695
0,585 585,1145 1585,1985 2395,2795 3415,3750
evaluation bias because originally this

445
00:13:26,695 --> 00:13:27,535
0,270 270,465 465,585 585,720 720,840
data set that you see

446
00:13:27,535 --> 00:13:28,435
0,90 90,240 240,480 480,705 705,900
on the screen is not

447
00:13:28,435 --> 00:13:29,260
0,165 165,345 345,540 540,675 675,825
the data set that these

448
00:13:29,260 --> 00:13:31,060
0,255 255,510 510,945 945,1250 1540,1800
models {were,evaluated -} on. They

449
00:13:31,060 --> 00:13:32,875
0,150 150,660 660,960 960,1310 1420,1815
were evaluated on one big

450
00:13:32,875 --> 00:13:34,710
0,360 360,720 720,995 1105,1470 1470,1835
bulk dataas set without any

451
00:13:34,970 --> 00:13:36,810
0,590 590,890 890,1430 1430,1565 1565,1840
classification {into,subgroups -} at all.

452
00:13:37,130 --> 00:13:38,550
0,400 420,770 770,980 980,1130 1130,1420
And therefore you can imagine

453
00:13:38,570 --> 00:13:39,820
0,290 290,425 425,770 770,1010 1010,1250
if the dataset was also

454
00:13:39,820 --> 00:13:41,260
0,300 300,620 640,915 915,1230 1230,1440
comprised mostly of lighter skinned

455
00:13:41,260 --> 00:13:43,270
0,260 640,1040 1060,1530 1530,1770 1770,2010
faces, these accuracy metrics would

456
00:13:43,270 --> 00:13:45,100
0,195 195,495 495,1070 1120,1520 1540,1830
be incredibly inflated and therefore

457
00:13:45,100 --> 00:13:47,260
0,195 195,450 450,1185 1185,1520 1870,2160
would cause unnecessary confidence and

458
00:13:47,260 --> 00:13:48,325
0,135 135,345 345,615 615,825 825,1065
we could deploy them into

459
00:13:48,325 --> 00:13:49,960
0,195 195,375 375,695
the real world.|

460
00:13:50,660 --> 00:13:52,180
0,305 305,610 630,890 890,1370 1370,1520
In fact, the biases in

461
00:13:52,180 --> 00:13:53,845
0,165 165,450 450,705 705,945 945,1665
these models were only uncovered

462
00:13:53,845 --> 00:13:55,860
0,270 270,605 685,1065 1065,1445 1615,2015
once an independent study actually

463
00:13:55,940 --> 00:13:57,430
0,455 455,605 605,815 815,1150 1230,1490
constructed a data set that

464
00:13:57,430 --> 00:14:00,085
0,180 180,500 790,1190 1510,1910 2080,2655
is specifically designed to uncover

465
00:14:00,085 --> 00:14:01,255
0,135 135,315 315,480 480,975 975,1170
these sorts of biases by

466
00:14:01,255 --> 00:14:03,060
0,600 600,915 915,1230 1230,1500 1500,1805
balancing across race and gender.|

467
00:14:04,810 --> 00:14:06,030
0,380 380,620 620,740 740,950 950,1220
However, there are other ways

468
00:14:06,030 --> 00:14:07,275
0,320 400,720 720,945 945,1110 1110,1245
that data sets can be

469
00:14:07,275 --> 00:14:08,160
0,345 345,510 510,630 630,765 765,885
biased that we {haven't -}

470
00:14:08,160 --> 00:14:10,080
0,180 180,450 450,800
yet talked about.|

471
00:14:11,060 --> 00:14:12,990
0,400 420,725 725,995 995,1385 1385,1930
So, so far we've assumed

472
00:14:13,370 --> 00:14:14,800
0,380 380,695 695,920 920,1325 1325,1430
a pretty key assumption in

473
00:14:14,800 --> 00:14:15,760
0,120 120,330 330,600 600,810 810,960
our data set, which is

474
00:14:15,760 --> 00:14:16,720
0,210 210,375 375,540 540,735 735,960
that the number of faces

475
00:14:16,720 --> 00:14:18,010
0,195 195,315 315,590 850,1125 1125,1290
in our data is the

476
00:14:18,010 --> 00:14:19,045
0,225 225,510 510,720 720,825 825,1035
exact same as the number

477
00:14:19,045 --> 00:14:20,035
0,255 255,450 450,690 690,870 870,990
of non faces in our

478
00:14:20,035 --> 00:14:21,600
0,275 745,1005 1005,1125 1125,1275 1275,1565
data. {But,you -} can imagine,

479
00:14:21,680 --> 00:14:22,645
0,320 320,485 485,680 680,800 800,965
especially if you're looking at

480
00:14:22,645 --> 00:14:24,160
0,165 165,420 420,750 750,1245 1245,1515
things like security feeds, this

481
00:14:24,160 --> 00:14:24,970
0,165 165,360 360,570 570,705 705,810
might not always be the

482
00:14:24,970 --> 00:14:26,365
0,260 580,855 855,1035 1035,1200 1200,1395
{case.,You -} might be faced

483
00:14:26,365 --> 00:14:27,970
0,240 240,480 480,750 750,1080 1080,1605
with many more negative samples

484
00:14:27,970 --> 00:14:29,350
0,225 225,525 525,1065 1065,1245 1245,1380
than positive samples in your

485
00:14:29,350 --> 00:14:30,860
0,210 210,530
data set.|

486
00:14:31,470 --> 00:14:32,825
0,275 275,395 395,640 690,950 950,1355
In the most so, what's

487
00:14:32,825 --> 00:14:34,655
0,120 120,390 390,785 1435,1710 1710,1830
the problem here? In the

488
00:14:34,655 --> 00:14:36,245
0,245 295,630 630,965 1105,1380 1380,1590
most extreme case, we may

489
00:14:36,245 --> 00:14:38,020
0,255 255,435 435,695 1015,1395 1395,1775
assign the label non face

490
00:14:38,220 --> 00:14:39,155
0,260 260,440 440,680 680,845 845,935
to every item in the

491
00:14:39,155 --> 00:14:40,805
0,180 180,515 985,1260 1260,1395 1395,1650
data set, because the model

492
00:14:40,805 --> 00:14:42,155
0,315 315,635 655,915 915,1050 1050,1350
sees items that are labeled

493
00:14:42,155 --> 00:14:44,165
0,180 180,485 625,960 960,1800 1800,2010
as faces so infrequently that

494
00:14:44,165 --> 00:14:45,220
0,105 105,345 345,555 555,780 780,1055
it isn't able to learn

495
00:14:45,930 --> 00:14:47,945
0,380 380,695 695,1030 1200,1790 1790,2015
an accurate class boundary between

496
00:14:47,945 --> 00:14:49,010
0,165 165,345 345,635 685,945 945,1065
the two Sam between the

497
00:14:49,010 --> 00:14:50,680
0,135 135,410
two classes.|

498
00:14:52,490 --> 00:14:54,040
0,400 690,965 965,1085 1085,1190 1190,1550
So how can we mitigate

499
00:14:54,040 --> 00:14:54,955
0,240 240,450 450,555 555,675 675,915
this? This is a really

500
00:14:54,955 --> 00:14:56,200
0,300 300,615 615,840 840,1020 1020,1245
big problem and it's very

501
00:14:56,200 --> 00:14:57,580
0,380 490,855 855,1080 1080,1230 1230,1380
common across a lot of

502
00:14:57,580 --> 00:14:58,660
0,195 195,435 435,660 660,855 855,1080
different types of machine learning

503
00:14:58,660 --> 00:15:00,840
0,350 400,660 660,840 840,1160 1780,2180
tasks and data sets. {And,the

504
00:15:01,040 --> 00:15:01,900
0,260 260,440 440,620 620,740 740,860
-} first way that we

505
00:15:01,900 --> 00:15:02,980
0,120 120,360 360,600 600,705 705,1080
can EM try to mitigate

506
00:15:02,980 --> 00:15:04,735
0,225 225,780 780,1020 1020,1310 1360,1755
class imbalance is using {sample

507
00:15:04,735 --> 00:15:06,360
0,255 255,695 925,1185 1185,1335 1335,1625
-} re-weighting which is when

508
00:15:06,410 --> 00:15:08,290
0,275 275,550 660,1100 1100,1625 1625,1880
instead of uniformly sampling from

509
00:15:08,290 --> 00:15:09,280
0,150 150,390 390,660 660,855 855,990
our data set at a

510
00:15:09,280 --> 00:15:11,010
0,195 195,530 790,1140 1140,1410 1410,1730
rate EM, we instead sample

511
00:15:11,060 --> 00:15:11,905
0,260 260,380 380,545 545,710 710,845
at a rate that is

512
00:15:11,905 --> 00:15:13,855
0,570 570,1215 1215,1410 1410,1515 1515,1950
inversely proportional to the incidence

513
00:15:13,855 --> 00:15:14,785
0,240 240,360 360,600 600,810 810,930
of a class in {our,data

514
00:15:14,785 --> 00:15:16,585
0,195 195,515 1135,1470 1470,1680 1680,1800
-} set. So in the

515
00:15:16,585 --> 00:15:18,580
0,245 355,755 1045,1380 1380,1695 1695,1995
previous example, if EM the

516
00:15:18,580 --> 00:15:20,430
0,645 645,975 975,1290 1290,1560 1560,1850
likelihood if faces were much,

517
00:15:21,020 --> 00:15:21,960
0,260 260,365 365,500 500,665 665,940
if the number of faces

518
00:15:22,130 --> 00:15:23,260
0,305 305,545 545,830 830,1040 1040,1130
was much lower than the

519
00:15:23,260 --> 00:15:24,460
0,180 180,420 420,645 645,975 975,1200
number of non faces in

520
00:15:24,460 --> 00:15:25,645
0,120 120,345 345,680 790,1035 1035,1185
our data set, we would

521
00:15:25,645 --> 00:15:26,920
0,305 445,705 705,930 930,1155 1155,1275
sample the faces with a

522
00:15:26,920 --> 00:15:28,740
0,210 210,770 970,1230 1230,1335 1335,1820
higher probability than the negatives

523
00:15:28,820 --> 00:15:29,905
0,245 245,410 410,590 590,815 815,1085
so that the model sees

524
00:15:29,905 --> 00:15:31,400
0,240 240,555 555,935
both classes equally.|

525
00:15:33,160 --> 00:15:34,530
0,260 260,515 515,910 960,1205 1205,1370
The second example, the second

526
00:15:34,530 --> 00:15:35,595
0,195 195,330 330,465 465,855 855,1065
way we can mitigate class

527
00:15:35,595 --> 00:15:37,200
0,585 585,870 870,1110 1110,1380 1380,1605
imbalance is through loss {re-rating,

528
00:15:37,200 --> 00:15:39,375
0,260 820,1095 1095,1260 1260,1550 1810,2175
-} which is when instead

529
00:15:39,375 --> 00:15:41,145
0,285 285,570 570,915 915,1295 1435,1770
of having every single mistake

530
00:15:41,145 --> 00:15:42,540
0,180 180,285 285,495 495,845 1045,1395
that the model makes contribute

531
00:15:42,540 --> 00:15:43,785
0,350 400,630 630,750 750,975 975,1245
equally to our total {loss

532
00:15:43,785 --> 00:15:45,930
0,335 985,1380 1380,1695 1695,1950 1950,2145
-} function, we're weight the

533
00:15:45,930 --> 00:15:47,745
0,525 525,840 840,1160 1180,1665 1665,1815
samples such that samples from

534
00:15:47,745 --> 00:15:50,070
0,765 765,1115 1465,1830 1830,2145 2145,2325
underrepresented classes contribute more {to,the

535
00:15:50,070 --> 00:15:52,230
0,90 90,285 285,620 1180,1580 1900,2160
-} loss function. So instead

536
00:15:52,230 --> 00:15:53,490
0,120 120,240 240,435 435,900 900,1260
of the model assigning every

537
00:15:53,490 --> 00:15:56,055
0,380 1180,1470 1470,1760 1990,2295 2295,2565
single input face to a

538
00:15:56,055 --> 00:15:57,990
0,240 240,390 390,665 1345,1755 1755,1935
as a negative, it'll be

539
00:15:57,990 --> 00:15:59,250
0,315 315,780 780,930 930,1065 1065,1260
highly penalized if it does

540
00:15:59,250 --> 00:16:01,305
0,320 580,980 1300,1560 1560,1770 1770,2055
so because the loss of

541
00:16:01,305 --> 00:16:02,760
0,240 240,510 510,825 825,1140 1140,1455
the faces would contribute more

542
00:16:02,760 --> 00:16:03,860
0,195 195,315 315,510 510,765 765,1100
to the total loss function

543
00:16:03,880 --> 00:16:04,710
0,260 260,380 380,560 560,740 740,830
than the loss of the

544
00:16:04,710 --> 00:16:05,520
0,470
negatives.|

545
00:16:07,210 --> 00:16:08,580
0,335 335,530 530,770 770,1115 1115,1370
And the final way that

546
00:16:08,580 --> 00:16:10,500
0,165 165,440 700,1170 1170,1365 1365,1920
we can mitigate class imbalance

547
00:16:10,500 --> 00:16:12,720
0,350 580,885 885,1220 1240,1640 1960,2220
is through batch selection, which

548
00:16:12,720 --> 00:16:14,010
0,135 135,285 285,465 465,705 705,1290
is when we choose randomly

549
00:16:14,010 --> 00:16:15,450
0,180 180,470 730,990 990,1155 1155,1440
from classes so that every

550
00:16:15,450 --> 00:16:16,905
0,315 315,680 820,1095 1095,1230 1230,1455
single batch has an equal

551
00:16:16,905 --> 00:16:18,255
0,300 300,495 495,690 690,1020 1020,1350
number of data points per

552
00:16:18,255 --> 00:16:19,780
0,335
class.|

553
00:16:22,300 --> 00:16:25,080
0,400 450,830 830,1115 1115,1600
So is everything solved?|

554
00:16:25,510 --> 00:16:27,795
0,400 480,755 755,935 935,1240 1980,2285
Clearly, there are other forms

555
00:16:27,795 --> 00:16:29,535
0,165 165,600 600,990 990,1380 1380,1740
of bias that exist even

556
00:16:29,535 --> 00:16:31,590
0,365 565,945 945,1325 1345,1725 1725,2055
when the classes are completely

557
00:16:31,590 --> 00:16:33,555
0,530 940,1340 1510,1755 1755,1860 1860,1965
balanced, because the thing that

558
00:16:33,555 --> 00:16:34,640
0,120 120,375 375,555 555,780 780,1085
we haven't thought about yet

559
00:16:34,840 --> 00:16:37,220
0,350 350,845 845,1180
is latent features.|

560
00:16:37,390 --> 00:16:38,670
0,400 420,680 680,830 830,1055 1055,1280
So if you remember from

561
00:16:38,670 --> 00:16:40,110
0,255 255,620 640,1005 1005,1230 1230,1440
lab two and the last

562
00:16:40,110 --> 00:16:42,620
0,350 790,1290 1290,1580 1690,2090 2110,2510
lecture, latent features are the

563
00:16:42,700 --> 00:16:44,010
0,290 290,575 575,860 860,1100 1100,1310
actual represent is the actual

564
00:16:44,010 --> 00:16:46,305
0,680 730,1020 1020,1215 1215,1520 1960,2295
representation of this image according

565
00:16:46,305 --> 00:16:48,600
0,180 180,285 285,545 1315,1715 1975,2295
to the model. {And,so -}

566
00:16:48,600 --> 00:16:50,090
0,315 315,660 660,1050 1050,1230 1230,1490
far we've mitigated the problem

567
00:16:50,200 --> 00:16:51,450
0,320 320,530 530,725 725,1010 1010,1250
of when we know that

568
00:16:51,450 --> 00:16:53,670
0,135 135,315 315,1110 1110,1460 1960,2220
we have underrepresented classes, but

569
00:16:53,670 --> 00:16:54,950
0,135 135,435 435,810 810,1005 1005,1280
we haven't mitigated the problem

570
00:16:54,970 --> 00:16:55,920
0,275 275,440 440,605 605,770 770,950
of when we have a

571
00:16:55,920 --> 00:16:57,750
0,195 195,375 375,980 1150,1545 1545,1830
lot of variability within the

572
00:16:57,750 --> 00:16:59,745
0,255 255,620 1360,1740 1740,1890 1890,1995
same class. Let's say we

573
00:16:59,745 --> 00:17:00,690
0,60 60,180 180,420 420,720 720,945
have an equal number of

574
00:17:00,690 --> 00:17:02,295
0,290 400,690 690,975 975,1365 1365,1605
faces and negative examples in

575
00:17:02,295 --> 00:17:04,160
0,135 135,360 360,695 1285,1575 1575,1865
our data {set.,What -} happens

576
00:17:04,210 --> 00:17:05,220
0,275 275,395 395,635 635,890 890,1010
if the majority of the

577
00:17:05,220 --> 00:17:06,225
0,260 280,555 555,690 690,810 810,1005
faces are from a certain

578
00:17:06,225 --> 00:17:07,590
0,780 780,1050 1050,1170 1170,1260 1260,1365
demographic or they have a

579
00:17:07,590 --> 00:17:09,435
0,195 195,375 375,495 495,770 1600,1845
certain set of features? Can

580
00:17:09,435 --> 00:17:10,530
0,135 135,390 390,675 675,855 855,1095
we still apply the techniques

581
00:17:10,530 --> 00:17:11,510
0,240 240,345 345,465 465,660 660,980
that we just learned about?|

582
00:17:12,300 --> 00:17:13,310
0,245 245,455 455,725 725,875 875,1010
The answer is that we

583
00:17:13,310 --> 00:17:14,810
0,255 255,495 495,770 1090,1350 1350,1500
cannot do this, and the

584
00:17:14,810 --> 00:17:16,055
0,255 255,525 525,705 705,840 840,1245
problem is that the bias

585
00:17:16,055 --> 00:17:17,405
0,285 285,570 570,905 955,1230 1230,1350
present right now is in

586
00:17:17,405 --> 00:17:19,380
0,150 150,510 510,785
our latent features.|

587
00:17:19,570 --> 00:17:20,790
0,290 290,455 455,590 590,850 930,1220
All of these images are

588
00:17:20,790 --> 00:17:22,065
0,360 360,510 510,675 675,960 960,1275
labeled with the exact same

589
00:17:22,065 --> 00:17:24,290
0,335 535,870 870,1140 1140,1475 1825,2225
label, so according to as

590
00:17:24,610 --> 00:17:26,025
0,260 260,520 600,920 920,1130 1130,1415
the model, all we know

591
00:17:26,025 --> 00:17:27,380
0,285 285,540 540,825 825,1005 1005,1355
is that they're all faces.

592
00:17:28,210 --> 00:17:29,570
0,245 245,350 350,530 530,850 960,1360
{So,we -} have no information

593
00:17:29,680 --> 00:17:30,860
0,290 290,500 500,695 695,875 875,1180
about any of these features,

594
00:17:30,970 --> 00:17:33,450
0,400 420,710 710,860 860,1120 2160,2480
only from the {label.,Therefore, -}

595
00:17:33,450 --> 00:17:34,740
0,240 240,645 645,915 915,1140 1140,1290
we can't apply any of

596
00:17:34,740 --> 00:17:35,910
0,150 150,435 435,795 795,1020 1020,1170
the previous approaches that we

597
00:17:35,910 --> 00:17:38,625
0,290 670,1070 1360,1890 1890,2115 2115,2715
used to mitigate class imbalanced

598
00:17:38,625 --> 00:17:40,125
0,240 240,390 390,690 690,1005 1005,1500
because our classes are balanced,

599
00:17:40,125 --> 00:17:41,415
0,225 225,360 360,540 540,780 780,1290
but we have feature imbalance

600
00:17:41,415 --> 00:17:42,180
0,305
now.|

601
00:17:42,640 --> 00:17:44,145
0,380 380,665 665,950 950,1280 1280,1505
However, we can adapt the

602
00:17:44,145 --> 00:17:45,765
0,255 255,635 835,1170 1170,1425 1425,1620
previous methods to account for

603
00:17:45,765 --> 00:17:47,505
0,375 375,570 570,870 870,1145 1435,1740
bias in latent features, which

604
00:17:47,505 --> 00:17:48,900
0,240 240,485 745,1035 1035,1230 1230,1395
we'll do in just a

605
00:17:48,900 --> 00:17:50,520
0,150 150,440
few slides.|

606
00:17:52,060 --> 00:17:53,565
0,400 510,860 860,1175 1175,1370 1370,1505
So let's unpack this a

607
00:17:53,565 --> 00:17:55,020
0,135 135,300 300,575 925,1215 1215,1455
little bit further. {We,have -}

608
00:17:55,020 --> 00:17:56,810
0,330 330,710 730,1215 1215,1455 1455,1790
our potentially biased data set,

609
00:17:56,980 --> 00:17:58,095
0,275 275,500 500,695 695,890 890,1115
and we're trying to build

610
00:17:58,095 --> 00:17:59,550
0,315 315,665 715,990 990,1215 1215,1455
and deploy a model that

611
00:17:59,550 --> 00:18:01,380
0,480 480,630 630,890 1210,1560 1560,1830
classifies the faces in a

612
00:18:01,380 --> 00:18:03,225
0,285 285,585 585,920 1420,1695 1695,1845
traditional training {pipeline.,This -} is

613
00:18:03,225 --> 00:18:04,215
0,150 150,315 315,585 585,825 825,990
what that pipeline would {look,like.

614
00:18:04,215 --> 00:18:05,190
0,285 285,525 525,660 660,810 810,975
-} We would train our

615
00:18:05,190 --> 00:18:06,510
0,585 585,840 840,945 945,1125 1125,1320
classifier and we would deploy

616
00:18:06,510 --> 00:18:07,430
0,120 120,285 285,450 450,615 615,920
it into {the,real -} world.

617
00:18:07,720 --> 00:18:09,285
0,275 275,485 485,755 755,1090 1110,1565
But this training pipeline doesn't

618
00:18:09,285 --> 00:18:10,545
0,195 195,510 510,750 750,1095 1095,1260
de bias our inputs in

619
00:18:10,545 --> 00:18:12,020
0,210 210,545
any way.|

620
00:18:13,440 --> 00:18:14,585
0,395 395,695 695,875 875,1010 1010,1145
So one thing we could

621
00:18:14,585 --> 00:18:16,220
0,275 295,615 615,935 955,1245 1245,1635
do is label our biased

622
00:18:16,220 --> 00:18:18,160
0,320 520,780 780,975 975,1215 1215,1940
features and then apply resampling.

623
00:18:18,510 --> 00:18:19,750
0,260 260,515 515,725 725,950 950,1240
{So,let's -} say in reality

624
00:18:20,040 --> 00:18:21,155
0,275 275,440 440,665 665,905 905,1115
that this data set was

625
00:18:21,155 --> 00:18:22,910
0,375 375,600 600,810 810,1115 1435,1755
biased on hair {color.,Most -}

626
00:18:22,910 --> 00:18:23,810
0,180 180,285 285,450 450,675 675,900
of the data set is

627
00:18:23,810 --> 00:18:24,695
0,180 180,300 300,435 435,660 660,885
made up of people with

628
00:18:24,695 --> 00:18:26,585
0,285 285,545 715,1115 1285,1650 1650,1890
blonde hair, with faces with

629
00:18:26,585 --> 00:18:27,485
0,195 195,375 375,510 510,690 690,900
black hair and red {hair,underrepresented.

630
00:18:27,485 --> 00:18:30,095
0,815 1675,1995 1995,2190 2190,2340 2340,2610
-} If we knew this

631
00:18:30,095 --> 00:18:31,775
0,395 745,1020 1020,1185 1185,1440 1440,1680
information, we could label the

632
00:18:31,775 --> 00:18:33,065
0,210 210,495 495,735 735,990 990,1290
hair color of every single

633
00:18:33,065 --> 00:18:34,270
0,300 300,510 510,645 645,870 870,1205
person in this data set,

634
00:18:34,410 --> 00:18:35,480
0,275 275,395 395,560 560,800 800,1070
and we could apply either

635
00:18:35,480 --> 00:18:36,980
0,350 400,855 855,1065 1065,1305 1305,1500
sample {weighting -} or loss

636
00:18:36,980 --> 00:18:37,925
0,285 285,465 465,645 645,780 780,945
re-weighting, just as we did

637
00:18:37,925 --> 00:18:39,480
0,305
previously.|

638
00:18:39,720 --> 00:18:40,715
0,350 350,620 620,800 800,905 905,995
But does anyone want to

639
00:18:40,715 --> 00:18:41,480
0,120 120,270 270,420 420,555 555,765
tell me what the problem

640
00:18:41,480 --> 00:18:43,160
0,240 240,530
is here?|

641
00:18:45,920 --> 00:18:47,555
0,240 240,420 420,690 690,1040 1060,1635
You go through eat samples,

642
00:18:47,555 --> 00:18:48,395
0,195 195,375 375,510 510,645 645,840
it takes a lot of

643
00:18:48,395 --> 00:18:48,800
0,305
time.|

644
00:18:48,970 --> 00:18:50,595
0,400 870,1265 1265,1490 1490,1550 1550,1625
Yeah, so there are a

645
00:18:50,595 --> 00:18:51,600
0,165 165,465 465,675 675,765 765,1005
couple problems here, and that's

646
00:18:51,600 --> 00:18:53,340
0,260 310,570 570,705 705,980 1480,1740
definitely one of them. {The,first

647
00:18:53,340 --> 00:18:54,525
0,195 195,530 580,855 855,990 990,1185
-} is how do we

648
00:18:54,525 --> 00:18:55,725
0,315 315,585 585,795 795,1035 1035,1200
know that hair color is

649
00:18:55,725 --> 00:18:56,730
0,120 120,450 450,690 690,870 870,1005
a biased feature in this

650
00:18:56,730 --> 00:18:58,790
0,210 210,530 880,1245 1245,1560 1560,2060
data set? Unless we visually

651
00:18:58,870 --> 00:19:00,660
0,400 420,820 870,1235 1235,1565 1565,1790
inspect every single sample in

652
00:19:00,660 --> 00:19:01,680
0,135 135,345 345,600 600,855 855,1020
this data set, we're not

653
00:19:01,680 --> 00:19:02,565
0,210 210,360 360,555 555,765 765,885
going to know what the

654
00:19:02,565 --> 00:19:04,590
0,300 300,555 555,905 1615,1890 1890,2025
biased features {are.,And -} the

655
00:19:04,590 --> 00:19:05,730
0,195 195,420 420,630 630,915 915,1140
second thing is exactly what

656
00:19:05,730 --> 00:19:07,260
0,150 150,440 610,885 885,1160 1210,1530
you said, which is once

657
00:19:07,260 --> 00:19:08,540
0,225 225,435 435,630 630,975 975,1280
we have our biased features,

658
00:19:08,890 --> 00:19:10,620
0,380 380,695 695,920 920,1460 1460,1730
going through and annotating every

659
00:19:10,620 --> 00:19:12,105
0,330 330,585 585,765 765,1070 1240,1485
image with this feature is

660
00:19:12,105 --> 00:19:13,880
0,240 240,630 630,945 945,1410 1410,1775
an extremely labor intensive task

661
00:19:14,080 --> 00:19:15,285
0,260 260,395 395,995 995,1115 1115,1205
that is infeasible in the

662
00:19:15,285 --> 00:19:16,680
0,150 150,455
real world.|

663
00:19:17,370 --> 00:19:18,760
0,400 420,710 710,860 860,1055 1055,1390
So now the question is,

664
00:19:19,050 --> 00:19:19,955
0,275 275,425 425,575 575,740 740,905
what if we had a

665
00:19:19,955 --> 00:19:22,130
0,255 255,635 655,1055 1225,1625 1705,2175
way to automatically learn latent

666
00:19:22,130 --> 00:19:24,065
0,290 760,1080 1080,1350 1350,1635 1635,1935
features and use this learn

667
00:19:24,065 --> 00:19:25,880
0,300 300,1055 1255,1515 1515,1635 1635,1815
feature representation to de bi

668
00:19:25,880 --> 00:19:27,620
0,165 165,410
a model?|

669
00:19:29,460 --> 00:19:30,800
0,400 420,680 680,830 830,1100 1100,1340
So what we want is

670
00:19:30,800 --> 00:19:31,820
0,120 120,345 345,615 615,840 840,1020
a way to learn the

671
00:19:31,820 --> 00:19:32,950
0,210 210,435 435,585 585,795 795,1130
features of this data set

672
00:19:33,060 --> 00:19:35,210
0,260 260,520 570,970 1140,1540 1770,2150
and then automatically determine the

673
00:19:35,210 --> 00:19:36,845
0,380 670,1140 1140,1275 1275,1395 1395,1635
EM samples with the highest

674
00:19:36,845 --> 00:19:38,315
0,315 315,810 810,1020 1020,1125 1125,1470
feature bias and the samples

675
00:19:38,315 --> 00:19:39,490
0,120 120,210 210,405 405,690 690,1175
with the lowest feature bias.

676
00:19:40,140 --> 00:19:41,435
0,410 410,665 665,935 935,1130 1130,1295
We've already learned a method

677
00:19:41,435 --> 00:19:42,845
0,180 180,375 375,695 1015,1275 1275,1410
of doing this in the

678
00:19:42,845 --> 00:19:44,540
0,360 360,735 735,995 1255,1515 1515,1695
generative modeling lecture. {You,all -}

679
00:19:44,540 --> 00:19:46,720
0,320 370,705 705,1250 1270,1590 1590,2180
learned about variational auto encoders,

680
00:19:46,860 --> 00:19:48,110
0,260 260,410 410,680 680,980 980,1250
which are models that learn

681
00:19:48,110 --> 00:19:49,370
0,225 225,555 555,830 880,1140 1140,1260
the latent features of a

682
00:19:49,370 --> 00:19:51,470
0,180 180,500 1270,1545 1545,1680 1680,2100
data set as a recap

683
00:19:51,470 --> 00:19:53,390
0,525 525,795 795,1290 1290,1605 1605,1920
variational auto encoders work by

684
00:19:53,390 --> 00:19:55,600
0,870 870,1395 1395,1680 1680,1905 1905,2210
probabilistically sampling from a learn

685
00:19:55,920 --> 00:19:57,890
0,425 425,730 1080,1370 1370,1655 1655,1970
latent space, and then they

686
00:19:57,890 --> 00:19:59,350
0,480 480,645 645,840 840,1155 1155,1460
decode this new latent vector

687
00:19:59,550 --> 00:20:00,910
0,400 420,710 710,905 905,1085 1085,1360
into back into the original

688
00:20:01,020 --> 00:20:02,975
0,305 305,610 840,1190 1190,1400 1400,1955
input space, measure the reconstruction

689
00:20:02,975 --> 00:20:04,100
0,345 345,585 585,765 765,1005 1005,1125
loss between the inputs and

690
00:20:04,100 --> 00:20:05,660
0,225 225,705 705,1035 1035,1290 1290,1560
the outputs, and continue to

691
00:20:05,660 --> 00:20:07,100
0,240 240,390 390,1035 1035,1290 1290,1440
update their representation of the

692
00:20:07,100 --> 00:20:08,160
0,300 300,590
latent space.|

693
00:20:08,590 --> 00:20:09,600
0,260 260,380 380,590 590,830 830,1010
And the reason why we

694
00:20:09,600 --> 00:20:10,635
0,210 210,405 405,645 645,885 885,1035
care so much about this

695
00:20:10,635 --> 00:20:12,300
0,330 330,635 805,1080 1080,1355 1375,1665
latent space is that we

696
00:20:12,300 --> 00:20:13,665
0,255 255,735 735,870 870,1050 1050,1365
want samples that are similar

697
00:20:13,665 --> 00:20:14,625
0,225 225,315 315,510 510,720 720,960
to each other in the

698
00:20:14,625 --> 00:20:16,710
0,365 535,810 810,1470 1470,1740 1740,2085
input to decode to latent

699
00:20:16,710 --> 00:20:17,850
0,405 405,585 585,690 690,885 885,1140
vectors that are very close

700
00:20:17,850 --> 00:20:18,630
0,150 150,240 240,435 435,630 630,780
to each other in this

701
00:20:18,630 --> 00:20:20,505
0,315 315,620 1060,1365 1365,1755 1755,1875
latent space. {And,samples -} that

702
00:20:20,505 --> 00:20:21,375
0,165 165,405 405,585 585,720 720,870
are far from each other

703
00:20:21,375 --> 00:20:22,860
0,270 270,675 675,780 780,915 915,1485
or samples that are dissimilar

704
00:20:22,860 --> 00:20:23,805
0,150 150,255 255,495 495,720 720,945
to each other in the

705
00:20:23,805 --> 00:20:26,010
0,365 595,870 870,1415 1615,2100 2100,2205
input should decode encode to

706
00:20:26,010 --> 00:20:27,675
0,300 300,675 675,870 870,1130 1360,1665
latent vectors that are far

707
00:20:27,675 --> 00:20:28,530
0,150 150,270 270,495 495,720 720,855
from each other in the

708
00:20:28,530 --> 00:20:30,120
0,300 300,620
latent space.|

709
00:20:32,090 --> 00:20:33,460
0,380 380,695 695,920 920,1085 1085,1370
So now we'll walk through

710
00:20:33,460 --> 00:20:34,540
0,240 240,465 465,735 735,945 945,1080
step by step, a deb

711
00:20:34,540 --> 00:20:36,570
0,510 510,915 915,1220 1240,1635 1635,2030
biasing algorithm that automatically uses

712
00:20:36,680 --> 00:20:38,515
0,400 540,980 980,1240 1260,1610 1610,1835
the latent features learned by

713
00:20:38,515 --> 00:20:40,560
0,120 120,555 555,855 855,1475 1645,2045
a variational auto encoder EM

714
00:20:40,640 --> 00:20:42,355
0,400 510,860 860,1190 1190,1460 1460,1715
to under sample and over

715
00:20:42,355 --> 00:20:43,720
0,365 445,720 720,990 990,1230 1230,1365
sample from regions in our

716
00:20:43,720 --> 00:20:46,015
0,290 340,740 1420,1770 1770,2055 2055,2295
data set EM. {Before,I,start, -

717
00:20:46,015 --> 00:20:46,810
0,210 210,390 390,525 525,660 660,795
-} I want to point

718
00:20:46,810 --> 00:20:48,040
0,165 165,405 405,660 660,840 840,1230
out that this deb biasing

719
00:20:48,040 --> 00:20:49,470
0,210 210,560 610,915 915,1125 1125,1430
model is actually the foundation

720
00:20:49,730 --> 00:20:51,700
0,275 275,785 785,1060 1470,1775 1775,1970
of themos's {work.,This -} work

721
00:20:51,700 --> 00:20:52,540
0,180 180,345 345,450 450,570 570,840
comes out of a paper

722
00:20:52,540 --> 00:20:53,560
0,240 240,390 390,645 645,885 885,1020
that we published a few

723
00:20:53,560 --> 00:20:54,745
0,225 225,590 670,915 915,1035 1035,1185
years ago that has been

724
00:20:54,745 --> 00:20:56,725
0,570 570,765 765,1145 1195,1560 1560,1980
demonstrated to deias commercial facial

725
00:20:56,725 --> 00:20:59,260
0,450 450,965 1105,1505 2095,2370 2370,2535
{detection,algorithms. -} And it was

726
00:20:59,260 --> 00:21:00,660
0,240 240,735 735,885 885,1080 1080,1400
so impactful that we decided

727
00:21:00,710 --> 00:21:02,310
0,400 450,710 710,845 845,1120 1200,1600
to make it available and

728
00:21:02,690 --> 00:21:04,135
0,290 290,470 470,740 740,1120 1170,1445
work with {companies,and -} industries.

729
00:21:04,135 --> 00:21:05,200
0,135 135,390 390,540 540,870 870,1065
And that's how themis was

730
00:21:05,200 --> 00:21:06,440
0,290
started.|

731
00:21:06,700 --> 00:21:08,295
0,400 540,920 920,1115 1115,1370 1370,1595
So let's first start by

732
00:21:08,295 --> 00:21:09,720
0,270 270,510 510,875 925,1230 1230,1425
training a vae on this

733
00:21:09,720 --> 00:21:11,475
0,210 210,530 910,1215 1215,1470 1470,1755
data set. {The,z -} shown

734
00:21:11,475 --> 00:21:13,080
0,255 255,435 435,570 570,1115 1315,1605
here in this diagram ends

735
00:21:13,080 --> 00:21:14,420
0,180 180,420 420,675 675,1035 1035,1340
up being our latent space,

736
00:21:14,800 --> 00:21:16,820
0,395 395,695 695,1040 1040,1330 1620,2020
and the latent space automatically

737
00:21:16,930 --> 00:21:18,795
0,590 590,910 1050,1325 1325,1535 1535,1865
captures features that were important

738
00:21:18,795 --> 00:21:20,800
0,270 270,755
for classification.|

739
00:21:20,870 --> 00:21:22,810
0,400 780,1145 1145,1295 1295,1565 1565,1940
So here's an example, latent

740
00:21:22,810 --> 00:21:24,090
0,240 240,480 480,645 645,915 915,1280
feature that this model captured

741
00:21:24,530 --> 00:21:25,765
0,365 365,590 590,740 740,890 890,1235
EM. {This,is -} the facial

742
00:21:25,765 --> 00:21:26,970
0,255 255,450 450,660 660,915 915,1205
position of an input {face.,And

743
00:21:27,440 --> 00:21:29,350
0,400 690,1010 1010,1295 1295,1550 1550,1910
-} something that's really crucial

744
00:21:29,350 --> 00:21:30,880
0,375 375,645 645,870 870,1185 1185,1530
here is that we never

745
00:21:30,880 --> 00:21:33,570
0,285 285,465 465,740 1060,1460 1990,2690
told the model to calculate,

746
00:21:34,010 --> 00:21:35,815
0,400 450,965 965,1175 1175,1460 1460,1805
to encode the feature vector

747
00:21:35,815 --> 00:21:37,780
0,365 835,1095 1095,1425 1425,1725 1725,1965
of the facial position of

748
00:21:37,780 --> 00:21:39,295
0,105 105,315 315,680 940,1245 1245,1515
a {given,face. -} It learned

749
00:21:39,295 --> 00:21:41,860
0,365 655,1055 1675,2010 2010,2265 2265,2565
this automatically, because this feature

750
00:21:41,860 --> 00:21:43,105
0,375 375,735 735,945 945,1035 1035,1245
is important for the model

751
00:21:43,105 --> 00:21:44,980
0,360 360,690 690,930 930,1140 1140,1875
to develop a good representation

752
00:21:44,980 --> 00:21:46,405
0,255 255,405 405,585 585,890 1090,1425
of what a face actually

753
00:21:46,405 --> 00:21:47,740
0,335
is.|

754
00:21:48,660 --> 00:21:49,820
0,400 450,725 725,845 845,980 980,1160
So now that we have

755
00:21:49,820 --> 00:21:51,320
0,165 165,465 465,770 1090,1350 1350,1500
our latent structure, we can

756
00:21:51,320 --> 00:21:52,715
0,195 195,405 405,585 585,1095 1095,1395
use it to calculate a

757
00:21:52,715 --> 00:21:54,530
0,395 505,780 780,1020 1020,1485 1485,1815
distribution of the inputs across

758
00:21:54,530 --> 00:21:56,480
0,330 330,750 750,1010 1540,1815 1815,1950
every latent variable, and we

759
00:21:56,480 --> 00:21:58,270
0,260 340,615 615,795 795,1340 1390,1790
can estimate a probability distribution

760
00:21:58,830 --> 00:22:00,755
0,380 380,760 1170,1505 1505,1685 1685,1925
depending on that's based on

761
00:22:00,755 --> 00:22:02,240
0,210 210,515 655,945 945,1185 1185,1485
the features of every item

762
00:22:02,240 --> 00:22:04,270
0,225 225,375 375,570 570,890 1630,2030
in this data set. {Essentially,,what

763
00:22:04,350 --> 00:22:05,525
0,290 290,485 485,770 770,1010 1010,1175
-} this means is that

764
00:22:05,525 --> 00:22:07,000
0,165 165,330 330,810 810,960 960,1475
we can calculate the probability

765
00:22:07,080 --> 00:22:08,540
0,245 245,410 410,695 695,1060 1170,1460
that a certain combination of

766
00:22:08,540 --> 00:22:09,905
0,290 550,885 885,1050 1050,1155 1155,1365
features appears in our data

767
00:22:09,905 --> 00:22:11,330
0,335 475,825 825,1035 1035,1140 1140,1425
set based on the latent

768
00:22:11,330 --> 00:22:13,030
0,195 195,375 375,540 540,830 1300,1700
space that we just learned.|

769
00:22:13,640 --> 00:22:14,450
0,150 150,285 285,420 420,555 555,810
And then we can over

770
00:22:14,450 --> 00:22:16,760
0,360 360,950 1390,1890 1890,2100 2100,2310
sample denser, sparser areas of

771
00:22:16,760 --> 00:22:17,855
0,135 135,345 345,615 615,840 840,1095
this data set and under

772
00:22:17,855 --> 00:22:19,265
0,330 330,570 570,930 930,1170 1170,1410
sample from denser areas of

773
00:22:19,265 --> 00:22:20,640
0,150 150,345 345,665
this data set.|

774
00:22:20,770 --> 00:22:22,305
0,400 600,950 950,1040 1040,1220 1220,1535
So let's say our distribution

775
00:22:22,305 --> 00:22:23,565
0,270 270,510 510,780 780,1050 1050,1260
looks something like this. {This,is

776
00:22:23,565 --> 00:22:25,020
0,90 90,210 210,935 1045,1320 1320,1455
-} an oversimplification, but for

777
00:22:25,020 --> 00:22:27,990
0,570 570,920 1570,1970 2170,2505 2505,2970
visualization purposes and the denser

778
00:22:27,990 --> 00:22:29,240
0,390 390,540 540,675 675,900 900,1250
portions of this data set,

779
00:22:29,380 --> 00:22:30,590
0,260 260,455 455,740 740,950 950,1210
we would expect to have

780
00:22:31,030 --> 00:22:32,760
0,275 275,845 845,1070 1070,1360 1440,1730
a homogeneous skin color and

781
00:22:32,760 --> 00:22:34,155
0,320 370,645 645,825 825,1125 1125,1395
pose in hair color and

782
00:22:34,155 --> 00:22:36,180
0,225 225,510 510,845 1615,1890 1890,2025
very good {lighting.,And -} then

783
00:22:36,180 --> 00:22:37,290
0,135 135,285 285,675 675,975 975,1110
in the sparser portions of

784
00:22:37,290 --> 00:22:38,520
0,150 150,375 375,710 790,1035 1035,1230
this data set, we would

785
00:22:38,520 --> 00:22:39,990
0,285 285,510 510,735 735,1070 1180,1470
expect to see diverse skin

786
00:22:39,990 --> 00:22:43,020
0,290 550,1010 1060,1320 1320,1850
color, pose and illumination.|

787
00:22:46,280 --> 00:22:47,380
0,365 365,605 605,740 740,890 890,1100
So now that we have

788
00:22:47,380 --> 00:22:48,745
0,285 285,650 700,975 975,1140 1140,1365
this distribution and we know

789
00:22:48,745 --> 00:22:50,130
0,210 210,485 535,795 795,1020 1020,1385
what areas of our distribution

790
00:22:50,150 --> 00:22:51,535
0,335 335,665 665,935 935,1115 1115,1385
are dense and which areas

791
00:22:51,535 --> 00:22:53,380
0,300 300,845 1015,1290 1290,1560 1560,1845
are sparse, we want to

792
00:22:53,380 --> 00:22:55,225
0,270 270,630 630,1010 1180,1515 1515,1845
under sample areas from the

793
00:22:55,225 --> 00:22:56,740
0,345 345,675 675,1110 1110,1275 1275,1515
under sample samples that fall

794
00:22:56,740 --> 00:22:58,150
0,210 210,315 315,770 790,1170 1170,1410
in the denser areas of

795
00:22:58,150 --> 00:23:00,000
0,225 225,590 970,1245 1245,1485 1485,1850
this distribution and over sample

796
00:23:00,980 --> 00:23:02,080
0,335 335,575 575,755 755,935 935,1100
data points that fall in

797
00:23:02,080 --> 00:23:03,340
0,120 120,525 525,765 765,1005 1005,1260
the sparser areas of this

798
00:23:03,340 --> 00:23:06,025
0,380 1420,1770 1770,2010 2010,2300 2440,2685
distribution. {So,for -} example, we

799
00:23:06,025 --> 00:23:07,555
0,135 135,420 420,795 795,1155 1155,1530
would probably under sample points

800
00:23:07,555 --> 00:23:09,790
0,395 775,1175 1315,1650 1650,1965 1965,2235
with the very common skin

801
00:23:09,790 --> 00:23:11,470
0,285 285,600 600,915 915,1310 1360,1680
colors, hair colors and good

802
00:23:11,470 --> 00:23:12,970
0,315 315,570 570,830 880,1230 1230,1500
lighting that is extremely present

803
00:23:12,970 --> 00:23:14,200
0,165 165,300 300,525 525,860 940,1230
in this data set and

804
00:23:14,200 --> 00:23:15,730
0,255 255,570 570,780 780,1040 1150,1530
over sample the diverse images

805
00:23:15,730 --> 00:23:16,600
0,225 225,360 360,570 570,750 750,870
that we saw on the

806
00:23:16,600 --> 00:23:18,595
0,210 210,560 1240,1515 1515,1740 1740,1995
last {slide.,And -} this allows

807
00:23:18,595 --> 00:23:19,630
0,210 210,405 405,660 660,870 870,1035
us to train in a

808
00:23:19,630 --> 00:23:22,000
0,300 300,570 570,1140 1140,1460
fair and unbiased manner.|

809
00:23:24,170 --> 00:23:25,375
0,260 260,425 425,730 750,1025 1025,1205
To dig in a little

810
00:23:25,375 --> 00:23:26,520
0,195 195,420 420,675 675,870 870,1145
bit more into the math

811
00:23:26,600 --> 00:23:28,170
0,320 320,545 545,740 740,1280 1280,1570
behind how this resampling works,

812
00:23:28,850 --> 00:23:30,910
0,335 335,605 605,940 1200,1880 1880,2060
this approach basically approximates the

813
00:23:30,910 --> 00:23:32,395
0,315 315,620 700,1020 1020,1245 1245,1485
latent space VIA a joint

814
00:23:32,395 --> 00:23:34,450
0,630 630,960 960,1290 1290,1650 1650,2055
histogram over the individual latent

815
00:23:34,450 --> 00:23:37,020
0,560 1000,1400 1540,1830 1830,2120 2170,2570
variables. {So,we -} have a

816
00:23:37,850 --> 00:23:39,660
0,635 635,860 860,1115 1115,1520 1520,1810
histogram for every latent variable

817
00:23:39,860 --> 00:23:41,545
0,320 320,515 515,790 1200,1505 1505,1685
z sub I, and what

818
00:23:41,545 --> 00:23:43,030
0,105 105,525 525,840 840,1215 1215,1485
the histogram essentially does is

819
00:23:43,030 --> 00:23:45,270
0,210 210,890 1030,1380 1380,1730 1840,2240
it discretizes the continuous distribution

820
00:23:45,590 --> 00:23:46,645
0,245 245,350 350,455 455,590 590,1055
so that we can calculate

821
00:23:46,645 --> 00:23:48,920
0,515 565,855 855,1145
probabilities more easily.|

822
00:23:49,370 --> 00:23:51,510
0,400 480,880 930,1550 1550,1700 1700,2140
Then we multiply the probabilities

823
00:23:51,530 --> 00:23:52,975
0,400 480,830 830,1085 1085,1265 1265,1445
together across all of the

824
00:23:52,975 --> 00:23:55,630
0,405 405,845 2005,2280 2280,2430 2430,2655
latent distributions, and then after

825
00:23:55,630 --> 00:23:56,850
0,285 285,480 480,645 645,885 885,1220
that we can develop an

826
00:23:57,440 --> 00:23:58,920
0,335 335,530 530,695 695,1000 1080,1480
understanding of the joint distribution

827
00:23:58,940 --> 00:23:59,965
0,275 275,425 425,545 545,665 665,1025
of all of the samples

828
00:23:59,965 --> 00:24:01,820
0,150 150,270 270,570 570,875
in our latent space.|

829
00:24:03,170 --> 00:24:04,405
0,320 320,515 515,785 785,1040 1040,1235
Based on this, we can

830
00:24:04,405 --> 00:24:06,250
0,285 285,585 585,930 930,1535 1555,1845
define the adjusted probability for

831
00:24:06,250 --> 00:24:07,930
0,530 640,885 885,1065 1065,1380 1380,1680
sampling for a particular data

832
00:24:07,930 --> 00:24:09,955
0,210 210,420 420,740 1330,1605 1605,2025
point as follows. {The,probability -}

833
00:24:09,955 --> 00:24:11,425
0,255 255,570 570,720 720,1025 1135,1470
of selecting a sample data

834
00:24:11,425 --> 00:24:12,745
0,240 240,545 685,945 945,1080 1080,1320
point X will be based

835
00:24:12,745 --> 00:24:13,825
0,240 240,375 375,690 690,900 900,1080
on the latent space of

836
00:24:13,825 --> 00:24:15,220
0,275 655,960 960,1140 1140,1260 1260,1395
X, such that it is

837
00:24:15,220 --> 00:24:16,555
0,180 180,660 660,915 915,1065 1065,1335
the inverse of the joint

838
00:24:16,555 --> 00:24:19,405
0,660 660,1055 2155,2430 2430,2625 2625,2850
approximated {distribution.,We -} have a

839
00:24:19,405 --> 00:24:20,815
0,435 435,870 870,1080 1080,1275 1275,1410
parameter Alpha here, which is

840
00:24:20,815 --> 00:24:22,675
0,225 225,765 765,1265 1405,1680 1680,1860
a biasing parameter, and as

841
00:24:22,675 --> 00:24:24,880
0,480 480,845 1165,1470 1470,1965 1965,2205
Alpha increases, this probability will

842
00:24:24,880 --> 00:24:26,490
0,270 270,615 615,930 930,1245 1245,1610
tend to the uniform distribution,

843
00:24:26,870 --> 00:24:28,585
0,260 260,395 395,875 875,1270 1440,1715
and if Alpha increases, we

844
00:24:28,585 --> 00:24:29,605
0,150 150,270 270,375 375,735 735,1020
tend to de bias more

845
00:24:29,605 --> 00:24:31,080
0,335
strongly.|

846
00:24:32,570 --> 00:24:33,760
0,275 275,470 470,680 680,920 920,1190
And this gives us the

847
00:24:33,760 --> 00:24:35,250
0,320 370,770 790,1065 1065,1215 1215,1490
final weight of the sample

848
00:24:35,750 --> 00:24:36,730
0,245 245,380 380,605 605,830 830,980
in our data set that

849
00:24:36,730 --> 00:24:37,945
0,120 120,345 345,855 855,1020 1020,1215
we can calculate on the

850
00:24:37,945 --> 00:24:39,690
0,305 535,935 985,1260 1260,1440 1440,1745
fly and use it to

851
00:24:39,860 --> 00:24:42,620
0,605 605,1100 1100,1295 1295,1600
adaptively resample while training.|

852
00:24:43,770 --> 00:24:45,370
0,305 305,610 780,1085 1085,1295 1295,1600
And so once we apply

853
00:24:45,630 --> 00:24:47,525
0,335 335,935 935,1205 1205,1510 1530,1895
this biasing, we have pretty

854
00:24:47,525 --> 00:24:49,490
0,365 475,875 1225,1515 1515,1725 1725,1965
remarkable results. {This,is -} the

855
00:24:49,490 --> 00:24:51,230
0,320 490,855 855,1185 1185,1470 1470,1740
original EM graph that shows

856
00:24:51,230 --> 00:24:53,170
0,315 315,750 750,1010 1030,1430 1540,1940
the accuracy gap between EM,

857
00:24:53,220 --> 00:24:54,905
0,365 365,815 815,1175 1175,1430 1430,1685
the darker Mills and the

858
00:24:54,905 --> 00:24:56,350
0,330 330,585 585,705 705,855 855,1445
lighter Mills in this dataset.|

859
00:24:57,770 --> 00:24:59,130
0,320 320,575 575,815 815,1040 1040,1360
Once we apply the device

860
00:24:59,330 --> 00:25:00,940
0,560 560,860 860,1070 1070,1430 1430,1610
algorithm, where as Alpha gets

861
00:25:00,940 --> 00:25:02,320
0,285 285,570 570,920 940,1215 1215,1380
smaller, we're devising more and

862
00:25:02,320 --> 00:25:03,505
0,290 370,660 660,810 810,960 960,1185
more, as we just talked

863
00:25:03,505 --> 00:25:06,430
0,335 1105,1500 1500,1935 1935,2195 2305,2925
about, this accuracy gap decreases

864
00:25:06,430 --> 00:25:08,815
0,380 1390,1650 1650,1980 1980,2205 2205,2385
significantly and that's because we

865
00:25:08,815 --> 00:25:10,435
0,180 180,330 330,555 555,935 1135,1620
tend to over sample samples

866
00:25:10,435 --> 00:25:12,120
0,225 225,615 615,795 795,1085 1285,1685
with darker skin color and

867
00:25:12,260 --> 00:25:13,495
0,320 320,500 500,710 710,1085 1085,1235
therefore the model learns them

868
00:25:13,495 --> 00:25:14,620
0,270 270,570 570,840 840,975 975,1125
better and tends to do

869
00:25:14,620 --> 00:25:16,340
0,225 225,465 465,770
better on them.|

870
00:25:16,380 --> 00:25:17,680
0,290 290,560 560,905 905,1025 1025,1300
Keep this algorithm in mind

871
00:25:17,730 --> 00:25:18,500
0,260 260,410 410,530 530,665 665,770
because you're going to need

872
00:25:18,500 --> 00:25:19,450
0,135 135,270 270,375 375,585 585,950
it for the lab three

873
00:25:19,530 --> 00:25:20,975
0,400 600,860 860,1055 1055,1220 1220,1445
competition, which I'll talk more

874
00:25:20,975 --> 00:25:21,965
0,270 270,540 540,705 705,855 855,990
about towards the end of

875
00:25:21,965 --> 00:25:23,560
0,135 135,425
this lecture.|

876
00:25:25,420 --> 00:25:26,820
0,400 420,725 725,995 995,1280 1280,1400
So, so far we've been

877
00:25:26,820 --> 00:25:28,370
0,290 310,690 690,975 975,1290 1290,1550
focusing mainly on facial recognition

878
00:25:28,540 --> 00:25:29,700
0,400 480,725 725,830 830,995 995,1160
systems and a couple of

879
00:25:29,700 --> 00:25:31,665
0,195 195,530 640,1005 1005,1635 1635,1965
other systems as canonical examples

880
00:25:31,665 --> 00:25:34,290
0,270 270,695 1435,1835 1915,2370 2370,2625
of bias. {However,,bias -} is

881
00:25:34,290 --> 00:25:36,210
0,375 375,770 790,1110 1110,1680 1680,1920
actually far more widespread in

882
00:25:36,210 --> 00:25:38,085
0,225 225,500 1090,1380 1380,1575 1575,1875
machine {learning.,Consider -} the example

883
00:25:38,085 --> 00:25:40,350
0,330 330,885 885,1175 1675,2010 2010,2265
of {autonomous,driving. -} Many data

884
00:25:40,350 --> 00:25:42,165
0,300 300,680 730,1230 1230,1545 1545,1815
sets are comprised mainly of

885
00:25:42,165 --> 00:25:43,815
0,285 285,615 615,965 1075,1410 1410,1650
cars driving down straight and

886
00:25:43,815 --> 00:25:45,150
0,240 240,575 625,915 915,1125 1125,1335
sunny roads in really good

887
00:25:45,150 --> 00:25:46,890
0,285 285,680 910,1230 1230,1500 1500,1740
weather conditions with {very,high -}

888
00:25:46,890 --> 00:25:48,570
0,500 820,1095 1095,1245 1245,1440 1440,1680
visibility. And this is because

889
00:25:48,570 --> 00:25:49,580
0,180 180,375 375,555 555,705 705,1010
the data for these cars

890
00:25:49,780 --> 00:25:51,405
0,290 290,580 630,1085 1085,1370 1370,1625
for these algorithms is actually

891
00:25:51,405 --> 00:25:53,370
0,275 865,1215 1215,1455 1455,1680 1680,1965
just collected by cars driving

892
00:25:53,370 --> 00:25:54,960
0,285 285,620
down roads.|

893
00:25:55,220 --> 00:25:57,450
0,400 750,1145 1145,1490 1490,1835 1835,2230
However, in some specific cases,

894
00:25:57,560 --> 00:25:58,810
0,290 290,395 395,515 515,740 740,1250
you're going to face adverse

895
00:25:58,810 --> 00:26:01,855
0,320 610,1010 1450,1785 1785,2330 2710,3045
weather, bad, bad visibility, near

896
00:26:01,855 --> 00:26:03,565
0,345 345,965 1045,1320 1320,1455 1455,1710
collision scenarios. {And,these -} are

897
00:26:03,565 --> 00:26:04,675
0,315 315,495 495,840 840,975 975,1110
actually the samples that are

898
00:26:04,675 --> 00:26:05,845
0,135 135,395 415,815 835,1080 1080,1170
the most important for the

899
00:26:05,845 --> 00:26:07,390
0,210 210,420 420,665 1045,1320 1320,1545
model to learn because they're

900
00:26:07,390 --> 00:26:08,665
0,105 105,450 450,885 885,1065 1065,1275
the hardest samples and they're

901
00:26:08,665 --> 00:26:09,475
0,105 105,435 435,570 570,660 660,810
the samples where the model

902
00:26:09,475 --> 00:26:10,830
0,240 240,510 510,825 825,1080 1080,1355
is most likely to fail.|

903
00:26:11,900 --> 00:26:13,295
0,345 345,570 570,735 735,1040 1060,1395
But in a traditional EM

904
00:26:13,295 --> 00:26:15,245
0,510 510,720 720,1055 1255,1545 1545,1950
autonomous driving pipeline, these samples

905
00:26:15,245 --> 00:26:17,375
0,135 135,395 595,990 990,1385 1765,2130
are often extremely low, have

906
00:26:17,375 --> 00:26:19,610
0,315 315,570 570,1325 1885,2130 2130,2235
extremely low representation. {So,this -}

907
00:26:19,610 --> 00:26:20,855
0,105 105,285 285,615 615,930 930,1245
is an example where using

908
00:26:20,855 --> 00:26:23,390
0,395 745,1590 1590,1995 1995,2415 2415,2535
the unsupervised latent biasing that

909
00:26:23,390 --> 00:26:24,620
0,120 120,285 285,540 540,890 970,1230
we just talked about, we

910
00:26:24,620 --> 00:26:25,535
0,120 120,240 240,480 480,720 720,915
would be able to up

911
00:26:25,535 --> 00:26:28,160
0,300 300,665 715,1115 2005,2355 2355,2625
sample these EM important data

912
00:26:28,160 --> 00:26:29,890
0,300 300,585 585,890 910,1310 1330,1730
points and under sample the

913
00:26:29,940 --> 00:26:31,420
0,320 320,605 605,860 860,1115 1115,1480
data points of driving down

914
00:26:31,440 --> 00:26:33,480
0,335 335,575 575,800 800,1120
straight and sunny roads.|

915
00:26:35,590 --> 00:26:37,695
0,760 930,1280 1280,1535 1535,1820 1820,2105
Similarly, consider the example of

916
00:26:37,695 --> 00:26:40,485
0,255 255,570 570,935 1675,2075 2425,2790
large language models. {EM,,an -}

917
00:26:40,485 --> 00:26:41,925
0,360 360,720 720,1035 1035,1260 1260,1440
extremely famous paper a couple

918
00:26:41,925 --> 00:26:43,215
0,240 240,575 685,990 990,1155 1155,1290
years ago showed that if

919
00:26:43,215 --> 00:26:44,600
0,165 165,390 390,705 705,930 930,1385
you put terms that imply

920
00:26:44,830 --> 00:26:46,545
0,400 420,710 710,980 980,1360 1410,1715
female or woman into a

921
00:26:46,545 --> 00:26:48,255
0,240 240,555 555,915 915,1410 1410,1710
large language model powered job

922
00:26:48,255 --> 00:26:49,635
0,240 240,545 835,1155 1155,1260 1260,1380
search engine, you're going to

923
00:26:49,635 --> 00:26:51,080
0,150 150,450 450,735 735,1025 1045,1445
get roles such as artist

924
00:26:51,340 --> 00:26:52,580
0,275 275,440 440,575 575,665 665,1240
or things in the {humanities.,But

925
00:26:53,080 --> 00:26:54,840
0,245 245,365 365,640 900,1300 1380,1760
-} if you input similar

926
00:26:54,840 --> 00:26:55,800
0,330 330,525 525,630 630,750 750,960
things but of the male

927
00:26:55,800 --> 00:26:57,180
0,615 615,825 825,975 975,1155 1155,1380
counterpart, you put things like

928
00:26:57,180 --> 00:26:58,500
0,300 300,615 615,930 930,1170 1170,1320
mail into the the search

929
00:26:58,500 --> 00:27:00,000
0,290 730,1065 1065,1185 1185,1335 1335,1500
engine. You'll end up with

930
00:27:00,000 --> 00:27:02,090
0,290 310,615 615,920 1330,1710 1710,2090
roles for scientists and engineers,

931
00:27:02,800 --> 00:27:05,385
0,400 660,980 980,1190 1190,1480 2010,2585
so this type of bias

932
00:27:05,385 --> 00:27:07,065
0,330 330,665 865,1260 1260,1530 1530,1680
also occurs regardless of the

933
00:27:07,065 --> 00:27:08,475
0,270 270,570 570,875 895,1215 1215,1410
task at hand for a

934
00:27:08,475 --> 00:27:10,020
0,270 270,665
specific model.|

935
00:27:11,190 --> 00:27:12,725
0,290 290,580 750,1130 1130,1310 1310,1535
And finally, let's talk about

936
00:27:12,725 --> 00:27:14,900
0,240 240,435 435,995 1105,1625 1885,2175
health care recommendation algorithms. {These,recommendation

937
00:27:14,900 --> 00:27:16,805
0,615 615,1065 1065,1305 1305,1455 1455,1905
-} algorithms tend to amplify

938
00:27:16,805 --> 00:27:18,575
0,360 360,935 1105,1380 1380,1590 1590,1770
racial {biases.,A -} paper from

939
00:27:18,575 --> 00:27:19,880
0,90 90,240 240,495 495,845 955,1305
a couple years ago showed

940
00:27:19,880 --> 00:27:21,185
0,285 285,555 555,890 910,1185 1185,1305
that black patients need to

941
00:27:21,185 --> 00:27:23,120
0,135 135,425 805,1385 1465,1755 1755,1935
be significantly sicker than their

942
00:27:23,120 --> 00:27:24,455
0,240 240,870 870,1005 1005,1140 1140,1335
white counterparts to get the

943
00:27:24,455 --> 00:27:26,120
0,240 240,480 480,705 705,1025 1375,1665
same level of care, and

944
00:27:26,120 --> 00:27:27,995
0,375 375,630 630,900 900,1425 1425,1875
that's because of inherent bias

945
00:27:27,995 --> 00:27:28,805
0,165 165,285 285,480 480,675 675,810
in the data set of

946
00:27:28,805 --> 00:27:30,425
0,165 165,455 925,1245 1245,1455 1455,1620
{this,model. -} And so in

947
00:27:30,425 --> 00:27:31,640
0,165 165,315 315,540 540,905 955,1215
all of these examples, we

948
00:27:31,640 --> 00:27:33,260
0,150 150,375 375,630 630,950 1090,1620
can use the above algorithmic

949
00:27:33,260 --> 00:27:35,060
0,345 345,795 795,1160 1330,1620 1620,1800
bias mitigation method to try

950
00:27:35,060 --> 00:27:36,470
0,180 180,420 420,705 705,1040 1120,1410
and solve these problems and

951
00:27:36,470 --> 00:27:37,640
0,290
more.|

952
00:27:40,360 --> 00:27:42,000
0,400 690,965 965,1130 1130,1355 1355,1640
So we just went through

953
00:27:42,000 --> 00:27:43,365
0,225 225,360 360,780 780,1095 1095,1365
how to mitigate some forms

954
00:27:43,365 --> 00:27:44,810
0,180 180,510 510,765 765,1080 1080,1445
of bias in artificial intelligence

955
00:27:45,040 --> 00:27:46,365
0,290 290,485 485,665 665,940 1050,1325
and where these solutions may

956
00:27:46,365 --> 00:27:48,150
0,195 195,515 1105,1380 1380,1545 1545,1785
be applied. {And,we -} talked

957
00:27:48,150 --> 00:27:50,100
0,350 370,660 660,1130 1360,1785 1785,1950
about a foundational algorithm that

958
00:27:50,100 --> 00:27:51,405
0,330 330,620 730,1005 1005,1140 1140,1305
themis uses that you all

959
00:27:51,405 --> 00:27:52,670
0,255 255,450 450,585 585,870 870,1265
will also be developing {today.,And

960
00:27:53,410 --> 00:27:54,555
0,395 395,650 650,755 755,950 950,1145
-} for the next part

961
00:27:54,555 --> 00:27:55,970
0,90 90,180 180,425 805,1155 1155,1415
of the lecture, we'll focus

962
00:27:56,020 --> 00:27:57,930
0,400 450,850 1170,1460 1460,1685 1685,1910
on uncertainty or when a

963
00:27:57,930 --> 00:27:59,175
0,290 340,645 645,885 885,1110 1110,1245
model does not know the

964
00:27:59,175 --> 00:28:00,560
0,245
answer.|

965
00:28:00,560 --> 00:28:01,910
0,195 195,360 360,600 600,920 970,1350
We'll talk about why uncertainty

966
00:28:01,910 --> 00:28:03,740
0,315 315,650 940,1260 1260,1575 1575,1830
is important and how we

967
00:28:03,740 --> 00:28:05,240
0,260 310,570 570,825 825,1215 1215,1500
can estimate it, and also

968
00:28:05,240 --> 00:28:07,270
0,285 285,660 660,990 990,1340 1540,2030
the applications of uncertainty estimation.|

969
00:28:08,600 --> 00:28:10,180
0,380 380,635 635,815 815,1120 1260,1580
So, to start with, what

970
00:28:10,180 --> 00:28:11,680
0,315 315,710 880,1185 1185,1365 1365,1500
is uncertainty and why is

971
00:28:11,680 --> 00:28:13,720
0,255 255,570 570,735 735,1130
it necessary to compute?|

972
00:28:13,720 --> 00:28:14,580
0,285 285,375 375,480 480,600 600,860
Let's look at the following

973
00:28:14,690 --> 00:28:16,735
0,400 870,1160 1160,1370 1370,1610 1610,2045
example. {This,is -} a binary

974
00:28:16,735 --> 00:28:18,190
0,615 615,840 840,1005 1005,1245 1245,1455
classifier that is trained on

975
00:28:18,190 --> 00:28:19,650
0,290 310,630 630,930 930,1185 1185,1460
images of cats and {dogs.,For

976
00:28:20,240 --> 00:28:21,805
0,275 275,545 545,940 990,1340 1340,1565
-} every single input, it

977
00:28:21,805 --> 00:28:23,520
0,275 295,555 555,720 720,1235 1315,1715
will output a probability distribution

978
00:28:23,780 --> 00:28:26,380
0,365 365,680 680,935 935,1240
over these two classes.|

979
00:28:27,610 --> 00:28:28,725
0,400 450,785 785,875 875,980 980,1115
Now, let's say I give

980
00:28:28,725 --> 00:28:29,655
0,150 150,375 375,570 570,750 750,930
this model an image of

981
00:28:29,655 --> 00:28:31,200
0,105 105,365 835,1170 1170,1350 1350,1545
a horse. It's never seen

982
00:28:31,200 --> 00:28:32,475
0,105 105,270 270,590 880,1125 1125,1275
a horse before. {The,horse -}

983
00:28:32,475 --> 00:28:33,830
0,210 210,510 510,840 840,1065 1065,1355
is clearly neither a cat

984
00:28:33,850 --> 00:28:35,730
0,260 260,380 380,640 1260,1640 1640,1880
nor a {dog.,However, -} the

985
00:28:35,730 --> 00:28:37,110
0,225 225,540 540,855 855,1155 1155,1380
model has no choice but

986
00:28:37,110 --> 00:28:38,960
0,270 270,645 645,930 930,1430 1450,1850
to output a probability distribution,

987
00:28:39,190 --> 00:28:40,215
0,275 275,545 545,665 665,830 830,1025
because that's how this model

988
00:28:40,215 --> 00:28:42,040
0,195 195,695
is structured.|

989
00:28:42,810 --> 00:28:44,315
0,400 570,845 845,1025 1025,1250 1250,1505
However, what if in addition

990
00:28:44,315 --> 00:28:46,060
0,180 180,330 330,695 985,1365 1365,1745
to this prediction, we also

991
00:28:46,290 --> 00:28:48,800
0,350 350,605 605,910 1290,1690 2220,2510
achieved a confidence estimate, in

992
00:28:48,800 --> 00:28:50,105
0,210 210,530 610,870 870,1065 1065,1305
this case the model which

993
00:28:50,105 --> 00:28:50,950
0,165 165,270 270,405 405,570 570,845
should be able to say,

994
00:28:51,630 --> 00:28:52,910
0,395 395,590 590,905 905,1130 1130,1280
I've never seen anything like

995
00:28:52,910 --> 00:28:53,795
0,165 165,420 420,645 645,750 750,885
this before and I have

996
00:28:53,795 --> 00:28:55,235
0,270 270,615 615,965 1015,1275 1275,1440
very low confidence in this

997
00:28:55,235 --> 00:28:56,810
0,365 655,945 945,1170 1170,1410 1410,1575
prediction. {So,you -} as the

998
00:28:56,810 --> 00:28:57,980
0,260 280,555 555,750 750,975 975,1170
user should not trust my

999
00:28:57,980 --> 00:28:59,675
0,270 270,450 450,585 585,860 1420,1695
prediction on this model, and

1000
00:28:59,675 --> 00:29:01,025
0,285 285,420 420,645 645,975 975,1350
that's the core idea behind

1001
00:29:01,025 --> 00:29:03,080
0,395 535,1025
uncertainty estimation.|

1002
00:29:03,700 --> 00:29:04,880
0,365 365,590 590,710 710,875 875,1180
So in the real world,

1003
00:29:05,050 --> 00:29:06,855
0,400 480,970 990,1250 1250,1510 1530,1805
uncertainty estimation is useful for

1004
00:29:06,855 --> 00:29:08,700
0,390 390,615 615,935 1375,1650 1650,1845
scenarios like this. {This,is -}

1005
00:29:08,700 --> 00:29:10,200
0,225 225,530 580,900 900,1125 1125,1500
an example of a Tesla

1006
00:29:10,200 --> 00:29:11,835
0,285 285,680 880,1200 1200,1410 1410,1635
car driving behind a horse

1007
00:29:11,835 --> 00:29:13,680
0,255 255,755 1195,1470 1470,1635 1635,1845
drawn buggy, which are very

1008
00:29:13,680 --> 00:29:14,610
0,255 255,465 465,630 630,810 810,930
common in some parts of

1009
00:29:14,610 --> 00:29:16,310
0,105 105,345 345,710 1150,1425 1425,1700
the United {States.,It -} has

1010
00:29:16,330 --> 00:29:17,430
0,365 365,635 635,800 800,920 920,1100
no idea what this horse

1011
00:29:17,430 --> 00:29:18,675
0,210 210,510 510,765 765,1050 1050,1245
drawn {buggy,is. -} It first

1012
00:29:18,675 --> 00:29:19,965
0,225 225,465 465,600 600,905 1015,1290
thinks it's a truck and

1013
00:29:19,965 --> 00:29:21,315
0,120 120,285 285,605 955,1230 1230,1350
then a car and then

1014
00:29:21,315 --> 00:29:24,555
0,150 150,455 805,1205 2125,2525 2875,3240
a person, and it continues

1015
00:29:24,555 --> 00:29:26,270
0,330 330,585 585,1095 1095,1380 1380,1715
to output predictions, even though

1016
00:29:26,650 --> 00:29:27,750
0,245 245,365 365,620 620,920 920,1100
it is very clear that

1017
00:29:27,750 --> 00:29:28,935
0,120 120,380 430,720 720,930 930,1185
the model does not know

1018
00:29:28,935 --> 00:29:30,460
0,210 210,360 360,570 570,905
what this image is.|

1019
00:29:32,160 --> 00:29:32,975
0,260 260,440 440,605 605,710 710,815
And now you might be

1020
00:29:32,975 --> 00:29:34,775
0,245 475,875 925,1320 1320,1695 1695,1800
asking, okay, so what's the

1021
00:29:34,775 --> 00:29:36,220
0,150 150,455 625,885 885,1140 1140,1445
big deal? It didn't recognize

1022
00:29:36,390 --> 00:29:37,880
0,245 245,410 410,635 635,1120 1230,1490
the horse drawn buggy, but

1023
00:29:37,880 --> 00:29:39,460
0,260 400,765 765,1020 1020,1245 1245,1580
it seemed to drive successfully

1024
00:29:39,900 --> 00:29:42,515
0,400 1110,1510 1620,1985 1985,2315 2315,2615
anyway. {However,,the -} exact same

1025
00:29:42,515 --> 00:29:44,000
0,330 330,660 660,990 990,1275 1275,1485
problem that resulted in that

1026
00:29:44,000 --> 00:29:45,980
0,320 670,1020 1020,1290 1290,1610 1660,1980
video has also resulted in

1027
00:29:45,980 --> 00:29:49,260
0,320 670,1305 1305,1560 1560,2180
numerous autonomous car crashes.|

1028
00:29:51,210 --> 00:29:52,580
0,365 365,710 710,875 875,1100 1100,1370
So let's go through why

1029
00:29:52,580 --> 00:29:53,735
0,285 285,510 510,735 735,975 975,1155
something like this might have

1030
00:29:53,735 --> 00:29:55,790
0,275 985,1245 1245,1365 1365,1625 1675,2055
happened. {There,are -} multiple different

1031
00:29:55,790 --> 00:29:57,440
0,360 360,690 690,1040 1090,1380 1380,1650
types of uncertainty in neural

1032
00:29:57,440 --> 00:29:59,405
0,290 730,1035 1035,1260 1260,1515 1515,1965
networks, which may cause incidents

1033
00:29:59,405 --> 00:30:00,305
0,225 225,375 375,555 555,750 750,900
like the ones that we

1034
00:30:00,305 --> 00:30:01,880
0,180 180,485 1015,1335 1335,1455 1455,1575
just saw. We'll go through

1035
00:30:01,880 --> 00:30:03,560
0,120 120,410 430,830 940,1200 1200,1680
a simple example that illustrates

1036
00:30:03,560 --> 00:30:04,850
0,225 225,450 450,765 765,1050 1050,1290
the two main types of

1037
00:30:04,850 --> 00:30:06,185
0,350 430,690 690,885 885,1080 1080,1335
uncertainty that we'll focus on

1038
00:30:06,185 --> 00:30:08,040
0,180 180,360 360,665
in this lecture.|

1039
00:30:09,980 --> 00:30:11,395
0,400 480,860 860,995 995,1250 1250,1415
So let's say I'm trying

1040
00:30:11,395 --> 00:30:12,810
0,300 300,570 570,720 720,995 1015,1415
to estimate the curve y

1041
00:30:12,830 --> 00:30:14,185
0,290 290,545 545,965 965,1160 1160,1355
equals X cubed as part

1042
00:30:14,185 --> 00:30:15,970
0,135 135,270 270,645 645,1025 1435,1785
of a regression task. {The,input

1043
00:30:15,970 --> 00:30:18,250
0,255 255,560 610,1010 1720,2040 2040,2280
-} here, X is some

1044
00:30:18,250 --> 00:30:19,945
0,225 225,530 670,1070 1150,1455 1455,1695
real number, and we want

1045
00:30:19,945 --> 00:30:21,310
0,255 255,575 715,1020 1020,1215 1215,1365
it to output f of

1046
00:30:21,310 --> 00:30:23,320
0,240 240,620 1030,1320 1320,1500 1500,2010
X, which should be ideally

1047
00:30:23,320 --> 00:30:24,920
0,270 270,770
X cubed.|

1048
00:30:24,990 --> 00:30:26,450
0,400 420,740 740,1055 1055,1310 1310,1460
So right away you might

1049
00:30:26,450 --> 00:30:27,670
0,240 240,465 465,630 630,870 870,1220
notice that there are some

1050
00:30:27,990 --> 00:30:29,380
0,400 420,680 680,830 830,1055 1055,1390
issues in this data set.

1051
00:30:29,400 --> 00:30:30,785
0,275 275,395 395,545 545,850 1050,1385
{Assume,the -} red points in

1052
00:30:30,785 --> 00:30:32,285
0,285 285,635 655,1005 1005,1260 1260,1500
this image are your training

1053
00:30:32,285 --> 00:30:33,780
0,545
samples.|

1054
00:30:37,040 --> 00:30:38,665
0,380 380,620 620,875 875,1270 1350,1625
So the box area of

1055
00:30:38,665 --> 00:30:41,155
0,165 165,455 985,1385 1585,1985 2125,2490
this image shows data points

1056
00:30:41,155 --> 00:30:42,100
0,210 210,345 345,570 570,795 795,945
in our data set where

1057
00:30:42,100 --> 00:30:43,560
0,135 135,360 360,690 690,1065 1065,1460
we have really high noise.

1058
00:30:44,060 --> 00:30:45,325
0,335 335,635 635,860 860,1025 1025,1265
{These,points -} do not follow

1059
00:30:45,325 --> 00:30:46,210
0,195 195,375 375,570 570,720 720,885
the {curve.,Why -} it equals

1060
00:30:46,210 --> 00:30:47,620
0,255 255,735 735,990 990,1215 1215,1410
{X,cubed. -} In fact, they

1061
00:30:47,620 --> 00:30:48,565
0,195 195,375 375,600 600,750 750,945
don't really seem to follow

1062
00:30:48,565 --> 00:30:50,520
0,300 300,600 600,795 795,1055 1555,1955
any {distribution,at -} all. And

1063
00:30:50,990 --> 00:30:52,975
0,245 245,490 1260,1625 1625,1730 1730,1985
the model won't be able

1064
00:30:52,975 --> 00:30:57,130
0,395 925,1505 2095,2430 2430,2705 3835,4155
to compute outputs for points

1065
00:30:57,130 --> 00:30:59,730
0,195 195,390 390,710 1300,1910 2200,2600
in this region accurately, because

1066
00:31:00,080 --> 00:31:02,070
0,400 420,820 930,1280 1280,1540 1590,1990
very similar inputs have extremely

1067
00:31:02,120 --> 00:31:03,760
0,400 570,1060 1110,1370 1370,1505 1505,1640
different outputs, which is the

1068
00:31:03,760 --> 00:31:06,380
0,260 460,780 780,1100 1180,1580
definition of data uncertainty.|

1069
00:31:09,720 --> 00:31:11,060
0,335 335,560 560,755 755,1055 1055,1340
We also have regions in

1070
00:31:11,060 --> 00:31:12,005
0,165 165,375 375,615 615,795 795,945
this data set where we

1071
00:31:12,005 --> 00:31:13,850
0,240 240,510 510,815 1315,1635 1635,1845
have no data. {So,if -}

1072
00:31:13,850 --> 00:31:15,005
0,180 180,495 495,630 630,890 910,1155
we queried the model for

1073
00:31:15,005 --> 00:31:16,355
0,120 120,435 435,690 690,965 1075,1350
a prediction in this part

1074
00:31:16,355 --> 00:31:17,390
0,165 165,315 315,465 465,720 720,1035
of in this region of

1075
00:31:17,390 --> 00:31:18,910
0,240 240,465 465,800 940,1230 1230,1520
the data set, we should

1076
00:31:18,960 --> 00:31:20,210
0,320 320,635 635,935 935,1130 1130,1250
not really expect to see

1077
00:31:20,210 --> 00:31:21,545
0,225 225,570 570,920 970,1230 1230,1335
an accurate result because the

1078
00:31:21,545 --> 00:31:22,745
0,330 330,510 510,810 810,1050 1050,1200
model's never seen anything like

1079
00:31:22,745 --> 00:31:24,590
0,180 180,485 1255,1545 1545,1710 1710,1845
this {before.,And -} this is

1080
00:31:24,590 --> 00:31:25,990
0,105 105,240 240,510 510,890 1000,1400
what is called model uncertainty

1081
00:31:26,430 --> 00:31:27,680
0,260 260,380 380,605 605,1025 1025,1250
when the model hasn't seen

1082
00:31:27,680 --> 00:31:28,870
0,210 210,420 420,645 645,870 870,1190
enough data points or cannot

1083
00:31:29,130 --> 00:31:30,365
0,305 305,530 530,800 800,1010 1010,1235
estimate that area of the

1084
00:31:30,365 --> 00:31:33,050
0,315 315,665 1465,1950 1950,2255 2305,2685
input distribution accurately enough to

1085
00:31:33,050 --> 00:31:35,860
0,255 255,465 465,800 1270,1760
output a correct prediction.|

1086
00:31:37,320 --> 00:31:38,840
0,400 570,845 845,980 980,1240 1260,1520
So what would happen if

1087
00:31:38,840 --> 00:31:40,445
0,150 150,440 490,780 780,1070 1270,1605
I added the following blue

1088
00:31:40,445 --> 00:31:43,210
0,300 300,665 895,1295 2005,2385 2385,2765
training points to the areas

1089
00:31:43,230 --> 00:31:44,405
0,320 320,545 545,770 770,995 995,1175
of the data set with

1090
00:31:44,405 --> 00:31:46,580
0,275 295,695 745,1145 1795,2040 2040,2175
high model uncertainty? Do you

1091
00:31:46,580 --> 00:31:48,250
0,225 225,480 480,795 795,1190 1270,1670
think the model uncertainty would

1092
00:31:48,390 --> 00:31:50,840
0,400 840,1115 1115,1235 1235,1480
decrease? Raise your hand.|

1093
00:31:52,020 --> 00:31:52,955
0,335 335,530 530,635 635,770 770,935
Does anyone think it would

1094
00:31:52,955 --> 00:31:54,760
0,180 180,485
not change?|

1095
00:31:55,520 --> 00:31:56,710
0,400 450,695 695,845 845,1040 1040,1190
Okay, so yeah, most of

1096
00:31:56,710 --> 00:31:58,590
0,105 105,285 285,620 1030,1430 1480,1880
you were correct. {Model,uncertainty -}

1097
00:31:58,670 --> 00:32:00,295
0,290 290,580 600,980 980,1340 1340,1625
can typically be reduced by

1098
00:32:00,295 --> 00:32:02,050
0,270 270,555 555,875 925,1325 1435,1755
adding in data into any

1099
00:32:02,050 --> 00:32:03,670
0,285 285,555 555,860 970,1335 1335,1620
region, but specifically regions with

1100
00:32:03,670 --> 00:32:05,980
0,255 255,585 585,980
high model uncertainty.|

1101
00:32:06,020 --> 00:32:07,795
0,275 275,550 1050,1325 1325,1550 1550,1775
And now, what happens if

1102
00:32:07,795 --> 00:32:09,580
0,275 415,815 865,1260 1260,1545 1545,1785
we add these blue data

1103
00:32:09,580 --> 00:32:12,330
0,345 345,740 910,1310 2080,2415 2415,2750
points into this data set?

1104
00:32:12,860 --> 00:32:14,550
0,365 365,695 695,1010 1010,1325 1325,1690
Would anyone expect the data

1105
00:32:14,570 --> 00:32:16,360
0,400 510,910 930,1330 1410,1670 1670,1790
uncertainty to decrease? You raise

1106
00:32:16,360 --> 00:32:17,660
0,105 105,350
your hand.|

1107
00:32:18,920 --> 00:32:20,760
0,410 410,700 750,1055 1055,1360 1440,1840
That's correct. {So,data -} uncertainty

1108
00:32:21,050 --> 00:32:23,155
0,335 335,1300 1500,1775 1775,1910 1910,2105
is {irreducible.,In -} the {real,world.

1109
00:32:23,155 --> 00:32:25,225
0,335 535,935 1225,1530 1530,1800 1800,2070
-} The blue points and

1110
00:32:25,225 --> 00:32:26,710
0,305 385,870 870,1065 1065,1290 1290,1485
the noisy red points on

1111
00:32:26,710 --> 00:32:28,465
0,225 225,560 850,1250 1300,1560 1560,1755
this image correspond to things

1112
00:32:28,465 --> 00:32:30,445
0,335 535,840 840,1325 1555,1890 1890,1980
like robot sensors. Let's say

1113
00:32:30,445 --> 00:32:31,705
0,245 385,660 660,795 795,1005 1005,1260
I I have a robot

1114
00:32:31,705 --> 00:32:33,550
0,375 375,720 720,1115 1495,1740 1740,1845
that's trained to has a

1115
00:32:33,550 --> 00:32:35,740
0,470 520,780 780,1040 1090,1490 1600,2190
sensor that is making {measurements,of

1116
00:32:35,740 --> 00:32:38,755
0,320 610,1010 1390,1790 2410,2685 2685,3015
-} depth. If the sensor

1117
00:32:38,755 --> 00:32:40,060
0,180 180,405 405,585 585,845 895,1305
has noise in it, there's

1118
00:32:40,060 --> 00:32:41,125
0,210 210,480 480,675 675,825 825,1065
no way that I can

1119
00:32:41,125 --> 00:32:42,880
0,300 300,600 600,870 870,1205 1405,1755
add any more data into

1120
00:32:42,880 --> 00:32:44,170
0,255 255,555 555,855 855,1080 1080,1290
the system to reduce that

1121
00:32:44,170 --> 00:32:45,595
0,290 370,645 645,900 900,1215 1215,1425
noise, unless I replace my

1122
00:32:45,595 --> 00:32:46,880
0,375 375,695
sensor entirely.|

1123
00:32:49,770 --> 00:32:51,170
0,260 260,425 425,710 710,1000 1050,1400
So now let's assign some

1124
00:32:51,170 --> 00:32:52,805
0,350 610,990 990,1230 1230,1395 1395,1635
names to the types of

1125
00:32:52,805 --> 00:32:53,915
0,330 330,600 600,735 735,885 885,1110
uncertainty that we just talked

1126
00:32:53,915 --> 00:32:55,865
0,335 655,975 975,1200 1200,1505 1645,1950
about. {The,blue -} area, or

1127
00:32:55,865 --> 00:32:57,040
0,165 165,375 375,630 630,855 855,1175
the area of high data

1128
00:32:57,060 --> 00:32:59,300
0,400 540,845 845,1085 1085,1370 1370,2240
uncertainty is known as aloric

1129
00:32:59,300 --> 00:33:01,940
0,380 1180,1440 1440,1605 1605,2415 2415,2640
{uncertainty.,It -} is irreducible, as

1130
00:33:01,940 --> 00:33:03,530
0,150 150,300 300,590 1150,1425 1425,1590
we just mentioned, and it

1131
00:33:03,530 --> 00:33:05,045
0,150 150,345 345,680 760,1160 1210,1515
can be directly learned from

1132
00:33:05,045 --> 00:33:06,200
0,305 325,600 600,795 795,945 945,1155
data, which we'll talk about

1133
00:33:06,200 --> 00:33:07,760
0,135 135,210 210,360 360,680
in a little bit.|

1134
00:33:08,650 --> 00:33:10,755
0,290 290,485 485,790 930,1330 1860,2105
The green areas of the

1135
00:33:10,755 --> 00:33:11,850
0,150 150,455 505,765 765,885 885,1095
green boxes that we talked

1136
00:33:11,850 --> 00:33:13,580
0,350 430,735 735,945 945,1250 1330,1730
about, which were model uncertainty,

1137
00:33:13,840 --> 00:33:15,860
0,305 305,560 560,860 860,1655 1655,2020
are known as epistemic uncertainty,

1138
00:33:16,450 --> 00:33:17,865
0,290 290,560 560,920 920,1175 1175,1415
and this cannot be learned

1139
00:33:17,865 --> 00:33:19,710
0,330 330,570 570,705 705,965 1465,1845
directly from the data. {However,,it

1140
00:33:19,710 --> 00:33:21,120
0,300 300,555 555,840 840,1155 1155,1410
-} can be reduced by

1141
00:33:21,120 --> 00:33:22,350
0,255 255,510 510,750 750,1020 1020,1230
adding more data into our

1142
00:33:22,350 --> 00:33:24,680
0,290 340,675 675,915 915,1220
systems into these regions.|

1143
00:33:30,410 --> 00:33:31,900
0,400 600,860 860,1040 1040,1310 1310,1490
Okay, so first let's go

1144
00:33:31,900 --> 00:33:35,050
0,225 225,960 960,1310 2440,2840 2860,3150
through allatoric uncertainty. {So,the -}

1145
00:33:35,050 --> 00:33:37,590
0,240 240,590 970,1410 1410,2190 2190,2540
goal of estimating allatoric uncertainty

1146
00:33:37,790 --> 00:33:39,040
0,305 305,485 485,725 725,1010 1010,1250
is to learn a set

1147
00:33:39,040 --> 00:33:40,960
0,240 240,915 915,1155 1155,1460 1660,1920
of variances that correspond to

1148
00:33:40,960 --> 00:33:42,480
0,225 225,590
the input.|

1149
00:33:42,490 --> 00:33:43,305
0,260 260,395 395,560 560,710 710,815
Keep in mind that we

1150
00:33:43,305 --> 00:33:44,520
0,120 120,360 360,705 705,1005 1005,1215
are not looking at a

1151
00:33:44,520 --> 00:33:45,945
0,270 270,650 790,1095 1095,1260 1260,1425
data distribution and we are,

1152
00:33:45,945 --> 00:33:47,340
0,225 225,495 495,720 720,990 990,1395
as humans are not estimating

1153
00:33:47,340 --> 00:33:48,765
0,165 165,585 585,930 930,1185 1185,1425
the variance. We're training the

1154
00:33:48,765 --> 00:33:49,880
0,270 270,525 525,645 645,810 810,1115
model to do this task.

1155
00:33:50,470 --> 00:33:51,530
0,305 305,470 470,605 605,770 770,1060
{And,so -} what that means

1156
00:33:51,610 --> 00:33:53,505
0,400 420,820 1260,1550 1550,1730 1730,1895
is typically when we train

1157
00:33:53,505 --> 00:33:54,435
0,135 135,395 445,705 705,825 825,930
a model, we give it

1158
00:33:54,435 --> 00:33:55,845
0,195 195,420 420,695 895,1185 1185,1410
an input X and we

1159
00:33:55,845 --> 00:33:57,380
0,270 270,600 600,915 915,1185 1185,1535
expect an output y hat,

1160
00:33:57,430 --> 00:33:58,545
0,260 260,395 395,530 530,875 875,1115
which is the prediction of

1161
00:33:58,545 --> 00:33:59,860
0,135 135,395
the model.|

1162
00:34:00,100 --> 00:34:01,905
0,400 540,940 960,1250 1250,1520 1520,1805
Now we also predict an

1163
00:34:01,905 --> 00:34:03,660
0,305 475,960 960,1295 1375,1635 1635,1755
additional sigma squared, so we

1164
00:34:03,660 --> 00:34:04,830
0,225 225,525 525,840 840,1050 1050,1170
add another layer to our

1165
00:34:04,830 --> 00:34:06,290
0,290 700,945 945,1035 1035,1170 1170,1460
model. {We,have -} the same

1166
00:34:06,310 --> 00:34:07,875
0,275 275,550 660,965 965,1415 1415,1565
output size that predicts a

1167
00:34:07,875 --> 00:34:09,940
0,420 420,615 615,875 985,1385
variance for every output.|

1168
00:34:11,230 --> 00:34:12,360
0,365 365,575 575,770 770,995 995,1130
So the reason why we

1169
00:34:12,360 --> 00:34:13,470
0,120 120,330 330,555 555,780 780,1110
do this is that we

1170
00:34:13,470 --> 00:34:14,745
0,330 330,585 585,890 910,1155 1155,1275
expect that areas in our

1171
00:34:14,745 --> 00:34:16,130
0,210 210,465 465,720 720,1020 1020,1385
data set with high data

1172
00:34:16,180 --> 00:34:17,760
0,400 750,1040 1040,1220 1220,1370 1370,1580
uncertainty are going to have

1173
00:34:17,760 --> 00:34:19,640
0,300 300,860
higher variance.|

1174
00:34:20,650 --> 00:34:21,900
0,290 290,455 455,730 780,1070 1070,1250
And the crucial thing to

1175
00:34:21,900 --> 00:34:23,190
0,240 240,590 670,930 930,1080 1080,1290
remember here is that this

1176
00:34:23,190 --> 00:34:25,620
0,465 465,750 750,1100 1120,1520 2080,2430
variance is not constant. {It,depends

1177
00:34:25,620 --> 00:34:26,910
0,315 315,555 555,705 705,980 1000,1290
-} on the value of

1178
00:34:26,910 --> 00:34:28,590
0,290 580,870 870,1160 1210,1515 1515,1680
X, we typically tend to

1179
00:34:28,590 --> 00:34:29,730
0,135 135,270 270,705 705,945 945,1140
think of variance as a

1180
00:34:29,730 --> 00:34:31,380
0,225 225,510 510,765 765,1335 1335,1650
single number that parameterizes an

1181
00:34:31,380 --> 00:34:33,900
0,350 460,860 1570,1970 2020,2310 2310,2520
entire {distribution.,However, -} in this

1182
00:34:33,900 --> 00:34:35,310
0,320 520,795 795,960 960,1140 1140,1410
case, we may have areas

1183
00:34:35,310 --> 00:34:36,735
0,240 240,465 465,780 780,1125 1125,1425
of our input distribution with

1184
00:34:36,735 --> 00:34:38,310
0,270 270,570 570,1145 1195,1455 1455,1575
really high variance, and we

1185
00:34:38,310 --> 00:34:39,240
0,135 135,270 270,480 480,705 705,930
may have areas with very

1186
00:34:39,240 --> 00:34:41,295
0,255 255,770 1030,1410 1410,1680 1680,2055
{low,variance. -} So our variance

1187
00:34:41,295 --> 00:34:42,780
0,285 285,635 715,1065 1065,1275 1275,1485
cannot be independent of the

1188
00:34:42,780 --> 00:34:44,130
0,315 315,540 540,780 780,1125 1125,1350
input, and it depends on

1189
00:34:44,130 --> 00:34:46,220
0,255 255,525 525,800
our input X.|

1190
00:34:47,250 --> 00:34:48,365
0,400 420,695 695,815 815,935 935,1115
So now that we have

1191
00:34:48,365 --> 00:34:49,220
0,210 210,465 465,660 660,750 750,855
this model, we have an

1192
00:34:49,220 --> 00:34:50,705
0,260 280,675 675,1035 1035,1245 1245,1485
extra layer attached to it.

1193
00:34:50,705 --> 00:34:52,145
0,300 300,540 540,735 735,1185 1185,1440
{In,addition -} to predicting y

1194
00:34:52,145 --> 00:34:53,405
0,270 270,570 570,810 810,1020 1020,1260
hat, we also predict a

1195
00:34:53,405 --> 00:34:55,340
0,345 345,695 1405,1680 1680,1785 1785,1935
sigma {squared.,How -} do we

1196
00:34:55,340 --> 00:34:57,220
0,225 225,420 420,710
train this model?|

1197
00:34:58,390 --> 00:35:00,120
0,305 305,560 560,860 860,1210 1440,1730
Our current loss function does

1198
00:35:00,120 --> 00:35:01,560
0,210 210,435 435,720 720,1020 1020,1440
not take into account variance

1199
00:35:01,560 --> 00:35:02,850
0,165 165,390 390,740 820,1110 1110,1290
at any point. {This,is -}

1200
00:35:02,850 --> 00:35:04,230
0,180 180,470 490,825 825,1110 1110,1380
your typical mean squared error

1201
00:35:04,230 --> 00:35:05,430
0,285 285,600 600,825 825,960 960,1200
loss function that is used

1202
00:35:05,430 --> 00:35:07,230
0,225 225,390 390,750 750,1130 1540,1800
to train regression {models.,And -}

1203
00:35:07,230 --> 00:35:08,685
0,240 240,420 420,740 910,1245 1245,1455
there's no way training from

1204
00:35:08,685 --> 00:35:10,110
0,165 165,375 375,695 985,1260 1260,1425
this loss function that we

1205
00:35:10,110 --> 00:35:11,295
0,195 195,480 480,810 810,1020 1020,1185
can learn whether or not

1206
00:35:11,295 --> 00:35:12,510
0,165 165,465 465,615 615,900 900,1215
the variance that we're estimating

1207
00:35:12,510 --> 00:35:14,240
0,315 315,710
is accurate.|

1208
00:35:15,210 --> 00:35:16,445
0,365 365,620 620,845 845,1025 1025,1235
So in addition to adding

1209
00:35:16,445 --> 00:35:18,665
0,285 285,605 805,1200 1200,1485 1485,2220
another layer to estimate allatoric

1210
00:35:18,665 --> 00:35:20,840
0,335 865,1265 1435,1800 1800,2025 2025,2175
uncertainty correctly, we also have

1211
00:35:20,840 --> 00:35:22,030
0,165 165,390 390,630 630,855 855,1190
to change our loss function.|

1212
00:35:24,340 --> 00:35:25,700
0,350 350,545 545,725 725,1025 1025,1360
So the mean squared error

1213
00:35:25,990 --> 00:35:29,595
0,400 1500,2015 2015,2285 2285,2650 2850,3605
actually learns A A multivariate

1214
00:35:29,595 --> 00:35:31,215
0,450 450,630 630,795 795,1085 1285,1620
gaussian with a mean Y

1215
00:35:31,215 --> 00:35:33,480
0,335 505,855 855,1205 1285,1895 2005,2265
I and constant variance, and

1216
00:35:33,480 --> 00:35:34,650
0,135 135,300 300,480 480,975 975,1170
we want to generalize this

1217
00:35:34,650 --> 00:35:35,910
0,225 225,560 730,975 975,1095 1095,1260
loss function to when we

1218
00:35:35,910 --> 00:35:37,460
0,165 165,315 315,570 570,950 970,1550
{don't -} have constant variance.|

1219
00:35:40,010 --> 00:35:40,840
0,290 290,425 425,545 545,695 695,830
And the way we do

1220
00:35:40,840 --> 00:35:41,905
0,195 195,420 420,615 615,870 870,1065
this is by changing the

1221
00:35:41,905 --> 00:35:43,120
0,180 180,515 625,855 855,960 960,1215
loss function to the negative

1222
00:35:43,120 --> 00:35:44,875
0,300 300,950 1210,1470 1470,1590 1590,1755
log likelihood. {We,can -} think

1223
00:35:44,875 --> 00:35:45,850
0,210 210,420 420,585 585,780 780,975
about this for now as

1224
00:35:45,850 --> 00:35:47,425
0,135 135,890 910,1185 1185,1335 1335,1575
a generalization of the mean

1225
00:35:47,425 --> 00:35:49,060
0,300 300,570 570,935 1075,1365 1365,1635
squared error loss to non

1226
00:35:49,060 --> 00:35:51,235
0,375 375,1160 1660,1920 1920,2055 2055,2175
constant {variances.,So -} now that

1227
00:35:51,235 --> 00:35:52,285
0,105 105,225 225,390 390,750 750,1050
we have a sigma squared

1228
00:35:52,285 --> 00:35:53,550
0,330 330,555 555,720 720,945 945,1265
term in our loss function,

1229
00:35:53,990 --> 00:35:55,855
0,260 260,470 470,785 785,1150 1290,1865
we can determine how accurately

1230
00:35:55,855 --> 00:35:57,085
0,225 225,600 600,840 840,1050 1050,1230
the sigma and the y

1231
00:35:57,085 --> 00:35:59,080
0,165 165,360 360,905 1135,1740 1740,1995
that we're predicting parameterize {the,distribution.

1232
00:35:59,080 --> 00:36:00,750
0,350 580,885 885,1050 1050,1290 1290,1670
-} That is our input.|

1233
00:36:04,510 --> 00:36:05,715
0,400 480,755 755,890 890,1025 1025,1205
So now that we know

1234
00:36:05,715 --> 00:36:07,370
0,165 165,425 475,735 735,1335 1335,1655
how to estimate alloric uncertainty,

1235
00:36:07,750 --> 00:36:08,760
0,365 365,470 470,575 575,740 740,1010
let's look at a real

1236
00:36:08,760 --> 00:36:11,210
0,330 330,710 1660,1950 1950,2145 2145,2450
world example. {For,this -} task,

1237
00:36:11,230 --> 00:36:13,430
0,350 350,590 590,920 920,1550 1550,2200
we'll focus on semantic segmentation,

1238
00:36:13,900 --> 00:36:14,960
0,260 260,410 410,590 590,770 770,1060
which is when we label

1239
00:36:14,980 --> 00:36:16,430
0,400 420,920 920,1070 1070,1190 1190,1450
every pixel of an image

1240
00:36:16,510 --> 00:36:19,095
0,260 260,440 440,1145 1145,1450 2310,2585
with its corresponding {class.,We -}

1241
00:36:19,095 --> 00:36:20,565
0,135 135,375 375,675 675,995 1075,1470
do this for scene understanding

1242
00:36:20,565 --> 00:36:21,615
0,330 330,540 540,660 660,810 810,1050
and because it is more

1243
00:36:21,615 --> 00:36:22,790
0,300 300,615 615,780 780,900 900,1175
fine grained than a typical

1244
00:36:22,960 --> 00:36:25,120
0,320 320,755 755,1300
object detection algorithm.|

1245
00:36:25,300 --> 00:36:26,660
0,320 320,605 605,950 950,1100 1100,1360
So the inputs of this

1246
00:36:26,710 --> 00:36:27,915
0,245 245,365 365,575 575,905 905,1205
to this data set are

1247
00:36:27,915 --> 00:36:28,890
0,210 210,450 450,735 735,855 855,975
known as it's from a

1248
00:36:28,890 --> 00:36:30,750
0,180 180,390 390,615 615,1280 1510,1860
data set called citycapes, and

1249
00:36:30,750 --> 00:36:32,510
0,315 315,630 630,870 870,1485 1485,1760
the inputs are rgb images

1250
00:36:32,530 --> 00:36:35,085
0,335 335,670 1500,1760 1760,2225 2225,2555
of scenes. {The,labels -} are

1251
00:36:35,085 --> 00:36:37,065
0,450 450,705 705,1295 1435,1740 1740,1980
pixel wise annotations of this

1252
00:36:37,065 --> 00:36:38,690
0,285 285,635 715,1020 1020,1275 1275,1625
entire image, of which label

1253
00:36:38,710 --> 00:36:41,205
0,380 380,860 860,1235 1235,1540 2220,2495
every pixel belongs to, and

1254
00:36:41,205 --> 00:36:42,345
0,255 255,600 600,780 780,930 930,1140
the outputs try to mimic

1255
00:36:42,345 --> 00:36:43,500
0,120 120,510 510,735 735,915 915,1155
the {labels.,There -} are also

1256
00:36:43,500 --> 00:36:46,250
0,390 390,750 750,960 960,1610 2350,2750
predicted pixel wise masks, so

1257
00:36:46,870 --> 00:36:48,105
0,335 335,545 545,755 755,1010 1010,1235
why would we expect that

1258
00:36:48,105 --> 00:36:49,640
0,225 225,495 495,780 780,1115 1135,1535
this data set has high

1259
00:36:49,810 --> 00:36:52,005
0,290 290,950 950,1270 1650,1955 1955,2195
natural allatoric uncertainty? And which

1260
00:36:52,005 --> 00:36:53,060
0,255 255,420 420,540 540,735 735,1055
parts of this data set

1261
00:36:53,140 --> 00:36:54,000
0,230 230,335 335,500 500,680 680,860
do you think would have

1262
00:36:54,000 --> 00:36:55,700
0,585 585,890
allatoric uncertainty?|

1263
00:36:58,880 --> 00:37:01,030
0,365 365,970 1020,1415 1415,1760 1760,2150
Because labeling every single pixel

1264
00:37:01,030 --> 00:37:02,080
0,105 105,210 210,435 435,750 750,1050
of an image is such

1265
00:37:02,080 --> 00:37:03,760
0,210 210,390 390,825 825,1190 1420,1680
a labor intensive task, and

1266
00:37:03,760 --> 00:37:05,020
0,240 240,465 465,765 765,1080 1080,1260
it's also very hard to

1267
00:37:05,020 --> 00:37:06,775
0,260 280,860 1060,1320 1320,1515 1515,1755
do accurately, we would expect

1268
00:37:06,775 --> 00:37:08,580
0,180 180,330 330,905 985,1385 1405,1805
that the boundaries between EM

1269
00:37:09,140 --> 00:37:10,885
0,400 930,1205 1205,1340 1340,1475 1475,1745
between objects in this image

1270
00:37:10,885 --> 00:37:13,300
0,315 315,570 570,1260 1260,1595 2155,2415
have high allatoric uncertainty, and

1271
00:37:13,300 --> 00:37:14,490
0,255 255,495 495,720 720,885 885,1190
that's exactly what we see.

1272
00:37:14,570 --> 00:37:15,535
0,260 260,410 410,575 575,710 710,965
{If,you -} train a model

1273
00:37:15,535 --> 00:37:17,365
0,240 240,420 420,1065 1065,1385 1525,1830
to predict allatoric uncertainty on

1274
00:37:17,365 --> 00:37:19,090
0,195 195,405 405,725 1015,1515 1515,1725
this data set, corners and

1275
00:37:19,090 --> 00:37:20,905
0,510 510,735 735,900 900,1170 1170,1815
boundaries have the highest allator

1276
00:37:20,905 --> 00:37:22,540
0,365 805,1080 1080,1275 1275,1470 1470,1635
uncertainty, because even if your

1277
00:37:22,540 --> 00:37:23,815
0,360 360,570 570,795 795,1035 1035,1275
pixels are like one row

1278
00:37:23,815 --> 00:37:25,230
0,255 255,495 495,720 720,1035 1035,1415
off or one column off,

1279
00:37:25,430 --> 00:37:26,875
0,290 290,755 755,1070 1070,1310 1310,1445
that introduces noise into the

1280
00:37:26,875 --> 00:37:27,620
0,245
model.|

1281
00:37:27,620 --> 00:37:28,850
0,210 210,420 420,675 675,915 915,1230
The model can still learn

1282
00:37:28,850 --> 00:37:29,675
0,240 240,360 360,510 510,660 660,825
in the face of this

1283
00:37:29,675 --> 00:37:31,130
0,305 415,660 660,780 780,1055 1075,1455
noise, but it does exist

1284
00:37:31,130 --> 00:37:32,320
0,225 225,375 375,660 660,855 855,1190
and it can't be reduced.|

1285
00:37:36,240 --> 00:37:37,640
0,400 600,875 875,1010 1010,1145 1145,1400
So now that we know

1286
00:37:37,640 --> 00:37:39,935
0,315 315,650 700,1100 1330,1590 1590,2295
about data uncertainty or allatoric

1287
00:37:39,935 --> 00:37:41,915
0,335 1015,1395 1395,1545 1545,1785 1785,1980
uncertainty, let's move on to

1288
00:37:41,915 --> 00:37:44,555
0,245 265,615 615,1365 1365,1715 2365,2640
learning about epistemic uncertainty. {As,a

1289
00:37:44,555 --> 00:37:46,760
0,150 150,575 715,1485 1485,1835 1945,2205
-} recap, epistemic uncertainty can

1290
00:37:46,760 --> 00:37:48,340
0,210 210,510 510,840 840,1200 1200,1580
best be described as uncertainty

1291
00:37:48,420 --> 00:37:50,375
0,305 305,485 485,760 900,1300 1710,1955
in the model itself, and

1292
00:37:50,375 --> 00:37:51,755
0,120 120,315 315,960 960,1140 1140,1380
it is reducible by adding

1293
00:37:51,755 --> 00:37:53,720
0,345 345,570 570,675 675,935
data to the model.|

1294
00:37:56,360 --> 00:37:58,405
0,365 365,620 620,1220 1220,1570 1680,2045
So with epistemic uncertainty, essentially

1295
00:37:58,405 --> 00:37:59,425
0,225 225,420 420,600 600,780 780,1020
what we're trying to ask

1296
00:37:59,425 --> 00:38:01,120
0,395 565,885 885,1080 1080,1350 1350,1695
is, is the model uncon

1297
00:38:01,120 --> 00:38:03,600
0,560 640,945 945,1125 1125,1490 2080,2480
confidentf about a prediction? So

1298
00:38:03,650 --> 00:38:05,370
0,275 275,530 530,910 930,1325 1325,1720
a really simple and very

1299
00:38:05,510 --> 00:38:06,540
0,320 320,500 500,620 620,755 755,1030
smart way to do this

1300
00:38:06,620 --> 00:38:08,320
0,400 720,1100 1100,1250 1250,1460 1460,1700
is let's say I train

1301
00:38:08,320 --> 00:38:10,140
0,225 225,465 465,800 1000,1400 1420,1820
the same network multiple times

1302
00:38:10,160 --> 00:38:12,520
0,305 305,575 575,1300 1770,2120 2120,2360
with random initializations and I

1303
00:38:12,520 --> 00:38:13,690
0,225 225,465 465,630 630,870 870,1170
ask it to predict the

1304
00:38:13,690 --> 00:38:15,055
0,285 285,650 760,1050 1050,1215 1215,1365
exact I call it on

1305
00:38:15,055 --> 00:38:17,335
0,150 150,425 445,845 1285,1685 1915,2280
the same input. {So,let's -}

1306
00:38:17,335 --> 00:38:18,355
0,90 90,225 225,420 420,690 690,1020
say I give model one

1307
00:38:18,355 --> 00:38:19,690
0,255 255,465 465,750 750,1050 1050,1335
the exact same input, and

1308
00:38:19,690 --> 00:38:21,040
0,300 300,555 555,855 855,1125 1125,1350
the blue X is the

1309
00:38:21,040 --> 00:38:22,800
0,195 195,300 300,465 465,770
output of this model.|

1310
00:38:23,270 --> 00:38:24,310
0,275 275,545 545,815 815,935 935,1040
And then I do the

1311
00:38:24,310 --> 00:38:25,465
0,135 135,315 315,615 615,900 900,1155
same thing again with model

1312
00:38:25,465 --> 00:38:27,895
0,365 1525,1785 1785,1965 1965,2205 2205,2430
two, and then again with

1313
00:38:27,895 --> 00:38:29,560
0,270 270,635
model three.|

1314
00:38:29,630 --> 00:38:30,900
0,305 305,500 500,665 665,905 905,1270
And again, with model four,

1315
00:38:31,100 --> 00:38:32,515
0,320 320,640 660,995 995,1205 1205,1415
these models all have the

1316
00:38:32,515 --> 00:38:34,360
0,285 285,555 555,945 945,1445 1555,1845
exact same hyper parameters, the

1317
00:38:34,360 --> 00:38:35,890
0,225 225,450 450,740 1090,1350 1350,1530
exact same architecture, and their

1318
00:38:35,890 --> 00:38:37,110
0,240 240,420 420,585 585,855 855,1220
train in the same way.

1319
00:38:37,310 --> 00:38:38,800
0,275 275,545 545,940 1020,1295 1295,1490
{The,only -} difference between them

1320
00:38:38,800 --> 00:38:40,030
0,210 210,420 420,660 660,1035 1035,1230
is that their weights are

1321
00:38:40,030 --> 00:38:42,190
0,240 240,780 780,1340 1510,1890 1890,2160
all randomly initialized, so where

1322
00:38:42,190 --> 00:38:43,530
0,210 210,495 495,810 810,1050 1050,1340
they start from is different.|

1323
00:38:45,330 --> 00:38:46,280
0,275 275,395 395,575 575,800 800,950
And the reason why we

1324
00:38:46,280 --> 00:38:47,440
0,135 135,330 330,570 570,825 825,1160
can use this to determine

1325
00:38:47,850 --> 00:38:49,970
0,770 770,1120 1470,1790 1790,1985 1985,2120
epistemic uncertainty is because we

1326
00:38:49,970 --> 00:38:52,000
0,225 225,590 760,1080 1080,1400 1630,2030
would expect that with familiar

1327
00:38:52,350 --> 00:38:54,260
0,500 500,725 725,860 860,1150 1530,1910
inputs in our network, our

1328
00:38:54,260 --> 00:38:55,940
0,375 375,645 645,920 970,1485 1485,1680
networks should all converge to

1329
00:38:55,940 --> 00:38:57,410
0,195 195,390 390,600 600,920 1210,1470
around the same answer, and

1330
00:38:57,410 --> 00:38:58,670
0,150 150,330 330,540 540,860 910,1260
we should see very little

1331
00:38:58,670 --> 00:39:00,485
0,570 570,825 825,1130 1270,1545 1545,1815
variance in the the log

1332
00:39:00,485 --> 00:39:01,610
0,255 255,480 480,780 780,930 930,1125
or the outputs that we're

1333
00:39:01,610 --> 00:39:03,100
0,530
predicting.|

1334
00:39:03,100 --> 00:39:04,360
0,380 430,690 690,810 810,1020 1020,1260
However, if a model has

1335
00:39:04,360 --> 00:39:05,665
0,255 255,495 495,645 645,920 1030,1305
never seen a specific input

1336
00:39:05,665 --> 00:39:06,985
0,275 445,720 720,960 960,1170 1170,1320
before, or that input is

1337
00:39:06,985 --> 00:39:08,680
0,285 285,615 615,825 825,1085 1405,1695
very hard to learn, all

1338
00:39:08,680 --> 00:39:10,165
0,165 165,345 345,650 700,1095 1095,1485
of these models should predict

1339
00:39:10,165 --> 00:39:11,980
0,390 390,720 720,1055 1405,1680 1680,1815
slightly different answers, and the

1340
00:39:11,980 --> 00:39:13,030
0,360 360,525 525,720 720,900 900,1050
variance of them should be

1341
00:39:13,030 --> 00:39:14,095
0,290 460,720 720,840 840,945 945,1065
higher than if they were

1342
00:39:14,095 --> 00:39:16,640
0,420 420,660 660,995 1195,1595
predicting a similar input.|

1343
00:39:18,520 --> 00:39:20,010
0,380 380,710 710,905 905,1385 1385,1490
So creating an ensemble of

1344
00:39:20,010 --> 00:39:21,630
0,260 280,585 585,825 825,1160 1300,1620
networks is quite simple, quite

1345
00:39:21,630 --> 00:39:23,730
0,320 580,980 1300,1575 1575,1785 1785,2100
simple. {You,start -} out with

1346
00:39:23,730 --> 00:39:25,065
0,420 420,525 525,675 675,825 825,1335
defining the number of ensembles

1347
00:39:25,065 --> 00:39:26,265
0,165 165,425 445,765 765,1005 1005,1200
you want, you create them

1348
00:39:26,265 --> 00:39:27,560
0,195 195,435 435,720 720,990 990,1295
all the exact same way,

1349
00:39:27,730 --> 00:39:28,635
0,260 260,395 395,560 560,740 740,905
and then you fit them

1350
00:39:28,635 --> 00:39:29,850
0,195 195,390 390,585 585,885 885,1215
all on the same training

1351
00:39:29,850 --> 00:39:32,540
0,350 370,770 1090,1410 1410,1730
data and training data.|

1352
00:39:33,090 --> 00:39:34,750
0,275 275,440 440,730 1020,1340 1340,1660
And then afterwards, when at

1353
00:39:34,770 --> 00:39:37,280
0,530 530,880 1170,1505 1505,1840 2220,2510
inference time we call all

1354
00:39:37,280 --> 00:39:38,480
0,150 150,270 270,530 550,900 900,1200
of the models, every model

1355
00:39:38,480 --> 00:39:40,460
0,240 240,390 390,1040 1240,1620 1620,1980
in the ensemble on our

1356
00:39:40,460 --> 00:39:43,115
0,380 550,950 1720,2010 2010,2300 2380,2655
specific input, and then we

1357
00:39:43,115 --> 00:39:44,710
0,180 180,485 745,1035 1035,1215 1215,1595
can treat our new prediction

1358
00:39:44,730 --> 00:39:46,235
0,290 290,470 470,760 900,1250 1250,1505
as the average of all

1359
00:39:46,235 --> 00:39:47,855
0,180 180,315 315,965 1045,1365 1365,1620
of the ensembles. {This,results -}

1360
00:39:47,855 --> 00:39:49,145
0,180 180,285 285,540 540,930 930,1290
in a usually more robust

1361
00:39:49,145 --> 00:39:51,515
0,345 345,615 615,965 1705,2100 2100,2370
and accurate prediction, and we

1362
00:39:51,515 --> 00:39:53,090
0,165 165,345 345,585 585,935 1225,1575
can treat the uncertainty as

1363
00:39:53,090 --> 00:39:54,290
0,255 255,705 705,900 900,1065 1065,1200
the variance of all of

1364
00:39:54,290 --> 00:39:57,125
0,165 165,710 1780,2160 2160,2490 2490,2835
these {predictions.,Again, -} remember that

1365
00:39:57,125 --> 00:39:58,685
0,285 285,450 450,645 645,965 1135,1560
if we saw familiar inputs

1366
00:39:58,685 --> 00:40:00,185
0,270 270,540 540,690 690,885 885,1500
or inputs with low epistemic

1367
00:40:00,185 --> 00:40:01,745
0,335 685,960 960,1170 1170,1410 1410,1560
uncertainty, we should expect to

1368
00:40:01,745 --> 00:40:03,470
0,165 165,450 450,750 750,1295 1465,1725
have very {little,variance. -} And

1369
00:40:03,470 --> 00:40:04,490
0,135 135,285 285,495 495,765 765,1020
if we had a very

1370
00:40:04,490 --> 00:40:06,185
0,750 750,1050 1050,1245 1245,1470 1470,1695
unfamiliar input or something that

1371
00:40:06,185 --> 00:40:07,565
0,180 180,375 375,630 630,995 1105,1380
was out of distribution or

1372
00:40:07,565 --> 00:40:08,690
0,195 195,360 360,555 555,945 945,1125
something the model hasn't seen

1373
00:40:08,690 --> 00:40:10,190
0,290 610,885 885,1035 1035,1215 1215,1500
before, we should have very

1374
00:40:10,190 --> 00:40:12,250
0,300 300,960 960,1280 1300,1575 1575,2060
high epistemic uncertainty or variance.|

1375
00:40:15,260 --> 00:40:16,750
0,400 540,905 905,1010 1010,1235 1235,1490
So what's the problem with

1376
00:40:16,750 --> 00:40:18,460
0,285 285,615 615,950 1270,1560 1560,1710
this? Can anyone raise their

1377
00:40:18,460 --> 00:40:19,060
0,135 135,270 270,390 390,510 510,600
hand and tell me what

1378
00:40:19,060 --> 00:40:19,990
0,90 90,300 300,525 525,735 735,930
a problem with training an

1379
00:40:19,990 --> 00:40:22,420
0,465 465,570 570,825 825,1220
ensemble of networks is?|

1380
00:40:25,440 --> 00:40:26,510
0,290 290,485 485,620 620,980 980,1070
So training an ensemble of

1381
00:40:26,510 --> 00:40:28,330
0,255 255,600 600,915 915,1440 1440,1820
networks is really compute expensive.

1382
00:40:29,250 --> 00:40:30,425
0,335 335,545 545,695 695,935 935,1175
{Even,if -} your model is

1383
00:40:30,425 --> 00:40:32,195
0,195 195,435 435,755 985,1385 1405,1770
not very large, training five

1384
00:40:32,195 --> 00:40:33,260
0,390 390,525 525,660 660,840 840,1065
copies of it or ten

1385
00:40:33,260 --> 00:40:35,140
0,360 360,480 480,740 1120,1575 1575,1880
copies of it tends to,

1386
00:40:35,580 --> 00:40:37,100
0,395 395,665 665,830 830,1250 1250,1520
it takes up compute and

1387
00:40:37,100 --> 00:40:38,915
0,320 610,1010 1030,1410 1410,1575 1575,1815
time, and that's just not

1388
00:40:38,915 --> 00:40:40,660
0,285 285,905 955,1260 1260,1485 1485,1745
really feasible when we're training

1389
00:40:41,460 --> 00:40:43,660
0,320 320,620 620,1000
on specific tasks.|

1390
00:40:43,730 --> 00:40:45,580
0,400 450,755 755,1060 1350,1685 1685,1850
However, the key insight for

1391
00:40:45,580 --> 00:40:47,430
0,615 615,870 870,1065 1065,1275 1275,1850
ensembles is that by introducing

1392
00:40:47,480 --> 00:40:49,375
0,320 320,635 635,950 950,1640 1640,1895
some method of randomness or

1393
00:40:49,375 --> 00:40:51,835
0,960 960,1245 1245,1425 1425,1715 2155,2460
stochasticity into our networks, we're

1394
00:40:51,835 --> 00:40:53,790
0,195 195,545 565,885 885,1590 1590,1955
able to estimate epistemic uncertainty.

1395
00:40:54,740 --> 00:40:56,215
0,400 570,875 875,1055 1055,1190 1190,1475
{So,another -} way that we've

1396
00:40:56,215 --> 00:40:59,335
0,305 565,965 1405,2040 2040,2940 2940,3120
seen about introducing stochasticity into

1397
00:40:59,335 --> 00:41:01,090
0,305 445,720 720,870 870,1145 1255,1755
networks is by using dropout

1398
00:41:01,090 --> 00:41:03,235
0,440 940,1290 1290,1455 1455,1800 1800,2145
layers. We've seen dropout layers

1399
00:41:03,235 --> 00:41:04,435
0,165 165,300 300,555 555,885 885,1200
as a method of reducing

1400
00:41:04,435 --> 00:41:06,625
0,755 985,1260 1260,1425 1425,1950 1950,2190
overfitting because we randomly drop

1401
00:41:06,625 --> 00:41:08,515
0,285 285,635 1135,1590 1590,1725 1725,1890
out different nodes in our,

1402
00:41:08,515 --> 00:41:09,940
0,165 165,315 315,605 865,1155 1155,1425
in our layer, and then

1403
00:41:09,940 --> 00:41:11,530
0,345 345,630 630,810 810,1260 1260,1590
we continue to propagate information

1404
00:41:11,530 --> 00:41:12,625
0,225 225,435 435,630 630,780 780,1095
through them and it prevents

1405
00:41:12,625 --> 00:41:15,060
0,330 330,615 615,1110 1110,1475
models from memorizing data.|

1406
00:41:15,190 --> 00:41:17,925
0,400 1080,1400 1400,1655 1655,1990 2370,2735
However, in the EM case

1407
00:41:17,925 --> 00:41:20,025
0,270 270,930 930,1265 1735,1980 1980,2100
of epistemic uncertainty, we can

1408
00:41:20,025 --> 00:41:21,620
0,225 225,630 630,945 945,1215 1215,1595
add dropout layers after every

1409
00:41:21,640 --> 00:41:23,270
0,400 600,965 965,1190 1190,1340 1340,1630
single layer in our model,

1410
00:41:23,620 --> 00:41:25,080
0,290 290,500 500,820 1020,1265 1265,1460
and in addition, we can

1411
00:41:25,080 --> 00:41:26,415
0,225 225,420 420,750 750,1005 1005,1335
keep these dropout layers enabled

1412
00:41:26,415 --> 00:41:28,470
0,300 300,585 585,935 1105,1505 1795,2055
at test time. {Usually,we -}

1413
00:41:28,470 --> 00:41:29,745
0,255 255,420 420,765 765,1020 1020,1275
don't keep dropout layers enabled

1414
00:41:29,745 --> 00:41:30,675
0,210 210,405 405,630 630,825 825,930
at test time because we

1415
00:41:30,675 --> 00:41:31,610
0,210 210,315 315,435 435,615 615,935
don't want to lose any

1416
00:41:31,720 --> 00:41:33,800
0,400 480,815 815,1150 1260,1505 1505,2080
information about the the network's

1417
00:41:34,900 --> 00:41:36,390
0,395 395,650 650,845 845,1265 1265,1490
process or any weights when

1418
00:41:36,390 --> 00:41:38,445
0,195 195,345 345,765 765,1100 1660,2055
we're at inference {time.,However, -}

1419
00:41:38,445 --> 00:41:40,520
0,255 255,605 655,1065 1065,1725 1725,2075
when we're estimating epistemic uncertainty,

1420
00:41:40,840 --> 00:41:41,895
0,290 290,485 485,695 695,875 875,1055
we do want to keep

1421
00:41:41,895 --> 00:41:43,340
0,375 375,675 675,930 930,1140 1140,1445
dropout enabled at test time,

1422
00:41:43,480 --> 00:41:44,570
0,260 260,485 485,620 620,800 800,1090
because that's how we can

1423
00:41:45,040 --> 00:41:46,980
0,320 320,910 990,1490 1490,1730 1730,1940
introduce randomness, inference time as

1424
00:41:46,980 --> 00:41:48,200
0,290
well.|

1425
00:41:48,270 --> 00:41:49,205
0,245 245,350 350,485 485,665 665,935
So what we do here

1426
00:41:49,205 --> 00:41:50,360
0,255 255,420 420,630 630,885 885,1155
is we have one model.

1427
00:41:50,360 --> 00:41:51,395
0,285 285,405 405,585 585,810 810,1035
It's the same model the

1428
00:41:51,395 --> 00:41:52,940
0,210 210,420 420,725 1135,1380 1380,1545
entire way through. {We,add -}

1429
00:41:52,940 --> 00:41:54,125
0,405 405,675 675,795 795,915 915,1185
dropout layers with a specific

1430
00:41:54,125 --> 00:41:55,840
0,635 835,1125 1125,1275 1275,1425 1425,1715
probability, and then we run

1431
00:41:55,980 --> 00:41:57,770
0,400 450,815 815,1180 1410,1655 1655,1790
multiple forward passes and at

1432
00:41:57,770 --> 00:41:59,705
0,255 255,555 555,890 1150,1515 1515,1935
every forward passes, different layers

1433
00:41:59,705 --> 00:42:01,100
0,305 415,765 765,1170 1170,1290 1290,1395
get different nodes in a

1434
00:42:01,100 --> 00:42:02,525
0,195 195,420 420,630 630,950 1180,1425
layer, get dropped {out.,So -}

1435
00:42:02,525 --> 00:42:04,180
0,120 120,300 300,605 925,1290 1290,1655
we have that measure of

1436
00:42:04,260 --> 00:42:06,800
0,635 635,845 845,1690
randomness and stochasticity.|

1437
00:42:07,930 --> 00:42:09,255
0,320 320,605 605,830 830,1010 1010,1325
So again, in order to

1438
00:42:09,255 --> 00:42:10,605
0,345 345,690 690,945 945,1080 1080,1350
implement this, what we have

1439
00:42:10,605 --> 00:42:12,405
0,315 315,555 555,875 1225,1575 1575,1800
is a model with the

1440
00:42:12,405 --> 00:42:13,905
0,275 355,660 660,965 1075,1350 1350,1500
exact one model. {And,then -}

1441
00:42:13,905 --> 00:42:15,225
0,165 165,570 570,840 840,1050 1050,1320
when we're running our forward

1442
00:42:15,225 --> 00:42:16,950
0,365 685,945 945,1095 1095,1365 1365,1725
passes, we can simply run

1443
00:42:16,950 --> 00:42:18,330
0,300 300,585 585,945 945,1230 1230,1380
t forward passes where t

1444
00:42:18,330 --> 00:42:19,215
0,120 120,315 315,480 480,645 645,885
is usually a number like

1445
00:42:19,215 --> 00:42:21,105
0,305 625,1020 1020,1320 1320,1530 1530,1890
twenty {EM.,We -} keep dropout

1446
00:42:21,105 --> 00:42:22,575
0,330 330,585 585,810 810,1145 1195,1470
enabled at test time, and

1447
00:42:22,575 --> 00:42:24,105
0,180 180,420 420,755 775,1170 1170,1530
then we use the mean

1448
00:42:24,105 --> 00:42:26,660
0,270 270,575 835,1395 1395,1775 2155,2555
of these samples as the

1449
00:42:26,920 --> 00:42:28,335
0,305 305,700 720,995 995,1115 1115,1415
new prediction and the variance

1450
00:42:28,335 --> 00:42:30,060
0,225 225,575 655,1170 1170,1470 1470,1725
of these samples as a

1451
00:42:30,060 --> 00:42:32,340
0,225 225,465 465,1080 1080,1430
measure of epistemic uncertainty.|

1452
00:42:34,300 --> 00:42:36,330
0,400 1080,1370 1370,1520 1520,1715 1715,2030
So both of the methods

1453
00:42:36,330 --> 00:42:37,490
0,240 240,435 435,660 660,855 855,1160
we talked about just now

1454
00:42:37,570 --> 00:42:39,615
0,380 380,1000 1110,1400 1400,1790 1790,2045
involves sampling, and sampling is

1455
00:42:39,615 --> 00:42:41,240
0,365 445,840 840,1125 1125,1320 1320,1625
expensive. {Ense,sampling -} is very

1456
00:42:41,290 --> 00:42:42,720
0,400 690,965 965,1145 1145,1310 1310,1430
expensive, but even if you

1457
00:42:42,720 --> 00:42:43,880
0,120 120,270 270,480 480,780 780,1160
have a pretty large model.|

1458
00:42:45,400 --> 00:42:47,470
0,290 610,915 915,1365 1365,1755 1755,2070
Having our introducing dropout layers

1459
00:42:47,470 --> 00:42:48,900
0,180 180,435 435,750 750,1065 1065,1430
and calling twenty forward passes

1460
00:42:49,100 --> 00:42:50,350
0,365 365,590 590,710 710,935 935,1250
might also be something that's

1461
00:42:50,350 --> 00:42:52,980
0,165 165,890 1390,1790 1810,2130 2130,2630
pretty infeasible. {And,at -} themus,

1462
00:42:53,150 --> 00:42:55,675
0,350 350,610 930,1330 1350,1750 2190,2525
we're dedicated to developing innovative

1463
00:42:55,675 --> 00:42:57,780
0,315 315,695 715,1125 1125,1770 1770,2105
methods of estimating epistemic uncertainty

1464
00:42:58,160 --> 00:42:59,545
0,320 320,710 710,950 950,1175 1175,1385
that don't rely on things

1465
00:42:59,545 --> 00:43:00,865
0,210 210,735 735,960 960,1095 1095,1320
like sampling so that they're

1466
00:43:00,865 --> 00:43:02,920
0,165 165,1055 1105,1410 1410,1650 1650,2055
more generalizable and they're usable

1467
00:43:02,920 --> 00:43:04,680
0,195 195,500 1030,1305 1305,1470 1470,1760
by more industries and people.|

1468
00:43:05,680 --> 00:43:07,120
0,350 490,765 765,975 975,1170 1170,1440
So a method that we've

1469
00:43:07,120 --> 00:43:08,980
0,290 400,800 850,1250 1450,1710 1710,1860
developed to estimate a method

1470
00:43:08,980 --> 00:43:10,705
0,150 150,345 345,620 670,1070 1450,1725
that we've studied to estimate

1471
00:43:10,705 --> 00:43:12,780
0,645 645,995 1375,1650 1650,1800 1800,2075
epistemic uncertainty is by using

1472
00:43:12,860 --> 00:43:15,265
0,515 515,1030 1590,1940 1940,2225 2225,2405
generative modeling. {So,we've -} talked

1473
00:43:15,265 --> 00:43:16,465
0,225 225,510 510,765 765,945 945,1200
about V A couple times

1474
00:43:16,465 --> 00:43:18,490
0,335 625,1025 1195,1590 1590,1770 1770,2025
now, but let's say I

1475
00:43:18,490 --> 00:43:20,680
0,255 480,770 1120,1520 1570,1920 1920,2190
trained AV on the exact

1476
00:43:20,680 --> 00:43:21,490
0,210 210,405 405,570 570,675 675,810
same data set we were

1477
00:43:21,490 --> 00:43:22,735
0,240 240,465 465,740 880,1125 1125,1245
talking about earlier, which is

1478
00:43:22,735 --> 00:43:24,970
0,240 240,585 585,870 870,1175 1975,2235
only dogs and {cats.,The -}

1479
00:43:24,970 --> 00:43:26,220
0,330 330,585 585,810 810,960 960,1250
latent space of this model

1480
00:43:26,300 --> 00:43:28,015
0,275 275,425 425,880 1020,1370 1370,1715
would be comprised of features

1481
00:43:28,015 --> 00:43:29,305
0,315 315,585 585,795 795,1020 1020,1290
that relate to dogs {and,cats.

1482
00:43:29,305 --> 00:43:30,520
0,305 565,810 810,915 915,1065 1065,1215
-} And if I give

1483
00:43:30,520 --> 00:43:32,395
0,135 135,330 330,990 990,1280 1570,1875
it a prototypical dog, it

1484
00:43:32,395 --> 00:43:33,325
0,165 165,285 285,480 480,675 675,930
should be able to generate

1485
00:43:33,325 --> 00:43:34,990
0,300 300,540 540,765 765,1425 1425,1665
a pretty good representation of

1486
00:43:34,990 --> 00:43:36,265
0,180 180,470 760,1005 1005,1125 1125,1275
this dog, and it should

1487
00:43:36,265 --> 00:43:38,130
0,210 210,495 495,825 825,1500 1500,1865
have pretty low reconstruction loss.|

1488
00:43:40,580 --> 00:43:41,695
0,365 365,590 590,740 740,935 935,1115
Now, if I gave the

1489
00:43:41,695 --> 00:43:43,230
0,225 225,575 775,1110 1110,1290 1290,1535
same example of the horse

1490
00:43:43,340 --> 00:43:45,510
0,260 260,425 425,575 575,820 1770,2170
to this V A, the

1491
00:43:45,920 --> 00:43:47,260
0,410 410,710 710,965 965,1130 1130,1340
latent vector that this horse

1492
00:43:47,260 --> 00:43:48,730
0,180 180,300 300,780 780,1070 1180,1470
would be decoded to would

1493
00:43:48,730 --> 00:43:50,635
0,180 180,1200 1200,1380 1380,1470 1470,1905
be incomprehensible to the decoder

1494
00:43:50,635 --> 00:43:52,225
0,135 135,300 300,605 985,1230 1230,1590
of this network. {The,decoder -}

1495
00:43:52,225 --> 00:43:53,230
0,270 270,390 390,600 600,825 825,1005
wouldn't be able to know

1496
00:43:53,230 --> 00:43:54,550
0,180 180,390 390,735 735,1005 1005,1320
how to project the latent

1497
00:43:54,550 --> 00:43:56,070
0,290 490,840 840,1095 1095,1260 1260,1520
vector back into the original

1498
00:43:56,180 --> 00:43:58,105
0,335 335,670 1020,1420 1440,1745 1745,1925
input space, and therefore we

1499
00:43:58,105 --> 00:43:59,080
0,195 195,390 390,555 555,750 750,975
should expect to see a

1500
00:43:59,080 --> 00:44:01,405
0,315 315,690 690,1410 1410,1790 2020,2325
much worse reconstruction {here.,And -}

1501
00:44:01,405 --> 00:44:02,665
0,180 180,345 345,635 865,1140 1140,1260
we should see that the

1502
00:44:02,665 --> 00:44:04,200
0,495 495,765 765,990 990,1215 1215,1535
reconstruction loss is much higher

1503
00:44:04,220 --> 00:44:05,170
0,245 245,365 365,530 530,755 755,950
than if we gave the

1504
00:44:05,170 --> 00:44:06,655
0,225 225,480 480,770 1030,1320 1320,1485
model a familiar input or

1505
00:44:06,655 --> 00:44:07,495
0,195 195,360 360,465 465,615 615,840
something that it was used

1506
00:44:07,495 --> 00:44:08,880
0,195 195,455
to seeing.|

1507
00:44:12,970 --> 00:44:14,280
0,400 420,695 695,920 920,1055 1055,1310
So now let's move on

1508
00:44:14,280 --> 00:44:15,465
0,375 375,630 630,795 795,1005 1005,1185
to what I think is

1509
00:44:15,465 --> 00:44:16,850
0,120 120,360 360,690 690,1005 1005,1385
the most exciting method of

1510
00:44:17,200 --> 00:44:19,440
0,460 660,1400 1400,1750 1770,2030 2030,2240
estimating epistemic uncertainty that we'll

1511
00:44:19,440 --> 00:44:21,690
0,165 165,375 375,680 1510,1910 1960,2250
talk about today. {So,in -}

1512
00:44:21,690 --> 00:44:22,790
0,180 180,330 330,480 480,735 735,1100
both of the examples before,

1513
00:44:23,080 --> 00:44:24,920
0,395 395,950 950,1175 1175,1460 1460,1840
EM sampling is compute intensive,

1514
00:44:25,180 --> 00:44:26,730
0,275 275,665 665,1070 1070,1325 1325,1550
but generative modeling can also

1515
00:44:26,730 --> 00:44:28,170
0,120 120,390 390,830 940,1305 1305,1440
be compute intensive. Let's say

1516
00:44:28,170 --> 00:44:29,385
0,135 135,465 465,765 765,1035 1035,1215
you don't actually need a

1517
00:44:29,385 --> 00:44:30,750
0,405 405,645 645,1095 1095,1230 1230,1365
variational auto encoder for your

1518
00:44:30,750 --> 00:44:32,355
0,290 670,945 945,1155 1155,1350 1350,1605
task, then you're training an

1519
00:44:32,355 --> 00:44:33,920
0,285 285,930 930,1140 1140,1290 1290,1565
entire decoder for no reason

1520
00:44:34,180 --> 00:44:35,565
0,335 335,605 605,830 830,1115 1115,1385
and other than to estimate

1521
00:44:35,565 --> 00:44:38,295
0,120 120,675 675,1025 1975,2375 2485,2730
the epistemic uncertainty, so what

1522
00:44:38,295 --> 00:44:39,060
0,135 135,285 285,420 420,555 555,765
if we had a method

1523
00:44:39,060 --> 00:44:40,215
0,240 240,390 390,615 615,915 915,1155
that did not rely on

1524
00:44:40,215 --> 00:44:42,135
0,420 420,900 900,1215 1215,1740 1740,1920
generative modeling or sampling in

1525
00:44:42,135 --> 00:44:43,650
0,150 150,455 505,825 825,990 990,1515
order to estimate the epistemic

1526
00:44:43,650 --> 00:44:44,600
0,320
uncertainty?|

1527
00:44:44,730 --> 00:44:46,090
0,410 410,680 680,935 935,1085 1085,1360
That's exactly what a method

1528
00:44:46,410 --> 00:44:47,735
0,275 275,560 560,850 870,1160 1160,1325
that we've developed here at

1529
00:44:47,735 --> 00:44:50,555
0,330 330,665 1405,1805 2275,2595 2595,2820
themis does. {So,we -} view

1530
00:44:50,555 --> 00:44:52,190
0,305 355,645 645,840 840,1145 1255,1635
learning as an evidence based

1531
00:44:52,190 --> 00:44:53,735
0,380 790,1035 1035,1140 1140,1305 1305,1545
{process.,So -} if you remember

1532
00:44:53,735 --> 00:44:55,000
0,210 210,485 595,855 855,990 990,1265
from earlier when we were

1533
00:44:55,440 --> 00:44:57,140
0,335 335,515 515,1100 1100,1385 1385,1700
training the ensemble and calling

1534
00:44:57,140 --> 00:44:58,930
0,380 400,1125 1125,1365 1365,1515 1515,1790
multiple ensembles on the same

1535
00:44:58,950 --> 00:45:01,445
0,400 810,1160 1160,1445 1445,1780 1830,2495
input, we received multiple predictions

1536
00:45:01,445 --> 00:45:03,130
0,240 240,405 405,885 885,1125 1125,1685
and we calculated that variance.|

1537
00:45:04,260 --> 00:45:05,960
0,400 930,1175 1175,1310 1310,1490 1490,1700
Now, the way we frame

1538
00:45:05,960 --> 00:45:07,505
0,600 600,860 910,1230 1230,1410 1410,1545
evidential learning is what if

1539
00:45:07,505 --> 00:45:08,960
0,225 225,540 540,855 855,1155 1155,1455
we assume that those data

1540
00:45:08,960 --> 00:45:10,970
0,315 315,600 600,1220 1330,1710 1710,2010
points, those predictions, were actually

1541
00:45:10,970 --> 00:45:12,550
0,270 270,450 450,630 630,980 1180,1580
drawn from a distribution themselves.

1542
00:45:13,230 --> 00:45:14,420
0,290 290,455 455,730 750,1025 1025,1190
{If,we -} could estimate the

1543
00:45:14,420 --> 00:45:16,010
0,480 480,720 720,900 900,1215 1215,1590
parameters of this higher order

1544
00:45:16,010 --> 00:45:18,170
0,780 780,1160 1690,1935 1935,2040 2040,2160
evidential distribution, we would be

1545
00:45:18,170 --> 00:45:19,520
0,195 195,405 405,615 615,855 855,1350
able to learn this variance

1546
00:45:19,520 --> 00:45:20,960
0,240 240,405 405,630 630,840 840,1440
or this measure of epistemic

1547
00:45:20,960 --> 00:45:23,450
0,350 790,1190 1600,1950 1950,2220 2220,2490
uncertainty automatically without doing any

1548
00:45:23,450 --> 00:45:25,490
0,510 510,735 735,1125 1125,1640 1780,2040
sampling or generative {modeling.,And -}

1549
00:45:25,490 --> 00:45:27,100
0,255 255,540 540,765 765,1290 1290,1610
that's exactly what evidential uncertainty

1550
00:45:27,150 --> 00:45:28,620
0,400
does.|

1551
00:45:30,920 --> 00:45:32,530
0,400 870,1145 1145,1265 1265,1385 1385,1610
So now that we have

1552
00:45:32,530 --> 00:45:33,910
0,285 285,585 585,795 795,945 945,1380
many methods in our toolbox

1553
00:45:33,910 --> 00:45:37,330
0,380 1210,1620 1620,2310 2310,2660 3040,3420
for estimating epistemic uncertainty, let's

1554
00:45:37,330 --> 00:45:38,305
0,150 150,390 390,585 585,735 735,975
go back to our real

1555
00:45:38,305 --> 00:45:40,120
0,315 315,695
world example.|

1556
00:45:40,120 --> 00:45:42,010
0,270 270,530 940,1335 1335,1680 1680,1890
Let's say again, the input

1557
00:45:42,010 --> 00:45:42,870
0,150 150,300 300,435 435,585 585,860
is the same as before,

1558
00:45:42,950 --> 00:45:44,680
0,320 320,545 545,1100 1100,1360 1380,1730
it's an rgb image of

1559
00:45:44,680 --> 00:45:45,780
0,285 285,525 525,675 675,810 810,1100
some scene in a city,

1560
00:45:46,310 --> 00:45:47,965
0,350 350,700 750,1085 1085,1400 1400,1655
and the output again is

1561
00:45:47,965 --> 00:45:49,330
0,180 180,570 570,795 795,1125 1125,1365
a pixel level mask of

1562
00:45:49,330 --> 00:45:50,605
0,150 150,435 435,900 900,1080 1080,1275
what every pixel in this

1563
00:45:50,605 --> 00:45:52,030
0,305 385,825 825,975 975,1155 1155,1425
image belongs to, which class

1564
00:45:52,030 --> 00:45:53,660
0,240 240,570 570,860
it belongs to.|

1565
00:45:53,700 --> 00:45:55,070
0,335 335,670 690,965 965,1145 1145,1370
Which parts of the data

1566
00:45:55,070 --> 00:45:56,210
0,255 255,465 465,660 660,930 930,1140
set would you expect to

1567
00:45:56,210 --> 00:45:58,760
0,195 195,495 495,1230 1230,1580 2290,2550
have high epistemic uncertainty? In

1568
00:45:58,760 --> 00:46:00,125
0,195 195,530 790,1065 1065,1200 1200,1365
this example, take a look

1569
00:46:00,125 --> 00:46:01,280
0,180 180,455 535,840 840,1020 1020,1155
at the output of the

1570
00:46:01,280 --> 00:46:03,095
0,260 310,710 1060,1320 1320,1530 1530,1815
model itself. {The,model -} does

1571
00:46:03,095 --> 00:46:05,050
0,335 355,705 705,960 960,1380 1380,1955
mostly well on semantic {segmentation.,However,

1572
00:46:05,550 --> 00:46:07,100
0,365 365,590 590,785 785,1025 1025,1550
-} it gets the {sidewalk,wrong.

1573
00:46:07,100 --> 00:46:09,350
0,350 970,1370 1600,2010 2010,2130 2130,2250
-} It assigns some of

1574
00:46:09,350 --> 00:46:10,300
0,120 120,450 450,570 570,675 675,950
the sidewalk to the road,

1575
00:46:10,500 --> 00:46:11,870
0,290 290,515 515,850 930,1220 1220,1370
and other parts of the

1576
00:46:11,870 --> 00:46:14,220
0,315 315,465 465,765 765,1550
sidewalk are labeled incorrectly.|

1577
00:46:15,610 --> 00:46:17,805
0,400 510,785 785,1060 1230,1565 1565,2195
And we can, using epistemic

1578
00:46:17,805 --> 00:46:19,305
0,335 655,900 900,1035 1035,1245 1245,1500
uncertainty, we can see why

1579
00:46:19,305 --> 00:46:20,910
0,210 210,485 865,1140 1140,1380 1380,1605
this is. {The,areas -} of

1580
00:46:20,910 --> 00:46:22,520
0,135 135,585 585,765 765,915 915,1610
the sidewalk that are discolored

1581
00:46:22,540 --> 00:46:24,330
0,335 335,590 590,905 905,1175 1175,1790
have high levels of epistemic

1582
00:46:24,330 --> 00:46:26,280
0,350 940,1275 1275,1470 1470,1665 1665,1950
{uncertainty.,Maybe -} this is because

1583
00:46:26,280 --> 00:46:27,375
0,195 195,390 390,615 615,840 840,1095
the model has never seen

1584
00:46:27,375 --> 00:46:28,620
0,225 225,510 510,735 735,870 870,1245
an example of a sidewalk

1585
00:46:28,620 --> 00:46:29,745
0,165 165,405 405,690 690,945 945,1125
with multiple different colors in

1586
00:46:29,745 --> 00:46:31,125
0,105 105,365 745,1020 1020,1200 1200,1380
it before, or maybe it

1587
00:46:31,125 --> 00:46:32,595
0,270 270,420 420,705 705,1085 1105,1470
hasn't been trained on examples

1588
00:46:32,595 --> 00:46:35,090
0,255 255,780 780,1085 1795,2145 2145,2495
with {sidewalks,generally. -} Either way,

1589
00:46:35,920 --> 00:46:38,205
0,725 725,1040 1040,1310 1310,1895 1895,2285
epistemic uncertainty has isolated this

1590
00:46:38,205 --> 00:46:39,620
0,390 390,780 780,1035 1035,1155 1155,1415
specific area of the image

1591
00:46:39,670 --> 00:46:40,920
0,275 275,410 410,665 665,965 965,1250
as an area of high

1592
00:46:40,920 --> 00:46:42,420
0,380
uncertainty.|

1593
00:46:45,040 --> 00:46:46,700
0,400 420,815 815,1175 1175,1340 1340,1660
So today, we've gone through

1594
00:46:47,320 --> 00:46:49,365
0,395 395,790 840,1240 1410,1760 1760,2045
two major challenges for robust

1595
00:46:49,365 --> 00:46:50,970
0,210 210,485 805,1170 1170,1350 1350,1605
deep learning. We've talked about

1596
00:46:50,970 --> 00:46:52,290
0,525 525,780 780,915 915,1065 1065,1320
bias, which is what happens

1597
00:46:52,290 --> 00:46:53,700
0,255 255,510 510,840 840,1230 1230,1410
when models are skewed by

1598
00:46:53,700 --> 00:46:55,850
0,290 310,710 730,1250 1390,1770 1770,2150
sensitive feature inputs and uncertainty,

1599
00:46:56,140 --> 00:46:57,255
0,275 275,545 545,830 830,980 980,1115
which is when we can

1600
00:46:57,255 --> 00:46:58,640
0,225 225,540 540,825 825,1065 1065,1385
measure a level of confidence

1601
00:46:58,780 --> 00:47:01,100
0,260 260,380 380,575 575,910 1920,2320
of a certain model. {Now,we'll

1602
00:47:01,120 --> 00:47:02,430
0,335 335,500 500,710 710,935 935,1310
-} talk about how themus

1603
00:47:02,430 --> 00:47:03,930
0,255 255,525 525,1095 1095,1290 1290,1500
uses these concepts to build

1604
00:47:03,930 --> 00:47:05,685
0,345 345,740 820,1125 1125,1430 1510,1755
products that transform models to

1605
00:47:05,685 --> 00:47:06,830
0,135 135,315 315,510 510,780 780,1145
make them more risk aware,

1606
00:47:06,970 --> 00:47:08,265
0,290 290,470 470,740 740,980 980,1295
and how we're changing the

1607
00:47:08,265 --> 00:47:09,645
0,335 415,735 735,945 945,1155 1155,1380
AI landscape in terms of

1608
00:47:09,645 --> 00:47:11,980
0,270 270,525 525,1110 1110,1445
safe and trustworthy AI.|

1609
00:47:14,230 --> 00:47:15,780
0,400 420,710 710,1070 1070,1310 1310,1550
So at themis, we believe

1610
00:47:15,780 --> 00:47:17,480
0,285 285,645 645,900 900,1200 1200,1700
that uncertainty and bias mitigation

1611
00:47:17,500 --> 00:47:20,265
0,605 605,1000 1500,1865 1865,2230 2460,2765
unlock a host of new

1612
00:47:20,265 --> 00:47:21,740
0,305 385,645 645,990 990,1170 1170,1475
solutions to solving these problems

1613
00:47:21,880 --> 00:47:23,630
0,305 305,545 545,830 830,1180 1350,1750
with safe and responsible AI.|

1614
00:47:24,490 --> 00:47:25,815
0,275 275,410 410,605 605,1070 1070,1325
We can use bias and

1615
00:47:25,815 --> 00:47:27,570
0,335 505,750 750,1170 1170,1470 1470,1755
uncertainty to mitigate risk in

1616
00:47:27,570 --> 00:47:28,725
0,320 340,660 660,855 855,975 975,1155
every part of the AI

1617
00:47:28,725 --> 00:47:30,525
0,240 240,545 1045,1425 1425,1590 1590,1800
life cycle. Let's start with

1618
00:47:30,525 --> 00:47:32,505
0,435 435,725 1045,1445 1495,1770 1770,1980
labeling data. {Today,,we -} talked

1619
00:47:32,505 --> 00:47:34,395
0,210 210,870 870,1205 1525,1785 1785,1890
about allatoric uncertainty, which is

1620
00:47:34,395 --> 00:47:35,955
0,135 135,390 390,690 690,960 960,1560
a method to detect mislabeled

1621
00:47:35,955 --> 00:47:37,820
0,485 595,870 870,1145 1165,1515 1515,1865
samples, to highlight label noise,

1622
00:47:37,900 --> 00:47:39,195
0,260 260,380 380,640 660,1025 1025,1295
and to generally maybe tell

1623
00:47:39,195 --> 00:47:42,140
0,525 525,905 1585,2175 2175,2435 2545,2945
labelers to relabel images or

1624
00:47:42,160 --> 00:47:43,695
0,530 530,725 725,935 935,1180 1230,1535
samples that they've {gotten.,That -}

1625
00:47:43,695 --> 00:47:45,220
0,180 180,345 345,635
may be wrong.|

1626
00:47:45,340 --> 00:47:46,215
0,245 245,365 365,575 575,770 770,875
In the second part of

1627
00:47:46,215 --> 00:47:47,940
0,135 135,425 565,855 855,1140 1140,1725
this cycle, we have analyzing

1628
00:47:47,940 --> 00:47:49,530
0,210 210,470 760,1125 1125,1365 1365,1590
the data before a model

1629
00:47:49,530 --> 00:47:50,730
0,225 225,465 465,780 780,1005 1005,1200
is even trained on any

1630
00:47:50,730 --> 00:47:52,095
0,320 370,645 645,780 780,1185 1185,1365
data. {We,can -} analyze the

1631
00:47:52,095 --> 00:47:53,220
0,345 345,525 525,690 690,915 915,1125
bias that is present in

1632
00:47:53,220 --> 00:47:54,980
0,210 210,525 525,890 1030,1395 1395,1760
this data set and EM

1633
00:47:55,120 --> 00:47:56,280
0,260 260,410 410,755 755,980 980,1160
tell the creators whether or

1634
00:47:56,280 --> 00:47:57,165
0,150 150,315 315,465 465,660 660,885
not they should add more

1635
00:47:57,165 --> 00:47:59,190
0,525 525,825 825,1530 1530,1755 1755,2025
samples, which demographics, which areas

1636
00:47:59,190 --> 00:48:00,045
0,225 225,315 315,495 495,705 705,855
of the data set are

1637
00:48:00,045 --> 00:48:01,635
0,765 765,1020 1020,1170 1170,1350 1350,1590
underrepresented in the current data

1638
00:48:01,635 --> 00:48:03,105
0,335 475,825 825,1050 1050,1275 1275,1470
set before we even train

1639
00:48:03,105 --> 00:48:04,800
0,105 105,285 285,480 480,755
a model on them.|

1640
00:48:05,160 --> 00:48:06,410
0,275 275,550 630,995 995,1085 1085,1250
And then let's go to

1641
00:48:06,410 --> 00:48:08,255
0,255 255,450 450,710 1300,1590 1590,1845
training the model. {Once,we're -}

1642
00:48:08,255 --> 00:48:09,230
0,210 210,435 435,615 615,795 795,975
actually training a model, if

1643
00:48:09,230 --> 00:48:10,535
0,210 210,435 435,705 705,1005 1005,1305
it's already been trained on

1644
00:48:10,535 --> 00:48:12,080
0,240 240,585 585,825 825,1175 1285,1545
a biased data set, we

1645
00:48:12,080 --> 00:48:13,565
0,150 150,330 330,645 645,855 855,1485
can de bias it adaptively

1646
00:48:13,565 --> 00:48:14,975
0,270 270,635 685,1020 1020,1215 1215,1410
during training using the methods

1647
00:48:14,975 --> 00:48:16,030
0,195 195,330 330,540 540,765 765,1055
that we talked about today.|

1648
00:48:17,300 --> 00:48:19,450
0,275 275,550 1230,1490 1490,1750 1770,2150
And afterwards, we can also

1649
00:48:19,450 --> 00:48:23,305
0,690 690,1040 1930,2600 3100,3615 3615,3855
verify or certify deployed machine

1650
00:48:23,305 --> 00:48:25,270
0,210 210,545 1105,1485 1485,1770 1770,1965
learning models, making sure that

1651
00:48:25,270 --> 00:48:26,440
0,240 240,435 435,675 675,960 960,1170
models that are actually out

1652
00:48:26,440 --> 00:48:27,910
0,225 225,405 405,680 910,1245 1245,1470
there are as safe and

1653
00:48:27,910 --> 00:48:29,215
0,540 540,705 705,900 900,1125 1125,1305
unbiased as they claim they

1654
00:48:29,215 --> 00:48:30,295
0,275 445,705 705,810 810,945 945,1080
are. {And,the -} way we

1655
00:48:30,295 --> 00:48:31,105
0,120 120,270 270,450 450,630 630,810
can do this is by

1656
00:48:31,105 --> 00:48:33,660
0,540 540,1245 1245,1625 1765,2070 2070,2555
leveraging epistemic uncertainty or bias

1657
00:48:33,830 --> 00:48:35,200
0,290 290,560 560,815 815,1235 1235,1370
in order to calculate the

1658
00:48:35,200 --> 00:48:36,520
0,420 420,615 615,840 840,1125 1125,1320
samples or data points that

1659
00:48:36,520 --> 00:48:37,255
0,120 120,315 315,510 510,630 630,735
the model will {do.,The -}

1660
00:48:37,255 --> 00:48:38,590
0,180 180,515 655,915 915,1110 1110,1335
worst on the model has

1661
00:48:38,590 --> 00:48:40,290
0,285 285,680 730,1080 1080,1365 1365,1700
the the most trouble learning

1662
00:48:40,340 --> 00:48:42,145
0,400 450,785 785,1120 1260,1700 1700,1805
or data set samples that

1663
00:48:42,145 --> 00:48:43,810
0,165 165,345 345,555 555,1440 1440,1665
are the most underrepresented in

1664
00:48:43,810 --> 00:48:45,140
0,120 120,345 345,645 645,980
a model data set.|

1665
00:48:45,210 --> 00:48:46,130
0,290 290,425 425,560 560,755 755,920
If we can test the

1666
00:48:46,130 --> 00:48:47,500
0,195 195,435 435,675 675,1080 1080,1370
model on these samples, specifically

1667
00:48:47,700 --> 00:48:48,935
0,275 275,605 605,950 950,1115 1115,1235
the hardest samples for the

1668
00:48:48,935 --> 00:48:50,440
0,245 535,810 810,960 960,1170 1170,1505
model, and it does well,

1669
00:48:50,670 --> 00:48:51,515
0,275 275,410 410,575 575,740 740,845
then we know that the

1670
00:48:51,515 --> 00:48:53,090
0,180 180,420 420,725 775,1175 1225,1575
model has probably been trained

1671
00:48:53,090 --> 00:48:54,395
0,195 195,330 330,555 555,765 765,1305
in a fair and unbiased

1672
00:48:54,395 --> 00:48:57,080
0,305 415,720 720,1215 1215,1595
manner that mitigates uncertainty.|

1673
00:48:57,310 --> 00:48:58,650
0,290 290,815 815,1010 1010,1145 1145,1340
And lastly, we can think

1674
00:48:58,650 --> 00:49:00,195
0,320 400,800 940,1245 1245,1395 1395,1545
about, EM, we, we are

1675
00:49:00,195 --> 00:49:01,530
0,270 270,525 525,750 750,960 960,1335
developing a product at themis

1676
00:49:01,530 --> 00:49:03,585
0,330 585,780 780,1310 1450,1740 1740,2055
called AI guardian, and that's

1677
00:49:03,585 --> 00:49:04,980
0,240 240,480 480,755 835,1140 1140,1395
essentially a layer between the

1678
00:49:04,980 --> 00:49:07,035
0,315 315,680 1300,1740 1740,1920 1920,2055
artificial intelligence algorithm and the

1679
00:49:07,035 --> 00:49:08,370
0,275 655,915 915,1020 1020,1155 1155,1335
user. {And,the -} way this

1680
00:49:08,370 --> 00:49:09,675
0,290 310,710 760,1035 1035,1170 1170,1305
works is this is a

1681
00:49:09,675 --> 00:49:10,920
0,135 135,360 360,735 735,990 990,1245
type of algorithm that if

1682
00:49:10,920 --> 00:49:12,320
0,255 255,465 465,630 630,1110 1110,1400
you're driving an autonomous vehicle,

1683
00:49:12,670 --> 00:49:14,805
0,305 305,610 750,1150 1260,1660 1800,2135
would say, hey, the model

1684
00:49:14,805 --> 00:49:16,275
0,405 405,705 705,1025 1105,1350 1350,1470
doesn't actually know what is

1685
00:49:16,275 --> 00:49:17,280
0,240 240,465 465,570 570,765 765,1005
happening in the world around

1686
00:49:17,280 --> 00:49:18,420
0,150 150,300 300,590 610,945 945,1140
it right {now.,As -} the

1687
00:49:18,420 --> 00:49:19,635
0,260 340,630 630,780 780,990 990,1215
user, you should take control

1688
00:49:19,635 --> 00:49:21,255
0,120 120,225 225,705 705,995 1345,1620
of this autonomous vehicle and

1689
00:49:21,255 --> 00:49:22,410
0,120 120,270 270,480 480,785 835,1155
we can apply this to

1690
00:49:22,410 --> 00:49:24,170
0,420 420,690 690,1260 1260,1470 1470,1760
spears outside autonomy as well.|

1691
00:49:27,050 --> 00:49:28,060
0,305 305,530 530,680 680,845 845,1010
So you'll notice that I

1692
00:49:28,060 --> 00:49:29,725
0,255 255,540 540,920 1000,1350 1350,1665
skipped one, uh, part of

1693
00:49:29,725 --> 00:49:31,150
0,270 270,575 685,1035 1035,1290 1290,1425
the cycle. {I,skipped -} the

1694
00:49:31,150 --> 00:49:32,370
0,180 180,435 435,735 735,960 960,1220
part about building the model

1695
00:49:32,480 --> 00:49:33,760
0,260 260,545 545,755 755,1010 1010,1280
and that's because today we're

1696
00:49:33,760 --> 00:49:34,495
0,75 75,180 180,360 360,555 555,735
going to focus a little

1697
00:49:34,495 --> 00:49:37,150
0,225 225,545 865,1265 1795,2195 2215,2655
bit on EM famous AI's

1698
00:49:37,150 --> 00:49:39,040
0,320 340,705 705,1370 1450,1725 1725,1890
product called capa, which is

1699
00:49:39,040 --> 00:49:40,885
0,210 210,480 480,1095 1095,1400 1570,1845
a model agnostic framework for

1700
00:49:40,885 --> 00:49:43,660
0,275 295,785 1495,1895 2065,2625 2625,2775
risk {estimation.,So -} capa is

1701
00:49:43,660 --> 00:49:44,995
0,195 195,420 420,615 615,920 1090,1335
an open {source,library. -} You

1702
00:49:44,995 --> 00:49:45,910
0,120 120,360 360,600 600,765 765,915
all will actually use it

1703
00:49:45,910 --> 00:49:47,370
0,105 105,225 225,420 420,740 1060,1460
in your lab today, EM,

1704
00:49:47,480 --> 00:49:49,195
0,400 600,1040 1040,1325 1325,1580 1580,1715
that transforms models so that

1705
00:49:49,195 --> 00:49:51,130
0,255 255,510 510,905 1555,1815 1815,1935
{they're,risk -} aware. So this

1706
00:49:51,130 --> 00:49:52,530
0,180 180,420 420,720 720,1050 1050,1400
is a typical training pipeline.

1707
00:49:52,550 --> 00:49:53,530
0,335 335,425 425,560 560,770 770,980
You've seen this many {times,in

1708
00:49:53,530 --> 00:49:54,480
0,135 135,255 255,465 465,675 675,950
-} the course. By now

1709
00:49:54,740 --> 00:49:55,990
0,275 275,500 500,740 740,1010 1010,1250
we have our data, we

1710
00:49:55,990 --> 00:49:57,085
0,135 135,255 255,500 610,885 885,1095
have the model, and it's

1711
00:49:57,085 --> 00:49:58,315
0,105 105,270 270,450 450,725 775,1230
Fed into the training algorithm

1712
00:49:58,315 --> 00:49:59,080
0,195 195,315 315,420 420,555 555,765
and we get a trained

1713
00:49:59,080 --> 00:50:00,265
0,240 240,435 435,570 570,810 810,1185
model at the end that

1714
00:50:00,265 --> 00:50:01,740
0,330 330,495 495,875 955,1215 1215,1475
outputs a prediction for every

1715
00:50:01,850 --> 00:50:02,940
0,400
input.|

1716
00:50:04,320 --> 00:50:05,630
0,260 260,425 425,965 965,1190 1190,1310
But with capa, what we

1717
00:50:05,630 --> 00:50:06,560
0,135 135,330 330,540 540,705 705,930
can do is by adding

1718
00:50:06,560 --> 00:50:08,165
0,285 285,585 585,915 915,1260 1260,1605
a single line into any

1719
00:50:08,165 --> 00:50:10,115
0,330 330,965 1315,1575 1575,1740 1740,1950
training workflow, we can turn

1720
00:50:10,115 --> 00:50:11,360
0,195 195,465 465,765 765,975 975,1245
this model into a risk

1721
00:50:11,360 --> 00:50:13,655
0,300 300,830 1030,1350 1350,1665 1665,2295
aware variant that essentially calculates

1722
00:50:13,655 --> 00:50:15,845
0,665 865,1265 1375,1650 1650,1875 1875,2190
biases, uncertainty and label noise

1723
00:50:15,845 --> 00:50:18,250
0,255 255,545 955,1355 1405,1805 2005,2405
for you. {Because,today, -} as

1724
00:50:19,050 --> 00:50:20,180
0,305 305,440 440,620 620,890 890,1130
you've heard by now, there

1725
00:50:20,180 --> 00:50:21,530
0,195 195,450 450,705 705,1020 1020,1350
are so many methods of

1726
00:50:21,530 --> 00:50:23,660
0,440 550,945 945,1215 1215,1670 1840,2130
estimating uncertainty and bias, and

1727
00:50:23,660 --> 00:50:25,265
0,290 580,900 900,1185 1185,1425 1425,1605
sometimes certain methods are better

1728
00:50:25,265 --> 00:50:26,765
0,180 180,455 715,1050 1050,1230 1230,1500
than others. It's really hard

1729
00:50:26,765 --> 00:50:28,130
0,240 240,525 525,840 840,1080 1080,1365
to determine what kind of

1730
00:50:28,130 --> 00:50:29,735
0,375 375,720 720,915 915,1230 1230,1605
uncertainty you're trying to estimate

1731
00:50:29,735 --> 00:50:30,820
0,285 285,465 465,630 630,795 795,1085
and how to do {so.,So

1732
00:50:30,960 --> 00:50:32,090
0,260 260,620 620,815 815,1010 1010,1130
-} capa takes care of

1733
00:50:32,090 --> 00:50:33,710
0,210 210,495 495,830 880,1155 1155,1620
this {for,you. -} By inserting

1734
00:50:33,710 --> 00:50:34,865
0,255 255,525 525,750 750,930 930,1155
one line into your training

1735
00:50:34,865 --> 00:50:36,575
0,545 595,885 885,1175 1225,1530 1530,1710
workflow, you can achieve a

1736
00:50:36,575 --> 00:50:37,850
0,270 270,585 585,885 885,1140 1140,1275
risk aware model that you

1737
00:50:37,850 --> 00:50:40,060
0,135 135,360 360,660 660,1220
can then further analyze.|

1738
00:50:41,500 --> 00:50:42,645
0,305 305,590 590,845 845,995 995,1145
And so this is the

1739
00:50:42,645 --> 00:50:43,485
0,165 165,360 360,510 510,720 720,840
one line that I've been

1740
00:50:43,485 --> 00:50:45,225
0,275 325,725 835,1185 1185,1500 1500,1740
talking about. {EM,,after -} you

1741
00:50:45,225 --> 00:50:46,230
0,180 180,375 375,645 645,885 885,1005
build your model, you can

1742
00:50:46,230 --> 00:50:47,505
0,195 195,450 450,660 660,1095 1095,1275
just create a wrapper or

1743
00:50:47,505 --> 00:50:48,630
0,135 135,300 300,510 510,690 690,1125
you can call a wrapper

1744
00:50:48,630 --> 00:50:50,445
0,210 210,615 615,890 1060,1460 1480,1815
that capa has an extensive

1745
00:50:50,445 --> 00:50:52,200
0,335 385,785 1105,1380 1380,1545 1545,1755
library {of.,And -} then, in

1746
00:50:52,200 --> 00:50:54,885
0,285 285,650 1030,1455 1455,1880 2350,2685
addition to achieving prediction, receiving

1747
00:50:54,885 --> 00:50:56,325
0,465 465,615 615,735 735,995 1195,1440
predictions from your model, you

1748
00:50:56,325 --> 00:50:57,885
0,195 195,480 480,810 810,1140 1140,1560
can also receive whatever bias

1749
00:50:57,885 --> 00:50:59,175
0,240 240,555 555,960 960,1095 1095,1290
or uncertainty metric that you're

1750
00:50:59,175 --> 00:51:00,920
0,210 210,525 525,905
trying to estimate.|

1751
00:51:03,180 --> 00:51:04,630
0,365 365,575 575,755 755,1190 1190,1450
And the way capsule works

1752
00:51:04,680 --> 00:51:05,720
0,275 275,395 395,545 545,785 785,1040
is it does this by

1753
00:51:05,720 --> 00:51:08,135
0,465 465,770 1390,1665 1665,1940 2020,2415
wrapping models for every uncertainty

1754
00:51:08,135 --> 00:51:09,425
0,495 495,675 675,810 810,990 990,1290
metric that we want to

1755
00:51:09,425 --> 00:51:11,060
0,395 565,840 840,1065 1065,1365 1365,1635
estimate, we can apply and

1756
00:51:11,060 --> 00:51:12,830
0,255 255,465 465,840 840,1095 1095,1770
create the minimal model modifications

1757
00:51:12,830 --> 00:51:14,945
0,380 490,890 1120,1440 1440,1950 1950,2115
as necessary while preserving the

1758
00:51:14,945 --> 00:51:16,690
0,210 210,545 775,1065 1065,1455 1455,1745
initial architecture and predictive capabilities.

1759
00:51:17,700 --> 00:51:18,995
0,260 260,380 380,560 560,725 725,1295
{In,the -} case of allatoric

1760
00:51:18,995 --> 00:51:20,210
0,335 475,765 765,900 900,1020 1020,1215
uncertainty, this could be adding

1761
00:51:20,210 --> 00:51:21,470
0,165 165,300 300,590 880,1140 1140,1260
a new {layer.,In -} the

1762
00:51:21,470 --> 00:51:22,535
0,165 165,315 315,420 420,795 795,1065
case of a variational auto

1763
00:51:22,535 --> 00:51:23,990
0,510 510,705 705,855 855,1095 1095,1455
encoder, this could be creating

1764
00:51:23,990 --> 00:51:25,550
0,270 270,495 495,690 690,1275 1275,1560
and training the decoder and

1765
00:51:25,550 --> 00:51:27,110
0,450 450,585 585,1050 1050,1350 1350,1560
calculating the reconstruction loss on

1766
00:51:27,110 --> 00:51:28,580
0,135 135,410
the fly.|

1767
00:51:29,990 --> 00:51:31,320
0,400 450,710 710,830 830,1010 1010,1330
And this is an example

1768
00:51:31,340 --> 00:51:33,760
0,320 320,880 1200,1600 1620,2020 2160,2420
of capa working on one

1769
00:51:33,760 --> 00:51:34,495
0,105 105,195 195,360 360,570 570,735
of the data sets that

1770
00:51:34,495 --> 00:51:35,695
0,150 150,360 360,570 570,845 925,1200
we talked about today, which

1771
00:51:35,695 --> 00:51:36,715
0,135 135,285 285,570 570,780 780,1020
was the cubic data set

1772
00:51:36,715 --> 00:51:38,010
0,300 300,630 630,885 885,1050 1050,1295
with added noise in it.

1773
00:51:38,120 --> 00:51:39,930
0,365 365,680 680,965 965,1235 1235,1810
{And,also -} another simple classification

1774
00:51:39,950 --> 00:51:41,490
0,400 630,905 905,1025 1025,1205 1205,1540
{task.,And -} the reason why

1775
00:51:41,750 --> 00:51:42,655
0,275 275,455 455,635 635,770 770,905
I wanted to show this

1776
00:51:42,655 --> 00:51:43,765
0,255 255,525 525,690 690,855 855,1110
image is to show that

1777
00:51:43,765 --> 00:51:45,175
0,330 330,780 780,915 915,1110 1110,1410
using capsa, we can achieve

1778
00:51:45,175 --> 00:51:47,040
0,285 285,495 495,765 765,1145 1375,1865
all of these uncertainty estimates

1779
00:51:47,120 --> 00:51:48,970
0,350 350,695 695,1070 1070,1450 1500,1850
with very little additional added

1780
00:51:48,970 --> 00:51:50,440
0,350
work.|

1781
00:51:53,840 --> 00:51:55,165
0,400 450,815 815,1055 1055,1190 1190,1325
So using all of the

1782
00:51:55,165 --> 00:51:56,095
0,225 225,420 420,555 555,720 720,930
products that I just talked

1783
00:51:56,095 --> 00:51:57,870
0,225 225,515 655,930 930,1170 1170,1775
about today and using capa

1784
00:51:58,040 --> 00:51:59,680
0,455 455,650 650,1250 1250,1400 1400,1640
themis is unlocking the key

1785
00:51:59,680 --> 00:52:01,000
0,270 270,510 510,720 720,975 975,1320
to deploy deep learning models

1786
00:52:01,000 --> 00:52:03,325
0,380 520,885 885,1250 1930,2190 2190,2325
safely across fields. {We,can -}

1787
00:52:03,325 --> 00:52:04,435
0,210 210,540 540,810 810,975 975,1110
now answer a lot of

1788
00:52:04,435 --> 00:52:05,575
0,120 120,395 445,705 705,825 825,1140
the questions that the headlines

1789
00:52:05,575 --> 00:52:07,140
0,180 180,405 405,755 1015,1290 1290,1565
were raising earlier, which is

1790
00:52:07,310 --> 00:52:08,605
0,365 365,575 575,710 710,965 965,1295
when should a human take

1791
00:52:08,605 --> 00:52:09,990
0,330 330,540 540,615 615,1095 1095,1385
control of an autonomous vehicle?

1792
00:52:10,550 --> 00:52:11,695
0,305 305,530 530,725 725,935 935,1145
What types of data are

1793
00:52:11,695 --> 00:52:13,795
0,720 720,1005 1005,1305 1305,1845 1845,2100
underrepresented in commercial autonomous driving

1794
00:52:13,795 --> 00:52:15,930
0,545 925,1200 1200,1440 1440,1770 1770,2135
pipelines? We now have educated

1795
00:52:16,100 --> 00:52:17,845
0,400 450,680 680,830 830,1150 1470,1745
answers to these questions due

1796
00:52:17,845 --> 00:52:19,030
0,150 150,390 390,645 645,975 975,1185
to products that themis is

1797
00:52:19,030 --> 00:52:20,380
0,320
developing.|

1798
00:52:21,440 --> 00:52:22,615
0,320 320,530 530,860 860,1010 1010,1175
And in spheres such as

1799
00:52:22,615 --> 00:52:24,205
0,305 385,660 660,870 870,1205 1315,1590
medicine and health care, we

1800
00:52:24,205 --> 00:52:25,405
0,135 135,300 300,585 585,945 945,1200
can now answer questions such

1801
00:52:25,405 --> 00:52:26,760
0,275 415,750 750,960 960,1095 1095,1355
as when is a model

1802
00:52:26,870 --> 00:52:28,240
0,400 450,710 710,830 830,1010 1010,1370
uncertain about a life threatening

1803
00:52:28,240 --> 00:52:30,130
0,500 820,1110 1110,1260 1260,1395 1395,1890
diagnosis? When should this diagnosis

1804
00:52:30,130 --> 00:52:31,200
0,270 270,540 540,735 735,810 810,1070
be passed to a medical

1805
00:52:31,250 --> 00:52:33,250
0,400 720,1070 1070,1400 1400,1745 1745,2000
professional before this information is

1806
00:52:33,250 --> 00:52:35,190
0,390 390,480 480,555 555,800 1540,1940
conveyed to a patient? Or

1807
00:52:35,390 --> 00:52:36,730
0,335 335,575 575,755 755,1025 1025,1340
what types of patients might

1808
00:52:36,730 --> 00:52:38,500
0,285 285,650 700,1170 1170,1395 1395,1770
drug discovery algorithms be biased

1809
00:52:38,500 --> 00:52:39,980
0,350
against?|

1810
00:52:39,980 --> 00:52:41,915
0,150 150,440 670,1050 1050,1430 1630,1935
And today, the, the application

1811
00:52:41,915 --> 00:52:42,740
0,165 165,300 300,465 465,630 630,825
that you guys will focus

1812
00:52:42,740 --> 00:52:44,590
0,320 430,720 720,915 915,1320 1320,1850
on is on facial detection.

1813
00:52:44,910 --> 00:52:46,415
0,350 350,530 530,995 995,1145 1145,1505
You'll use capsa in today's

1814
00:52:46,415 --> 00:52:49,210
0,275 535,935 1435,1965 1965,2460 2460,2795
lab to thoroughly analyze a

1815
00:52:49,440 --> 00:52:51,520
0,400 720,1175 1175,1535 1535,1745 1745,2080
common facial detection data set

1816
00:52:51,570 --> 00:52:52,745
0,260 260,500 500,905 905,1025 1025,1175
that we've perturbed in some

1817
00:52:52,745 --> 00:52:53,780
0,225 225,495 495,735 735,915 915,1035
ways for you so that

1818
00:52:53,780 --> 00:52:54,620
0,120 120,315 315,555 555,720 720,840
you can discover them on

1819
00:52:54,620 --> 00:52:56,525
0,135 135,410 850,1200 1200,1550 1600,1905
your own. {And,we, -} we

1820
00:52:56,525 --> 00:52:57,875
0,305 355,705 705,915 915,1110 1110,1350
highly encourage you to compete

1821
00:52:57,875 --> 00:52:59,975
0,150 150,395 415,815 1285,1685 1765,2100
in the competition, which the

1822
00:52:59,975 --> 00:53:00,950
0,225 225,450 450,690 690,855 855,975
details are described in the

1823
00:53:00,950 --> 00:53:02,555
0,260 400,645 645,890 1000,1365 1365,1605
{lab.,But -} basically it's about

1824
00:53:02,555 --> 00:53:04,300
0,585 585,810 810,1020 1020,1350 1350,1745
analyzing this data set, creating

1825
00:53:04,350 --> 00:53:06,710
0,380 380,755 755,1150 1500,1865 1865,2360
risk aware models that mitigate

1826
00:53:06,710 --> 00:53:08,300
0,405 405,675 675,1040 1150,1425 1425,1590
bias and uncertainty in the

1827
00:53:08,300 --> 00:53:10,320
0,290 310,660 660,1010
specific training pipeline.|

1828
00:53:11,410 --> 00:53:12,735
0,290 290,485 485,680 680,1070 1070,1325
And so at themis our

1829
00:53:12,735 --> 00:53:14,175
0,225 225,435 435,630 630,935 1075,1440
goal is to design, advance,

1830
00:53:14,175 --> 00:53:16,250
0,315 315,645 645,1290 1290,1625 1675,2075
and deploy trustworthy AI across

1831
00:53:16,390 --> 00:53:17,600
0,335 335,575 575,770 770,935 935,1210
industries and around the world.

1832
00:53:18,100 --> 00:53:20,180
0,400 630,1055 1055,1565 1565,1775 1775,2080
{EM,,we're -} passionate about scientific

1833
00:53:20,440 --> 00:53:22,290
0,400 720,1040 1040,1340 1340,1610 1610,1850
{innovation.,We -} release open source

1834
00:53:22,290 --> 00:53:23,340
0,285 285,510 510,645 645,795 795,1050
tools like the ones you'll

1835
00:53:23,340 --> 00:53:25,100
0,180 180,500 910,1230 1230,1455 1455,1760
use today, and our products

1836
00:53:25,420 --> 00:53:26,985
0,365 365,605 605,1100 1100,1310 1310,1565
transform AI workflows and make

1837
00:53:26,985 --> 00:53:29,000
0,360 360,725 775,1275 1275,1595 1615,2015
artificial intelligence safer {for,everyone. -}

1838
00:53:29,590 --> 00:53:31,140
0,275 275,515 515,875 875,1250 1250,1550
We partner with industries around

1839
00:53:31,140 --> 00:53:32,880
0,210 210,500 790,1185 1185,1515 1515,1740
the globe and we're hiring

1840
00:53:32,880 --> 00:53:34,185
0,225 225,420 420,705 705,1005 1005,1305
for the upcoming summer and

1841
00:53:34,185 --> 00:53:35,610
0,195 195,360 360,585 585,905 1195,1425
for {full,time -} roles. So

1842
00:53:35,610 --> 00:53:36,870
0,75 75,405 405,780 780,1080 1080,1260
if you're interested, please send

1843
00:53:36,870 --> 00:53:38,115
0,195 195,480 480,735 735,1080 1080,1245
an email to careers at

1844
00:53:38,115 --> 00:53:39,870
0,330 330,555 555,720 720,1145 1375,1755
famousus I dot io or

1845
00:53:39,870 --> 00:53:41,270
0,360 360,645 645,945 945,1125 1125,1400
apply by submitting your resume

1846
00:53:41,560 --> 00:53:42,680
0,245 245,350 350,515 515,770 770,1120
to the deep learning resume

1847
00:53:42,700 --> 00:53:43,770
0,350 350,590 590,815 815,920 920,1070
drop and we'll see those

1848
00:53:43,770 --> 00:53:44,820
0,405 405,570 570,705 705,900 900,1050
resumes and {get,back -} to

1849
00:53:44,820 --> 00:53:46,540
0,230 250,555 555,860
you. Thank you.|

