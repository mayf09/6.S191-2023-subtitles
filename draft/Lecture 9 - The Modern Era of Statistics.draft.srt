1
00:00:09,270 --> 00:00:11,435
0,305 305,610 810,1160 1160,1510 1770,2165
Thank you. Hi everyone. Thanks

2
00:00:11,435 --> 00:00:13,560
0,395 535,780 780,870 870,1115
Alexander for the introduction.|

3
00:00:13,630 --> 00:00:16,260
0,400 570,950 950,1280 1280,1630 2280,2630
Alright, very excited to talk

4
00:00:16,260 --> 00:00:17,865
0,240 240,530 850,1185 1185,1395 1395,1605
about this modern era of

5
00:00:17,865 --> 00:00:20,220
0,335 955,1275 1275,1560 1560,1835 2035,2355
statistics. You you've heard throughout

6
00:00:20,220 --> 00:00:22,005
0,195 195,680 1030,1380 1380,1590 1590,1785
the lectures, probably a lot

7
00:00:22,005 --> 00:00:23,100
0,225 225,515
about the.|

8
00:00:23,250 --> 00:00:24,500
0,260 260,500 500,755 755,1010 1010,1250
You know, deep learning and

9
00:00:24,500 --> 00:00:26,110
0,105 105,350 460,735 735,1100 1210,1610
the technology that enables this.

10
00:00:26,430 --> 00:00:27,290
0,290 290,425 425,560 560,725 725,860
But what I want to

11
00:00:27,290 --> 00:00:28,415
0,195 195,530 640,885 885,990 990,1125
talk about, I want to

12
00:00:28,415 --> 00:00:30,815
0,275 385,735 735,1085 1495,1895 2125,2400
say why works, okay? So

13
00:00:30,815 --> 00:00:31,895
0,165 165,330 330,480 480,630 630,1080
and give you some intuitions

14
00:00:31,895 --> 00:00:33,980
0,395 565,965 1555,1830 1830,1935 1935,2085
about am where we are

15
00:00:33,980 --> 00:00:35,000
0,270 270,495 495,660 660,840 840,1020
standing in terms of the

16
00:00:35,000 --> 00:00:36,520
0,570 570,840 840,1095 1095,1245 1245,1520
theoretical analysis of this system

17
00:00:37,200 --> 00:00:38,300
0,400 480,725 725,830 830,935 935,1100
because a lot of people

18
00:00:38,300 --> 00:00:39,230
0,210 210,435 435,615 615,765 765,930
think that machine learning is

19
00:00:39,230 --> 00:00:41,110
0,120 120,285 285,740 760,1160 1480,1880
an ad hoc field and

20
00:00:41,400 --> 00:00:42,725
0,290 290,485 485,770 770,1085 1085,1325
deep learning is extremely ad

21
00:00:42,725 --> 00:00:43,955
0,285 285,465 465,690 690,975 975,1230
hoc. This change a couple

22
00:00:43,955 --> 00:00:45,395
0,150 150,435 435,825 825,1155 1155,1440
of hyper parameters and everything

23
00:00:45,395 --> 00:00:47,090
0,225 225,545 955,1230 1230,1500 1500,1695
starts working, but that's not

24
00:00:47,090 --> 00:00:47,825
0,195 195,300 300,435 435,585 585,735
actually the case. So we

25
00:00:47,825 --> 00:00:50,080
0,225 225,575 1255,1635 1635,1815 1815,2255
have some cues like what's

26
00:00:50,130 --> 00:00:51,080
0,380 380,500 500,635 635,770 770,950
what's the whole thing is

27
00:00:51,080 --> 00:00:52,240
0,320 400,800
about, okay.|

28
00:00:53,100 --> 00:00:56,630
0,400 480,880 1380,1780 1860,2560 3270,3530
Alright, so to motivate, I

29
00:00:56,630 --> 00:00:57,400
0,105 105,210 210,345 345,495 495,770
want to tell you about

30
00:00:58,230 --> 00:00:59,400
0,400
this.|

31
00:00:59,400 --> 00:01:01,005
0,350 1000,1275 1275,1395 1395,1545 1545,1605
Ah, I think it's a

32
00:01:01,005 --> 00:01:02,150
0,150 150,405 405,675 675,870 870,1145
very common photo these days

33
00:01:02,290 --> 00:01:03,290
0,260 260,380 380,545 545,725 725,1000
that you can see that

34
00:01:03,910 --> 00:01:05,990
0,400 480,815 815,1265 1265,1540 1680,2080
the more doubling law got

35
00:01:06,190 --> 00:01:08,835
0,400 420,820 1020,1720 2070,2420 2420,2645
broken after 2012 and we

36
00:01:08,835 --> 00:01:11,400
0,275 655,1055 1555,1815 1815,2075 2275,2565
got into kind of a

37
00:01:11,400 --> 00:01:13,005
0,180 180,345 345,495 495,770 1240,1605
new type of models that

38
00:01:13,005 --> 00:01:14,320
0,330 330,695
as we.|

39
00:01:14,510 --> 00:01:16,060
0,305 305,545 545,880 1020,1295 1295,1550
Growth in size on the

40
00:01:16,060 --> 00:01:17,290
0,380 400,705 705,900 900,1065 1065,1230
why access here. What you

41
00:01:17,290 --> 00:01:19,290
0,165 165,315 315,590 730,1130 1600,2000
see is that ah ah,

42
00:01:19,430 --> 00:01:20,910
0,335 335,605 605,830 830,1100 1100,1480
energy consumption of this models.

43
00:01:21,140 --> 00:01:22,375
0,290 290,440 440,515 515,710 710,1235
It could be even accuracy.

44
00:01:22,375 --> 00:01:23,575
0,180 180,425 475,795 795,1110 1110,1200
You know, the accuracy of

45
00:01:23,575 --> 00:01:25,285
0,165 165,435 435,705 705,1380 1380,1710
this models or generalization ability

46
00:01:25,285 --> 00:01:26,755
0,195 195,345 345,635 925,1245 1245,1470
of these models goes higher

47
00:01:26,755 --> 00:01:28,795
0,180 180,455 835,1235 1315,1715 1735,2040
and higher as ah, we

48
00:01:28,795 --> 00:01:30,265
0,210 210,515 745,1035 1035,1185 1185,1470
scale them, okay? And that's

49
00:01:30,265 --> 00:01:31,360
0,120 120,225 225,450 450,815 835,1095
the kind of observation that

50
00:01:31,360 --> 00:01:32,760
0,120 120,315 315,540 540,830
we had so far.|

51
00:01:32,800 --> 00:01:33,735
0,275 275,530 530,635 635,755 755,935
And that's what I mean

52
00:01:33,735 --> 00:01:35,745
0,305 595,960 960,1325 1405,1695 1695,2010
by modern era, because we

53
00:01:35,745 --> 00:01:39,180
0,785 1825,2160 2160,2400 2400,2705
exhaustively increasing their size.|

54
00:01:39,250 --> 00:01:41,880
0,400 780,1180
As these.|

55
00:01:42,020 --> 00:01:43,230
0,365 365,635 635,815 815,950 950,1210
Photo can show you like

56
00:01:43,340 --> 00:01:45,220
0,400 510,860 860,1115 1115,1420 1590,1880
some scale of this large

57
00:01:45,220 --> 00:01:46,270
0,240 240,570 570,795 795,900 900,1050
language models that are out

58
00:01:46,270 --> 00:01:47,725
0,290 700,960 960,1110 1110,1275 1275,1455
there. You can see that

59
00:01:47,725 --> 00:01:49,050
0,165 165,345 345,665 715,1020 1020,1325
we have models up to

60
00:01:49,250 --> 00:01:53,140
0,880 1050,1450 1500,2110 2730,3130 3630,3890
540 billion parameters where, you

61
00:01:53,140 --> 00:01:54,370
0,105 105,300 300,465 465,740 850,1230
know, it's beyond our understanding

62
00:01:54,370 --> 00:01:55,930
0,255 255,420 420,705 705,975 975,1560
how these models perform representation

63
00:01:55,930 --> 00:01:56,920
0,350
learning.|

64
00:01:56,920 --> 00:01:58,660
0,225 225,620 1120,1455 1455,1575 1575,1740
And, ah, it's not only

65
00:01:58,660 --> 00:01:59,665
0,135 135,240 240,435 435,660 660,1005
in the realm of language

66
00:01:59,665 --> 00:02:01,555
0,510 510,705 705,975 975,1325 1585,1890
modeling, but it's also across

67
00:02:01,555 --> 00:02:02,740
0,210 210,465 465,765 765,990 990,1185
like different fields. For example,

68
00:02:02,740 --> 00:02:05,095
0,210 210,435 435,690 690,1190 2080,2355
in time series modeling, in

69
00:02:05,095 --> 00:02:07,255
0,270 270,905 985,1365 1365,1745 1855,2160
medical diagnosis, in financial time

70
00:02:07,255 --> 00:02:08,910
0,305 565,840 840,1095 1095,1365 1365,1655
series, we have new technologies

71
00:02:09,110 --> 00:02:10,510
0,335 335,635 635,950 950,1220 1220,1400
that are getting better and

72
00:02:10,510 --> 00:02:12,510
0,210 210,465 465,770 1210,1605 1605,2000
better with size and am

73
00:02:12,650 --> 00:02:14,050
0,290 290,500 500,680 680,940 1110,1400
this seems to be the

74
00:02:14,050 --> 00:02:14,980
0,290
case.|

75
00:02:15,080 --> 00:02:17,260
0,320 320,605 605,920 920,1630 1830,2180
Across different data modalities and

76
00:02:17,260 --> 00:02:18,940
0,300 300,525 525,705 705,1010 1390,1680
perhaps the one that was

77
00:02:18,940 --> 00:02:21,670
0,290 310,705 705,1100 1750,2390 2470,2730
present before gener modeling we

78
00:02:21,670 --> 00:02:23,880
0,165 165,345 345,480 480,1190
went from in 2014.|

79
00:02:23,880 --> 00:02:26,490
0,555 555,830 1120,1425 1425,1730 2350,2610
Generative models like that to

80
00:02:26,490 --> 00:02:29,090
0,435 435,710 1300,1605 1605,1910 2200,2600
generative models like this, right?

81
00:02:29,230 --> 00:02:31,470
0,245 245,365 365,640 900,1780 1890,2240
So the quality drastically improve,

82
00:02:31,470 --> 00:02:32,430
0,240 240,510 510,750 750,840 840,960
not only because of the

83
00:02:32,430 --> 00:02:34,400
0,290 580,960 960,1340 1450,1710 1710,1970
size, but also the underlying.|

84
00:02:35,520 --> 00:02:39,200
0,400 1020,1325 1325,1750 3120,3455 3455,3680
Structures that enabled us to

85
00:02:39,200 --> 00:02:40,810
0,195 195,375 375,570 570,830 1210,1610
scale this neural networks, because

86
00:02:40,920 --> 00:02:41,870
0,275 275,455 455,650 650,815 815,950
we already knew that if

87
00:02:41,870 --> 00:02:43,520
0,120 120,380 460,860 1150,1470 1470,1650
you have to stack two

88
00:02:43,520 --> 00:02:44,900
0,255 255,405 405,630 630,890 1090,1380
layers of neural networks next

89
00:02:44,900 --> 00:02:46,115
0,135 135,240 240,500 820,1080 1080,1215
to each other, you have

90
00:02:46,115 --> 00:02:48,640
0,195 195,510 510,1205 1405,1805 2125,2525
a universal approximator right? So

91
00:02:49,140 --> 00:02:50,705
0,400 630,935 935,1145 1145,1340 1340,1565
then why couldn't we scale

92
00:02:50,705 --> 00:02:52,340
0,275 325,725 925,1290 1290,1515 1515,1635
it now? We had to

93
00:02:52,340 --> 00:02:53,340
0,150 150,285 285,530
find the right.|

94
00:02:53,340 --> 00:02:54,435
0,380 490,735 735,855 855,990 990,1095
Structure in order to do

95
00:02:54,435 --> 00:02:55,455
0,120 120,270 270,420 420,795 795,1020
that, for example, diffusion was

96
00:02:55,455 --> 00:02:57,140
0,120 120,240 240,515 805,1205 1285,1685
one of those structures that

97
00:02:57,610 --> 00:02:58,900
0,275 275,550
actually presented.|

98
00:02:58,940 --> 00:03:00,670
0,245 245,365 365,530 530,820 1350,1730
So it seems like bigger

99
00:03:00,670 --> 00:03:03,160
0,330 330,680 1090,1490 1570,1970 2200,2490
seems better. But why? Okay,

100
00:03:03,160 --> 00:03:04,950
0,240 240,390 390,680 1240,1515 1515,1790
let's find out the reason.|

101
00:03:06,610 --> 00:03:08,730
0,365 365,605 605,880 1080,1480 1800,2120
So you all am, I

102
00:03:08,730 --> 00:03:09,650
0,195 195,345 345,465 465,615 615,920
assume that you would all

103
00:03:09,700 --> 00:03:10,665
0,290 290,440 440,575 575,755 755,965
know how to solve these

104
00:03:10,665 --> 00:03:12,290
0,195 195,495 495,875 925,1260 1260,1625
two equations. So any equations

105
00:03:12,310 --> 00:03:14,715
0,400 450,850 1110,1475 1475,1840 2160,2405
requires and unknown, right? So

106
00:03:14,715 --> 00:03:15,750
0,90 90,210 210,360 360,635 715,1035
how many of you, you

107
00:03:15,750 --> 00:03:16,875
0,300 300,615 615,825 825,960 960,1125
know, still how to solve

108
00:03:16,875 --> 00:03:18,100
0,195 195,345 345,450 450,695
this kind of thing?|

109
00:03:20,050 --> 00:03:22,560
0,400 720,1120 1920,2210 2210,2345 2345,2510
I, yeah, I think it's

110
00:03:22,560 --> 00:03:24,060
0,260 490,750 750,960 960,1215 1215,1500
pretty. But then the crazy

111
00:03:24,060 --> 00:03:25,080
0,285 285,465 465,630 630,825 825,1020
thing about deep learning is

112
00:03:25,080 --> 00:03:26,990
0,290 730,1020 1020,1275 1275,1575 1575,1910
that it comes says that,

113
00:03:27,160 --> 00:03:28,080
0,400
yeah.|

114
00:03:28,690 --> 00:03:29,850
0,290 290,440 440,635 635,875 875,1160
Make the number of these

115
00:03:29,850 --> 00:03:31,305
0,285 285,480 480,770 850,1215 1215,1455
X and y larger and

116
00:03:31,305 --> 00:03:32,775
0,275 415,960 960,1095 1095,1260 1260,1470
larger excessively. For these two

117
00:03:32,775 --> 00:03:35,265
0,335 895,1170 1170,1445 1975,2280 2280,2490
equations and things, things would

118
00:03:35,265 --> 00:03:36,200
0,305
start.|

119
00:03:36,200 --> 00:03:37,475
0,210 210,510 510,855 855,1125 1125,1275
Working even better. And what

120
00:03:37,475 --> 00:03:38,440
0,120 120,255 255,420 420,630 630,965
does it mean? Even better

121
00:03:38,940 --> 00:03:40,085
0,245 245,335 335,545 545,830 830,1145
when you have two equations

122
00:03:40,085 --> 00:03:41,570
0,240 240,360 360,605 1015,1305 1305,1485
and you have a lot

123
00:03:41,570 --> 00:03:43,200
0,290 370,950
of unknowns?|

124
00:03:43,270 --> 00:03:44,805
0,275 275,425 425,650 650,1000 1230,1535
How does that even make

125
00:03:44,805 --> 00:03:46,185
0,255 255,465 465,725 835,1200 1200,1380
sense? You know, let's do

126
00:03:46,185 --> 00:03:47,715
0,240 240,575 715,1005 1005,1335 1335,1530
an analysis and numerical analysis

127
00:03:47,715 --> 00:03:49,695
0,210 210,485 565,915 915,1265 1645,1980
of the data set. You,

128
00:03:49,695 --> 00:03:51,540
0,270 270,545 1075,1410 1410,1650 1650,1845
you all, ah, seen this

129
00:03:51,540 --> 00:03:52,470
0,225 225,420 420,615 615,840 840,930
data set before. It's a

130
00:03:52,470 --> 00:03:55,605
0,260 610,1010 1600,2180 2680,2970 2970,3135
hundred hundred digit and as

131
00:03:55,605 --> 00:03:56,835
0,195 195,435 435,630 630,900 900,1230
you like it has sixty

132
00:03:56,835 --> 00:03:58,755
0,255 255,575 1045,1335 1335,1575 1575,1920
k points. It has them

133
00:03:58,755 --> 00:04:00,660
0,300 300,540 540,780 780,1235 1585,1905
of twenty by 28 great

134
00:04:00,660 --> 00:04:02,000
0,210 210,500
scale images.|

135
00:04:02,000 --> 00:04:03,800
0,210 210,360 360,825 825,1160 1540,1800
And in today's models, they

136
00:04:03,800 --> 00:04:05,765
0,210 210,555 555,840 840,1340 1720,1965
have millions of parameters to

137
00:04:05,765 --> 00:04:08,980
0,245 385,785 805,1205 1615,2015 2815,3215
model sixty k images. So

138
00:04:09,270 --> 00:04:11,060
0,380 380,760 1110,1385 1385,1550 1550,1790
the performance on this data

139
00:04:11,060 --> 00:04:13,955
0,350 400,705 705,1010 1600,2000 2530,2895
set actually keeps improving as

140
00:04:13,955 --> 00:04:15,970
0,365 1135,1425 1425,1575 1575,1755 1755,2015
we scale the neural networks.|

141
00:04:16,770 --> 00:04:18,920
0,400 810,1070 1070,1205 1205,1480 1830,2150
And how does this make

142
00:04:18,920 --> 00:04:19,870
0,225 225,420 420,570 570,690 690,950
sense? Like there is the

143
00:04:19,890 --> 00:04:21,790
0,400 750,1150 1170,1445 1445,1655 1655,1900
information basically that you're learning

144
00:04:22,170 --> 00:04:24,275
0,320 320,640 810,1210 1500,1835 1835,2105
from sixty image sixty k

145
00:04:24,275 --> 00:04:26,015
0,335 685,1005 1005,1290 1290,1530 1530,1740
images with millions of data?

146
00:04:26,015 --> 00:04:28,240
0,335 1045,1595
Ah, parameters.|

147
00:04:28,680 --> 00:04:30,220
0,260 260,380 380,515 515,790
What are we learning?|

148
00:04:30,590 --> 00:04:32,050
0,380 380,760 900,1160 1160,1295 1295,1460
Now, ah, we know that

149
00:04:32,050 --> 00:04:34,020
0,630 630,980 1090,1410 1410,1650 1650,1970
generalization error or test error

150
00:04:34,280 --> 00:04:35,365
0,290 290,485 485,635 635,815 815,1085
has this kind of proportion

151
00:04:35,365 --> 00:04:37,000
0,210 210,360 360,635 955,1305 1305,1635
from the theory that, ah,

152
00:04:37,000 --> 00:04:38,095
0,315 315,720 720,825 825,930 930,1095
it's proportional to the number

153
00:04:38,095 --> 00:04:39,210
0,195 195,540 540,705 705,840 840,1115
of parameters of the system

154
00:04:39,350 --> 00:04:40,915
0,400 780,1085 1085,1265 1265,1415 1415,1565
over the square root of

155
00:04:40,915 --> 00:04:41,695
0,135 135,255 255,525 525,660 660,780
number of parameters of the

156
00:04:41,695 --> 00:04:43,675
0,275 655,1020 1020,1385 1435,1755 1755,1980
system over the data set

157
00:04:43,675 --> 00:04:44,875
0,305 445,705 705,840 840,975 975,1200
size. That means if I

158
00:04:44,875 --> 00:04:46,120
0,270 270,435 435,615 615,840 840,1245
increase the number of parameters

159
00:04:46,120 --> 00:04:47,815
0,195 195,360 360,650 1270,1545 1545,1695
of my system, then I

160
00:04:47,815 --> 00:04:49,350
0,270 270,645 645,960 960,1215 1215,1535
would expect at some point

161
00:04:49,490 --> 00:04:51,090
0,305 305,1010 1010,1220 1220,1340 1340,1600
that generalization or the error

162
00:04:51,110 --> 00:04:52,660
0,305 305,610
was high.|

163
00:04:53,010 --> 00:04:54,190
0,335 335,560 560,710 710,875 875,1180
Then why is it that

164
00:04:54,570 --> 00:04:55,790
0,260 260,410 410,700 720,1040 1040,1220
we make them larger and

165
00:04:55,790 --> 00:04:57,860
0,260 430,690 690,810 810,1070
larger, but they work?|

166
00:04:58,530 --> 00:04:59,675
0,275 275,425 425,575 575,830 830,1145
In case of image net

167
00:04:59,675 --> 00:05:00,995
0,180 180,425 475,840 840,1080 1080,1320
and other large scale data

168
00:05:00,995 --> 00:05:02,630
0,365 565,810 810,975 975,1295 1375,1635
set a very common machine

169
00:05:02,630 --> 00:05:04,115
0,260 310,570 570,705 705,885 885,1485
learning, we have like 1.4

170
00:05:04,115 --> 00:05:06,160
0,305 535,855 855,1175
million ah images.|

171
00:05:06,160 --> 00:05:07,510
0,195 195,500 580,855 855,1095 1095,1350
Of size two, fifty six,

172
00:05:07,510 --> 00:05:09,010
0,150 150,360 360,630 630,950 1210,1500
two fifty six three, and

173
00:05:09,010 --> 00:05:10,885
0,290 460,720 720,980 1300,1650 1650,1875
then you have models with

174
00:05:10,885 --> 00:05:12,270
0,225 225,480 480,735 735,960 960,1385
hundreds of millions of parameters

175
00:05:12,560 --> 00:05:14,215
0,275 275,425 425,700 780,1085 1085,1655
that you fit this 1.4

176
00:05:14,215 --> 00:05:16,180
0,305 475,875
million images.|

177
00:05:16,520 --> 00:05:17,470
0,275 275,410 410,560 560,755 755,950
In N L P, as

178
00:05:17,470 --> 00:05:18,630
0,150 150,300 300,590 640,900 900,1160
we showed before, we have

179
00:05:19,010 --> 00:05:20,695
0,320 320,545 545,755 755,1060 1140,1685
data points of few billions

180
00:05:20,695 --> 00:05:21,940
0,195 195,455 475,825 825,1035 1035,1245
and then models with hundred

181
00:05:21,940 --> 00:05:22,980
0,500
billions.|

182
00:05:23,780 --> 00:05:24,820
0,260 260,410 410,635 635,875 875,1040
And then, perhaps like the

183
00:05:24,820 --> 00:05:27,610
0,260 1120,1410 1410,1700 2440,2685 2685,2790
best, my favorite kind of

184
00:05:27,610 --> 00:05:29,515
0,495 495,705 705,980 1060,1460 1510,1905
illustration of this size, improving

185
00:05:29,515 --> 00:05:31,080
0,345 345,540 540,765 765,1275 1275,1565
performance in this generative I.|

186
00:05:31,660 --> 00:05:32,665
0,180 180,315 315,540 540,795 795,1005
When you have a prompt,

187
00:05:32,665 --> 00:05:33,610
0,165 165,285 285,420 420,555 555,945
this is like a generative

188
00:05:33,610 --> 00:05:34,990
0,225 225,360 360,675 675,1010 1090,1380
I that receives text input

189
00:05:34,990 --> 00:05:37,140
0,165 165,590 700,990 990,1280
and generates output images.|

190
00:05:37,140 --> 00:05:38,235
0,210 210,345 345,615 615,885 885,1095
So the prompt or the

191
00:05:38,235 --> 00:05:39,260
0,210 210,315 315,435 435,675 675,1025
input to this system was

192
00:05:39,520 --> 00:05:40,695
0,275 275,620 620,830 830,1025 1025,1175
a portrait photo of a

193
00:05:40,695 --> 00:05:42,560
0,450 450,755 925,1185 1185,1395 1395,1865
kangaroo wearing an orange hy

194
00:05:42,790 --> 00:05:45,555
0,350 350,700 1230,2020 2250,2570 2570,2765
and blue sunglasses, standing on

195
00:05:45,555 --> 00:05:46,635
0,150 150,425 475,765 765,930 930,1080
the grass in front of

196
00:05:46,635 --> 00:05:48,285
0,150 150,345 345,705 705,965 1285,1650
the city opera house, holding

197
00:05:48,285 --> 00:05:49,545
0,255 255,545 625,885 885,1035 1035,1260
a sign on the chest

198
00:05:49,545 --> 00:05:51,160
0,225 225,435 435,720 720,1085
that says welcome friends.|

199
00:05:51,550 --> 00:05:52,800
0,245 245,395 395,575 575,850 960,1250
And as we see that

200
00:05:52,800 --> 00:05:54,015
0,165 165,405 405,645 645,915 915,1215
on the top of each

201
00:05:54,015 --> 00:05:54,855
0,225 225,390 390,510 510,660 660,840
image, we have the size

202
00:05:54,855 --> 00:05:57,345
0,305 805,1080 1080,1355 2005,2295 2295,2490
of the model, and as

203
00:05:57,345 --> 00:05:58,440
0,255 255,465 465,615 615,855 855,1095
we improve the quality of

204
00:05:58,440 --> 00:05:59,955
0,290 850,1125 1125,1275 1275,1410 1410,1515
the, the size of the

205
00:05:59,955 --> 00:06:01,770
0,245 355,645 645,935 985,1505 1555,1815
models, the quality improves. And

206
00:06:01,770 --> 00:06:02,910
0,150 150,330 330,615 615,870 870,1140
we're getting closer and closer

207
00:06:02,910 --> 00:06:04,710
0,195 195,440 910,1310 1330,1590 1590,1800
to that description that we

208
00:06:04,710 --> 00:06:06,380
0,350
provided.|

209
00:06:08,440 --> 00:06:09,240
0,260 260,425 425,605 605,710 710,800
As an input to the

210
00:06:09,240 --> 00:06:10,600
0,260 460,860
system, right?|

211
00:06:10,940 --> 00:06:12,190
0,275 275,410 410,560 560,850 900,1250
Like the first image actually

212
00:06:12,190 --> 00:06:13,660
0,645 645,975 975,1140 1140,1290 1290,1470
350 it's still like, has

213
00:06:13,660 --> 00:06:14,995
0,180 180,435 435,780 780,1050 1050,1335
all the components of that

214
00:06:14,995 --> 00:06:16,165
0,395 565,810 810,945 945,1020 1020,1170
input, but it's not as

215
00:06:16,165 --> 00:06:17,080
0,165 165,285 285,405 405,600 600,915
good as the last one,

216
00:06:17,080 --> 00:06:18,040
0,380
right?|

217
00:06:18,370 --> 00:06:19,845
0,320 320,695 695,970 1050,1325 1325,1475
It misses on a couple

218
00:06:19,845 --> 00:06:21,500
0,150 150,425
of things.|

219
00:06:22,010 --> 00:06:25,410
0,400 540,940 2340,2645 2645,2950 3000,3400
Alright, so this happens, and

220
00:06:26,390 --> 00:06:27,745
0,395 395,670 720,1025 1025,1205 1205,1355
let's now figure out a

221
00:06:27,745 --> 00:06:29,700
0,225 225,575 745,1035 1035,1325 1555,1955
way to explain this. Okay,

222
00:06:30,020 --> 00:06:30,910
0,275 275,425 425,575 575,725 725,890
how many of you have

223
00:06:30,910 --> 00:06:32,935
0,225 225,560 1150,1410 1410,1845 1845,2025
heard about a phenomenon called

224
00:06:32,935 --> 00:06:34,780
0,240 240,755
double descent?|

225
00:06:37,360 --> 00:06:38,860
0,400
One.|

226
00:06:39,090 --> 00:06:40,540
0,400
Two.|

227
00:06:41,950 --> 00:06:43,580
0,275 275,440 440,730
All right, so.|

228
00:06:43,770 --> 00:06:45,635
0,290 290,485 485,790 1500,1760 1760,1865
All right, so this is

229
00:06:45,635 --> 00:06:47,500
0,105 105,225 225,435 435,785 1465,1865
not a learning curve first.|

230
00:06:48,160 --> 00:06:49,675
0,165 165,710 790,1110 1110,1290 1290,1515
X axis shows the model

231
00:06:49,675 --> 00:06:51,040
0,365
size.|

232
00:06:51,460 --> 00:06:52,980
0,260 260,455 455,695 695,950 950,1520
You have an image classification

233
00:06:52,980 --> 00:06:55,020
0,380 910,1185 1185,1365 1365,1670 1780,2040
problem c far ten, you

234
00:06:55,020 --> 00:06:55,900
0,260
know.|

235
00:06:55,900 --> 00:06:57,020
0,320
And?|

236
00:06:57,730 --> 00:06:58,755
0,260 260,395 395,560 560,815 815,1025
These are ten classes. You

237
00:06:58,755 --> 00:07:00,110
0,135 135,420 420,960 960,1095 1095,1355
want to classify these images

238
00:07:00,190 --> 00:07:01,065
0,260 260,425 425,590 590,695 695,875
and now on the X

239
00:07:01,065 --> 00:07:03,375
0,575 865,1170 1170,1475 1765,2100 2100,2310
axis you are increasing the

240
00:07:03,375 --> 00:07:04,860
0,165 165,300 300,390 390,635
size of the networks.|

241
00:07:05,740 --> 00:07:07,680
0,290 290,470 470,760 1170,1490 1490,1940
And on the y axis

242
00:07:07,680 --> 00:07:08,630
0,165 165,300 300,435 435,630 630,950
we see the test error.

243
00:07:09,160 --> 00:07:11,130
0,400 660,995 995,1160 1160,1480 1650,1970
Okay, let's just concentrate on

244
00:07:11,130 --> 00:07:13,140
0,320
the.|

245
00:07:13,550 --> 00:07:15,250
0,260 260,380 380,640 990,1390 1440,1700
On the purple ah side

246
00:07:15,250 --> 00:07:17,380
0,150 150,440 670,1070 1570,1920 1920,2130
of the basically process because

247
00:07:17,380 --> 00:07:18,190
0,210 210,330 330,450 450,600 600,810
that's at the end of

248
00:07:18,190 --> 00:07:19,645
0,210 210,450 450,800 1030,1275 1275,1455
the training process if you're

249
00:07:19,645 --> 00:07:20,560
0,180 180,360 360,495 495,690 690,915
looking at the test error

250
00:07:20,560 --> 00:07:21,175
0,180 180,270 270,345 345,480 480,615
at the end of the

251
00:07:21,175 --> 00:07:22,040
0,245
process.|

252
00:07:22,080 --> 00:07:24,365
0,400 750,1150 1260,1660 1770,2075 2075,2285
So classical statistics was telling

253
00:07:24,365 --> 00:07:25,610
0,210 210,405 405,630 630,960 960,1245
us that as you improve,

254
00:07:25,610 --> 00:07:27,095
0,210 210,530 820,1125 1125,1305 1305,1485
as you increase the size

255
00:07:27,095 --> 00:07:28,910
0,180 180,405 405,665 1375,1680 1680,1815
of neural networks up to

256
00:07:28,910 --> 00:07:30,110
0,90 90,315 315,680 760,1035 1035,1200
a certain point, you find

257
00:07:30,110 --> 00:07:32,420
0,135 135,525 525,830 1150,1550
a nominal point where.|

258
00:07:32,420 --> 00:07:34,200
0,270 270,570 570,810 810,1100
The performance of model.|

259
00:07:34,200 --> 00:07:35,385
0,180 180,690 690,900 900,1020 1020,1185
The generalization that you have

260
00:07:35,385 --> 00:07:36,900
0,270 270,755
is optimal.|

261
00:07:36,900 --> 00:07:38,085
0,240 240,405 405,570 570,825 825,1185
And from that moment on,

262
00:07:38,085 --> 00:07:39,060
0,270 270,465 465,675 675,825 825,975
if you increase the size

263
00:07:39,060 --> 00:07:40,430
0,135 135,225 225,435 435,720 720,1370
of the network, you're overfitting

264
00:07:40,870 --> 00:07:41,790
0,275 275,440 440,635 635,800 800,920
what that means. That means

265
00:07:41,790 --> 00:07:42,885
0,260 310,615 615,780 780,885 885,1095
like the the kind of

266
00:07:42,885 --> 00:07:44,565
0,495 495,825 825,1125 1125,1425 1425,1680
accuracy, basically that bell, the

267
00:07:44,565 --> 00:07:46,860
0,275 655,1055 1495,1785 1785,2025 2025,2295
first bell shape that starts

268
00:07:46,860 --> 00:07:48,260
0,225 225,530 640,930 930,1110 1110,1400
going up. As you see

269
00:07:48,730 --> 00:07:50,835
0,350 350,700 930,1205 1205,1480 1830,2105
that part was going and,

270
00:07:50,835 --> 00:07:52,365
0,165 165,450 450,840 840,1170 1170,1530
and the project, they projected

271
00:07:52,365 --> 00:07:53,085
0,120 120,285 285,450 450,600 600,720
that that thing is going

272
00:07:53,085 --> 00:07:54,795
0,90 90,335 895,1230 1230,1485 1485,1710
to go up as we

273
00:07:54,795 --> 00:07:56,120
0,225 225,420 420,540 540,785
actually scale the models.|

274
00:07:56,190 --> 00:07:57,500
0,275 275,395 395,515 515,1085 1085,1310
But then the phenomenon that

275
00:07:57,500 --> 00:07:58,910
0,210 210,560 880,1140 1140,1275 1275,1410
we observed is that there

276
00:07:58,910 --> 00:08:01,865
0,120 120,285 285,590 970,1640 2620,2955
is a second descent as

277
00:08:01,865 --> 00:08:03,185
0,255 255,450 450,585 585,845 1075,1320
we scale the size. So

278
00:08:03,185 --> 00:08:03,875
0,90 90,195 195,315 315,450 450,690
this is called a double

279
00:08:03,875 --> 00:08:05,860
0,465 465,915 915,1140 1140,1455 1455,1985
descent phenomenon. So first descent

280
00:08:06,330 --> 00:08:07,925
0,260 260,470 470,820 1260,1490 1490,1595
we knew already in the

281
00:08:07,925 --> 00:08:09,485
0,210 210,545 895,1170 1170,1350 1350,1560
modern era, we figured out

282
00:08:09,485 --> 00:08:10,535
0,195 195,405 405,645 645,855 855,1050
that as we scale this

283
00:08:10,535 --> 00:08:11,870
0,225 225,485 805,1080 1080,1230 1230,1335
neural networks the size of

284
00:08:11,870 --> 00:08:13,460
0,90 90,350 970,1260 1260,1410 1410,1590
the models and this is

285
00:08:13,460 --> 00:08:14,710
0,195 195,345 345,570 570,885 885,1250
this has been observed across

286
00:08:14,760 --> 00:08:16,990
0,350 350,635 635,1450 1590,1910 1910,2230
many different architectures. OK, so

287
00:08:17,130 --> 00:08:18,725
0,290 290,500 500,820 1080,1400 1400,1595
as we scale, it could

288
00:08:18,725 --> 00:08:20,570
0,180 180,375 375,905 1075,1475 1585,1845
be a resonate architecture, it

289
00:08:20,570 --> 00:08:21,470
0,120 120,210 210,300 300,720 720,900
could be a convolution on

290
00:08:21,470 --> 00:08:22,910
0,165 165,440 850,1155 1155,1320 1320,1440
neural network, it could be

291
00:08:22,910 --> 00:08:24,530
0,120 120,630 630,750 750,1140 1140,1620
an ldm or multiay perceptor

292
00:08:24,530 --> 00:08:26,160
0,180 180,500 640,900 900,1160
or whatever they do.|

293
00:08:26,330 --> 00:08:27,730
0,275 275,550 780,1040 1040,1190 1190,1400
You know, but as we

294
00:08:27,730 --> 00:08:28,870
0,195 195,345 345,620 700,1035 1035,1140
increase the size, that's the

295
00:08:28,870 --> 00:08:29,770
0,135 135,270 270,645 645,750 750,900
kind of phenomena that we

296
00:08:29,770 --> 00:08:30,680
0,290
see.|

297
00:08:31,060 --> 00:08:32,940
0,275 275,425 425,700 1470,1745 1745,1880
Now, let me make it

298
00:08:32,940 --> 00:08:34,480
0,90 90,210 210,375 375,650
a little bit easy.|

299
00:08:34,670 --> 00:08:37,420
0,400 1320,1720 1740,2140
Easier to understand.|

300
00:08:37,420 --> 00:08:38,890
0,150 150,345 345,650 790,1190 1210,1470
This was classical statistics in

301
00:08:38,890 --> 00:08:41,280
0,150 150,435 435,930 930,1190
terms of accuracy now.|

302
00:08:41,280 --> 00:08:42,120
0,180 180,300 300,495 495,705 705,840
In the previous one we

303
00:08:42,120 --> 00:08:44,025
0,135 135,330 330,770 1480,1755 1755,1905
were seeing errors, now we

304
00:08:44,025 --> 00:08:45,240
0,210 210,755
see accuracy.|

305
00:08:45,240 --> 00:08:46,530
0,150 150,315 315,620 910,1185 1185,1290
We go high up to

306
00:08:46,530 --> 00:08:47,850
0,90 90,300 300,650 940,1185 1185,1320
a certain point and then

307
00:08:47,850 --> 00:08:48,795
0,225 225,480 480,675 675,810 810,945
as we increase the size

308
00:08:48,795 --> 00:08:50,280
0,90 90,165 165,425 985,1290 1290,1485
of the models we start

309
00:08:50,280 --> 00:08:51,520
0,770
overfing.|

310
00:08:52,270 --> 00:08:53,460
0,400 450,755 755,875 875,965 965,1190
Now, up to a certain

311
00:08:53,460 --> 00:08:55,010
0,350 820,1065 1065,1170 1170,1290 1290,1550
point now, if you have.|

312
00:08:56,840 --> 00:08:58,670
0,240 240,500 850,1095 1095,1275 1275,1830
The new kind of experimental

313
00:08:58,670 --> 00:09:00,200
0,255 255,480 480,770 880,1350 1350,1530
results showed that that's actually

314
00:09:00,200 --> 00:09:02,390
0,120 120,380 1030,1430 1750,2055 2055,2190
the case where up to

315
00:09:02,390 --> 00:09:04,565
0,75 75,300 300,680 1780,2055 2055,2175
a certain point we go

316
00:09:04,565 --> 00:09:06,005
0,245 325,585 585,780 780,1115 1195,1440
up and then again there

317
00:09:06,005 --> 00:09:07,600
0,90 90,335 685,1005 1005,1260 1260,1595
is an improvement in performance.|

318
00:09:09,100 --> 00:09:10,350
0,380 380,620 620,770 770,995 995,1250
This regime is called all

319
00:09:10,350 --> 00:09:12,165
0,300 300,1130 1150,1440 1440,1695 1695,1815
over parameterization regime, I'll tell

320
00:09:12,165 --> 00:09:14,355
0,275 505,905 1045,1445 1825,2070 2070,2190
you more. Ah, and I

321
00:09:14,355 --> 00:09:16,110
0,135 135,315 315,540 540,1115 1465,1755
give you more substance. Why

322
00:09:16,110 --> 00:09:17,070
0,165 165,315 315,435 435,615 615,960
we call them over parameter

323
00:09:17,070 --> 00:09:19,350
0,260 730,1035 1035,1635 1635,1970 2020,2280
price over parameterization regime should

324
00:09:19,350 --> 00:09:20,850
0,120 120,375 375,720 720,1070 1210,1500
be pretty obvious. But ah,

325
00:09:20,850 --> 00:09:21,615
0,180 180,330 330,450 450,570 570,765
I put it in the

326
00:09:21,615 --> 00:09:23,210
0,335 415,1035 1035,1185 1185,1320 1320,1595
ah, theoretical and the technical

327
00:09:23,710 --> 00:09:25,130
0,245 245,365 365,620 620,1000 1020,1420
kind of language of ah.|

328
00:09:25,850 --> 00:09:27,040
0,275 275,550
Machine learning.|

329
00:09:27,310 --> 00:09:28,500
0,260 260,520 720,980 980,1085 1085,1190
Alright, so one of the

330
00:09:28,500 --> 00:09:29,265
0,135 135,270 270,375 375,540 540,765
things that we can observe

331
00:09:29,265 --> 00:09:30,740
0,180 180,455 655,975 975,1185 1185,1475
from this image is that

332
00:09:30,850 --> 00:09:32,100
0,365 365,815 815,920 920,1055 1055,1250
the accuracy at the very

333
00:09:32,100 --> 00:09:33,620
0,210 210,405 405,585 585,780 780,1520
end of this over parametriization

334
00:09:33,640 --> 00:09:34,890
0,275 275,425 425,545 545,785 785,1250
regime is see that it's

335
00:09:34,890 --> 00:09:37,040
0,380 640,1035 1035,1320 1320,1610 1750,2150
slightly better than the first

336
00:09:37,060 --> 00:09:38,085
0,425 425,530 530,665 665,845 845,1025
accuracy that you get from

337
00:09:38,085 --> 00:09:39,420
0,135 135,395 415,660 660,795 795,1335
a model that is reasonably

338
00:09:39,420 --> 00:09:41,055
0,320 670,1065 1065,1365 1365,1470 1470,1635
sized, okay? It's not that

339
00:09:41,055 --> 00:09:43,040
0,180 180,485 565,885 885,1445
much better the accuracy.|

340
00:09:43,040 --> 00:09:44,420
0,255 255,530 550,900 900,1170 1170,1380
But then the discovery of

341
00:09:44,420 --> 00:09:45,440
0,180 180,390 390,600 600,810 810,1020
deep learning was that when

342
00:09:45,440 --> 00:09:46,720
0,210 210,285 285,375 375,555 555,1280
we're in the over parameterization

343
00:09:46,770 --> 00:09:49,595
0,400 810,1100 1100,1390 2340,2615 2615,2825
regime we get a new

344
00:09:49,595 --> 00:09:51,160
0,225 225,450 450,785 805,1185 1185,1565
type of behavior starts emerging.|

345
00:09:51,780 --> 00:09:53,475
0,180 180,330 330,525 525,860 1420,1695
What kind of behavior, the

346
00:09:53,475 --> 00:09:55,170
0,675 675,930 930,1305 1305,1485 1485,1695
characteristics that emerge in that

347
00:09:55,170 --> 00:09:56,985
0,255 255,980 1030,1350 1350,1575 1575,1815
over parameterization regime is something

348
00:09:56,985 --> 00:09:58,215
0,195 195,390 390,540 540,845 895,1230
that I'm going to talk

349
00:09:58,215 --> 00:09:59,620
0,335 415,815
about next.|

350
00:09:59,620 --> 00:10:00,685
0,360 360,600 600,705 705,825 825,1065
So one of the things

351
00:10:00,685 --> 00:10:02,260
0,365
is.|

352
00:10:04,350 --> 00:10:05,750
0,335 335,545 545,820 870,1205 1205,1400
As we go larger and

353
00:10:05,750 --> 00:10:07,880
0,210 210,420 420,680 1060,1490 1840,2130
larger in networks sizes, they

354
00:10:07,880 --> 00:10:09,610
0,285 285,1005 1005,1260 1260,1440 1440,1730
learn concepts that they can

355
00:10:09,840 --> 00:10:11,500
0,335 335,620 620,875 875,1180 1260,1660
pass on to different tasks.

356
00:10:11,640 --> 00:10:12,940
0,275 275,425 425,560 560,710 710,1300
That means they can generalize

357
00:10:12,960 --> 00:10:14,870
0,320 320,605 605,970 1470,1745 1745,1910
across different tasks. That means

358
00:10:14,870 --> 00:10:16,090
0,225 225,675 675,795 795,945 945,1220
those concepts that they learn,

359
00:10:16,380 --> 00:10:17,900
0,275 275,440 440,650 650,1250 1250,1520
they can be transferred to

360
00:10:17,900 --> 00:10:19,715
0,270 270,620 820,1185 1185,1530 1530,1815
actually perform more tasks, not

361
00:10:19,715 --> 00:10:20,960
0,210 210,420 420,690 690,1020 1020,1245
even a single task that

362
00:10:20,960 --> 00:10:21,880
0,105 105,210 210,375 375,600 600,920
they have been trained on.

363
00:10:22,440 --> 00:10:24,220
0,400 720,1120
Okay, so.|

364
00:10:24,220 --> 00:10:25,075
0,135 135,300 300,465 465,675 675,855
It seems like you're giving

365
00:10:25,075 --> 00:10:26,650
0,210 210,450 450,795 795,1065 1065,1575
them more ability to generalize

366
00:10:26,650 --> 00:10:27,970
0,270 270,570 570,900 900,1125 1125,1320
and getting closer to those

367
00:10:27,970 --> 00:10:29,605
0,195 195,440 970,1215 1215,1350 1350,1635
kind of kind of general

368
00:10:29,605 --> 00:10:31,520
0,705 705,960 960,1295
representation of AI.|

369
00:10:31,560 --> 00:10:32,795
0,365 365,530 530,680 680,800 995,1235
I'm afraid to say AI

370
00:10:32,795 --> 00:10:34,940
0,305 475,765 765,1055 1285,1685 1885,2145
yet. Okay, but yeah, but

371
00:10:34,940 --> 00:10:35,690
0,240 240,360 360,480 480,600 600,750
that's the kind of thing

372
00:10:35,690 --> 00:10:37,325
0,290 460,780 780,1100 1300,1545 1545,1635
that we observe, the kind

373
00:10:37,325 --> 00:10:38,410
0,120 120,510 510,630 630,795 795,1085
of concepts that they learn.

374
00:10:38,790 --> 00:10:39,830
0,245 245,350 350,485 485,725 725,1040
They are being able to,

375
00:10:39,830 --> 00:10:41,980
0,350 880,1245 1245,1515 1515,1785 1785,2150
um, perform across different tasks

376
00:10:42,420 --> 00:10:43,985
0,290 290,500 500,940 1170,1430 1430,1565
across different domains. They get

377
00:10:43,985 --> 00:10:45,580
0,195 195,375 375,635
better and better.|

378
00:10:45,710 --> 00:10:47,155
0,395 395,790 870,1130 1130,1265 1265,1445
Another observation that we had

379
00:10:47,155 --> 00:10:48,445
0,180 180,315 315,495 495,810 810,1290
is that the scale improves

380
00:10:48,445 --> 00:10:50,010
0,665 775,1035 1035,1155 1155,1290 1290,1565
robustness. What does it mean

381
00:10:50,210 --> 00:10:52,330
0,400 1290,1550 1550,1685 1685,1880 1880,2120
for a deep learning model

382
00:10:52,330 --> 00:10:53,660
0,180 180,375 375,710
to be robust?|

383
00:10:53,660 --> 00:10:54,905
0,165 165,440 460,720 720,945 945,1245
That means if I change

384
00:10:54,905 --> 00:10:56,410
0,285 285,635 805,1050 1050,1200 1200,1505
the input a little bit

385
00:10:56,700 --> 00:10:58,505
0,380 380,635 635,785 785,1060 1530,1805
per bit with noise on

386
00:10:58,505 --> 00:11:00,365
0,275 325,725 895,1155 1155,1545 1545,1860
the output, it doesn't completely

387
00:11:00,365 --> 00:11:01,835
0,255 255,575 865,1125 1125,1275 1275,1470
go crash. So the change

388
00:11:01,835 --> 00:11:03,110
0,165 165,375 375,570 570,705 705,1275
of the input is proportional

389
00:11:03,110 --> 00:11:04,560
0,105 105,315 315,555 555,830
to the output changes.|

390
00:11:04,560 --> 00:11:05,700
0,300 300,570 570,810 810,990 990,1140
The robust means that you

391
00:11:05,700 --> 00:11:06,825
0,165 165,405 405,630 630,840 840,1125
are being being able to

392
00:11:06,825 --> 00:11:07,880
0,255 255,390 390,585 585,795 795,1055
control the error and the

393
00:11:07,900 --> 00:11:09,225
0,400 630,890 890,1010 1010,1160 1160,1325
output if you have a

394
00:11:09,225 --> 00:11:10,485
0,150 150,270 270,390 390,665 895,1260
little bit of error or

395
00:11:10,485 --> 00:11:11,940
0,510 510,720 720,915 915,1235
deviation of the input.|

396
00:11:12,040 --> 00:11:13,860
0,400 840,1145 1145,1385 1385,1610 1610,1820
So this curve actually shows

397
00:11:13,860 --> 00:11:16,005
0,320 790,1110 1110,1335 1335,1670 1870,2145
that has been scaled these

398
00:11:16,005 --> 00:11:17,280
0,225 225,485
neural networks.|

399
00:11:17,350 --> 00:11:18,195
0,275 275,410 410,530 530,665 665,845
We see that the size

400
00:11:18,195 --> 00:11:19,730
0,225 225,525 525,900 900,1215 1215,1535
of, ah, the, the robust

401
00:11:19,780 --> 00:11:21,645
0,335 335,670 990,1390 1470,1745 1745,1865
actually improve. Okay, I'm gonna

402
00:11:21,645 --> 00:11:22,845
0,210 210,405 405,600 600,900 900,1200
talk about this in much

403
00:11:22,845 --> 00:11:24,915
0,255 255,540 540,875 1525,1815 1815,2070
more detail in because that's

404
00:11:24,915 --> 00:11:25,680
0,120 120,285 285,465 465,615 615,765
the part where we have

405
00:11:25,680 --> 00:11:27,300
0,165 165,405 405,770 1240,1500 1500,1620
the theory for from the

406
00:11:27,300 --> 00:11:28,700
0,120 120,375 375,770
deep learning perspective.|

407
00:11:28,800 --> 00:11:30,820
0,335 335,670 720,1085 1085,1600 1620,2020
Now, not everything improves by.|

408
00:11:32,040 --> 00:11:34,550
0,380 380,760 1110,1510 1530,1930 2130,2510
By ah ah, grow growing.

409
00:11:34,550 --> 00:11:36,250
0,360 360,645 645,950 1150,1425 1425,1700
Ah, in size, for example,

410
00:11:36,840 --> 00:11:38,765
0,365 365,665 665,890 890,1420 1590,1925
the problems of bias and

411
00:11:38,765 --> 00:11:41,345
0,605 655,1005 1005,1355 1525,1925 2185,2580
accountability and and minor accuracy

412
00:11:41,345 --> 00:11:43,160
0,90 90,330 330,930 930,1355 1525,1815
on minor minority samples. As

413
00:11:43,160 --> 00:11:45,040
0,210 210,530 790,1065 1065,1305 1305,1880
we scale they get worsen.

414
00:11:45,330 --> 00:11:46,420
0,245 245,560 560,725 725,830 830,1090
So that's we have evidence

415
00:11:46,440 --> 00:11:47,855
0,260 260,520 540,845 845,1145 1145,1415
for those, ah, ah kind

416
00:11:47,855 --> 00:11:49,670
0,275 415,750 750,990 990,1295 1585,1815
of cases as well. So

417
00:11:49,670 --> 00:11:50,410
0,90 90,210 210,315 315,450 450,740
you need to be careful

418
00:11:50,730 --> 00:11:51,710
0,275 275,380 380,530 530,830 830,980
when you are deploying this

419
00:11:51,710 --> 00:11:52,960
0,150 150,360 360,710
in our society.|

420
00:11:53,250 --> 00:11:54,815
0,335 335,620 620,950 950,1310 1310,1565
Now, another very important part

421
00:11:54,815 --> 00:11:56,270
0,210 210,525 525,750 750,915 915,1455
of intelligence, which is reasoning,

422
00:11:56,270 --> 00:11:58,055
0,180 180,435 435,645 645,890 1150,1785
the ability to log logically,

423
00:11:58,055 --> 00:11:59,840
0,210 210,545 1195,1455 1455,1575 1575,1785
talk about kind of different

424
00:11:59,840 --> 00:12:02,470
0,650 760,1035 1035,1310 1330,2030 2230,2630
phenomena is basically reasoning and,

425
00:12:03,210 --> 00:12:04,685
0,290 290,695 695,815 815,1090 1170,1475
and reasoning is basically stays

426
00:12:04,685 --> 00:12:06,290
0,525 525,780 780,945 945,1235 1315,1605
unchanged if you just scale

427
00:12:06,290 --> 00:12:07,440
0,150 150,410
a model.|

428
00:12:07,630 --> 00:12:09,135
0,400 450,800 800,1055 1055,1250 1250,1505
Unless you provide the system

429
00:12:09,135 --> 00:12:11,270
0,365 445,845 1045,1350 1350,1785 1785,2135
with, ah, a simulation engine,

430
00:12:11,470 --> 00:12:12,195
0,320 320,395 395,485 485,605 605,725
let's say you want to

431
00:12:12,195 --> 00:12:13,770
0,120 120,360 360,995 1225,1485 1485,1575
do physical reasoning, say there

432
00:12:13,770 --> 00:12:15,345
0,105 105,300 300,800 1030,1365 1365,1575
are two cubes, they're both

433
00:12:15,345 --> 00:12:17,175
0,300 300,635 1045,1380 1380,1620 1620,1830
moving in X on X

434
00:12:17,175 --> 00:12:18,300
0,515 565,795 795,885 885,990 990,1125
axis. One of them is

435
00:12:18,300 --> 00:12:19,430
0,285 285,555 555,675 675,825 825,1130
faster than the other one,

436
00:12:19,840 --> 00:12:20,685
0,260 260,440 440,635 635,755 755,845
so one thing that you

437
00:12:20,685 --> 00:12:21,780
0,195 195,405 405,555 555,810 810,1095
have as a human being

438
00:12:21,780 --> 00:12:22,725
0,180 180,345 345,585 585,795 795,945
in your head is a

439
00:12:22,725 --> 00:12:24,405
0,390 390,725 1105,1380 1380,1530 1530,1680
simulation engine that you can

440
00:12:24,405 --> 00:12:25,770
0,275 415,900 900,1080 1080,1245 1245,1365
basically simulate that kind of

441
00:12:25,770 --> 00:12:27,330
0,260 790,1005 1005,1065 1065,1275 1275,1560
reality. So if you provide

442
00:12:27,330 --> 00:12:28,485
0,225 225,390 390,525 525,800 880,1155
that kind of reality to

443
00:12:28,485 --> 00:12:30,520
0,180 180,480 480,875
a language model.|

444
00:12:30,930 --> 00:12:32,285
0,320 320,560 560,740 740,905 905,1355
The results of that simulation

445
00:12:32,285 --> 00:12:33,815
0,225 225,420 420,755 865,1260 1260,1530
to language model you, you

446
00:12:33,815 --> 00:12:35,500
0,180 180,420 420,735 735,1080 1080,1685
would see again increasing reasoning.

447
00:12:35,640 --> 00:12:37,120
0,335 335,575 575,770 770,1060 1080,1480
So that part is also

448
00:12:37,560 --> 00:12:38,960
0,395 395,790
extremely important.|

449
00:12:38,960 --> 00:12:40,775
0,350 910,1230 1230,1470 1470,1680 1680,1815
Now, the part that we

450
00:12:40,775 --> 00:12:42,305
0,245 535,825 825,1005 1005,1260 1260,1530
are like all these results

451
00:12:42,305 --> 00:12:43,580
0,165 165,390 390,570 570,875 1045,1275
that I'm showing here, they

452
00:12:43,580 --> 00:12:45,455
0,105 105,380 490,1310 1420,1710 1710,1875
are very experimental. So there

453
00:12:45,455 --> 00:12:47,510
0,195 195,515 655,1055 1555,1845 1845,2055
has been like a large

454
00:12:47,510 --> 00:12:49,400
0,530 580,960 960,1320 1320,1650 1650,1890
corporations involved to actually perform

455
00:12:49,400 --> 00:12:51,065
0,180 180,315 315,480 480,800 1420,1665
this kind of analysis to

456
00:12:51,065 --> 00:12:52,175
0,225 225,510 510,690 690,870 870,1110
actually to see the behavior

457
00:12:52,175 --> 00:12:53,660
0,225 225,390 390,665 715,1115 1225,1485
of this large models. But

458
00:12:53,660 --> 00:12:54,730
0,105 105,210 210,360 360,650 670,1070
do we have an actual

459
00:12:54,930 --> 00:12:57,130
0,400 570,875 875,1670 1670,1865 1865,2200
theory that fundamentally is true

460
00:12:57,450 --> 00:12:59,390
0,305 305,610 1110,1475 1475,1715 1715,1940
about this models or this

461
00:12:59,390 --> 00:13:00,965
0,300 300,510 510,645 645,920 1330,1575
behavior that we see? Let

462
00:13:00,965 --> 00:13:02,860
0,120 120,330 330,555 555,845 1255,1895
me focus on the robustness.|

463
00:13:04,840 --> 00:13:06,860
0,290 290,470 470,760 870,1270 1620,2020
This is from, ah, this

464
00:13:07,360 --> 00:13:08,570
0,245 245,395 395,650 650,905 905,1210
kind of graph is from

465
00:13:08,890 --> 00:13:11,540
0,335 335,910 1590,1990 2070,2360 2360,2650
Alexander Madrid group from here,

466
00:13:11,680 --> 00:13:13,520
0,400 420,820 1080,1310 1310,1490 1490,1840
MIT, where they are studying

467
00:13:14,020 --> 00:13:15,780
0,590 590,800 800,1010 1010,1270
robustness in neural network.|

468
00:13:16,390 --> 00:13:18,165
0,260 260,410 410,700 1260,1535 1535,1775
What they do, I mean,

469
00:13:18,165 --> 00:13:19,215
0,225 225,450 450,645 645,885 885,1050
it doesn't matter what, what

470
00:13:19,215 --> 00:13:20,460
0,165 165,315 315,525 525,875 985,1245
the three lines are, what

471
00:13:20,460 --> 00:13:21,195
0,135 135,270 270,405 405,540 540,735
they do, they try to

472
00:13:21,195 --> 00:13:22,940
0,255 255,480 480,645 645,905
attack the input images.|

473
00:13:23,460 --> 00:13:25,400
0,275 275,550 1020,1445 1445,1640 1640,1940
And then compute the accuracy

474
00:13:25,400 --> 00:13:27,060
0,105 105,380
of models.|

475
00:13:27,070 --> 00:13:28,320
0,320 320,575 575,890 890,1130 1130,1250
As we scale again on

476
00:13:28,320 --> 00:13:29,160
0,105 105,240 240,585 585,720 720,840
the X axis, we see

477
00:13:29,160 --> 00:13:30,885
0,165 165,360 360,615 615,1190 1390,1725
the scale and accuracy as

478
00:13:30,885 --> 00:13:33,165
0,335 625,1025 1165,1515 1515,1865 1915,2280
we start increasing the capacity

479
00:13:33,165 --> 00:13:34,640
0,225 225,345 345,605
of the networks.|

480
00:13:34,640 --> 00:13:36,550
0,165 165,360 360,945 945,1290 1290,1910
In image classification and classification

481
00:13:36,570 --> 00:13:38,390
0,400 1110,1385 1385,1505 1505,1610 1610,1820
here we see that there's

482
00:13:38,390 --> 00:13:40,535
0,135 135,440 790,1140 1140,1790 1870,2145
a jump in robustness that

483
00:13:40,535 --> 00:13:41,705
0,165 165,420 420,765 765,1020 1020,1170
means the attacks that they

484
00:13:41,705 --> 00:13:43,520
0,165 165,455 625,945 945,1575 1575,1815
were doing or perturbing the

485
00:13:43,520 --> 00:13:45,455
0,210 210,470 1090,1380 1380,1635 1635,1935
input images with something called

486
00:13:45,455 --> 00:13:46,760
0,255 255,465 465,630 630,870 870,1305
an attack is called projected

487
00:13:46,760 --> 00:13:47,960
0,150 150,270 270,680
grand and descent.|

488
00:13:48,030 --> 00:13:49,535
0,290 290,580 600,1000 1020,1310 1310,1505
It was basically like you.

489
00:13:49,535 --> 00:13:50,600
0,180 180,345 345,555 555,780 780,1065
You got into a really

490
00:13:50,600 --> 00:13:52,940
0,380 760,1260 1260,1550 1840,2130 2130,2340
good accuracy after you actually

491
00:13:52,940 --> 00:13:53,660
0,225 225,390 390,525 525,630 630,720
increase the size of the

492
00:13:53,660 --> 00:13:54,845
0,260 490,780 780,900 900,990 990,1185
network up to a certain

493
00:13:54,845 --> 00:13:56,075
0,335 445,720 720,855 855,1005 1005,1230
point and there was this

494
00:13:56,075 --> 00:13:57,640
0,335 715,960 960,1080 1080,1260 1260,1565
transition, there was a shift.|

495
00:13:58,980 --> 00:14:01,325
0,400 840,1240 1620,1910 1910,2090 2090,2345
Ah, ah, in, in, in

496
00:14:01,325 --> 00:14:02,870
0,365 715,990 990,1140 1140,1290 1290,1545
performance. And that has been

497
00:14:02,870 --> 00:14:04,010
0,300 300,495 495,660 660,855 855,1140
confirmed, as I said, by

498
00:14:04,010 --> 00:14:06,185
0,380 970,1245 1245,1410 1410,1700 1870,2175
experiments and we said alright,

499
00:14:06,185 --> 00:14:07,730
0,305 385,705 705,885 885,1380 1380,1545
so scale. The conclusions of

500
00:14:07,730 --> 00:14:08,720
0,195 195,360 360,570 570,825 825,990
those kind of results was

501
00:14:08,720 --> 00:14:11,300
0,260 280,680 700,1250 1450,2060
that scale improves robustness.|

502
00:14:11,970 --> 00:14:14,585
0,275 275,550 960,1360 2190,2450 2450,2615
But then, and the best

503
00:14:14,585 --> 00:14:16,835
0,285 285,555 555,705 705,965 1975,2250
paper award at the the

504
00:14:16,835 --> 00:14:18,430
0,270 270,555 555,945 945,1260 1260,1595
conference on neural information processing

505
00:14:18,450 --> 00:14:21,485
0,400 420,820 1440,2320 2490,2810 2810,3035
system ri 2021 came and

506
00:14:21,485 --> 00:14:22,780
0,300 300,615 615,810 810,990 990,1295
said scale is a law

507
00:14:22,860 --> 00:14:24,320
0,365 365,970
of robustness.|

508
00:14:24,320 --> 00:14:25,550
0,270 270,420 420,555 555,830 970,1230
Okay, what that means, okay,

509
00:14:25,550 --> 00:14:26,890
0,135 135,270 270,420 420,720 720,1340
that means like, let's formulate

510
00:14:27,060 --> 00:14:29,435
0,380 380,760 1110,1400 1400,1690 1890,2375
how scale is basically contributing

511
00:14:29,435 --> 00:14:31,140
0,270 270,785
to robustness.|

512
00:14:32,020 --> 00:14:33,220
0,400
So.|

513
00:14:33,220 --> 00:14:33,985
0,195 195,315 315,510 510,645 645,765
I'm gonna talk a little

514
00:14:33,985 --> 00:14:36,115
0,165 165,455 625,1025 1675,1950 1950,2130
bit more technical about this

515
00:14:36,115 --> 00:14:37,750
0,305 355,690 690,900 900,1175 1375,1635
thing. Hopefully you can, you

516
00:14:37,750 --> 00:14:38,560
0,105 105,255 255,480 480,660 660,810
can all follow, but you

517
00:14:38,560 --> 00:14:39,505
0,150 150,255 255,420 420,705 705,945
you can ask questions. Like

518
00:14:39,505 --> 00:14:41,350
0,180 180,485 655,960 960,1265 1555,1845
even now, if you have

519
00:14:41,350 --> 00:14:42,385
0,285 285,540 540,660 660,810 810,1035
questions, let me just finish

520
00:14:42,385 --> 00:14:44,605
0,240 240,545 745,1035 1035,1325 1915,2220
this one and then we'll

521
00:14:44,605 --> 00:14:46,495
0,120 120,270 270,495 495,845 1585,1890
take some questions. So let's

522
00:14:46,495 --> 00:14:48,960
0,120 120,345 345,600 600,935 2065,2465
say fix any reasonable, reasonable

523
00:14:49,040 --> 00:14:50,130
0,305 305,455 455,545 545,740 740,1090
function. What is a reasonable

524
00:14:50,210 --> 00:14:51,985
0,400 810,1085 1085,1325 1325,1550 1550,1775
function is basically a function

525
00:14:51,985 --> 00:14:53,220
0,255 255,545
that has.|

526
00:14:53,220 --> 00:14:54,495
0,165 165,405 405,740 850,1140 1140,1275
A smooth behavior, like, like

527
00:14:54,495 --> 00:14:55,815
0,105 105,405 405,695 865,1110 1110,1320
a sigmoid function, OK? That's

528
00:14:55,815 --> 00:14:57,195
0,135 135,330 330,635 685,1085 1105,1380
a very reasonable function, OK?

529
00:14:57,195 --> 00:14:58,460
0,210 210,480 480,765 765,990 990,1265
A crazy function would be

530
00:14:58,480 --> 00:14:59,510
0,320 320,500 500,605 605,740 740,1030
like if you have like

531
00:14:59,710 --> 00:15:01,830
0,610 690,995 995,1190 1190,1480 1680,2120
jumps across like different modes,

532
00:15:01,830 --> 00:15:02,475
0,120 120,240 240,375 375,510 510,645
you know, like you have

533
00:15:02,475 --> 00:15:04,560
0,150 150,425 565,965 1225,1625
a reasonable function, okay?|

534
00:15:04,630 --> 00:15:07,100
0,335 335,605 605,880
And it basically.|

535
00:15:07,330 --> 00:15:09,075
0,275 275,515 515,830 830,1420 1470,1745
It has, it's parameterized okay,

536
00:15:09,075 --> 00:15:09,855
0,135 135,255 255,390 390,525 525,780
like a sig mode function

537
00:15:09,855 --> 00:15:11,000
0,195 195,285 285,420 420,840 840,1145
that you can parameterize it

538
00:15:11,350 --> 00:15:13,080
0,305 305,610 810,1160 1160,1565 1565,1730
and then it's polyized like

539
00:15:13,080 --> 00:15:14,205
0,120 120,300 300,480 480,740 820,1125
it has also reasonable size

540
00:15:14,205 --> 00:15:16,095
0,195 195,665 1075,1335 1335,1620 1620,1890
in parameters, and it's not

541
00:15:16,095 --> 00:15:17,760
0,300 300,780 780,1170 1170,1380 1380,1665
a comograph rld type network.

542
00:15:17,760 --> 00:15:19,305
0,240 240,375 375,555 555,860 1240,1545
What does that mean that

543
00:15:19,305 --> 00:15:21,160
0,305
means.|

544
00:15:21,650 --> 00:15:23,430
0,335 335,500 500,820 870,1115 1115,1780
I'm showing you a representation

545
00:15:23,480 --> 00:15:25,615
0,305 305,610 930,1250 1250,1570 1680,2135
that was discovered by Arnold

546
00:15:25,615 --> 00:15:26,910
0,165 165,360 360,630 630,1020 1020,1295
and, and, and karog gro.

547
00:15:27,170 --> 00:15:28,105
0,290 290,470 470,635 635,785 785,935
That shows that there are

548
00:15:28,105 --> 00:15:30,550
0,275 715,1115 1375,2130 2130,2295 2295,2445
this, this decomposition that we

549
00:15:30,550 --> 00:15:32,845
0,290 580,900 900,1485 1485,1790 1960,2295
see can approximate any continuous

550
00:15:32,845 --> 00:15:35,500
0,335 505,1325 1405,1740 1740,2075
function, multivariate continuous function.|

551
00:15:35,820 --> 00:15:36,740
0,290 290,440 440,560 560,680 680,920
Okay, so these are basically

552
00:15:36,740 --> 00:15:38,975
0,255 255,405 405,1100 1780,2055 2055,2235
two non linearities and the

553
00:15:38,975 --> 00:15:40,570
0,305 325,645 645,840 840,1115 1195,1595
some operator is basically applying

554
00:15:40,890 --> 00:15:42,860
0,275 275,550 1140,1505 1505,1775 1775,1970
ah ah joining the, the,

555
00:15:42,860 --> 00:15:44,110
0,135 135,380 670,900 900,990 990,1250
the inner kind of processes.

556
00:15:44,460 --> 00:15:45,640
0,260 260,425 425,680 680,905 905,1180
But one problem with this

557
00:15:45,660 --> 00:15:47,495
0,400 840,1100 1100,1220 1220,1480 1560,1835
ah kind of functions is

558
00:15:47,495 --> 00:15:48,215
0,165 165,285 285,390 390,540 540,720
that they are not as

559
00:15:48,215 --> 00:15:51,130
0,305 805,1170 1170,1535 2185,2550 2550,2915
smooth and ah as ah

560
00:15:51,450 --> 00:15:53,750
0,520 690,965 965,1240 1890,2150 2150,2300
tommy actually mention they show

561
00:15:53,750 --> 00:15:55,175
0,285 285,680 700,990 990,1155 1155,1425
wild behavior. They could be

562
00:15:55,175 --> 00:15:56,645
0,390 390,660 660,915 915,1215 1215,1470
anything. The function in inner

563
00:15:56,645 --> 00:15:58,130
0,270 270,480 480,705 705,1055 1165,1485
function could be anything. So

564
00:15:58,130 --> 00:15:59,630
0,440 520,900 900,1065 1065,1260 1260,1500
let's let's rule out those

565
00:15:59,630 --> 00:16:00,580
0,180 180,440
kind of.|

566
00:16:00,890 --> 00:16:02,725
0,400 570,970 1170,1505 1505,1655 1655,1835
Ah, functions. Let's talk about

567
00:16:02,725 --> 00:16:04,780
0,210 210,525 525,785 1345,1745 1765,2055
only neural networks. Okay, like

568
00:16:04,780 --> 00:16:06,295
0,195 195,500 520,920 940,1260 1260,1515
very reasonable functions and really

569
00:16:06,295 --> 00:16:07,480
0,285 285,510 510,785
function as well.|

570
00:16:07,850 --> 00:16:09,415
0,275 275,545 545,820 840,1220 1220,1565
Now let's sample and data

571
00:16:09,415 --> 00:16:10,330
0,300 300,495 495,615 615,765 765,915
points for the case of

572
00:16:10,330 --> 00:16:11,635
0,255 255,600 600,950 970,1185 1185,1305
m data set. You have

573
00:16:11,635 --> 00:16:13,870
0,305 325,645 645,900 900,1235 1885,2235
sixty k data points, truly

574
00:16:13,870 --> 00:16:15,400
0,240 240,750 750,885 885,1130 1240,1530
high dimensional. I mean is

575
00:16:15,400 --> 00:16:17,040
0,255 255,705 705,915 915,1335 1335,1640
like 28 by 28 times

576
00:16:17,660 --> 00:16:19,345
0,335 335,500 500,605 605,725 950,1685
one, so it's like 728

577
00:16:19,345 --> 00:16:20,520
0,305 445,675 675,795 795,900 900,1175
right? So it's not that.|

578
00:16:21,650 --> 00:16:23,095
0,320 320,530 530,1100 1100,1280 1280,1445
Truly high dimensional, but let's

579
00:16:23,095 --> 00:16:24,670
0,90 90,300 300,525 525,705 855,1575
say image that is 256

580
00:16:24,670 --> 00:16:27,210
0,270 450,1155 1155,1490 1510,1910 2140,2540
times 256 times three, so

581
00:16:27,230 --> 00:16:29,740
0,400 540,815 815,1480
truly high dimensional.|

582
00:16:30,440 --> 00:16:32,400
0,290 290,580
And then?|

583
00:16:32,410 --> 00:16:34,020
0,350 350,665 665,1030 1050,1400 1400,1610
Add label noise. Why? Why

584
00:16:34,020 --> 00:16:34,560
0,90 90,165 165,270 270,375 375,540
do we want to add

585
00:16:34,560 --> 00:16:35,700
0,270 270,450 450,540 540,915 915,1140
noise to the labels? What

586
00:16:35,700 --> 00:16:37,185
0,120 120,285 285,450 450,710 1210,1485
does that mean? Even that

587
00:16:37,185 --> 00:16:37,830
0,135 135,240 240,360 360,495 495,645
means we want to make

588
00:16:37,830 --> 00:16:39,120
0,165 165,440 460,860 880,1155 1155,1290
the problem harder for the

589
00:16:39,120 --> 00:16:40,470
0,180 180,440 790,1050 1050,1185 1185,1350
neural network. That means it

590
00:16:40,470 --> 00:16:41,535
0,150 150,285 285,420 420,570 570,1065
should not be the mapping

591
00:16:41,535 --> 00:16:43,005
0,225 225,465 465,750 750,930 930,1470
between the input. High dimensional

592
00:16:43,005 --> 00:16:44,150
0,210 210,345 345,570 570,840 840,1145
input than the output classes

593
00:16:44,440 --> 00:16:46,220
0,260 260,410 410,620 620,1120 1380,1780
should not be trivial. Okay?

594
00:16:46,300 --> 00:16:47,415
0,245 245,335 335,545 545,875 875,1115
So we add noise, a

595
00:16:47,415 --> 00:16:48,470
0,150 150,285 285,450 450,705 705,1055
little bit of label noise

596
00:16:48,940 --> 00:16:51,855
0,260 260,520 1020,1370 1370,1720 2670,2915
to basically create this, you

597
00:16:51,855 --> 00:16:53,360
0,105 105,330 330,615 615,935 1105,1505
know, a complex problem. Okay,

598
00:16:53,590 --> 00:16:54,330
0,245 245,350 350,485 485,620 620,740
so that means like if

599
00:16:54,330 --> 00:16:55,340
0,105 105,255 255,480 480,705 705,1010
you have all, all your

600
00:16:55,630 --> 00:16:57,165
0,395 395,530 530,790 1110,1370 1370,1535
labels are random. The problem

601
00:16:57,165 --> 00:16:58,635
0,195 195,485 535,840 840,1145 1195,1470
is really complex, right? So

602
00:16:58,635 --> 00:16:59,415
0,240 240,465 465,570 570,675 675,780
you want to add a

603
00:16:59,415 --> 00:17:00,210
0,105 105,225 225,360 360,555 555,795
little bit of random noise

604
00:17:00,210 --> 00:17:01,500
0,210 210,500
as well.|

605
00:17:01,660 --> 00:17:04,545
0,275 275,550 1080,1480 2100,2390 2390,2885
And then then, to memorize

606
00:17:04,545 --> 00:17:05,940
0,255 255,525 525,875 985,1245 1245,1395
this data set, what does

607
00:17:05,940 --> 00:17:07,830
0,645 645,1040 1300,1575 1575,1740 1740,1890
memorization mean? That means if

608
00:17:07,830 --> 00:17:08,925
0,150 150,330 330,510 510,800 850,1095
I have a function and

609
00:17:08,925 --> 00:17:10,500
0,225 225,585 585,765 765,1365 1365,1575
I'm fitting a parametric model,

610
00:17:10,500 --> 00:17:11,490
0,195 195,345 345,510 510,765 765,990
like a neural network to

611
00:17:11,490 --> 00:17:12,770
0,230 550,810 810,945 945,1050 1050,1280
it, I want to be

612
00:17:12,970 --> 00:17:15,000
0,400 570,1055 1055,1360 1380,1730 1730,2030
completely fitting every single data

613
00:17:15,000 --> 00:17:15,720
0,350
point.|

614
00:17:15,820 --> 00:17:17,145
0,380 380,695 695,965 965,1175 1175,1325
Okay, during training, that means

615
00:17:17,145 --> 00:17:18,060
0,150 150,300 300,510 510,720 720,915
I want to achieve a

616
00:17:18,060 --> 00:17:20,610
0,320 1150,1550 1810,2085 2085,2280 2280,2550
zero loss on my training

617
00:17:20,610 --> 00:17:21,980
0,350 820,1220
set, okay?|

618
00:17:22,280 --> 00:17:23,590
0,275 275,410 410,605 605,1115 1115,1310
That means like memorizing, so

619
00:17:23,590 --> 00:17:25,410
0,260 280,570 570,1185 1185,1485 1485,1820
definition of memorization during learning.|

620
00:17:27,580 --> 00:17:29,295
0,400 750,1115 1115,1265 1265,1460 1460,1715
Now optimize the training error

621
00:17:29,295 --> 00:17:31,650
0,270 270,605 775,1175 1885,2175 2175,2355
below the ah noise level

622
00:17:31,650 --> 00:17:32,850
0,195 195,480 480,735 735,945 945,1200
and below the noise level.

623
00:17:32,850 --> 00:17:33,855
0,195 195,345 345,510 510,750 750,1005
What does that mean? Again,

624
00:17:33,855 --> 00:17:35,595
0,270 270,515 865,1155 1155,1445 1495,1740
that's like another definition that

625
00:17:35,595 --> 00:17:36,410
0,105 105,255 255,420 420,555 555,815
you guys have to know

626
00:17:36,730 --> 00:17:38,775
0,400 420,820 1440,1715 1715,1880 1880,2045
is, um, as I said,

627
00:17:38,775 --> 00:17:39,930
0,135 135,270 270,435 435,975 975,1155
we want to complicate the

628
00:17:39,930 --> 00:17:41,685
0,290 670,960 960,1250 1270,1650 1650,1755
process so that it's not

629
00:17:41,685 --> 00:17:43,215
0,135 135,495 495,995 1195,1425 1425,1530
a trivial mapping. So you

630
00:17:43,215 --> 00:17:44,445
0,195 195,420 420,725 835,1095 1095,1230
add that noise and then

631
00:17:44,445 --> 00:17:45,795
0,135 135,390 390,915 915,1155 1155,1350
when your accuracy is a

632
00:17:45,795 --> 00:17:46,815
0,135 135,330 330,585 585,825 825,1020
little bit higher than the

633
00:17:46,815 --> 00:17:47,700
0,210 210,405 405,615 615,795 795,885
amount of noise that you

634
00:17:47,700 --> 00:17:49,365
0,560 820,1110 1110,1350 1350,1560 1560,1665
injected, for example, for the

635
00:17:49,365 --> 00:17:50,985
0,245 445,825 825,1110 1110,1380 1380,1620
m, basically the hard part

636
00:17:50,985 --> 00:17:52,010
0,135 135,285 285,525 525,750 750,1025
of the training of the

637
00:17:52,120 --> 00:17:53,460
0,335 335,670 720,1040 1040,1160 1160,1340
data set, let's say if

638
00:17:53,460 --> 00:17:55,110
0,290 400,780 780,1035 1035,1310 1390,1650
you all kind of machine

639
00:17:55,110 --> 00:17:56,235
0,180 180,465 465,720 720,915 915,1125
learning models can get up

640
00:17:56,235 --> 00:17:58,335
0,165 165,810 810,1625 1645,2025 2025,2100
to {92%91% -} accuracy on

641
00:17:58,335 --> 00:17:59,580
0,90 90,300 300,615 615,965
the m data set.|

642
00:17:59,580 --> 00:18:00,615
0,180 180,420 420,735 735,840 840,1035
But then, what's the hard

643
00:18:00,615 --> 00:18:02,115
0,335 535,810 810,1065 1065,1335 1335,1500
part? The hard part of

644
00:18:02,115 --> 00:18:03,710
0,270 270,555 555,720 720,995 1015,1595
it is the last {2%-5%

645
00:18:03,730 --> 00:18:05,280
0,305 305,875 875,1130 1130,1340 1340,1550
- -} to reach the

646
00:18:05,280 --> 00:18:06,340
0,195 195,530
hundred percent.|

647
00:18:06,410 --> 00:18:07,510
0,245 245,455 455,590 590,830 830,1100
So that's the hard part.

648
00:18:07,510 --> 00:18:08,880
0,300 300,420 420,555 555,830 970,1370
That's what we call below

649
00:18:08,930 --> 00:18:11,605
0,260 260,470 470,820 1500,1900 2430,2675
the noise level. Okay? That

650
00:18:11,605 --> 00:18:12,325
0,120 120,240 240,345 345,495 495,720
means if we can learn

651
00:18:12,325 --> 00:18:15,040
0,335 865,1265 1525,1890 1890,2255 2395,2715
this process really like with

652
00:18:15,040 --> 00:18:16,620
0,240 240,525 525,1100
really good accuracy.|

653
00:18:17,460 --> 00:18:19,990
0,400 900,1300 1770,2045 2045,2225 2225,2530
Now, and to do this

654
00:18:20,040 --> 00:18:21,360
0,730
robustly.|

655
00:18:21,360 --> 00:18:22,185
0,150 150,270 270,405 405,585 585,825
In the sense of lip

656
00:18:22,185 --> 00:18:23,600
0,335
she.|

657
00:18:23,970 --> 00:18:24,725
0,260 260,410 410,545 545,635 635,755
Who knows what is the

658
00:18:24,725 --> 00:18:26,980
0,515 565,965
lipitz function?|

659
00:18:29,580 --> 00:18:31,360
0,260 310,710 850,1250
Five, six, okay.|

660
00:18:31,780 --> 00:18:34,480
0,290 290,580 900,1385 1385,1660
Alright, so lipit nest.|

661
00:18:34,630 --> 00:18:35,925
0,400 600,860 860,980 980,1130 1130,1295
So good that I put

662
00:18:35,925 --> 00:18:37,880
0,210 210,545 715,1005 1005,1295 1555,1955
this in here. So, so

663
00:18:38,350 --> 00:18:39,285
0,260 260,410 410,590 590,770 770,935
as I said, look, so

664
00:18:39,285 --> 00:18:40,980
0,165 165,405 405,755 1105,1455 1455,1695
your moving your, your input

665
00:18:40,980 --> 00:18:42,765
0,770 1120,1395 1395,1515 1515,1650 1650,1785
withpsilon okay, a little bit

666
00:18:42,765 --> 00:18:44,240
0,225 225,795 795,975 975,1155 1155,1475
of perturbation at the input

667
00:18:44,530 --> 00:18:45,920
0,290 290,440 440,700
of a function.|

668
00:18:45,920 --> 00:18:47,170
0,225 225,345 345,620 670,960 960,1250
Then, if the output is

669
00:18:47,190 --> 00:18:49,480
0,275 275,485 485,695 695,1270 1890,2290
also moving with epsilon or

670
00:18:49,500 --> 00:18:51,560
0,860 860,1325 1325,1850 1850,1955 1955,2060
proportional linearly proportional to that

671
00:18:51,560 --> 00:18:53,360
0,590 1090,1350 1350,1470 1470,1605 1605,1800
epsilon, that means this function

672
00:18:53,360 --> 00:18:54,650
0,195 195,680 910,1140 1140,1215 1215,1290
is lipshit, so you have

673
00:18:54,650 --> 00:18:56,260
0,230 250,650 910,1170 1170,1320 1320,1610
a controlled kind of process.

674
00:18:56,880 --> 00:18:58,910
0,400 450,815 815,1180 1530,1805 1805,2030
Changing the input do not

675
00:18:58,910 --> 00:19:01,250
0,530 760,1160 1210,1605 1605,2000 2080,2340
dramatically change the output of

676
00:19:01,250 --> 00:19:02,200
0,135 135,410
a function.|

677
00:19:02,320 --> 00:19:03,190
0,105 105,255 255,390 390,585 585,870
That's called the leap sheets

678
00:19:03,190 --> 00:19:04,240
0,350
function.|

679
00:19:06,360 --> 00:19:07,620
0,400
Now.|

680
00:19:09,490 --> 00:19:10,680
0,290 290,500 500,695 695,1055 1055,1190
Yeah, so you memorize the

681
00:19:10,680 --> 00:19:11,600
0,260
data.|

682
00:19:11,850 --> 00:19:12,725
0,260 260,380 380,515 515,665 665,875
And you want to do

683
00:19:12,725 --> 00:19:14,820
0,240 240,845 925,1625
this memorization robustly.|

684
00:19:14,820 --> 00:19:15,930
0,75 75,150 150,410 640,945 945,1110
So if you want to

685
00:19:15,930 --> 00:19:17,985
0,135 135,410 940,1185 1185,1430 1750,2055
do that, it is necessary

686
00:19:17,985 --> 00:19:20,835
0,305 475,875 1285,1685 1915,2235 2235,2850
is absolutely necessary to parameterize

687
00:19:20,835 --> 00:19:22,520
0,210 210,495 495,785
your neural network.|

688
00:19:23,070 --> 00:19:24,790
0,350 350,700 870,1220 1220,1445 1445,1720
At least equal to N

689
00:19:25,020 --> 00:19:26,840
0,365 365,620 620,910 930,1205 1205,1820
N is basically the dimensionality

690
00:19:26,840 --> 00:19:27,965
0,90 90,225 225,450 450,800 850,1125
of your data set, which

691
00:19:27,965 --> 00:19:30,160
0,165 165,450 450,845 1255,1655 1795,2195
is sixty k times D

692
00:19:30,210 --> 00:19:31,700
0,290 290,470 470,620 620,1340 1340,1490
D is the dimensionality of

693
00:19:31,700 --> 00:19:32,980
0,290
your.|

694
00:19:33,020 --> 00:19:35,080
0,290 290,580 660,950 950,1240 1740,2060
Of every input sample, let's

695
00:19:35,080 --> 00:19:35,875
0,90 90,210 210,435 435,660 660,795
say if your input is

696
00:19:35,875 --> 00:19:37,465
0,275 355,720 720,1085 1285,1515 1515,1590
an data set, I mean

697
00:19:37,465 --> 00:19:38,740
0,180 180,425 745,1020 1020,1125 1125,1275
I'm gonna give you an

698
00:19:38,740 --> 00:19:40,735
0,320 640,945 945,1140 1140,1430 1630,1995
example later on, but ah,

699
00:19:40,735 --> 00:19:41,785
0,285 285,390 390,585 585,795 795,1050
let's say the input is

700
00:19:42,055 --> 00:19:43,975
0,815 1165,1425 1425,1545 1545,1725 1725,1920
728 in the order of

701
00:19:43,975 --> 00:19:44,820
0,150 150,240 240,300 300,495 495,845
ten to the power three.|

702
00:19:45,450 --> 00:19:46,370
0,275 275,395 395,545 545,710 710,920
And the number of data

703
00:19:46,370 --> 00:19:48,130
0,195 195,330 330,585 585,950 1360,1760
set is sixty k, right.

704
00:19:48,540 --> 00:19:50,500
0,305 305,610 930,1330 1380,1670 1670,1960
Then the minimum size of

705
00:19:50,760 --> 00:19:51,725
0,335 335,545 545,710 710,845 845,965
data set has to be

706
00:19:51,725 --> 00:19:52,600
0,150 150,270 270,375 375,555 555,875
tend to the power eight

707
00:19:53,610 --> 00:19:54,605
0,350 350,560 560,680 680,815 815,995
that would be the size

708
00:19:54,605 --> 00:19:55,900
0,165 165,285 285,540 540,845 895,1295
of the neural network model.

709
00:19:56,400 --> 00:19:57,520
0,290 290,410 410,515 515,755 755,1120
Tend to the power nine

710
00:19:57,960 --> 00:20:00,995
0,400 510,1330 1590,1990 2340,2705 2705,3035
to robustly learn m data

711
00:20:00,995 --> 00:20:03,080
0,365 745,1065 1065,1245 1245,1595 1705,2085
set. That's a huge neural

712
00:20:03,080 --> 00:20:03,900
0,260
network.|

713
00:20:03,910 --> 00:20:05,145
0,290 290,470 470,760 780,1070 1070,1235
But this is one of

714
00:20:05,145 --> 00:20:07,220
0,165 165,455 895,1410 1410,1740 1740,2075
the fundamental explanations, very recent

715
00:20:07,510 --> 00:20:08,520
0,290 290,455 455,650 650,860 860,1010
that we have about the

716
00:20:08,520 --> 00:20:11,025
0,180 180,500 760,1065 1065,1370 2170,2505
theory of deep learning and

717
00:20:11,025 --> 00:20:12,260
0,210 210,345 345,480 480,755 835,1235
why is it called, ah,

718
00:20:12,610 --> 00:20:16,905
0,400 450,770 770,1480 2100,2500 3510,4295
dramatic over paramatization because intuitively,

719
00:20:16,905 --> 00:20:18,645
0,135 135,300 300,480 480,785 1135,1740
as we showed before, memorizing

720
00:20:18,645 --> 00:20:20,010
0,270 270,540 540,825 825,1080 1080,1365
n data points would require

721
00:20:20,010 --> 00:20:22,460
0,350 880,1460 1750,2040 2040,2190 2190,2450
in parameters and we had

722
00:20:23,020 --> 00:20:25,280
0,305 305,790 990,1265 1265,1540 1590,2260
Eric baum and David hessler,

723
00:20:25,450 --> 00:20:26,840
0,275 275,545 545,860 860,1085 1085,1390
they were showing that two

724
00:20:27,250 --> 00:20:28,335
0,275 275,470 470,710 710,890 890,1085
two layer neural network with

725
00:20:28,335 --> 00:20:29,910
0,465 465,870 870,1185 1185,1440 1440,1575
threshold activation function. They showed

726
00:20:29,910 --> 00:20:32,100
0,120 120,255 255,1040 1390,1790 1930,2190
it in 1988 that you

727
00:20:32,100 --> 00:20:32,940
0,120 120,285 285,525 525,705 705,840
would need p the number

728
00:20:32,940 --> 00:20:34,190
0,150 150,585 585,810 810,960 960,1250
of parameters you would need

729
00:20:34,510 --> 00:20:36,360
0,400 570,970 990,1340 1340,1610 1610,1850
almost equivalent order of number

730
00:20:36,360 --> 00:20:37,635
0,210 210,450 450,735 735,1020 1020,1275
of data set data points

731
00:20:37,635 --> 00:20:39,050
0,180 180,315 315,575 745,1080 1080,1415
that you have that would

732
00:20:39,250 --> 00:20:41,270
0,290 290,515 515,785 785,1120 1230,2020
actually would be enough theoretically.|

733
00:20:41,710 --> 00:20:43,515
0,290 290,580 1230,1520 1520,1670 1670,1805
And then they showed it

734
00:20:43,515 --> 00:20:44,780
0,275 295,570 570,720 720,930 930,1265
recently for the radio networks.|

735
00:20:45,700 --> 00:20:47,485
0,350 1030,1275 1275,1425 1425,1620 1620,1785
And we even have that

736
00:20:47,485 --> 00:20:48,990
0,150 150,285 285,570 570,990 990,1505
in the neural tangent kernels.

737
00:20:49,430 --> 00:20:50,950
0,400 870,1130 1130,1265 1265,1415 1415,1520
So how many of you

738
00:20:50,950 --> 00:20:52,195
0,90 90,350 370,645 645,900 900,1245
are familiar with neural tangent

739
00:20:52,195 --> 00:20:53,620
0,455
kernels?|

740
00:20:56,750 --> 00:20:58,540
0,260 260,380 380,530 530,820
Three out of three.|

741
00:20:59,700 --> 00:21:00,880
0,255 255,530
At one.|

742
00:21:01,070 --> 00:21:01,980
0,400
Two.|

743
00:21:01,980 --> 00:21:03,390
0,195 195,435 435,750 750,1065 1065,1410
Yeah, so neural tangent kernels

744
00:21:03,390 --> 00:21:04,500
0,150 150,410
is that?|

745
00:21:04,540 --> 00:21:06,080
0,400
So.|

746
00:21:06,080 --> 00:21:08,975
0,380 1780,2055 2055,2280 2280,2565 2565,2895
Imagine the process of training

747
00:21:08,975 --> 00:21:10,355
0,255 255,495 495,750 750,1035 1035,1380
and neural network with gradium

748
00:21:10,355 --> 00:21:13,115
0,455 1465,1740 1740,1965 1965,2315 2365,2760
descent. The whole process from

749
00:21:13,115 --> 00:21:14,315
0,300 300,525 525,840 840,1080 1080,1200
beginning of training to the

750
00:21:14,315 --> 00:21:16,460
0,180 180,420 420,755 1765,2025 2025,2145
end of training is a

751
00:21:16,460 --> 00:21:18,560
0,555 555,860 1330,1605 1605,1755 1755,2100
dynamical process. That means you're

752
00:21:18,560 --> 00:21:19,820
0,510 510,690 690,960 960,1095 1095,1260
updating the weights of the

753
00:21:19,820 --> 00:21:21,610
0,290 730,1065 1065,1260 1260,1455 1455,1790
system as you go further,

754
00:21:22,140 --> 00:21:23,780
0,320 320,530 530,800 800,1180 1320,1640
given a data set, given

755
00:21:23,780 --> 00:21:25,250
0,180 180,405 405,680 940,1245 1245,1470
a neural network, and given

756
00:21:25,250 --> 00:21:27,040
0,195 195,585 585,795 795,1065 1065,1790
the parameters of your optimizer,

757
00:21:27,930 --> 00:21:29,800
0,275 275,515 515,830 830,1175 1175,1870
you can this learning dynamics.|

758
00:21:30,620 --> 00:21:32,010
0,320 320,605 605,965 965,1115 1115,1390
Can be converge if I

759
00:21:33,050 --> 00:21:35,095
0,400 510,815 815,1120 1290,1850 1850,2045
can actually be modeled by

760
00:21:35,095 --> 00:21:36,640
0,90 90,540 540,815
a dynamical process.|

761
00:21:36,830 --> 00:21:38,470
0,275 275,770 770,1010 1010,1310 1310,1640
My differential equation that explains

762
00:21:38,470 --> 00:21:39,730
0,195 195,420 420,705 705,930 930,1260
how the updates of gradient

763
00:21:39,730 --> 00:21:41,140
0,410 580,840 840,960 960,1170 1170,1410
descent of a neural network

764
00:21:41,140 --> 00:21:42,120
0,255 255,530
would work.|

765
00:21:42,120 --> 00:21:43,060
0,290
Now.|

766
00:21:43,070 --> 00:21:45,490
0,305 305,610 1620,1955 1955,2180 2180,2420
If I increase the size

767
00:21:45,490 --> 00:21:46,735
0,255 255,405 405,630 630,890 970,1245
of the neural network to

768
00:21:46,735 --> 00:21:48,880
0,570 570,965
infinite width.|

769
00:21:48,980 --> 00:21:50,080
0,350 350,590 590,755 755,935 935,1100
I increase the size of

770
00:21:50,080 --> 00:21:51,360
0,105 105,270 270,465 465,800 880,1280
the neural network to with

771
00:21:51,950 --> 00:21:53,820
0,400 420,820 870,1220 1220,1520 1520,1870
then this dynamic of learning

772
00:21:54,800 --> 00:21:56,460
0,320 320,590 590,940 960,1310 1310,1660
has a close form solution

773
00:21:56,900 --> 00:21:57,955
0,260 260,380 380,515 515,785 785,1055
that means it has actually

774
00:21:57,955 --> 00:21:59,860
0,180 180,485 1405,1665 1665,1785 1785,1905
a solution, which is a

775
00:21:59,860 --> 00:22:00,925
0,285 285,510 510,705 705,870 870,1065
kernel method. So basically you

776
00:22:00,925 --> 00:22:01,810
0,150 150,315 315,480 480,675 675,885
will end up having a

777
00:22:01,810 --> 00:22:02,880
0,500
kernel.|

778
00:22:02,880 --> 00:22:04,550
0,150 150,360 360,920 1000,1365 1365,1670
And that kernel explains the

779
00:22:04,570 --> 00:22:06,300
0,400 420,770 770,1010 1010,1520 1520,1730
entire behavior and dynamics of

780
00:22:06,300 --> 00:22:07,650
0,180 180,420 420,770 1030,1275 1275,1350
your learning process in the

781
00:22:07,650 --> 00:22:09,030
0,345 345,620 820,1080 1080,1215 1215,1380
infinite way. This is called

782
00:22:09,030 --> 00:22:10,370
0,135 135,390 390,705 705,1050 1050,1340
the neural tangent kernel theory

783
00:22:10,780 --> 00:22:12,280
0,400
and.|

784
00:22:12,280 --> 00:22:13,285
0,120 120,285 285,555 555,810 810,1005
We have A A ph

785
00:22:13,285 --> 00:22:15,055
0,195 195,485 865,1265 1285,1575 1575,1770
d student actually sitting over

786
00:22:15,055 --> 00:22:17,560
0,305 865,1230 1230,1505 1675,2075 2215,2505
there, Nan Lu, that is

787
00:22:17,560 --> 00:22:18,880
0,285 285,540 540,800 910,1185 1185,1320
focusing on that, and this

788
00:22:18,880 --> 00:22:20,155
0,180 180,360 360,620 820,1110 1110,1275
is actually his ph d

789
00:22:20,155 --> 00:22:22,500
0,275 655,945 945,1355 1645,1995 1995,2345
topic that he's working on.|

790
00:22:23,040 --> 00:22:25,260
0,400 810,1280 1280,1540
In danielle lab.|

791
00:22:26,470 --> 00:22:28,100
0,305 305,455 455,680 680,1160 1160,1630
Okay, so now let's let's

792
00:22:28,330 --> 00:22:30,830
0,335 335,575 575,860 860,1240 2100,2500
move from this ah theory

793
00:22:31,180 --> 00:22:32,280
0,260 260,545 545,800 800,920 920,1100
and let's let's give an

794
00:22:32,280 --> 00:22:33,360
0,320 550,795 795,870 870,960 960,1080
example. So we have the

795
00:22:33,360 --> 00:22:34,860
0,225 225,555 555,920 1030,1305 1305,1500
m data set. It has

796
00:22:34,860 --> 00:22:36,315
0,320 820,1095 1095,1200 1200,1275 1275,1455
around ten to the power

797
00:22:36,315 --> 00:22:39,000
0,335 925,1215 1215,1380 1380,1805 2305,2685
five number of parameters. The

798
00:22:39,000 --> 00:22:40,635
0,810 810,900 900,1080 1080,1335 1335,1635
dimensionality of each data point

799
00:22:40,635 --> 00:22:42,410
0,365 925,1185 1185,1290 1290,1455 1455,1775
is ten to power three,

800
00:22:42,520 --> 00:22:43,890
0,305 305,515 515,725 725,1030 1080,1370
seven hundred twenty eight, just

801
00:22:43,890 --> 00:22:44,880
0,165 165,440
the scale.|

802
00:22:45,010 --> 00:22:46,190
0,275 275,455 455,665 665,875 875,1180
And then we saw the

803
00:22:46,240 --> 00:22:48,255
0,400 540,815 815,1090 1110,1510 1770,2015
transition in the, ah, kind

804
00:22:48,255 --> 00:22:49,470
0,180 180,735 735,930 930,1020 1020,1215
of robustness. That is like,

805
00:22:49,470 --> 00:22:50,295
0,285 285,510 510,645 645,735 735,825
at least you need to

806
00:22:50,295 --> 00:22:52,490
0,135 135,425 595,945 945,1295 1555,2195
have one our six parameters

807
00:22:52,600 --> 00:22:54,150
0,350 350,860 860,1145 1145,1370 1370,1550
to robustly fit the m

808
00:22:54,150 --> 00:22:55,320
0,300 300,650
data set.|

809
00:22:55,790 --> 00:22:56,815
0,275 275,550 630,860 860,935 935,1025
But then there are a

810
00:22:56,815 --> 00:22:57,610
0,120 120,285 285,495 495,675 675,795
couple of notes that we

811
00:22:57,610 --> 00:22:59,350
0,135 135,255 255,500 1240,1515 1515,1740
want to have. The notion

812
00:22:59,350 --> 00:23:00,990
0,285 285,765 765,945 945,1220 1240,1640
of robustness in the, um,

813
00:23:02,090 --> 00:23:03,160
0,260 260,395 395,590 590,845 845,1070
in the theory paper was

814
00:23:03,160 --> 00:23:04,000
0,135 135,255 255,405 405,630 630,840
a little bit different than

815
00:23:04,000 --> 00:23:05,110
0,120 120,315 315,585 585,960 960,1110
the notion of robustness and

816
00:23:05,110 --> 00:23:06,745
0,195 195,630 630,980 1030,1380 1380,1635
Le sheetness that we showed

817
00:23:06,745 --> 00:23:08,700
0,165 165,425
in the.|

818
00:23:08,700 --> 00:23:09,780
0,255 255,450 450,660 660,840 840,1080
In the theory of law,

819
00:23:09,780 --> 00:23:11,880
0,560 940,1230 1230,1520 1540,1875 1875,2100
robustness, and then another point

820
00:23:11,880 --> 00:23:13,140
0,195 195,500 610,885 885,1065 1065,1260
is that the law seems

821
00:23:13,140 --> 00:23:14,925
0,120 120,240 240,860 1000,1400 1510,1785
to be contradicted because if

822
00:23:14,925 --> 00:23:16,070
0,135 135,555 555,705 705,855 855,1145
you multiply we just said

823
00:23:16,090 --> 00:23:17,475
0,245 245,380 380,545 545,820 1140,1385
the law is like you

824
00:23:17,475 --> 00:23:19,200
0,245 565,900 900,1170 1170,1425 1425,1725
know and times d right?

825
00:23:19,200 --> 00:23:20,205
0,255 255,450 450,540 540,750 750,1005
Like that's the minimum number

826
00:23:20,205 --> 00:23:21,435
0,305 355,810 810,945 945,1080 1080,1230
of samples that you can,

827
00:23:21,435 --> 00:23:22,890
0,120 120,240 240,390 390,665 1195,1455
you have the transition. So

828
00:23:22,890 --> 00:23:23,805
0,180 180,435 435,630 630,765 765,915
but here if you do

829
00:23:23,805 --> 00:23:26,040
0,275 505,795 795,1085 1855,2115 2115,2235
that ten times ten to

830
00:23:26,040 --> 00:23:27,615
0,210 210,560 940,1245 1245,1425 1425,1575
power five times ten to

831
00:23:27,615 --> 00:23:29,235
0,255 255,635 1015,1305 1305,1470 1470,1620
power three is tend to

832
00:23:29,235 --> 00:23:31,005
0,275 325,690 690,1055 1195,1440 1440,1770
power ah eight and it's

833
00:23:31,005 --> 00:23:32,535
0,300 300,615 615,855 855,1115 1285,1530
much larger than that than

834
00:23:32,535 --> 00:23:33,975
0,90 90,300 300,665 925,1200 1200,1440
to power six that was

835
00:23:33,975 --> 00:23:34,960
0,255 255,545
observed in.|

836
00:23:34,970 --> 00:23:37,260
0,400 990,1390
Ah, reality.|

837
00:23:37,390 --> 00:23:38,820
0,400
But.|

838
00:23:39,230 --> 00:23:40,030
0,260 260,380 380,500 500,650 650,800
One of the things that

839
00:23:40,030 --> 00:23:40,855
0,105 105,240 240,405 405,555 555,825
you have to also notice

840
00:23:40,855 --> 00:23:42,115
0,270 270,435 435,675 675,935 955,1260
is that there's something about

841
00:23:42,115 --> 00:23:43,810
0,285 285,665 775,1080 1080,1350 1350,1695
data sets is called effective

842
00:23:43,810 --> 00:23:46,810
0,950 1210,1530 1530,1845 1845,2790 2790,3000
dimensionality. And effective dimensionality means

843
00:23:46,810 --> 00:23:48,295
0,320 640,945 945,1170 1170,1365 1365,1485
that when I show you

844
00:23:48,295 --> 00:23:49,500
0,120 120,395 595,825 825,930 930,1205
an image, there are principal

845
00:23:49,760 --> 00:23:51,445
0,400 420,695 695,845 845,1120 1380,1685
components of an image. So

846
00:23:51,445 --> 00:23:53,080
0,300 300,570 570,845 1105,1440 1440,1635
finding the principal components of

847
00:23:53,080 --> 00:23:54,780
0,135 135,410 670,975 975,1280 1300,1700
an image that how small

848
00:23:54,950 --> 00:23:56,605
0,290 290,580 720,1070 1070,1330 1350,1655
that image, what's the information?

849
00:23:56,605 --> 00:23:57,780
0,255 255,525 525,720 720,885 885,1175
The information is not the

850
00:23:57,860 --> 00:23:59,320
0,320 320,640 660,935 935,1070 1070,1460
same size as the pixel

851
00:23:59,320 --> 00:24:00,925
0,320 400,750 750,1035 1035,1290 1290,1605
itself. The information is much

852
00:24:00,925 --> 00:24:01,820
0,395
smaller.|

853
00:24:01,970 --> 00:24:03,570
0,245 245,380 380,650 650,1370 1370,1600
So the effective dimensionality of,

854
00:24:03,620 --> 00:24:05,035
0,380 380,560 560,800 800,1085 1085,1415
it's hard to actually determine

855
00:24:05,035 --> 00:24:06,520
0,315 315,435 435,660 660,1395 1395,1485
what's the effective dimensionality of

856
00:24:06,520 --> 00:24:07,870
0,120 120,300 300,570 570,920 1030,1350
a given data set, but

857
00:24:07,870 --> 00:24:09,025
0,210 210,345 345,585 585,915 915,1155
still, for the data set,

858
00:24:09,025 --> 00:24:09,940
0,395
it's.|

859
00:24:09,940 --> 00:24:10,860
0,240 240,330 330,405 405,585 585,920
Tend to the power one

860
00:24:10,910 --> 00:24:11,755
0,260 260,395 395,530 530,680 680,845
and now we have ten

861
00:24:11,755 --> 00:24:13,300
0,135 135,345 345,660 660,1025 1255,1545
to power five in and

862
00:24:13,300 --> 00:24:14,995
0,195 195,405 405,705 705,1530 1530,1695
if the effective dimensionality is

863
00:24:14,995 --> 00:24:17,100
0,305 1225,1485 1485,1605 1605,1785 1785,2105
basically tend to power one,

864
00:24:17,210 --> 00:24:18,300
0,260 260,380 380,515 515,740 740,1090
then you would have basically

865
00:24:18,500 --> 00:24:19,900
0,305 305,590 590,845 845,1115 1115,1400
the same. You can confirm

866
00:24:19,900 --> 00:24:22,140
0,290 310,710 1030,1320 1320,1905 1905,2240
with experiments the theoretical results

867
00:24:22,460 --> 00:24:24,280
0,320 320,620 620,1000 1470,1715 1715,1820
that was observed with the

868
00:24:24,280 --> 00:24:26,365
0,120 120,285 285,830 1300,1700 1810,2085
law of robustness. Now the

869
00:24:26,365 --> 00:24:27,685
0,360 360,750 750,975 975,1125 1125,1320
noisy labels, as I said,

870
00:24:27,685 --> 00:24:29,260
0,330 330,660 660,1005 1005,1320 1320,1575
it's basically learning the difficult

871
00:24:29,260 --> 00:24:30,480
0,135 135,240 240,375 375,650
part of the training.|

872
00:24:30,570 --> 00:24:33,020
0,275 275,550 1440,1745 1745,2050 2160,2450
And then, ah, in regard

873
00:24:33,020 --> 00:24:34,540
0,150 150,375 375,740 970,1245 1245,1520
to image net is basically

874
00:24:34,590 --> 00:24:35,990
0,400 420,665 665,770 770,950 950,1400
shows the law of robustness

875
00:24:35,990 --> 00:24:37,565
0,320 490,780 780,960 960,1305 1305,1575
predict because we haven't yet

876
00:24:37,565 --> 00:24:40,385
0,365 835,1170 1170,1505 1555,1955 2515,2820
trained super large networks. It

877
00:24:40,385 --> 00:24:41,600
0,210 210,510 510,750 750,975 975,1215
seems like the networks that

878
00:24:41,600 --> 00:24:42,700
0,90 90,225 225,480 480,765 765,1100
we have trained so far,

879
00:24:43,020 --> 00:24:44,405
0,230 230,380 380,665 665,1030 1140,1385
they are actually small. You

880
00:24:44,405 --> 00:24:45,220
0,90 90,180 180,315 315,510 510,815
know, we have trained like

881
00:24:45,270 --> 00:24:47,195
0,335 335,670 840,1190 1190,1450 1530,1925
really large neural networks still.

882
00:24:47,195 --> 00:24:48,160
0,240 240,360 360,540 540,705 705,965
But they have to be

883
00:24:48,210 --> 00:24:50,360
0,275 275,410 410,635 635,1000 1890,2150
on the order of ten

884
00:24:50,360 --> 00:24:51,440
0,120 120,330 330,660 660,930 930,1080
to power twelve or ten

885
00:24:51,440 --> 00:24:52,600
0,105 105,285 285,620 640,900 900,1160
to power ten, you know.|

886
00:24:53,040 --> 00:24:53,975
0,305 305,500 500,650 650,785 785,935
And this is like the

887
00:24:53,975 --> 00:24:55,420
0,425 625,900 900,1035 1035,1170 1170,1445
prediction of the law of

888
00:24:55,920 --> 00:24:57,180
0,640
robustness.|

889
00:24:57,220 --> 00:24:59,900
0,400 480,725 725,970 1775,2020
Okay, so now let's.|

890
00:24:59,900 --> 00:25:00,740
0,195 195,360 360,495 495,615 615,840
Get back to this image.

891
00:25:00,740 --> 00:25:02,090
0,210 210,375 375,680 730,1110 1110,1350
So all these networks that

892
00:25:02,090 --> 00:25:03,130
0,105 105,240 240,480 480,735 735,1040
I was talking about and

893
00:25:03,210 --> 00:25:05,915
0,320 320,635 635,1300 1740,2140 2430,2705
law of robustness, basically in

894
00:25:05,915 --> 00:25:07,940
0,270 270,665 1075,1365 1365,1650 1650,2025
that regime, in that regime,

895
00:25:07,940 --> 00:25:08,855
0,285 285,480 480,630 630,780 780,915
I showed you that we

896
00:25:08,855 --> 00:25:10,740
0,180 180,420 420,1085
have great generalization.|

897
00:25:11,050 --> 00:25:12,960
0,260 260,440 440,760 990,1390 1560,1910
We get more, probably more

898
00:25:12,960 --> 00:25:16,100
0,620 790,1190 1360,1635 1635,1910 2410,3140
robustness. Ah, and then reasoning

899
00:25:16,150 --> 00:25:17,835
0,400 660,935 935,1130 1130,1430 1430,1685
still we have questions about

900
00:25:17,835 --> 00:25:19,140
0,165 165,360 360,540 540,815 1045,1305
how to achieve it and

901
00:25:19,140 --> 00:25:20,460
0,180 180,525 525,690 690,1095 1095,1320
then bias and fairness, which

902
00:25:20,460 --> 00:25:22,490
0,135 135,345 345,680 1330,1680 1680,2030
is very important, energy consumption

903
00:25:22,540 --> 00:25:24,470
0,350 350,1325 1325,1565 1565,1685 1685,1930
and accountability of the models.|

904
00:25:26,180 --> 00:25:27,730
0,305 305,610 690,965 965,1240 1290,1550
There is a way, and

905
00:25:27,730 --> 00:25:28,930
0,165 165,375 375,570 570,860 880,1200
that has been the focus

906
00:25:28,930 --> 00:25:30,220
0,225 225,525 525,915 915,1185 1185,1290
of the research that we

907
00:25:30,220 --> 00:25:31,120
0,90 90,225 225,375 375,525 525,900
have been doing at daniela

908
00:25:31,120 --> 00:25:33,475
0,285 285,560 940,1340 1390,1790 2050,2355
rus' lab with Alexander and

909
00:25:33,475 --> 00:25:35,160
0,165 165,300 300,435 435,695 1285,1685
a couple of other graduate

910
00:25:35,270 --> 00:25:37,560
0,400 600,875 875,1150
students of ours.|

911
00:25:37,720 --> 00:25:39,135
0,260 260,395 395,590 590,910 1110,1415
Is to find out how

912
00:25:39,135 --> 00:25:39,960
0,165 165,285 285,450 450,645 645,825
can we get out of

913
00:25:39,960 --> 00:25:43,260
0,165 165,680 1090,1490 2170,2570 2830,3300
that overpower regime while addressing

914
00:25:43,260 --> 00:25:46,190
0,150 150,440 1840,2175 2175,2510 2530,2930
all these social technical challenges.|

915
00:25:47,370 --> 00:25:49,000
0,400 750,1040 1040,1190 1190,1340 1340,1630
And how we did that,

916
00:25:49,350 --> 00:25:50,500
0,275 275,455 455,680 680,875 875,1150
we went back to source.|

917
00:25:52,270 --> 00:25:54,230
0,400 1050,1310 1310,1445 1445,1640 1640,1960
Basically, we looked into brains,

918
00:25:54,670 --> 00:25:56,270
0,400 570,830 830,980 980,1235 1235,1600
okay? We looked into how

919
00:25:56,350 --> 00:25:57,675
0,275 275,410 410,545 545,1040 1040,1325
we can get inspiration from

920
00:25:57,675 --> 00:26:01,320
0,305 1195,1595 1735,2055 2055,2375 2785,3645
brains to improve over architectural

921
00:26:01,320 --> 00:26:02,840
0,645 645,915 915,1050 1050,1215 1215,1520
biases that we have in

922
00:26:03,370 --> 00:26:05,280
0,380 380,640 1170,1445 1445,1670 1670,1910
neural networks in order to

923
00:26:05,280 --> 00:26:06,440
0,180 180,330 330,450 450,630 630,1160
break the law of robustness.|

924
00:26:08,430 --> 00:26:10,070
0,335 335,545 545,820 1050,1400 1400,1640
Now and then we we

925
00:26:10,070 --> 00:26:11,705
0,255 255,570 570,920 1000,1350 1350,1635
invented something called liquid neural

926
00:26:11,705 --> 00:26:14,150
0,275 295,675 675,1055 1525,2160 2160,2445
networks, the direct inspiration from

927
00:26:14,150 --> 00:26:16,150
0,290 550,870 870,1200 1200,1410 1410,2000
how, ah, neurons and synapses

928
00:26:16,170 --> 00:26:17,090
0,320 320,485 485,590 590,755 755,920
interact with each other in

929
00:26:17,090 --> 00:26:18,850
0,120 120,380 640,1040 1150,1515 1515,1760
the brain. Okay, that's how,

930
00:26:18,900 --> 00:26:20,945
0,305 305,610 960,1360 1470,1775 1775,2045
ah, ah, we, we started

931
00:26:20,945 --> 00:26:22,670
0,365 625,975 975,1185 1185,1425 1425,1725
our focus and the second

932
00:26:22,670 --> 00:26:23,645
0,195 195,345 345,525 525,735 735,975
half of my talk, I'm

933
00:26:23,645 --> 00:26:24,920
0,120 120,300 300,525 525,845 955,1275
just gonna talk about liquid

934
00:26:24,920 --> 00:26:26,350
0,270 270,480 480,690 690,825 825,1430
neural networks and their implications

935
00:26:26,640 --> 00:26:28,295
0,260 260,520 840,1235 1235,1400 1400,1655
in this realm of modern

936
00:26:28,295 --> 00:26:29,780
0,210 210,420 420,755
era of statistics.|

937
00:26:30,780 --> 00:26:31,910
0,380 380,620 620,770 770,950 950,1130
So, as I said, we

938
00:26:31,910 --> 00:26:34,520
0,225 225,560 610,960 960,1310
started with nervous systems.|

939
00:26:35,010 --> 00:26:36,180
0,400
Then.|

940
00:26:36,190 --> 00:26:37,230
0,245 245,380 380,620 620,845 845,1040
In order to understand their

941
00:26:37,230 --> 00:26:38,490
0,285 285,510 510,660 660,950 970,1260
assistance, you want to go

942
00:26:38,490 --> 00:26:39,645
0,240 240,480 480,770 790,1050 1050,1155
down and you you can

943
00:26:39,645 --> 00:26:41,550
0,105 105,345 345,705 705,1175 1615,1905
look into neural circuits. No

944
00:26:41,550 --> 00:26:43,020
0,330 330,525 525,990 990,1245 1245,1470
circuits are circuits that are

945
00:26:43,020 --> 00:26:44,400
0,330 330,510 510,920 1000,1260 1260,1380
composed of neurons. Then they

946
00:26:44,400 --> 00:26:45,975
0,225 225,590 640,1185 1185,1455 1455,1575
can get sensory inputs and

947
00:26:45,975 --> 00:26:47,780
0,275 835,1185 1185,1425 1425,1560 1560,1805
generate some, some sort of

948
00:26:49,600 --> 00:26:51,340
0,395 395,700 810,1300
outputs, motor outputs.|

949
00:26:51,430 --> 00:26:52,305
0,245 245,365 365,515 515,665 665,875
And then we went even

950
00:26:52,305 --> 00:26:53,280
0,300 300,525 525,705 705,870 870,975
deeper than that and we

951
00:26:53,280 --> 00:26:54,855
0,150 150,360 360,585 585,1040 1210,1575
looked into how neurons, individual

952
00:26:54,855 --> 00:26:56,390
0,485 595,960 960,1170 1170,1275 1275,1535
neurons, communicate with each other

953
00:26:56,950 --> 00:26:59,210
0,290 290,580 870,1270 1380,1780 1860,2260
to cells, receiving information between

954
00:26:59,380 --> 00:27:01,080
0,305 305,610 1110,1385 1385,1535 1535,1700
each other. And then we

955
00:27:01,080 --> 00:27:03,255
0,240 240,510 510,830 940,1340 1840,2175
arrived at an equation that,

956
00:27:03,255 --> 00:27:05,060
0,225 225,435 435,1115 1225,1515 1515,1805
or a formulation for the

957
00:27:05,110 --> 00:27:06,770
0,365 365,605 605,875 875,1055 1055,1660
interaction of neurons and synapses

958
00:27:06,940 --> 00:27:08,985
0,275 275,550 750,1150 1170,1570 1770,2045
that is abstract enough so

959
00:27:08,985 --> 00:27:10,350
0,150 150,270 270,465 465,750 750,1365
that we can perform computation,

960
00:27:10,350 --> 00:27:12,090
0,330 330,920 1210,1470 1470,1590 1590,1740
efficient computation, but at the

961
00:27:12,090 --> 00:27:14,060
0,225 225,560 670,1005 1005,1340 1570,1970
same time has more details

962
00:27:14,170 --> 00:27:15,780
0,350 350,605 605,910 930,1205 1205,1610
of how the actual computation

963
00:27:15,780 --> 00:27:17,870
0,320 580,915 915,1250 1450,1770 1770,2090
happens in, in, in brains.|

964
00:27:18,500 --> 00:27:19,840
0,290 290,500 500,725 725,905 905,1340
And not just the threshold

965
00:27:19,840 --> 00:27:21,870
0,285 285,705 705,1040 1240,1635 1635,2030
or activate. Very, ah, ah,

966
00:27:22,130 --> 00:27:23,530
0,260 260,410 410,700 810,1175 1175,1400
kind of the function that

967
00:27:23,530 --> 00:27:25,080
0,260 280,680 790,1035 1035,1275 1275,1550
we see. So let's get

968
00:27:25,250 --> 00:27:27,120
0,395 395,740 740,1025 1025,1360
more deeper into that.|

969
00:27:27,120 --> 00:27:28,275
0,225 225,375 375,555 555,860 880,1155
And we showed that if

970
00:27:28,275 --> 00:27:29,900
0,150 150,360 360,585 585,875 1225,1625
you really get into more

971
00:27:30,550 --> 00:27:33,120
0,800 800,1445 1445,2150 2150,2345 2345,2570
biologically plausible representation of neural

972
00:27:33,120 --> 00:27:34,425
0,260 490,735 735,855 855,1035 1035,1305
networks, you can gain more

973
00:27:34,425 --> 00:27:36,920
0,545 1165,1440 1440,1715 1735,2115 2115,2495
expressivity you can handle memory

974
00:27:36,940 --> 00:27:40,530
0,400 720,980 980,1240 2160,2560 3300,3590
in a much more natural

975
00:27:40,530 --> 00:27:41,440
0,290
way.|

976
00:27:41,750 --> 00:27:43,570
0,400 540,890 890,1145 1145,1450 1560,1820
You gain some properties, such

977
00:27:43,570 --> 00:27:45,505
0,165 165,920 1090,1425 1425,1665 1665,1935
as causality and which was

978
00:27:45,505 --> 00:27:46,825
0,365 385,690 690,855 855,975 975,1320
basically something that we haven't

979
00:27:46,825 --> 00:27:48,550
0,365 745,1110 1110,1455 1455,1575 1575,1725
discussed and what's the cause

980
00:27:48,550 --> 00:27:49,885
0,195 195,390 390,600 600,920 1060,1335
and effect of task? Can

981
00:27:49,885 --> 00:27:51,420
0,210 210,435 435,630 630,935
we actually learn that?|

982
00:27:51,460 --> 00:27:53,300
0,275 275,545 545,890 890,1190 1190,1840
You can get to robustness

983
00:27:53,590 --> 00:27:54,465
0,275 275,410 410,620 620,740 740,875
and you don't need to

984
00:27:54,465 --> 00:27:56,910
0,150 150,455 655,1055 1375,1775 2185,2445
be crazy like large. The

985
00:27:56,910 --> 00:27:58,365
0,135 135,285 285,560 760,1125 1125,1455
out of the that regime

986
00:27:58,365 --> 00:27:59,805
0,225 225,435 435,720 720,990 990,1440
you can perform a generative

987
00:27:59,805 --> 00:28:02,175
0,485 685,1020 1020,1290 1290,1625 2125,2370
modeling which was ah, what

988
00:28:02,175 --> 00:28:04,515
0,210 210,575 715,1115 1135,1535 2095,2340
I described ah before and

989
00:28:04,515 --> 00:28:06,050
0,120 120,255 255,450 450,675 675,1535
you can even do extrapolation.

990
00:28:06,430 --> 00:28:07,380
0,275 275,425 425,575 575,770 770,950
That means you can, you

991
00:28:07,380 --> 00:28:08,790
0,105 105,285 285,600 600,980 1090,1410
can even go beyond the

992
00:28:08,790 --> 00:28:09,840
0,180 180,300 300,450 450,740 790,1050
the kind of data that

993
00:28:09,840 --> 00:28:10,760
0,120 120,240 240,420 420,630 630,920
you have been trained on.

994
00:28:10,870 --> 00:28:11,610
0,245 245,350 350,455 455,590 590,740
That means you can, you

995
00:28:11,610 --> 00:28:12,890
0,120 120,285 285,540 540,885 885,1280
can go out of distribution.

996
00:28:13,360 --> 00:28:14,630
0,320 320,575 575,770 770,905 905,1270
That something that we couldn't

997
00:28:14,770 --> 00:28:16,680
0,400 420,820 1020,1325 1325,1630 1650,1910
do and like the, the

998
00:28:16,680 --> 00:28:17,820
0,260 310,570 570,690 690,855 855,1140
area that we were focused

999
00:28:17,820 --> 00:28:19,670
0,380 490,855 855,1260 1260,1515 1515,1850
on was robotics. Real world,

1000
00:28:19,690 --> 00:28:20,910
0,260 260,520 570,875 875,1055 1055,1220
you know like we call

1001
00:28:20,910 --> 00:28:22,610
0,195 195,500 520,920 1030,1365 1365,1700
it mixed horizon decision making

1002
00:28:22,840 --> 00:28:23,520
0,245 245,350 350,470 470,575 575,680
and means if you have

1003
00:28:23,520 --> 00:28:24,975
0,225 225,590 730,1200 1200,1305 1305,1455
a robot interacting in the

1004
00:28:24,975 --> 00:28:26,300
0,305 415,660 660,765 765,975 975,1325
environment in a real setting

1005
00:28:26,530 --> 00:28:27,600
0,290 290,500 500,695 695,875 875,1070
now how to bring this

1006
00:28:27,600 --> 00:28:29,810
0,150 150,300 300,590 1450,1830 1830,2210
kind of networks inside ah

1007
00:28:30,190 --> 00:28:31,935
0,400 750,1040 1040,1280 1280,1490 1490,1745
ah real world. And that's

1008
00:28:31,935 --> 00:28:34,070
0,120 120,395 835,1140 1140,1445 1735,2135
the focus of our research.|

1009
00:28:35,450 --> 00:28:37,120
0,400
Um.|

1010
00:28:37,610 --> 00:28:39,420
0,320 320,640
Yeah, so.|

1011
00:28:39,490 --> 00:28:40,845
0,260 260,365 365,610 660,1040 1040,1355
What are the building blocks

1012
00:28:40,845 --> 00:28:41,880
0,225 225,435 435,630 630,795 795,1035
of this type of neural

1013
00:28:41,880 --> 00:28:43,245
0,260 280,585 585,870 870,1125 1125,1365
networks? I said the building

1014
00:28:43,245 --> 00:28:44,745
0,255 255,405 405,665 895,1245 1245,1500
blocks are basically interaction of

1015
00:28:44,745 --> 00:28:46,050
0,180 180,540 540,795 795,1005 1005,1305
two neurons or two cells

1016
00:28:46,050 --> 00:28:47,600
0,240 240,360 360,620 1060,1305 1305,1550
with each other. One of

1017
00:28:47,770 --> 00:28:49,250
0,335 335,670 750,1025 1025,1190 1190,1480
some observation about this process.

1018
00:28:49,720 --> 00:28:50,985
0,245 245,455 455,800 800,1040 1040,1265
The first observation is that

1019
00:28:50,985 --> 00:28:53,000
0,365 715,960 960,1155 1155,1505 1615,2015
the kind of interaction between

1020
00:28:53,140 --> 00:28:54,120
0,260 260,545 545,695 695,800 800,980
two neurons in the brain

1021
00:28:54,120 --> 00:28:55,700
0,180 180,405 405,750 750,1130 1180,1580
is a continuous time process.|

1022
00:28:56,620 --> 00:28:58,560
0,400 600,1145 1145,1490 1490,1730 1730,1940
So that's something to account

1023
00:28:58,560 --> 00:28:59,940
0,285 285,495 495,1080 1080,1185 1185,1380
for, so we're not talking

1024
00:28:59,940 --> 00:29:01,780
0,210 210,615 615,950
about discrete processes.|

1025
00:29:01,880 --> 00:29:03,355
0,320 320,485 485,620 620,860 860,1475
Another thing is that synaptic

1026
00:29:03,355 --> 00:29:04,600
0,365 475,765 765,915 915,1035 1035,1245
release right now in neural

1027
00:29:04,600 --> 00:29:05,620
0,240 240,465 465,630 630,855 855,1020
networks, when you connect to

1028
00:29:05,620 --> 00:29:06,745
0,480 480,585 585,705 705,900 900,1125
nodes with each other, you

1029
00:29:06,745 --> 00:29:07,660
0,165 165,285 285,390 390,540 540,915
connect them with a scalar

1030
00:29:07,660 --> 00:29:09,140
0,290 460,860
weight, right?|

1031
00:29:09,140 --> 00:29:10,655
0,290 940,1185 1185,1275 1275,1380 1380,1515
Now, what if I tell

1032
00:29:10,655 --> 00:29:11,525
0,120 120,255 255,420 420,630 630,870
you that when you, when

1033
00:29:11,525 --> 00:29:12,530
0,150 150,450 450,720 720,870 870,1005
two neurons interact with each

1034
00:29:12,530 --> 00:29:14,020
0,290 490,825 825,945 945,1155 1155,1490
other, it's not only a

1035
00:29:14,040 --> 00:29:15,545
0,455 455,730 960,1220 1220,1325 1325,1505
scalar rate, but there is

1036
00:29:15,545 --> 00:29:17,615
0,180 180,330 330,875 955,1355 1735,2070
actually a probability distribution that

1037
00:29:17,615 --> 00:29:20,120
0,225 225,515 625,870 870,1115 1555,2505
how many kind of neurotransmitters

1038
00:29:20,120 --> 00:29:22,070
0,290 400,795 795,1110 1110,1430 1660,1950
generated from one cell is

1039
00:29:22,070 --> 00:29:23,320
0,180 180,330 330,590 730,990 990,1250
going to bind to the

1040
00:29:23,490 --> 00:29:24,850
0,380 380,650 650,785 785,995 995,1360
channels of the other cell

1041
00:29:24,900 --> 00:29:26,105
0,290 290,485 485,665 665,875 875,1205
and how it can actually

1042
00:29:26,105 --> 00:29:28,160
0,515 1165,1410 1410,1605 1605,1860 1860,2055
activate the other cell? So

1043
00:29:28,160 --> 00:29:29,720
0,240 240,590 730,1005 1005,1140 1140,1560
the communication between the nodes

1044
00:29:29,720 --> 00:29:31,175
0,270 270,480 480,1110 1110,1275 1275,1455
is very sophisticated and it's

1045
00:29:31,175 --> 00:29:32,270
0,105 105,210 210,330 330,605 745,1095
one of the fundamental building

1046
00:29:32,270 --> 00:29:34,940
0,350 520,870 870,1220 1720,2120 2410,2670
blocks of intelligence which we

1047
00:29:34,940 --> 00:29:36,640
0,260 340,740 760,1230 1230,1410 1410,1700
have actually abstracted way in

1048
00:29:37,290 --> 00:29:38,765
0,320 320,560 560,800 800,1085 1085,1475
artificial neural network to await,

1049
00:29:38,765 --> 00:29:40,040
0,315 315,570 570,905
to scale rate.|

1050
00:29:40,540 --> 00:29:42,870
0,400 1020,1420 1470,1870 1920,2195 2195,2330
Now, another ah point is

1051
00:29:42,870 --> 00:29:45,180
0,135 135,255 255,450 450,800 1570,2310
that we have massive parallelization

1052
00:29:45,180 --> 00:29:47,150
0,255 255,510 510,1160 1360,1665 1665,1970
and massive recurrence and feedback

1053
00:29:47,290 --> 00:29:49,290
0,275 275,550 660,980 980,1690 1740,2000
and memory and sparsity kind

1054
00:29:49,290 --> 00:29:50,930
0,165 165,390 390,710 730,1130 1240,1640
of, ah, ah ah, structures

1055
00:29:51,250 --> 00:29:52,740
0,305 305,610 870,1130 1130,1325 1325,1490
in brains. And that's something

1056
00:29:52,740 --> 00:29:55,080
0,165 165,300 300,570 570,950
that is missing from.|

1057
00:29:55,530 --> 00:29:57,700
0,400 960,1295 1295,1595 1595,1865 1865,2170
Ah, not entirely but but

1058
00:29:57,780 --> 00:29:59,045
0,350 350,635 635,830 830,1055 1055,1265
somehow it's missing from the

1059
00:29:59,045 --> 00:30:00,650
0,335 355,755 775,1050 1050,1440 1440,1605
artificial network. We deviated a

1060
00:30:00,650 --> 00:30:02,210
0,135 135,410 610,1010 1210,1455 1455,1560
little bit. Now what I

1061
00:30:02,210 --> 00:30:03,245
0,135 135,345 345,555 555,735 735,1035
want to argue is that

1062
00:30:03,245 --> 00:30:04,595
0,270 270,495 495,945 945,1140 1140,1350
if we incorporate all these

1063
00:30:04,595 --> 00:30:06,605
0,300 300,695 1075,1365 1365,1655 1705,2010
building blocks we might get

1064
00:30:06,605 --> 00:30:08,510
0,305 325,660 660,1290 1290,1605 1605,1905
into better representation, learning more

1065
00:30:08,510 --> 00:30:10,400
0,320 370,705 705,990 990,1340 1630,1890
flexible models and robust and

1066
00:30:10,400 --> 00:30:11,015
0,90 90,195 195,345 345,495 495,615
at the same time be

1067
00:30:11,015 --> 00:30:12,490
0,165 165,420 420,750 750,1110 1110,1475
able to interpret those results

1068
00:30:12,750 --> 00:30:14,530
0,305 305,610 930,1235 1235,1460 1460,1780
and this ah and for

1069
00:30:14,730 --> 00:30:15,950
0,305 305,470 470,665 665,980 980,1220
because the first reason that

1070
00:30:15,950 --> 00:30:17,590
0,105 105,285 285,615 615,1010 1240,1640
the whole process was ah,

1071
00:30:17,790 --> 00:30:18,950
0,305 305,500 500,665 665,890 890,1160
build on top of continuous

1072
00:30:18,950 --> 00:30:20,450
0,225 225,530 610,990 990,1230 1230,1500
time processes, let's get get

1073
00:30:20,450 --> 00:30:21,790
0,210 210,510 510,825 825,1050 1050,1340
into this continuous time processes

1074
00:30:22,200 --> 00:30:23,300
0,305 305,485 485,710 710,935 935,1100
where we are in terms

1075
00:30:23,300 --> 00:30:25,295
0,165 165,420 420,680 1420,1770 1770,1995
of neurural networks, continuous time

1076
00:30:25,295 --> 00:30:26,180
0,275
processes.|

1077
00:30:26,360 --> 00:30:28,585
0,400 1140,1540 1650,1955 1955,2090 2090,2225
So here I'm showing you

1078
00:30:28,585 --> 00:30:30,580
0,165 165,485 925,1215 1215,1505 1735,1995
an equation, so f is

1079
00:30:30,580 --> 00:30:31,840
0,120 120,315 315,590 850,1125 1125,1260
a neural network. It could

1080
00:30:31,840 --> 00:30:33,100
0,120 120,270 270,495 495,830 880,1260
be a five layer network,

1081
00:30:33,100 --> 00:30:34,900
0,300 300,525 525,765 765,1040 1450,1800
six layer neural network, fully

1082
00:30:34,900 --> 00:30:35,940
0,350
connected.|

1083
00:30:35,940 --> 00:30:38,610
0,150 150,345 345,680 1330,1730 2350,2670
But this f that has

1084
00:30:38,610 --> 00:30:40,910
0,225 225,680 1000,1380 1380,1760 1900,2300
n layers and with k,

1085
00:30:41,350 --> 00:30:42,480
0,290 290,560 560,815 815,980 980,1130
and then it has a

1086
00:30:42,480 --> 00:30:44,340
0,260 280,720 720,1070
certain activation function.|

1087
00:30:44,350 --> 00:30:46,005
0,275 275,550 990,1340 1340,1460 1460,1655
It has it a function

1088
00:30:46,005 --> 00:30:47,840
0,315 315,840 840,1185 1185,1425 1425,1835
that receives input. It receives

1089
00:30:48,010 --> 00:30:49,545
0,605 605,935 935,1205 1205,1325 1325,1535
recurrent connections from the other

1090
00:30:49,545 --> 00:30:51,560
0,365
cells.|

1091
00:30:51,560 --> 00:30:53,495
0,165 165,590 730,1560 1560,1800 1800,1935
It receives exogenous input as

1092
00:30:53,495 --> 00:30:55,280
0,275 295,600 600,810 810,1115 1525,1785
well, like this I, and

1093
00:30:55,280 --> 00:30:57,130
0,105 105,255 255,795 795,1130 1270,1850
it is parameterized by teta.|

1094
00:30:57,780 --> 00:30:59,975
0,260 260,485 485,830 830,1090 1860,2195
Now this neural network is

1095
00:30:59,975 --> 00:31:02,270
0,665 955,1260 1260,1905 1905,2130 2130,2295
parameterizing the derivatives of the

1096
00:31:02,270 --> 00:31:03,815
0,255 255,650 790,1065 1065,1245 1245,1545
hidden state and not hidden

1097
00:31:03,815 --> 00:31:05,160
0,375 375,755
state itself.|

1098
00:31:05,170 --> 00:31:07,080
0,350 350,890 890,1250 1250,1610 1610,1910
That builds a continuous time

1099
00:31:07,080 --> 00:31:09,045
0,240 240,500 1570,1815 1815,1890 1890,1965
neural network. Now, if you

1100
00:31:09,045 --> 00:31:10,520
0,135 135,375 375,675 675,1025 1075,1475
have a continuous time process,

1101
00:31:10,690 --> 00:31:12,420
0,260 260,395 395,670 1110,1445 1445,1730
that means like the updates

1102
00:31:12,420 --> 00:31:13,260
0,210 210,420 420,630 630,735 735,840
or the output of a

1103
00:31:13,260 --> 00:31:14,910
0,180 180,440 700,1065 1065,1305 1305,1650
neural network is actually generating

1104
00:31:14,910 --> 00:31:17,235
0,255 255,525 525,750 750,1040 1750,2325
the updates of your derivative

1105
00:31:17,235 --> 00:31:18,045
0,105 105,210 210,420 420,660 660,810
of the hidden state and

1106
00:31:18,045 --> 00:31:19,815
0,165 165,420 420,765 765,1145 1495,1770
not hidden state itself. What

1107
00:31:19,815 --> 00:31:21,150
0,135 135,395 655,930 930,1125 1125,1335
kind of you can give

1108
00:31:21,150 --> 00:31:22,710
0,195 195,420 420,690 690,1005 1005,1560
rise to continuous time dynamics

1109
00:31:22,710 --> 00:31:23,670
0,210 210,420 420,630 630,840 840,960
with neural networks that we

1110
00:31:23,670 --> 00:31:25,160
0,345 345,615 615,920
haven't explored before?|

1111
00:31:25,160 --> 00:31:26,510
0,300 300,510 510,770 820,1140 1140,1350
Now, what does this mean

1112
00:31:26,510 --> 00:31:27,905
0,150 150,285 285,450 450,740 1060,1395
in terms of like neural

1113
00:31:27,905 --> 00:31:29,530
0,275 775,1125 1125,1245 1245,1365 1365,1625
networks? Let's look at this,

1114
00:31:30,540 --> 00:31:32,435
0,290 290,580 1200,1460 1460,1655 1655,1895
this image. How many of

1115
00:31:32,435 --> 00:31:33,605
0,165 165,300 300,495 495,705 705,1170
you have heard about residual

1116
00:31:33,605 --> 00:31:35,200
0,275
networks?|

1117
00:31:38,220 --> 00:31:39,905
0,275 275,680 680,935 935,1330 1380,1685
Okay, residual networks are deep

1118
00:31:39,905 --> 00:31:41,285
0,225 225,465 465,705 705,965 1105,1380
neural networks that have a

1119
00:31:41,285 --> 00:31:43,120
0,135 135,330 330,615 615,965 1435,1835
kind of sk connections, okay?

1120
00:31:43,140 --> 00:31:44,225
0,275 275,455 455,650 650,890 890,1085
Like from one layer to

1121
00:31:44,225 --> 00:31:45,430
0,150 150,360 360,660 660,930 930,1205
the other one you basically

1122
00:31:45,540 --> 00:31:47,210
0,335 335,670 990,1235 1235,1415 1415,1670
sk connections and that sk

1123
00:31:47,210 --> 00:31:48,340
0,240 240,435 435,645 645,855 855,1130
connection is model by this

1124
00:31:48,540 --> 00:31:49,925
0,395 395,710 710,920 920,1130 1130,1385
equation, H T plus one

1125
00:31:49,925 --> 00:31:51,035
0,270 270,450 450,630 630,870 870,1110
equal to H T plus

1126
00:31:51,035 --> 00:31:52,900
0,225 225,515 955,1355
f of whatever.|

1127
00:31:52,910 --> 00:31:56,215
0,290 290,820 1140,1415 1415,1690 2610,3305
That HP is basically resembling

1128
00:31:56,215 --> 00:31:58,820
0,315 315,695 1345,1680 1680,1985
basically a skip connection.|

1129
00:31:58,820 --> 00:32:00,490
0,105 105,350 610,1010 1120,1395 1395,1670
And now here on the

1130
00:32:00,510 --> 00:32:02,200
0,305 305,880 900,1205 1205,1400 1400,1690
y axis, what we see,

1131
00:32:02,250 --> 00:32:03,155
0,275 275,410 410,545 545,725 725,905
we see the depth of

1132
00:32:03,155 --> 00:32:04,810
0,225 225,485 745,1020 1020,1275 1275,1655
neural network and each dot,

1133
00:32:05,220 --> 00:32:09,050
0,400 1860,2180 2180,2480 2480,2860 3480,3830
each black dot here, shows

1134
00:32:09,050 --> 00:32:11,015
0,255 255,855 855,1110 1110,1400 1720,1965
a computation that happened in

1135
00:32:11,015 --> 00:32:12,290
0,120 120,360 360,725 865,1140 1140,1275
the system. So when you

1136
00:32:12,290 --> 00:32:13,205
0,105 105,210 210,450 450,675 675,915
have a neural network that

1137
00:32:13,205 --> 00:32:14,585
0,225 225,540 540,825 825,1050 1050,1380
is layer wise, like let's

1138
00:32:14,585 --> 00:32:15,755
0,195 195,345 345,570 570,885 885,1170
call it layer wise, because

1139
00:32:15,755 --> 00:32:17,255
0,305 475,870 870,1140 1140,1320 1320,1500
the photos actually showing the

1140
00:32:17,255 --> 00:32:19,120
0,395 475,750 750,960 960,1260 1260,1865
layers in the vertical axis.

1141
00:32:19,470 --> 00:32:20,225
0,230 230,305 305,470 470,650 650,755
So if you look at

1142
00:32:20,225 --> 00:32:21,380
0,105 105,345 345,825 825,990 990,1155
the vertical axis, you see

1143
00:32:21,380 --> 00:32:22,910
0,225 225,780 780,1080 1080,1320 1320,1530
that computation happen at each

1144
00:32:22,910 --> 00:32:23,700
0,320
layer.|

1145
00:32:24,500 --> 00:32:25,780
0,335 335,605 605,875 875,1055 1055,1280
Because as the input is

1146
00:32:25,780 --> 00:32:27,160
0,390 390,555 555,810 810,1125 1125,1380
computed from the first layer

1147
00:32:27,160 --> 00:32:28,120
0,150 150,255 255,465 465,750 750,960
to the second one and

1148
00:32:28,120 --> 00:32:29,380
0,135 135,270 270,465 465,800 940,1260
then the next one, next

1149
00:32:29,380 --> 00:32:30,685
0,320 670,915 915,1020 1020,1140 1140,1305
one, but if you have

1150
00:32:30,685 --> 00:32:32,850
0,305 325,725 745,1145 1465,1815 1815,2165
a continuous process, continuous process

1151
00:32:32,960 --> 00:32:34,735
0,400 450,695 695,830 830,1120 1500,1775
equivalent to this process, you

1152
00:32:34,735 --> 00:32:36,565
0,165 165,375 375,695 1135,1410 1410,1830
have the ability to compute

1153
00:32:36,565 --> 00:32:38,860
0,255 255,555 555,1305 1305,1685 2035,2295
at an arbitrary point in

1154
00:32:38,860 --> 00:32:40,195
0,150 150,435 435,800 1000,1245 1245,1335
a vector field. So if

1155
00:32:40,195 --> 00:32:40,945
0,135 135,300 300,420 420,570 570,750
you, if you know what

1156
00:32:40,945 --> 00:32:43,260
0,210 210,780 780,1115 1555,1935 1935,2315
are differential equations and am,

1157
00:32:43,430 --> 00:32:44,520
0,350 350,575 575,710 710,830 830,1090
how, how do they basically

1158
00:32:44,900 --> 00:32:46,435
0,350 350,650 650,995 995,1295 1295,1535
change the entire space into

1159
00:32:46,435 --> 00:32:48,535
0,335 595,990 990,1355 1645,1935 1935,2100
a vector field, how can

1160
00:32:48,535 --> 00:32:50,500
0,120 120,365 475,875 985,1385 1705,1965
you basically go, ah, you

1161
00:32:50,500 --> 00:32:51,580
0,240 240,615 615,855 855,945 945,1080
know, you, you can do

1162
00:32:51,580 --> 00:32:53,830
0,390 390,950 1270,1670 1750,2025 2025,2250
adaptive computation, okay? And that's

1163
00:32:53,830 --> 00:32:55,105
0,105 105,195 195,300 300,560 880,1275
one of the massive benefits

1164
00:32:55,105 --> 00:32:57,220
0,395 745,1065 1065,1290 1290,1595
of continuous time processes.|

1165
00:32:57,320 --> 00:32:58,720
0,400 660,935 935,1085 1085,1235 1235,1400
Now, in terms of things

1166
00:32:58,720 --> 00:32:59,610
0,150 150,240 240,375 375,585 585,890
that you have seen before,

1167
00:32:59,720 --> 00:33:02,180
0,335 335,785 785,950 950,1240
standard recurring neural networks.|

1168
00:33:02,420 --> 00:33:03,940
0,290 290,580 660,920 920,1175 1175,1520
You had the lecture here,

1169
00:33:03,940 --> 00:33:05,430
0,350 460,720 720,945 945,1155 1155,1490
so a neural network f

1170
00:33:05,930 --> 00:33:07,315
0,275 275,500 500,935 935,1115 1115,1385
is basically computes the next

1171
00:33:07,315 --> 00:33:08,965
0,395 655,945 945,1095 1095,1320 1320,1650
step of the hidden state.

1172
00:33:08,965 --> 00:33:10,315
0,195 195,330 330,420 420,1110 1110,1350
So it's a discized kind

1173
00:33:10,315 --> 00:33:11,950
0,180 180,485 745,1125 1125,1440 1440,1635
of process of upd the

1174
00:33:11,950 --> 00:33:13,160
0,240 240,620
next step.|

1175
00:33:13,160 --> 00:33:14,555
0,120 120,390 390,800 880,1185 1185,1395
A neural ode updates the

1176
00:33:14,555 --> 00:33:15,520
0,210 210,360 360,480 480,690 690,965
state with a neural network

1177
00:33:15,540 --> 00:33:16,900
0,290 290,580
like that.|

1178
00:33:16,900 --> 00:33:18,400
0,380 640,885 885,1050 1050,1290 1290,1500
Eh, in a continuous time

1179
00:33:18,400 --> 00:33:19,735
0,290 670,945 945,1095 1095,1215 1215,1335
fashion. And then there is

1180
00:33:19,735 --> 00:33:22,840
0,135 135,395 2095,2445 2445,2775 2775,3105
a better, more stable version

1181
00:33:22,840 --> 00:33:24,565
0,225 225,405 405,990 990,1310 1480,1725
of this differential equation that

1182
00:33:24,565 --> 00:33:26,260
0,135 135,420 420,750 750,1085 1345,1695
is called continuous time or

1183
00:33:26,260 --> 00:33:27,190
0,225 225,390 390,555 555,690 690,930
C T R N N

1184
00:33:27,190 --> 00:33:29,155
0,495 495,890 1120,1485 1485,1770 1770,1965
recur networks there continuous time

1185
00:33:29,155 --> 00:33:30,850
0,360 360,725 805,1205 1315,1575 1575,1695
recur networks where they have

1186
00:33:30,850 --> 00:33:32,200
0,120 120,585 585,890 940,1200 1200,1350
a damping factor. So that

1187
00:33:32,200 --> 00:33:34,530
0,570 570,840 840,1310 1720,2025 2025,2330
differential a linear O D

1188
00:33:34,790 --> 00:33:37,330
0,350 350,890 890,1210 1620,2000 2000,2540
or differential equation that describes

1189
00:33:37,330 --> 00:33:38,730
0,360 360,600 600,990 990,1140 1140,1400
basically the dynamics of air.|

1190
00:33:39,260 --> 00:33:40,340
0,330 330,600 600,765 765,885 885,1080
Ah, ah, of a neural

1191
00:33:40,340 --> 00:33:42,470
0,260 1090,1470 1470,1725 1725,1905 1905,2130
network, hidden state of neural

1192
00:33:42,470 --> 00:33:44,080
0,260 610,945 945,1170 1170,1335 1335,1610
network. Now, in terms of

1193
00:33:44,100 --> 00:33:45,275
0,290 290,455 455,730 780,1055 1055,1175
what kind of, what kind

1194
00:33:45,275 --> 00:33:46,520
0,165 165,435 435,785 865,1110 1110,1245
of, ah, benefits will you

1195
00:33:46,520 --> 00:33:47,825
0,290 610,945 945,1050 1050,1155 1155,1305
get? Let's look at the

1196
00:33:47,825 --> 00:33:49,510
0,210 210,515 565,825 825,960 960,1685
top one, these are thestruction

1197
00:33:49,620 --> 00:33:50,660
0,430
plots.|

1198
00:33:50,660 --> 00:33:53,630
0,290 670,1070 1300,1700 1840,2220 2220,2970
From ah data data corresponding

1199
00:33:53,630 --> 00:33:55,360
0,345 345,555 555,705 705,1125 1125,1730
on to a spiral dynamics,

1200
00:33:55,710 --> 00:33:56,920
0,260 260,380 380,485 485,590 590,1210
if you have a disized

1201
00:33:57,150 --> 00:33:59,480
0,350 350,610 1020,1385 1385,1805 1805,2330
neural network, this spiral dynamics

1202
00:33:59,480 --> 00:34:00,755
0,255 255,435 435,660 660,1010 1030,1275
is being able to, you

1203
00:34:00,755 --> 00:34:02,075
0,210 210,575 655,960 960,1170 1170,1320
know, it the, the, the

1204
00:34:02,075 --> 00:34:03,065
0,105 105,210 210,735 735,900 900,990
kind of interpolation that you

1205
00:34:03,065 --> 00:34:04,600
0,180 180,360 360,480 480,935
have kind of edgy.|

1206
00:34:04,600 --> 00:34:05,320
0,225 225,330 330,435 435,525 525,720
But if you have a

1207
00:34:05,320 --> 00:34:07,195
0,300 300,555 555,860 1270,1635 1635,1875
continuous time process, it actually

1208
00:34:07,195 --> 00:34:08,905
0,150 150,510 510,810 810,1350 1350,1710
can compute very smoothly and

1209
00:34:08,905 --> 00:34:10,255
0,225 225,330 330,465 465,690 690,1350
also it can even generalize

1210
00:34:10,255 --> 00:34:11,695
0,225 225,345 345,885 885,1170 1170,1440
to the unseen area of

1211
00:34:11,695 --> 00:34:12,550
0,180 180,315 315,450 450,615 615,855
this, which is the red

1212
00:34:12,550 --> 00:34:13,870
0,225 225,375 375,650 880,1155 1155,1320
part of this. As we

1213
00:34:13,870 --> 00:34:15,535
0,210 210,530 790,1035 1035,1280 1300,1665
see here, the normal require

1214
00:34:15,535 --> 00:34:17,815
0,360 360,855 855,1145 1285,1685 2005,2280
network misses out on on

1215
00:34:17,815 --> 00:34:19,230
0,165 165,315 315,510 510,885 885,1415
this kind of spiral dynamics.

1216
00:34:19,400 --> 00:34:20,730
0,290 290,515 515,785 785,1025 1025,1330
So the continuous time process

1217
00:34:21,140 --> 00:34:22,975
0,275 275,550 1050,1430 1430,1685 1685,1835
it is believe that you

1218
00:34:22,975 --> 00:34:24,300
0,150 150,425 565,885 885,1065 1065,1325
can get better and better

1219
00:34:24,620 --> 00:34:26,080
0,755 755,1090
representation only.|

1220
00:34:26,360 --> 00:34:28,255
0,275 275,550 1140,1415 1415,1655 1655,1895
But then the problem here

1221
00:34:28,255 --> 00:34:32,200
0,150 150,425 2155,2460 2460,2765
is that if you.|

1222
00:34:32,450 --> 00:34:33,475
0,305 305,500 500,635 635,800 800,1025
If, if, if you actually

1223
00:34:33,475 --> 00:34:34,770
0,210 210,420 420,720 720,1005 1005,1295
bring this models in practice,

1224
00:34:35,030 --> 00:34:36,070
0,290 290,530 530,740 740,905 905,1040
a simple L S T

1225
00:34:36,070 --> 00:34:38,515
0,230 430,830 1030,1430 1900,2235 2235,2445
M network works better than

1226
00:34:38,515 --> 00:34:40,195
0,275 295,585 585,875 1105,1470 1470,1680
this type of network. So

1227
00:34:40,195 --> 00:34:41,665
0,225 225,495 495,785 955,1290 1290,1470
basically you, you can actually

1228
00:34:41,665 --> 00:34:43,120
0,635 685,945 945,1080 1080,1245 1245,1455
outperform everything that we showed

1229
00:34:43,120 --> 00:34:45,355
0,320 520,840 840,1460 1600,1980 1980,2235
here with lsdm network so

1230
00:34:45,355 --> 00:34:46,405
0,275 385,630 630,780 780,900 900,1050
far. So what's the point

1231
00:34:46,405 --> 00:34:48,805
0,165 165,455 715,1115 1315,1715 2125,2400
of basically creating such complex

1232
00:34:48,805 --> 00:34:50,120
0,555 555,720 720,1025
architectures and stuff?|

1233
00:34:50,120 --> 00:34:50,915
0,105 105,240 240,405 405,570 570,795
So this was the place

1234
00:34:50,915 --> 00:34:52,955
0,335 565,855 855,1035 1035,1325 1705,2040
where we thought that the

1235
00:34:52,955 --> 00:34:54,065
0,255 255,450 450,720 720,975 975,1110
continuous time processes that we

1236
00:34:54,065 --> 00:34:56,200
0,195 195,515 745,1145 1405,1770 1770,2135
bring from nature can actually

1237
00:34:56,400 --> 00:34:58,430
0,290 290,580 960,1280 1280,1535 1535,2030
help us build better inductive

1238
00:34:58,430 --> 00:34:59,520
0,530
biases.|

1239
00:34:59,560 --> 00:35:01,320
0,400 810,1160 1160,1415 1415,1580 1580,1760
So we introduced a neural

1240
00:35:01,320 --> 00:35:02,720
0,210 210,495 495,795 795,1080 1080,1400
network called liquid time constant

1241
00:35:02,950 --> 00:35:05,160
0,400 450,755 755,980 980,1750
networks on short ltcs.|

1242
00:35:05,200 --> 00:35:07,410
0,320 320,530 530,820 1230,1630 1740,2210
L T C are constructed

1243
00:35:07,410 --> 00:35:08,835
0,225 225,540 540,735 735,1245 1245,1425
by neurons and synapses. So

1244
00:35:08,835 --> 00:35:11,510
0,120 120,435 435,725 1225,1625 2275,2675
a neuron model is a

1245
00:35:11,710 --> 00:35:13,020
0,350 350,665 665,935 935,1130 1130,1310
continuous process like that. It's

1246
00:35:13,020 --> 00:35:14,475
0,105 105,615 615,840 840,1035 1035,1455
a differential equation, a linear

1247
00:35:14,475 --> 00:35:16,830
0,600 600,905 1405,1695 1695,2130 2130,2355
differential equation that receives the

1248
00:35:16,830 --> 00:35:18,760
0,585 585,870 870,1160
synaptic input s.|

1249
00:35:19,300 --> 00:35:20,910
0,75 75,195 195,650 670,1305 1305,1610
It's a linear differential equation.|

1250
00:35:23,520 --> 00:35:25,355
0,485 485,755 755,1390 1470,1730 1730,1835
Neurons and synapses now we

1251
00:35:25,355 --> 00:35:26,630
0,120 120,285 285,630 630,965 985,1275
have a synapse model s

1252
00:35:26,630 --> 00:35:27,940
0,195 195,500 640,900 900,1035 1035,1310
of t is a function

1253
00:35:28,530 --> 00:35:29,590
0,260 260,380 380,515 515,785 785,1060
that has a neural network

1254
00:35:29,850 --> 00:35:31,775
0,665 665,1000 1230,1505 1505,1715 1715,1925
multiplied by a term called

1255
00:35:31,775 --> 00:35:33,460
0,150 150,360 360,615 615,935
a difference of potential.|

1256
00:35:34,260 --> 00:35:36,920
0,320 320,530 530,1300 1680,2435 2435,2660
That non linearity resembles the

1257
00:35:36,920 --> 00:35:38,825
0,150 150,590 820,1220 1450,1725 1725,1905
non linear behavior between the

1258
00:35:38,825 --> 00:35:40,640
0,630 630,930 930,1235 1465,1710 1710,1815
synapses in real kind of

1259
00:35:40,640 --> 00:35:42,590
0,380 640,900 900,1005 1005,1250 1360,1950
neurons if you have synaptic

1260
00:35:42,590 --> 00:35:44,140
0,315 315,585 585,720 720,980 1150,1550
connections and they are basically

1261
00:35:45,720 --> 00:35:47,375
0,275 275,410 410,1130 1130,1295 1295,1655
designed by nonlinearity because that's

1262
00:35:47,375 --> 00:35:48,845
0,365 565,840 840,1080 1080,1320 1320,1470
actually the reality of the

1263
00:35:48,845 --> 00:35:49,640
0,275
thing.|

1264
00:35:49,640 --> 00:35:50,300
0,150 150,255 255,360 360,510 510,660
And then if you, if

1265
00:35:50,300 --> 00:35:51,340
0,165 165,375 375,540 540,720 720,1040
you plug in this s

1266
00:35:51,990 --> 00:35:54,200
0,290 290,485 485,845 845,1180 1950,2210
inside this linear equation, you

1267
00:35:54,200 --> 00:35:55,205
0,105 105,225 225,390 390,680 760,1005
will end up having a

1268
00:35:55,205 --> 00:35:56,855
0,465 465,750 750,990 990,1265 1285,1650
differential equation which is looking

1269
00:35:56,855 --> 00:35:58,205
0,270 270,885 885,1080 1080,1200 1200,1350
very sophisticated. But you will

1270
00:35:58,205 --> 00:35:59,885
0,150 150,255 255,845 1225,1515 1515,1680
see the implications of this

1271
00:35:59,885 --> 00:36:02,585
0,480 480,785 1195,1485 1485,1775 2425,2700
differential equation. It has a

1272
00:36:02,585 --> 00:36:04,625
0,285 285,575 1015,1275 1275,1440 1440,2040
neural network as a coefficient

1273
00:36:04,625 --> 00:36:05,945
0,210 210,435 435,675 675,995 1045,1320
of X of t, which

1274
00:36:05,945 --> 00:36:06,830
0,150 150,315 315,510 510,690 690,885
is this X of t

1275
00:36:06,830 --> 00:36:08,200
0,320
here.|

1276
00:36:09,030 --> 00:36:10,430
0,305 305,590 590,785 785,1085 1085,1400
That neural network is input

1277
00:36:10,430 --> 00:36:12,590
0,350 940,1215 1215,1470 1470,1830 1830,2160
dependent. That means the inputs

1278
00:36:12,590 --> 00:36:14,440
0,135 135,240 240,450 450,710 1270,1850
to the neural network defines

1279
00:36:15,060 --> 00:36:16,835
0,400 750,1070 1070,1370 1370,1625 1625,1775
how the behavior of this

1280
00:36:16,835 --> 00:36:18,140
0,510 510,750 750,975 975,1155 1155,1305
differential equation is going to

1281
00:36:18,140 --> 00:36:19,415
0,260 340,570 570,735 735,1020 1020,1275
be. So it sets the

1282
00:36:19,415 --> 00:36:20,710
0,240 240,435 435,540 540,990 990,1295
behavior of the differential equation

1283
00:36:20,970 --> 00:36:22,475
0,260 260,380 380,640 840,1235 1235,1505
in a way that when

1284
00:36:22,475 --> 00:36:23,750
0,315 315,645 645,780 780,1020 1020,1275
you're deploying this system on

1285
00:36:23,750 --> 00:36:25,480
0,290 550,855 855,1050 1050,1335 1335,1730
board, it can be, ah,

1286
00:36:26,190 --> 00:36:28,025
0,620 620,845 845,1270 1380,1655 1655,1835
adaptable to inputs. So this

1287
00:36:28,025 --> 00:36:29,885
0,285 285,545 835,1155 1155,1475 1585,1860
neural network, this system, if

1288
00:36:29,885 --> 00:36:31,090
0,150 150,315 315,480 480,755 805,1205
you have it in practice,

1289
00:36:31,410 --> 00:36:33,060
0,440 440,710 710,1030
it's input dependent.|

1290
00:36:33,060 --> 00:36:34,335
0,225 225,465 465,705 705,960 960,1275
And as you change the

1291
00:36:34,335 --> 00:36:36,015
0,365 745,1050 1050,1260 1260,1440 1440,1680
input as the result of

1292
00:36:36,015 --> 00:36:37,650
0,455 625,960 960,1245 1245,1470 1470,1635
inputs, the behavior of this

1293
00:36:37,650 --> 00:36:39,940
0,495 495,795 795,1190
differential equation changes.|

1294
00:36:40,780 --> 00:36:42,350
0,395 395,650 650,800 800,1025 1025,1570
Now, in terms of connectivity

1295
00:36:42,370 --> 00:36:44,625
0,400 900,1190 1190,1480 1500,1900 1980,2255
structures, it has, ah, if

1296
00:36:44,625 --> 00:36:45,585
0,165 165,315 315,435 435,675 675,960
you look at the range

1297
00:36:45,585 --> 00:36:47,445
0,255 255,605 775,1305 1305,1650 1650,1860
of possible connectivity structures that

1298
00:36:47,445 --> 00:36:48,285
0,105 105,240 240,375 375,540 540,840
you have in a standard

1299
00:36:48,285 --> 00:36:50,030
0,285 285,575 1075,1335 1335,1470 1470,1745
world network, you would have,

1300
00:36:50,050 --> 00:36:53,600
0,400 960,1510 2130,2530 2760,3200 3200,3550
ah, sigmoid basically activation functions.

1301
00:36:54,070 --> 00:36:55,640
0,275 275,455 455,650 650,1250 1250,1570
You might have reciprocal connections

1302
00:36:55,690 --> 00:36:57,090
0,305 305,470 470,730 1020,1265 1265,1400
between two notes, you might

1303
00:36:57,090 --> 00:36:58,800
0,290 610,1010 1090,1455 1455,1590 1590,1710
have external inputs and you

1304
00:36:58,800 --> 00:37:00,260
0,150 150,440 460,735 735,1140 1140,1460
might have a recurrent connections

1305
00:37:00,670 --> 00:37:01,970
0,245 245,470 470,800 800,1055 1055,1300
for a standard neural network.

1306
00:37:02,260 --> 00:37:03,240
0,275 275,380 380,470 470,680 680,980
Now for a liquid neural

1307
00:37:03,240 --> 00:37:05,235
0,260 520,920 1030,1425 1425,1845 1845,1995
network. Instead, each node in

1308
00:37:05,235 --> 00:37:06,645
0,150 150,425 535,795 795,900 900,1410
the system is a differential

1309
00:37:06,645 --> 00:37:07,600
0,305
equation.|

1310
00:37:07,600 --> 00:37:09,355
0,350 940,1275 1275,1485 1485,1605 1605,1755
X X J and X

1311
00:37:09,355 --> 00:37:10,600
0,305
I.|

1312
00:37:11,290 --> 00:37:12,930
0,245 245,380 380,910 1200,1490 1490,1640
They have dynamics, and then

1313
00:37:12,930 --> 00:37:14,930
0,90 90,240 240,555 555,950 1300,2000
they are connected by synapses,

1314
00:37:15,460 --> 00:37:16,730
0,275 275,545 545,785 785,950 950,1270
and then there are process

1315
00:37:16,780 --> 00:37:19,190
0,695 695,1030 1170,1570 1680,2045 2045,2410
nonlinear processes that controls the

1316
00:37:19,240 --> 00:37:21,000
0,395 395,680 680,1270
interaction of synapses.|

1317
00:37:21,000 --> 00:37:22,520
0,165 165,410 610,915 915,1170 1170,1520
So now in some sense,

1318
00:37:22,540 --> 00:37:23,730
0,275 275,470 470,725 725,950 950,1190
you can think about liquid

1319
00:37:23,730 --> 00:37:27,090
0,270 270,530 550,870 870,1190 3010,3360
neural networks as being being

1320
00:37:27,090 --> 00:37:31,440
0,350 490,780 780,1070 3580,3870 3870,4350
processes that have non linearity

1321
00:37:31,440 --> 00:37:32,660
0,105 105,240 240,420 420,645 645,1220
of the system of synapses

1322
00:37:33,070 --> 00:37:34,860
0,245 245,365 365,485 485,850
instead of the neurons.|

1323
00:37:34,870 --> 00:37:35,985
0,305 305,470 470,695 695,920 920,1115
So in neural networks we

1324
00:37:35,985 --> 00:37:37,365
0,135 135,390 390,795 795,1125 1125,1380
have the activation functions which

1325
00:37:37,365 --> 00:37:38,310
0,135 135,240 240,750 750,825 825,945
are the nonlinearity of the

1326
00:37:38,310 --> 00:37:39,495
0,260 520,780 780,885 885,1005 1005,1185
system. Now you can think

1327
00:37:39,495 --> 00:37:40,350
0,180 180,315 315,645 645,735 735,855
about non linearity of the

1328
00:37:40,350 --> 00:37:41,520
0,210 210,465 465,630 630,765 765,1170
system being on the synapses

1329
00:37:41,520 --> 00:37:42,150
0,105 105,195 195,345 345,510 510,630
or the weight of the

1330
00:37:42,150 --> 00:37:43,040
0,260
system.|

1331
00:37:43,040 --> 00:37:44,020
0,225 225,330 330,465 465,660 660,980
Now, in terms of practice,

1332
00:37:44,610 --> 00:37:45,880
0,350 350,440 440,560 560,820 870,1270
let's look at this application

1333
00:37:46,260 --> 00:37:47,600
0,350 350,590 590,770 770,1040 1040,1340
here. We train an artificial

1334
00:37:47,600 --> 00:37:49,130
0,270 270,530 700,990 990,1260 1260,1530
neural network that can control

1335
00:37:49,130 --> 00:37:50,690
0,195 195,500 910,1170 1170,1335 1335,1560
a car that can drive

1336
00:37:50,690 --> 00:37:51,940
0,195 195,450 450,705 705,915 915,1250
the car in this environment

1337
00:37:52,620 --> 00:37:53,555
0,290 290,470 470,590 590,710 710,935
and what we are showing

1338
00:37:53,555 --> 00:37:55,030
0,225 225,515 655,975 975,1185 1185,1475
on the sides of this

1339
00:37:55,110 --> 00:37:56,500
0,320 320,640
middle image.|

1340
00:37:56,500 --> 00:37:58,105
0,255 255,600 600,945 945,1290 1290,1605
Is the activity of two

1341
00:37:58,105 --> 00:38:00,090
0,515 895,1170 1170,1410 1410,1680 1680,1985
neurons that are inside the

1342
00:38:00,140 --> 00:38:01,810
0,380 380,710 710,970 1290,1550 1550,1670
standard neural network and a

1343
00:38:01,810 --> 00:38:03,340
0,225 225,510 510,770 1120,1395 1395,1530
liquid neural network on the

1344
00:38:03,340 --> 00:38:05,575
0,210 210,830 1210,1530 1530,1850 1870,2235
X axis, we see the

1345
00:38:05,575 --> 00:38:08,365
0,300 300,635 685,1065 1065,1895 2485,2790
time constant or sensitivity of

1346
00:38:08,365 --> 00:38:09,870
0,225 225,540 540,795 795,1055 1105,1505
the behavior of the output

1347
00:38:10,040 --> 00:38:11,970
0,400 480,880 1080,1535 1535,1670 1670,1930
behavior, basically controlling the vehicles

1348
00:38:12,740 --> 00:38:14,180
0,500 500,820
steering angle.|

1349
00:38:14,280 --> 00:38:15,890
0,290 290,845 845,1070 1070,1355 1355,1610
The sensitivity of that control

1350
00:38:15,890 --> 00:38:17,975
0,120 120,225 225,405 405,950 1780,2085
on the X axis and

1351
00:38:17,975 --> 00:38:20,050
0,180 180,450 450,845 1225,1545 1545,2075
on the ah y axis

1352
00:38:20,160 --> 00:38:21,850
0,320 320,640 720,1055 1055,1415 1415,1690
we see the steering angle.

1353
00:38:22,080 --> 00:38:24,050
0,320 320,640 690,935 935,1180 1590,1970
The color also represents the

1354
00:38:24,050 --> 00:38:25,790
0,285 285,480 480,770 940,1500 1500,1740
output which is mapping between

1355
00:38:25,790 --> 00:38:28,475
0,290 700,1095 1095,1370 1660,2060 2350,2685
the steering angle and the

1356
00:38:28,475 --> 00:38:29,350
0,195 195,315 315,435 435,630 630,875
output of the neural network.

1357
00:38:29,670 --> 00:38:30,995
0,400 600,830 830,935 935,1115 1115,1325
Okay, so now as we

1358
00:38:30,995 --> 00:38:32,855
0,305 625,915 915,1205 1345,1635 1635,1860
see, we added with liquid

1359
00:38:32,855 --> 00:38:33,875
0,255 255,465 465,675 675,795 795,1020
neural network we have an

1360
00:38:33,875 --> 00:38:36,070
0,365 625,930 930,1170 1170,1505 1795,2195
additional degree of freedom that

1361
00:38:36,150 --> 00:38:37,790
0,290 290,485 485,790 870,1265 1265,1640
that these networks can set

1362
00:38:37,790 --> 00:38:38,760
0,380
its.|

1363
00:38:38,760 --> 00:38:40,770
0,230 310,1130 1270,1530 1530,1740 1740,2010
A sensitivity? A liquid neural

1364
00:38:40,770 --> 00:38:41,840
0,260
network.|

1365
00:38:41,910 --> 00:38:43,570
0,350 350,665 665,965 965,1340 1340,1660
Depending on whether we're turning,

1366
00:38:44,010 --> 00:38:45,370
0,335 335,500 500,635 635,940 960,1360
whether we are going straight,

1367
00:38:45,540 --> 00:38:47,345
0,275 275,485 485,710 710,1090 1440,1805
if you're going straight the

1368
00:38:47,345 --> 00:38:48,995
0,365 445,735 735,930 930,1235 1285,1650
ah, the time constant, you

1369
00:38:48,995 --> 00:38:50,210
0,255 255,390 390,495 495,720 720,1215
want to be more cautious

1370
00:38:50,210 --> 00:38:51,640
0,180 180,420 420,690 690,1050 1050,1430
when you taking turns, right.

1371
00:38:51,840 --> 00:38:52,880
0,245 245,365 365,590 590,815 815,1040
So your neural network, you

1372
00:38:52,880 --> 00:38:53,860
0,150 150,315 315,450 450,645 645,980
want to, you want to

1373
00:38:53,940 --> 00:38:55,025
0,230 230,335 335,610 750,980 980,1085
to be faster to be

1374
00:38:55,025 --> 00:38:56,660
0,210 210,465 465,750 750,1115 1315,1635
able to actually control during

1375
00:38:56,660 --> 00:38:58,220
0,255 255,450 450,615 615,920 1330,1560
those kind of ah kind

1376
00:38:58,220 --> 00:38:59,390
0,180 180,480 480,705 705,975 975,1170
of events where you're actually

1377
00:38:59,390 --> 00:39:00,845
0,290 670,930 930,1200 1200,1320 1320,1455
turning. So that's the kind

1378
00:39:00,845 --> 00:39:01,835
0,240 240,555 555,765 765,870 870,990
of degree that you can

1379
00:39:01,835 --> 00:39:02,915
0,180 180,390 390,555 555,675 675,1080
add even at the neuronal

1380
00:39:02,915 --> 00:39:04,570
0,275 475,810 810,1245 1245,1380 1380,1655
level for interpreting these systems.|

1381
00:39:05,640 --> 00:39:06,440
0,245 245,350 350,485 485,620 620,800
Now let's look at the

1382
00:39:06,440 --> 00:39:08,690
0,300 300,615 615,950 1630,1980 1980,2250
case study of liquid neural

1383
00:39:08,690 --> 00:39:09,840
0,260
networks.|

1384
00:39:10,130 --> 00:39:11,620
0,290 290,580 930,1205 1205,1355 1355,1490
So usually you saw a

1385
00:39:11,620 --> 00:39:12,805
0,150 150,360 360,620 790,1050 1050,1185
deep neural network for an

1386
00:39:12,805 --> 00:39:15,500
0,665 865,1265 1465,1865
autonomous driving application.|

1387
00:39:15,750 --> 00:39:17,440
0,260 260,500 500,880 1140,1415 1415,1690
We have, ah, a conv

1388
00:39:17,550 --> 00:39:19,010
0,275 275,455 455,860 860,1130 1130,1460
stack of convolution on networks.

1389
00:39:19,010 --> 00:39:20,900
0,330 330,660 660,1040 1120,1635 1635,1890
They receive camera inputs and

1390
00:39:20,900 --> 00:39:23,435
0,135 135,405 405,800 1180,1580 2260,2535
they can output the a

1391
00:39:23,435 --> 00:39:24,490
0,135 135,240 240,450 450,795 795,1055
kind of a steering angle

1392
00:39:24,750 --> 00:39:25,940
0,260 260,485 485,850
at its output.|

1393
00:39:26,680 --> 00:39:28,790
0,290 290,440 440,700 1530,1850 1850,2110
This kind of neural network,

1394
00:39:28,870 --> 00:39:29,610
0,260 260,380 380,485 485,605 605,740
one of the things that

1395
00:39:29,610 --> 00:39:30,315
0,120 120,240 240,405 405,585 585,705
we can do, first of

1396
00:39:30,315 --> 00:39:31,155
0,120 120,255 255,405 405,630 630,840
all, they have like a

1397
00:39:31,155 --> 00:39:32,430
0,135 135,395 445,960 960,1140 1140,1275
lot of parameters in this

1398
00:39:32,430 --> 00:39:33,420
0,290
system.|

1399
00:39:33,420 --> 00:39:34,185
0,210 210,330 330,465 465,600 600,765
What we want to do,

1400
00:39:34,185 --> 00:39:35,970
0,165 165,330 330,635 1255,1545 1545,1785
we want to take out

1401
00:39:35,970 --> 00:39:37,590
0,350 370,750 750,1095 1095,1455 1455,1620
the fully connected layers of

1402
00:39:37,590 --> 00:39:39,210
0,180 180,390 390,650 880,1280 1300,1620
this neural network and replace

1403
00:39:39,210 --> 00:39:40,530
0,210 210,405 405,870 870,1080 1080,1320
it with recurrent neural network

1404
00:39:40,530 --> 00:39:42,540
0,380 760,1020 1020,1170 1170,1460 1480,2010
processes, one of those recurrent

1405
00:39:42,540 --> 00:39:44,055
0,285 285,555 555,830 1030,1335 1335,1515
processes that we replace it

1406
00:39:44,055 --> 00:39:45,990
0,150 150,360 360,695 1345,1680 1680,1935
with, its eh liquid neural

1407
00:39:45,990 --> 00:39:47,340
0,225 225,450 450,555 555,800 1030,1350
network and the l and

1408
00:39:47,340 --> 00:39:48,315
0,180 180,360 360,510 510,720 720,975
L S T M and

1409
00:39:48,315 --> 00:39:50,010
0,210 210,545 835,1155 1155,1425 1425,1695
the normal continuous time neural

1410
00:39:50,010 --> 00:39:50,860
0,260
networks.|

1411
00:39:50,870 --> 00:39:52,530
0,400 480,755 755,995 995,1310 1310,1660
Now, if I replace this,

1412
00:39:52,640 --> 00:39:53,650
0,275 275,440 440,620 620,785 785,1010
I would end up having

1413
00:39:53,650 --> 00:39:56,540
0,285 285,570 570,920 940,1610
like four different variants.|

1414
00:39:56,610 --> 00:39:58,055
0,320 320,515 515,1030 1080,1325 1325,1445
This four variants, one of

1415
00:39:58,055 --> 00:39:58,925
0,150 150,315 315,480 480,645 645,870
them is called an N

1416
00:39:58,925 --> 00:39:59,945
0,210 210,480 480,750 750,885 885,1020
C P, which is a

1417
00:39:59,945 --> 00:40:02,255
0,345 345,780 780,1115 1795,2100 2100,2310
neural circuit policy that has

1418
00:40:02,255 --> 00:40:04,025
0,225 225,465 465,720 720,1055 1375,1770
a four layer architecture. Each

1419
00:40:04,025 --> 00:40:05,840
0,330 330,570 570,780 780,1085 1435,1815
note of this system is

1420
00:40:05,840 --> 00:40:07,990
0,300 300,495 495,770 1090,1755 1755,2150
defined by an ltc neuron

1421
00:40:08,370 --> 00:40:09,605
0,380 380,770 770,980 980,1100 1100,1235
that equations that I was

1422
00:40:09,605 --> 00:40:10,790
0,195 195,515 595,855 855,960 960,1185
showing you, and it is

1423
00:40:10,790 --> 00:40:12,305
0,720 720,1035 1035,1245 1245,1335 1335,1515
sparsely connected to the other

1424
00:40:12,305 --> 00:40:13,660
0,225 225,405 405,540 540,785
parts of the network.|

1425
00:40:13,660 --> 00:40:14,500
0,165 165,255 255,360 360,510 510,840
So we have a sparse

1426
00:40:14,500 --> 00:40:16,330
0,210 210,390 390,710 910,1310 1570,1830
neural network architecture here. We

1427
00:40:16,330 --> 00:40:17,395
0,150 150,405 405,660 660,870 870,1065
have then one neural network

1428
00:40:17,395 --> 00:40:18,580
0,165 165,300 300,840 840,960 960,1185
that has lsdm as the

1429
00:40:18,580 --> 00:40:19,750
0,255 255,495 495,705 705,1020 1020,1170
control signal. It receives the

1430
00:40:19,750 --> 00:40:21,450
0,375 375,740 760,1275 1275,1440 1440,1700
perception with convolution on networks.|

1431
00:40:22,280 --> 00:40:23,135
0,210 210,315 315,420 420,630 630,855
And then we have c

1432
00:40:23,135 --> 00:40:23,885
0,225 225,330 330,480 480,645 645,750
ttr and n and we

1433
00:40:23,885 --> 00:40:25,055
0,195 195,450 450,870 870,1035 1035,1170
have a convolution on ne

1434
00:40:25,055 --> 00:40:25,985
0,255 255,525 525,660 660,780 780,930
networks. Now I want to

1435
00:40:25,985 --> 00:40:27,340
0,150 150,300 300,480 480,785 955,1355
show you the driving performance

1436
00:40:27,660 --> 00:40:28,820
0,275 275,455 455,710 710,965 965,1160
of these different types of

1437
00:40:28,820 --> 00:40:30,280
0,290 580,855 855,1020 1020,1185 1185,1460
networks and what kind of

1438
00:40:30,420 --> 00:40:32,170
0,800 800,995 995,1280 1280,1505 1505,1750
characteristics is added to these

1439
00:40:32,370 --> 00:40:34,955
0,400 780,1180 1590,1865 1865,2140 2250,2585
eh systems. So first let's

1440
00:40:34,955 --> 00:40:36,785
0,120 120,395 475,750 750,1325 1495,1830
look at these dashboard where

1441
00:40:36,785 --> 00:40:37,640
0,180 180,345 345,525 525,705 705,855
where I'm showing you a

1442
00:40:37,640 --> 00:40:39,185
0,420 420,600 600,780 780,1040 1150,1545
convolution on neural network followed

1443
00:40:39,185 --> 00:40:41,165
0,345 345,675 675,1055 1105,1655 1705,1980
by fully connected layers, a

1444
00:40:41,165 --> 00:40:43,330
0,275 805,1200 1200,1590 1590,1875 1875,2165
normal, very standard deep learning

1445
00:40:43,470 --> 00:40:44,950
0,350 350,575 575,905 905,1145 1145,1480
system that receives those camera

1446
00:40:45,030 --> 00:40:46,865
0,470 470,725 725,965 965,1330 1470,1835
inputs and has learned to

1447
00:40:46,865 --> 00:40:48,695
0,270 270,480 480,785 1105,1505 1585,1830
control this car. Okay, so

1448
00:40:48,695 --> 00:40:49,805
0,150 150,435 435,765 765,930 930,1110
those camera inputs comes in

1449
00:40:49,805 --> 00:40:51,230
0,135 135,360 360,725 805,1185 1185,1425
and the output decisions are

1450
00:40:51,230 --> 00:40:52,860
0,260 370,770 820,1220
basically driving decisions.|

1451
00:40:52,990 --> 00:40:54,440
0,335 335,560 560,725 725,1000 1050,1450
Now, on the bottom left,

1452
00:40:54,880 --> 00:40:56,680
0,260 260,425 425,730
what we see.|

1453
00:40:56,880 --> 00:40:58,460
0,260 260,380 380,590 590,940 1200,1580
We see the decision making

1454
00:40:58,460 --> 00:40:59,750
0,345 345,600 600,780 780,1005 1005,1290
process of this system, the

1455
00:40:59,750 --> 00:41:00,965
0,255 255,390 390,675 675,990 990,1215
inputs if you realize the

1456
00:41:00,965 --> 00:41:01,655
0,180 180,315 315,435 435,570 570,690
input has a little bit

1457
00:41:01,655 --> 00:41:02,525
0,150 150,375 375,570 570,720 720,870
of noise on top of

1458
00:41:02,525 --> 00:41:04,400
0,275 415,645 645,765 765,1055 1555,1875
them. So I added some

1459
00:41:04,400 --> 00:41:05,740
0,270 270,480 480,705 705,1005 1005,1340
noise at the input so,

1460
00:41:06,000 --> 00:41:06,830
0,245 245,350 350,470 470,650 650,830
so that we can see

1461
00:41:06,830 --> 00:41:08,195
0,165 165,645 645,900 900,1140 1140,1365
the robustness in decision making

1462
00:41:08,195 --> 00:41:09,455
0,150 150,285 285,575 895,1140 1140,1260
of this process. And as

1463
00:41:09,455 --> 00:41:11,230
0,180 180,485 1075,1365 1365,1515 1515,1775
we see actually there is

1464
00:41:11,280 --> 00:41:12,860
0,400 720,995 995,1130 1130,1325 1325,1580
the, the kind of decision

1465
00:41:12,860 --> 00:41:14,500
0,300 300,570 570,945 945,1220 1240,1640
making the brighter regions here

1466
00:41:14,700 --> 00:41:15,995
0,350 350,635 635,830 830,1085 1085,1295
is where the neural network

1467
00:41:15,995 --> 00:41:17,580
0,240 240,510 510,875
is paying attention.|

1468
00:41:17,895 --> 00:41:19,130
0,120 120,240 240,515 655,945 945,1235
When it's taking a driving

1469
00:41:19,150 --> 00:41:20,180
0,400
decision.|

1470
00:41:20,180 --> 00:41:21,130
0,240 240,375 375,510 510,660 660,950
And we see that the

1471
00:41:21,150 --> 00:41:22,730
0,335 335,545 545,820 990,1355 1355,1580
attention is basically scattered with

1472
00:41:22,730 --> 00:41:23,585
0,120 120,270 270,405 405,555 555,855
a little bit of noise

1473
00:41:23,585 --> 00:41:24,550
0,270 270,405 405,540 540,690 690,965
on top of the system.|

1474
00:41:25,380 --> 00:41:26,780
0,400 690,965 965,1100 1100,1220 1220,1400
Now, if you do the

1475
00:41:26,780 --> 00:41:28,090
0,270 270,540 540,735 735,960 960,1310
same thing and add noise,

1476
00:41:28,320 --> 00:41:30,140
0,260 260,520 930,1250 1250,1505 1505,1820
we then replace that fully

1477
00:41:30,140 --> 00:41:31,510
0,345 345,645 645,885 885,1110 1110,1370
connected layer of neural network

1478
00:41:31,740 --> 00:41:34,080
0,365 365,730
with nineteen.|

1479
00:41:34,150 --> 00:41:37,820
0,400 1230,1780 2730,3005 3005,3275 3275,3670
Liquid neurons, you can actually

1480
00:41:37,930 --> 00:41:39,810
0,400 900,1130 1130,1310 1310,1625 1625,1880
get to a performance of

1481
00:41:39,810 --> 00:41:40,860
0,225 225,480 480,660 660,810 810,1050
Lane keeping on the same

1482
00:41:40,860 --> 00:41:42,555
0,350 580,870 870,1110 1110,1395 1395,1695
environment while having the attention

1483
00:41:42,555 --> 00:41:44,780
0,255 255,545 1225,1605 1605,1905 1905,2225
of the system being basically

1484
00:41:45,250 --> 00:41:46,970
0,400 450,725 725,965 965,1325 1325,1720
focus on the road horizon,

1485
00:41:47,200 --> 00:41:48,180
0,290 290,440 440,590 590,740 740,980
like the way that we

1486
00:41:48,180 --> 00:41:50,715
0,315 315,650 790,1190 1570,1970 2170,2535
actually drive, right? So, and

1487
00:41:50,715 --> 00:41:52,280
0,240 240,435 435,755
the fact that.|

1488
00:41:52,280 --> 00:41:53,495
0,120 120,525 525,750 750,930 930,1215
The parameters that are needed

1489
00:41:53,495 --> 00:41:55,480
0,345 345,630 630,885 885,1205
for performing this task.|

1490
00:41:55,480 --> 00:41:57,520
0,225 225,590 640,1190 1630,1905 1905,2040
Basically, nineteen neurons with a

1491
00:41:57,520 --> 00:41:58,810
0,225 225,495 495,900 900,1095 1095,1290
very small convolution on neural

1492
00:41:58,810 --> 00:42:01,480
0,240 240,620 700,1260 1260,1820 2290,2670
network as perception modelule that's

1493
00:42:01,480 --> 00:42:02,650
0,255 255,615 615,885 885,1035 1035,1170
the fascinating part that you

1494
00:42:02,650 --> 00:42:03,925
0,195 195,375 375,525 525,1005 1005,1275
get from that inductive bias

1495
00:42:03,925 --> 00:42:05,110
0,135 135,285 285,575 715,990 990,1185
that we put inside neural

1496
00:42:05,110 --> 00:42:07,345
0,210 210,465 465,770 1270,1670 1930,2235
networks from brains. Okay? So

1497
00:42:07,345 --> 00:42:08,290
0,180 180,315 315,525 525,780 780,945
if you model that so

1498
00:42:08,290 --> 00:42:09,850
0,260 430,690 690,825 825,1100 1210,1560
you, you have like ah,

1499
00:42:09,850 --> 00:42:11,155
0,350 490,750 750,870 870,1020 1020,1305
ah, a set of neurons

1500
00:42:11,155 --> 00:42:12,400
0,135 135,255 255,465 465,815 925,1245
that you can really go

1501
00:42:12,400 --> 00:42:13,465
0,225 225,420 420,825 825,945 945,1065
through their dynamics, you can

1502
00:42:13,465 --> 00:42:14,755
0,420 420,585 585,690 690,935 985,1290
analyze them, you can understand

1503
00:42:14,755 --> 00:42:15,900
0,210 210,465 465,690 690,855 855,1145
that process of that system.|

1504
00:42:16,530 --> 00:42:17,615
0,260 260,365 365,500 500,785 785,1085
And you get benefits like

1505
00:42:17,615 --> 00:42:18,850
0,210 210,405 405,675 675,945 945,1235
real world benefits, for example,

1506
00:42:19,170 --> 00:42:20,225
0,275 275,425 425,545 545,695 695,1055
if on the X axis,

1507
00:42:20,225 --> 00:42:21,610
0,225 225,575 595,915 915,1110 1110,1385
as I increase the noise,

1508
00:42:22,320 --> 00:42:23,690
0,380 380,665 665,845 845,1115 1115,1370
I increase the noise, the

1509
00:42:23,690 --> 00:42:24,545
0,150 150,330 330,540 540,720 720,855
amount of noise that I

1510
00:42:24,545 --> 00:42:26,330
0,255 255,570 570,905 1345,1620 1620,1785
add the input, and on

1511
00:42:26,330 --> 00:42:27,800
0,270 270,555 555,960 960,1125 1125,1470
the y axis I compute

1512
00:42:27,800 --> 00:42:29,720
0,260 310,710 1030,1545 1545,1710 1710,1920
the output, crashes, number of

1513
00:42:29,720 --> 00:42:31,300
0,375 375,585 585,840 840,1160 1180,1580
crashes. That actually happens when

1514
00:42:31,320 --> 00:42:32,645
0,290 290,580 630,890 890,1055 1055,1325
the drive. When the network

1515
00:42:32,645 --> 00:42:34,150
0,255 255,435 435,725 925,1215 1215,1505
wants to drive the car

1516
00:42:34,230 --> 00:42:36,410
0,400 690,980 980,1115 1115,1360 1920,2180
outside, we see that these

1517
00:42:36,410 --> 00:42:37,430
0,135 135,240 240,390 390,710 730,1020
are the other networks. And

1518
00:42:37,430 --> 00:42:39,680
0,165 165,315 315,590
here we see.|

1519
00:42:39,680 --> 00:42:41,255
0,180 180,375 375,660 660,920 1210,1575
A liquid neural network where

1520
00:42:41,255 --> 00:42:42,815
0,270 270,495 495,675 675,935 1225,1560
actually keeps the level extremely

1521
00:42:42,815 --> 00:42:44,330
0,270 270,510 510,690 690,965 1255,1515
low. L T C if

1522
00:42:44,330 --> 00:42:45,335
0,120 120,255 255,450 450,690 690,1005
you look into the attention

1523
00:42:45,335 --> 00:42:47,960
0,395 625,960 960,1295 2005,2355 2355,2625
map of different those four

1524
00:42:47,960 --> 00:42:49,880
0,270 270,585 585,1160 1450,1755 1755,1920
different network variants, how do

1525
00:42:49,880 --> 00:42:51,260
0,135 135,360 360,710 760,1125 1125,1380
they make driving decisions when

1526
00:42:51,260 --> 00:42:52,660
0,165 165,440 670,1005 1005,1125 1125,1400
they are deployed in the

1527
00:42:52,830 --> 00:42:54,520
0,400 840,1115 1115,1235 1235,1385 1385,1690
environment? We see that the

1528
00:42:54,780 --> 00:42:56,290
0,560 560,695 695,950 950,1205 1205,1510
consistency of attention is different

1529
00:42:56,730 --> 00:42:59,990
0,305 305,610 1320,1720 2190,2590 3000,3260
across different networks, while we

1530
00:42:59,990 --> 00:43:01,030
0,165 165,330 330,525 525,780 780,1040
have a liquid neural network

1531
00:43:01,380 --> 00:43:03,260
0,260 260,680 680,905 905,1210
actually maintains its focus.|

1532
00:43:03,260 --> 00:43:04,490
0,210 210,560 670,1035 1035,1125 1125,1230
And, ah, that's one of

1533
00:43:04,490 --> 00:43:05,780
0,260 400,720 720,945 945,1125 1125,1290
the nice thing about this.

1534
00:43:05,780 --> 00:43:06,910
0,150 150,300 300,450 450,710 730,1130
But then we ask why?

1535
00:43:07,290 --> 00:43:08,720
0,400 570,845 845,1025 1025,1235 1235,1430
Why is it that the

1536
00:43:08,720 --> 00:43:10,960
0,240 240,510 510,770 1180,1580 1840,2240
liquid neural network can focus

1537
00:43:10,980 --> 00:43:12,965
0,275 275,530 530,910 1140,1540 1710,1985
on the actual task, which

1538
00:43:12,965 --> 00:43:14,165
0,165 165,435 435,780 780,1050 1050,1200
is Lane keeping here? There

1539
00:43:14,165 --> 00:43:15,560
0,120 120,395 475,840 840,1155 1155,1395
is no driving and just

1540
00:43:15,560 --> 00:43:17,090
0,165 165,440 670,1035 1035,1335 1335,1530
a simple driving example where

1541
00:43:17,090 --> 00:43:18,215
0,105 105,300 300,650 760,1005 1005,1125
you have just, you know,

1542
00:43:18,215 --> 00:43:19,040
0,120 120,240 240,480 480,705 705,825
like a road and you

1543
00:43:19,040 --> 00:43:20,315
0,135 135,410 820,1065 1065,1170 1170,1275
want to stay in the

1544
00:43:20,315 --> 00:43:21,420
0,245 265,665
road, right?|

1545
00:43:22,310 --> 00:43:24,980
0,400
Then.|

1546
00:43:25,080 --> 00:43:26,090
0,275 275,485 485,695 695,845 845,1010
Now what, as I said,

1547
00:43:26,090 --> 00:43:27,970
0,290 430,720 720,1365 1365,1590 1590,1880
like the representation that learned

1548
00:43:28,200 --> 00:43:29,435
0,320 320,515 515,725 725,980 980,1235
by a liquid neural network

1549
00:43:29,435 --> 00:43:31,205
0,300 300,510 510,705 705,995 1525,1770
is much more CA. So

1550
00:43:31,205 --> 00:43:32,330
0,120 120,395 475,765 765,960 960,1125
that means they can, they

1551
00:43:32,330 --> 00:43:34,085
0,135 135,410 520,900 900,1280 1480,1755
can really focus and find

1552
00:43:34,085 --> 00:43:34,925
0,135 135,240 240,555 555,690 690,840
out the essence of the

1553
00:43:34,925 --> 00:43:35,860
0,275
task.|

1554
00:43:35,900 --> 00:43:36,985
0,290 290,545 545,785 785,935 935,1085
And then if you look

1555
00:43:36,985 --> 00:43:38,670
0,210 210,545 595,870 870,1095 1095,1685
into the machine learning modeling,

1556
00:43:38,900 --> 00:43:40,465
0,665 665,1070 1070,1250 1250,1415 1415,1565
statistical modeling is like the

1557
00:43:40,465 --> 00:43:42,190
0,275 445,750 750,990 990,1395 1395,1725
least form of causal modeling

1558
00:43:42,190 --> 00:43:43,890
0,180 180,465 465,705 705,980 1300,1700
is basically you just extract.

1559
00:43:44,450 --> 00:43:45,280
0,260 260,395 395,560 560,710 710,830
These are like, these are

1560
00:43:45,280 --> 00:43:46,735
0,120 120,720 720,885 885,1095 1095,1455
the taxonomies of the causal

1561
00:43:46,735 --> 00:43:48,190
0,275 685,960 960,1155 1155,1335 1335,1455
models you have on the

1562
00:43:48,190 --> 00:43:49,180
0,180 180,375 375,540 540,870 870,990
bottom of this axis. You

1563
00:43:49,180 --> 00:43:50,800
0,150 150,435 435,1065 1065,1340 1360,1620
have the statistical models that

1564
00:43:50,800 --> 00:43:51,780
0,135 135,270 270,465 465,690 690,980
they can learn from data,

1565
00:43:51,950 --> 00:43:53,860
0,260 260,395 395,670 750,1150 1530,1910
but they cannot actually establish

1566
00:43:53,860 --> 00:43:55,765
0,380 400,930 930,1250 1420,1695 1695,1905
the causal relationship between the

1567
00:43:55,765 --> 00:43:57,340
0,335 385,750 750,1205
input and outputs.|

1568
00:43:57,340 --> 00:43:58,390
0,165 165,375 375,600 600,795 795,1050
The best type of models

1569
00:43:58,390 --> 00:43:59,455
0,210 210,360 360,570 570,825 825,1065
that we could have is

1570
00:43:59,455 --> 00:44:01,075
0,285 285,630 630,995 1015,1425 1425,1620
physical models that describes the

1571
00:44:01,075 --> 00:44:02,400
0,270 270,750 750,915 915,1050 1050,1325
exact dynamics of a process

1572
00:44:02,600 --> 00:44:03,955
0,260 260,395 395,670 750,1115 1115,1355
than you have basically a

1573
00:44:03,955 --> 00:44:05,155
0,300 300,545 745,990 990,1095 1095,1200
causal models. And in the

1574
00:44:05,155 --> 00:44:06,145
0,195 195,390 390,540 540,795 795,990
middle you have a kind

1575
00:44:06,145 --> 00:44:07,105
0,90 90,240 240,510 510,750 750,960
of a spectrum of different

1576
00:44:07,105 --> 00:44:08,725
0,225 225,405 405,705 705,965 1345,1620
types of caal models. So

1577
00:44:08,725 --> 00:44:09,780
0,180 180,360 360,495 495,705 705,1055
one thing that we realize

1578
00:44:10,100 --> 00:44:12,985
0,400 420,820 1170,1570 1830,2230 2520,2885
is, ah, basically, ah, liquid

1579
00:44:12,985 --> 00:44:14,550
0,300 300,575 625,930 930,1200 1200,1565
neural networks are something that

1580
00:44:14,660 --> 00:44:16,410
0,305 305,610 690,1055 1055,1475 1475,1750
is called dynamic causal models.|

1581
00:44:17,780 --> 00:44:19,645
0,335 335,695 695,970 1290,1580 1580,1865
Dynamic causal models are models

1582
00:44:19,645 --> 00:44:21,990
0,300 300,555 555,905 1375,1695 1695,2345
that can adapt their dynamics

1583
00:44:22,370 --> 00:44:23,880
0,400
to.|

1584
00:44:23,920 --> 00:44:25,580
0,320 320,500 500,635 635,910 1260,1660
So that they can extract

1585
00:44:26,050 --> 00:44:27,360
0,335 335,605 605,785 785,1145 1145,1310
the, the, the essence of

1586
00:44:27,360 --> 00:44:28,665
0,135 135,410 580,870 870,1065 1065,1305
a task and, and really

1587
00:44:28,665 --> 00:44:29,930
0,210 210,375 375,665 685,975 975,1265
find out the, the, the,

1588
00:44:30,400 --> 00:44:31,830
0,335 335,670 690,950 950,1145 1145,1430
the relationship of an input

1589
00:44:31,830 --> 00:44:33,080
0,270 270,585 585,840 840,975 975,1250
output relationship of a task

1590
00:44:33,370 --> 00:44:35,540
0,335 335,670 870,1130 1130,1390 1770,2170
based on a mechanism that

1591
00:44:36,040 --> 00:44:37,110
0,380 380,650 650,755 755,905 905,1070
is ruled out by this

1592
00:44:37,110 --> 00:44:38,745
0,480 480,765 765,1130 1300,1530 1530,1635
differential equation here. So it

1593
00:44:38,745 --> 00:44:40,320
0,270 270,840 840,1140 1140,1350 1350,1575
has parameters A B and

1594
00:44:40,320 --> 00:44:42,230
0,350 640,945 945,1230 1230,1560 1560,1910
c that they account for

1595
00:44:42,490 --> 00:44:44,205
0,395 395,1235 1235,1370 1370,1475 1475,1715
internal interventions to the system

1596
00:44:44,205 --> 00:44:45,405
0,285 285,465 465,645 645,900 900,1200
that if I change something

1597
00:44:45,405 --> 00:44:46,215
0,225 225,330 330,480 480,660 660,810
in the middle of the

1598
00:44:46,215 --> 00:44:48,050
0,275 595,885 885,1175 1315,1575 1575,1835
system there mechanism that can

1599
00:44:48,070 --> 00:44:50,115
0,380 380,680 680,1000 1440,1790 1790,2045
control that processes. If if

1600
00:44:50,115 --> 00:44:51,540
0,270 270,540 540,765 765,1085 1135,1425
something that comes from outside

1601
00:44:51,540 --> 00:44:53,325
0,165 165,830 1090,1365 1365,1530 1530,1785
and intervention inside the process

1602
00:44:53,325 --> 00:44:54,660
0,225 225,360 360,635 925,1200 1200,1335
of the system, then you

1603
00:44:54,660 --> 00:44:56,390
0,225 225,480 480,660 660,950 1330,1730
would actually get into, ah,

1604
00:44:56,620 --> 00:44:57,555
0,260 260,380 380,485 485,680 680,935
you can, you can control

1605
00:44:57,555 --> 00:44:58,575
0,195 195,330 330,450 450,725 775,1020
those kind of processes with

1606
00:44:58,575 --> 00:45:00,420
0,165 165,405 405,735 735,995
the dynamic causal model.|

1607
00:45:00,730 --> 00:45:01,780
0,400
Now.|

1608
00:45:01,780 --> 00:45:02,940
0,345 345,570 570,720 720,885 885,1160
Ah, a little bit I

1609
00:45:03,170 --> 00:45:04,500
0,335 335,530 530,725 725,995 995,1330
wanted to go through. Ah,

1610
00:45:04,730 --> 00:45:07,170
0,305 305,665 665,1115 1115,1480 2040,2440
the causal modeling. Ah, ah,

1611
00:45:07,310 --> 00:45:09,820
0,400 690,1385 1385,1660 1800,2200 2250,2510
process, ofural network. Basically a

1612
00:45:09,820 --> 00:45:11,845
0,555 555,890 1210,1530 1530,1785 1785,2025
differential equation can form a

1613
00:45:11,845 --> 00:45:13,360
0,390 390,725
causal structure.|

1614
00:45:13,360 --> 00:45:14,425
0,330 330,555 555,690 690,840 840,1065
What, what does that mean?

1615
00:45:14,425 --> 00:45:15,720
0,210 210,485 505,795 795,990 990,1295
That means it can predict

1616
00:45:16,220 --> 00:45:17,725
0,260 260,410 410,700 870,1265 1265,1505
from the current situation, we

1617
00:45:17,725 --> 00:45:19,435
0,135 135,375 375,600 600,875 1405,1710
can predict the future one,

1618
00:45:19,435 --> 00:45:20,365
0,255 255,450 450,555 555,675 675,930
one step in the future

1619
00:45:20,365 --> 00:45:21,760
0,270 270,420 420,675 675,990 990,1395
of a process, that temporal

1620
00:45:21,760 --> 00:45:23,545
0,470 820,1110 1110,1365 1365,1620 1620,1785
causation. And another thing is

1621
00:45:23,545 --> 00:45:24,745
0,180 180,360 360,585 585,885 885,1200
that if I change something

1622
00:45:24,745 --> 00:45:26,130
0,240 240,870 870,960 960,1095 1095,1385
or intervene in a system,

1623
00:45:26,600 --> 00:45:28,540
0,305 305,470 470,730 1500,1745 1745,1940
how can I, can I

1624
00:45:28,540 --> 00:45:30,070
0,300 300,555 555,735 735,1290 1290,1530
actually control that intervention so

1625
00:45:30,070 --> 00:45:31,300
0,150 150,345 345,495 495,740 910,1230
or, or can I account

1626
00:45:31,300 --> 00:45:32,455
0,195 195,375 375,855 855,1035 1035,1155
for that intervention that I

1627
00:45:32,455 --> 00:45:33,565
0,165 165,300 300,420 420,695 865,1110
had in the system? So

1628
00:45:33,565 --> 00:45:34,735
0,150 150,450 450,735 735,930 930,1170
this would construct this two

1629
00:45:34,735 --> 00:45:36,565
0,335 655,930 930,1170 1170,1515 1515,1830
points being able to account

1630
00:45:36,565 --> 00:45:38,485
0,255 255,575 955,1290 1290,1625 1675,1920
for future ah, evolution of

1631
00:45:38,485 --> 00:45:40,600
0,135 135,425 655,960 960,1775
a system and interventions.|

1632
00:45:40,600 --> 00:45:41,485
0,135 135,285 285,495 495,705 705,885
And being able to account

1633
00:45:41,485 --> 00:45:42,670
0,165 165,750 750,870 870,975 975,1185
for interventions in the system.

1634
00:45:42,670 --> 00:45:43,360
0,165 165,225 225,300 300,435 435,690
So if you have these

1635
00:45:43,360 --> 00:45:44,545
0,225 225,500 700,945 945,1050 1050,1185
two models, then you have

1636
00:45:44,545 --> 00:45:47,500
0,165 165,635 895,1295
a causal structure.|

1637
00:45:47,570 --> 00:45:48,730
0,260 260,380 380,545 545,890 890,1160
So for that I'm just

1638
00:45:48,730 --> 00:45:51,415
0,350 1120,1670 1840,2205 2205,2475 2475,2685
ah, skipping over over this

1639
00:45:51,415 --> 00:45:52,300
0,195 195,345 345,480 480,645 645,885
part. I just wanted to

1640
00:45:52,300 --> 00:45:53,395
0,225 225,360 360,620 760,1005 1005,1095
tell you that. I mean

1641
00:45:53,395 --> 00:45:54,160
0,105 105,285 285,480 480,630 630,765
I wanted to show you

1642
00:45:54,160 --> 00:45:56,380
0,165 165,390 390,710 1030,1430 1900,2220
like more about, um, how

1643
00:45:56,380 --> 00:45:58,560
0,390 390,750 750,1125 1125,1520 1780,2180
you're driving this, ah, connection

1644
00:45:58,580 --> 00:46:00,385
0,275 275,550 600,1000 1020,1420 1470,1805
between liquid networks and cause

1645
00:46:00,385 --> 00:46:01,720
0,335 625,870 870,990 990,1155 1155,1335
models. But I share this

1646
00:46:01,720 --> 00:46:02,620
0,225 225,420 420,555 555,720 720,900
slide so you can see

1647
00:46:02,620 --> 00:46:04,375
0,240 240,590 640,975 975,1310 1450,1755
and also a professor tomorrow

1648
00:46:04,375 --> 00:46:05,005
0,165 165,300 300,435 435,540 540,630
is going to give a

1649
00:46:05,005 --> 00:46:06,520
0,245 535,810 810,945 945,1205 1225,1515
lecture on the topic that

1650
00:46:06,520 --> 00:46:08,190
0,290 670,1035 1035,1260 1260,1395 1395,1670
hopefully, ah, she can cover

1651
00:46:09,770 --> 00:46:11,820
0,290 290,580
these parts.|

1652
00:46:11,980 --> 00:46:13,950
0,400 840,1240 1350,1610 1610,1730 1730,1970
And just a couple of

1653
00:46:13,950 --> 00:46:16,860
0,380 1150,1550 1840,2130 2130,2420 2650,2910
ah, remarks on, on, on

1654
00:46:16,860 --> 00:46:17,985
0,195 195,530 580,855 855,975 975,1125
the performance of the network

1655
00:46:17,985 --> 00:46:19,050
0,165 165,390 390,465 465,885 885,1065
and what's the implication of

1656
00:46:19,050 --> 00:46:20,640
0,165 165,360 360,705 705,980 1330,1590
having a causal model. Now,

1657
00:46:20,640 --> 00:46:21,540
0,210 210,330 330,435 435,615 615,900
let's look at this environment.

1658
00:46:21,540 --> 00:46:22,820
0,255 255,525 525,780 780,1020 1020,1280
We trained some neural networks.|

1659
00:46:23,830 --> 00:46:25,190
0,290 290,515 515,760 810,1085 1085,1360
These neural networks are basically

1660
00:46:26,110 --> 00:46:27,660
0,335 335,575 575,880 1110,1385 1385,1550
learned to fly towards a

1661
00:46:27,660 --> 00:46:29,450
0,290 370,600 600,705 705,1440 1440,1790
target in an unstructured environment.|

1662
00:46:30,220 --> 00:46:31,910
0,400 480,815 815,1130 1130,1400 1400,1690
So we collected some data,

1663
00:46:32,140 --> 00:46:34,100
0,290 290,560 560,905 905,1180 1200,1960
we trained neural networks instances,

1664
00:46:34,450 --> 00:46:35,790
0,275 275,425 425,635 635,970 990,1340
and then we tested this

1665
00:46:35,790 --> 00:46:36,860
0,240 240,405 405,570 570,765 765,1070
then then we take this

1666
00:46:37,270 --> 00:46:38,415
0,350 350,560 560,755 755,905 905,1145
neural networks that we train

1667
00:46:38,415 --> 00:46:40,100
0,300 300,665 715,1005 1005,1290 1290,1685
by moving towards, like basically

1668
00:46:40,120 --> 00:46:41,750
0,260 260,485 485,850 1020,1325 1325,1630
these are scenes that are

1669
00:46:41,890 --> 00:46:43,280
0,395 395,725 725,965 965,1115 1115,1390
drone is inside the forest

1670
00:46:43,630 --> 00:46:45,000
0,245 245,380 380,605 605,815 815,1370
and the drone is navigating

1671
00:46:45,000 --> 00:46:46,740
0,255 255,405 405,680 1030,1430 1480,1740
towards a target. OK, now

1672
00:46:46,740 --> 00:46:47,790
0,180 180,390 390,585 585,840 840,1050
we collect this data from

1673
00:46:47,790 --> 00:46:49,620
0,150 150,360 360,600 600,1160 1570,1830
a couple of traces that

1674
00:46:49,620 --> 00:46:51,320
0,150 150,620 880,1155 1155,1365 1365,1700
we simulate. Then we take

1675
00:46:51,730 --> 00:46:54,105
0,400 990,1390 1680,1970 1970,2150 2150,2375
this data, we train neural

1676
00:46:54,105 --> 00:46:55,620
0,275 745,1035 1035,1200 1200,1335 1335,1515
networks, we bring the neural

1677
00:46:55,620 --> 00:46:56,625
0,240 240,495 495,630 630,780 780,1005
networks back on the drone

1678
00:46:56,625 --> 00:46:58,020
0,165 165,315 315,525 525,845
and we test them.|

1679
00:46:58,030 --> 00:46:59,070
0,275 275,425 425,650 650,875 875,1040
On the Dr to see,

1680
00:46:59,070 --> 00:47:00,360
0,165 165,440 520,855 855,1080 1080,1290
to see whether they can

1681
00:47:00,360 --> 00:47:02,780
0,320 760,1035 1035,1580 1750,2085 2085,2420
learn to navigate this task

1682
00:47:03,100 --> 00:47:05,480
0,395 395,790 1080,1480 1800,2090 2090,2380
without even programming ah ah,

1683
00:47:05,830 --> 00:47:06,855
0,260 260,395 395,590 590,830 830,1025
what is the objective of

1684
00:47:06,855 --> 00:47:07,820
0,150 150,425
the task?|

1685
00:47:07,820 --> 00:47:08,975
0,255 255,540 540,795 795,1020 1020,1155
Basically, the objective of the

1686
00:47:08,975 --> 00:47:10,310
0,255 255,525 525,660 660,795 795,1335
task has to be distilled

1687
00:47:10,310 --> 00:47:12,065
0,165 165,315 315,590 850,1250 1510,1755
from the data itself. And

1688
00:47:12,065 --> 00:47:13,235
0,150 150,345 345,635 775,1035 1035,1170
as we saw here on

1689
00:47:13,235 --> 00:47:14,090
0,150 150,345 345,540 540,675 675,855
the right, we see the

1690
00:47:14,090 --> 00:47:15,320
0,240 240,510 510,825 825,1065 1065,1230
decision making process of these

1691
00:47:15,320 --> 00:47:18,010
0,290 760,1160 1480,1815 1815,2150 2290,2690
networks that liquid networks learned

1692
00:47:18,150 --> 00:47:19,280
0,275 275,485 485,785 785,995 995,1130
to pay attention to the

1693
00:47:19,280 --> 00:47:21,065
0,290 640,945 945,1125 1125,1400 1450,1785
target. As the target becomes

1694
00:47:21,065 --> 00:47:22,430
0,300 300,540 540,720 720,1020 1020,1365
visible, that means it actually

1695
00:47:22,430 --> 00:47:24,050
0,300 300,650 760,1020 1020,1275 1275,1620
figured out the most important

1696
00:47:24,050 --> 00:47:25,430
0,225 225,360 360,540 540,860 1090,1380
part of this process was

1697
00:47:25,430 --> 00:47:26,630
0,225 225,555 555,795 795,930 930,1200
really focusing on the target,

1698
00:47:26,630 --> 00:47:27,500
0,300 300,510 510,645 645,750 750,870
even if there is an

1699
00:47:27,500 --> 00:47:29,640
0,675 675,840 840,1100
unstructured kind of.|

1700
00:47:29,920 --> 00:47:31,485
0,400 420,680 680,830 830,1120 1290,1565
Ah, kind of, ah, input

1701
00:47:31,485 --> 00:47:33,500
0,275 475,720 720,840 840,1115 1615,2015
data to the system. Now

1702
00:47:33,550 --> 00:47:35,120
0,275 275,550 600,920 920,1205 1205,1570
if we compare the attention

1703
00:47:35,140 --> 00:47:37,335
0,400 630,950 950,1270 1440,1850 1850,2195
map of this neural circuit

1704
00:47:37,335 --> 00:47:38,540
0,305 385,645 645,780 780,930 930,1205
policies, which is the first,

1705
00:47:38,800 --> 00:47:41,175
0,275 275,550 1110,1510 1950,2240 2240,2375
the second column compared to

1706
00:47:41,175 --> 00:47:43,155
0,120 120,395 475,870 870,1265 1705,1980
the other attention maps, we

1707
00:47:43,155 --> 00:47:44,180
0,135 135,270 270,420 420,660 660,1025
see that the only network

1708
00:47:44,380 --> 00:47:45,645
0,290 290,470 470,740 740,1025 1025,1265
type of network that learn

1709
00:47:45,645 --> 00:47:47,100
0,240 240,465 465,785 985,1260 1260,1455
from this data to pay

1710
00:47:47,100 --> 00:47:48,660
0,315 315,555 555,705 705,1010 1270,1560
attention to this target is

1711
00:47:48,660 --> 00:47:50,060
0,225 225,525 525,800
liquid neural networks.|

1712
00:47:50,060 --> 00:47:51,065
0,135 135,555 555,780 780,900 900,1005
And that's the kind of

1713
00:47:51,065 --> 00:47:52,280
0,465 465,630 630,750 750,975 975,1215
implication that you have. So

1714
00:47:52,280 --> 00:47:53,825
0,195 195,500 640,975 975,1260 1260,1545
you learn the cause and

1715
00:47:53,825 --> 00:47:55,295
0,225 225,375 375,525 525,815 1135,1470
effect of a task using

1716
00:47:55,295 --> 00:47:57,245
0,195 195,405 405,675 675,935 1645,1950
a liquid neural network that

1717
00:47:57,245 --> 00:48:00,155
0,305 1105,1685 1855,2255 2425,2715 2715,2910
has dramatically less number of

1718
00:48:00,155 --> 00:48:01,970
0,485 535,825 825,945 945,1175 1525,1815
parameters compared to other types

1719
00:48:01,970 --> 00:48:03,815
0,165 165,375 375,620 1030,1430 1570,1845
of neural networks. Now, as

1720
00:48:03,815 --> 00:48:06,100
0,165 165,375 375,630 630,965 1885,2285
I told you, the relation

1721
00:48:06,270 --> 00:48:07,900
0,320 320,515 515,910
between two neurons.|

1722
00:48:07,900 --> 00:48:08,845
0,270 270,480 480,705 705,855 855,945
Can be defined by a

1723
00:48:08,845 --> 00:48:10,660
0,465 465,785 865,1170 1170,1530 1530,1815
differential equation by neuron equation

1724
00:48:10,660 --> 00:48:12,565
0,285 285,660 660,1010 1360,1635 1635,1905
and synapse equation. We recently

1725
00:48:12,565 --> 00:48:14,670
0,330 330,905 925,1230 1230,1785 1785,2105
have solved this differential equation,

1726
00:48:14,720 --> 00:48:16,560
0,230 230,410 410,755 755,1150
also in closed form.|

1727
00:48:16,560 --> 00:48:17,790
0,150 150,390 390,705 705,975 975,1230
And then this gave rise

1728
00:48:17,790 --> 00:48:18,570
0,180 180,270 270,420 420,600 600,780
to a new type of

1729
00:48:18,570 --> 00:48:20,610
0,255 255,530 1240,1515 1515,1770 1770,2040
neural networks, which is again

1730
00:48:20,610 --> 00:48:23,505
0,180 180,420 420,770 1000,1400 2530,2895
a close form. Ah, continuous

1731
00:48:23,505 --> 00:48:24,885
0,270 270,525 525,785 985,1245 1245,1380
time. Neural networks, you call

1732
00:48:24,885 --> 00:48:26,160
0,210 210,390 390,570 570,905 1015,1275
them C F C, these

1733
00:48:26,160 --> 00:48:27,150
0,135 135,285 285,495 495,735 735,990
are the close form liquid

1734
00:48:27,150 --> 00:48:28,490
0,350 520,780 780,915 915,1065 1065,1340
networks. They have the same

1735
00:48:28,780 --> 00:48:30,495
0,400 720,980 980,1115 1115,1370 1370,1715
behavior, but they are ah,

1736
00:48:30,495 --> 00:48:32,360
0,360 360,755 865,1335 1335,1545 1545,1865
ah, basically defining close form.|

1737
00:48:32,900 --> 00:48:34,765
0,400 1110,1370 1370,1505 1505,1670 1670,1865
Now, what does that mean?

1738
00:48:34,765 --> 00:48:35,545
0,165 165,315 315,465 465,615 615,780
That means if I have

1739
00:48:35,545 --> 00:48:37,135
0,135 135,675 675,995 1195,1470 1470,1590
a differential equation, you see

1740
00:48:37,135 --> 00:48:37,810
0,105 105,255 255,405 405,540 540,675
the O D E on

1741
00:48:37,810 --> 00:48:38,920
0,150 150,375 375,555 555,720 720,1110
the top. If I simulate

1742
00:48:38,920 --> 00:48:40,290
0,165 165,345 345,495 495,770 970,1370
this O D E, okay,

1743
00:48:40,580 --> 00:48:42,280
0,305 305,545 545,785 785,1090 1320,1700
the close form solution would

1744
00:48:42,280 --> 00:48:44,485
0,285 285,495 495,800 1000,1400 1840,2205
actually give you the very

1745
00:48:44,485 --> 00:48:46,255
0,330 330,645 645,900 900,1200 1200,1770
same behavior of the differential

1746
00:48:46,255 --> 00:48:48,400
0,305 325,725 955,1260 1260,1565 1795,2145
equation itself, but it does

1747
00:48:48,400 --> 00:48:50,550
0,350 400,735 735,1065 1065,1635 1635,2150
not require any numerical solvers.|

1748
00:48:50,990 --> 00:48:52,045
0,230 230,305 305,455 455,740 740,1055
So it does not require

1749
00:48:52,045 --> 00:48:53,520
0,335 385,630 630,875 985,1230 1230,1475
any kind of, you know,

1750
00:48:53,690 --> 00:48:55,360
0,335 335,695 695,1150 1200,1490 1490,1670
complex numerical solvers. So as

1751
00:48:55,360 --> 00:48:56,850
0,210 210,530 610,870 870,1110 1110,1490
a result, you could scale

1752
00:48:56,900 --> 00:48:59,005
0,350 350,650 650,910 960,1360 1740,2105
liquid neural networks much larger

1753
00:48:59,005 --> 00:49:00,550
0,300 300,525 525,780 780,1380 1380,1545
to much larger instances if

1754
00:49:00,550 --> 00:49:01,360
0,150 150,315 315,525 525,690 690,810
you want to scale the

1755
00:49:01,360 --> 00:49:03,030
0,260 520,795 795,960 960,1250 1270,1670
networks in terms of performance

1756
00:49:03,050 --> 00:49:05,280
0,400 570,1070 1070,1600
in modeling dynamics.|

1757
00:49:05,290 --> 00:49:06,720
0,320 320,605 605,860 860,1145 1145,1430
Liquid neural networks. We see

1758
00:49:06,720 --> 00:49:08,630
0,380 610,960 960,1290 1290,1590 1590,1910
here a series of different

1759
00:49:08,650 --> 00:49:10,520
0,305 305,605 605,965 965,1505 1505,1870
types of advanced recurrent networks

1760
00:49:10,870 --> 00:49:12,500
0,260 260,410 410,700 720,1310 1310,1630
and we see variants of

1761
00:49:12,820 --> 00:49:14,700
0,365 365,730 840,1205 1205,1550 1550,1880
ah, ah, close form, liquid

1762
00:49:14,700 --> 00:49:15,930
0,270 270,530 550,825 825,1020 1020,1230
neural networks and L T

1763
00:49:15,930 --> 00:49:17,690
0,330 330,710 910,1170 1170,1395 1395,1760
CS themselves that are performing

1764
00:49:17,920 --> 00:49:19,875
0,635 635,905 905,1160 1160,1450 1620,1955
remarkably better than the other

1765
00:49:19,875 --> 00:49:21,830
0,330 330,615 615,1035 1035,1320 1320,1955
systems in modeling physical dynamics.|

1766
00:49:22,970 --> 00:49:23,905
0,290 290,440 440,635 635,830 830,935
And the last thing I

1767
00:49:23,905 --> 00:49:25,375
0,120 120,270 270,545 655,1055 1195,1470
want to show is the

1768
00:49:25,375 --> 00:49:29,040
0,275 475,875 1315,1715 2515,2895 2895,3665
difference between this understanding causality

1769
00:49:29,060 --> 00:49:30,370
0,400 480,785 785,965 965,1130 1130,1310
and understanding the cause and

1770
00:49:30,370 --> 00:49:31,420
0,180 180,330 330,465 465,740 760,1050
effect of a task and

1771
00:49:31,420 --> 00:49:32,710
0,240 240,465 465,675 675,1005 1005,1290
not being able to understand

1772
00:49:32,710 --> 00:49:34,525
0,290 430,780 780,1130 1330,1635 1635,1815
that. Now here you see

1773
00:49:34,525 --> 00:49:35,485
0,195 195,495 495,705 705,825 825,960
a drone, which is an

1774
00:49:35,485 --> 00:49:36,970
0,275 415,705 705,885 885,1050 1050,1485
agent that wants to navigate

1775
00:49:36,970 --> 00:49:38,485
0,210 210,435 435,740 1090,1410 1410,1515
towards a target. There's a

1776
00:49:38,485 --> 00:49:39,895
0,195 195,375 375,510 510,785 1075,1410
target in the environment. Now

1777
00:49:39,895 --> 00:49:41,485
0,285 285,635 745,1275 1275,1425 1425,1590
we collected traces of a

1778
00:49:41,485 --> 00:49:43,330
0,335 445,1050 1050,1350 1350,1575 1575,1845
drone navigating towards this target

1779
00:49:43,330 --> 00:49:44,620
0,240 240,420 420,740
in this forest.|

1780
00:49:45,020 --> 00:49:47,050
0,400 540,830 830,980 980,1240 1710,2030
Then what we did, we

1781
00:49:47,050 --> 00:49:48,630
0,255 255,465 465,740 970,1275 1275,1580
collected this data, then we

1782
00:49:48,950 --> 00:49:50,490
0,305 305,545 545,820 1020,1280 1280,1540
train neural networks. And now

1783
00:49:50,510 --> 00:49:51,700
0,305 305,530 530,755 755,950 950,1190
we brought back this neural

1784
00:49:51,700 --> 00:49:53,125
0,240 240,525 525,705 705,1010 1120,1425
networks on the drone to

1785
00:49:53,125 --> 00:49:54,550
0,210 210,435 435,660 660,965 1165,1425
see whether they learned to

1786
00:49:54,550 --> 00:49:55,765
0,390 390,585 585,780 780,1005 1005,1215
navigate towards that target or

1787
00:49:55,765 --> 00:49:57,400
0,275 445,780 780,1095 1095,1440 1440,1635
not. Now here I'm showing

1788
00:49:57,400 --> 00:49:58,285
0,240 240,480 480,645 645,765 765,885
the performance of an L

1789
00:49:58,285 --> 00:49:59,220
0,165 165,315 315,435 435,660 660,935
S D M neural network.|

1790
00:50:01,080 --> 00:50:03,080
0,260 260,425 425,635 635,940
So, as we see.|

1791
00:50:04,120 --> 00:50:04,800
0,230 230,320 320,470 470,590 590,680
The L S T M

1792
00:50:04,800 --> 00:50:06,825
0,120 120,380 1120,1485 1485,1755 1755,2025
is basically completely like looking

1793
00:50:06,825 --> 00:50:08,265
0,315 315,525 525,765 765,1095 1095,1440
around and it cannot really

1794
00:50:08,265 --> 00:50:10,275
0,285 285,575 985,1385 1555,1860 1860,2010
control the drawn. Actually, if

1795
00:50:10,275 --> 00:50:11,025
0,105 105,225 225,330 330,480 480,750
you look at the attention

1796
00:50:11,025 --> 00:50:12,525
0,255 255,420 420,570 570,845 1225,1500
map of the system actually

1797
00:50:12,525 --> 00:50:14,490
0,275 865,1200 1200,1440 1440,1710 1710,1965
looks all around the the

1798
00:50:14,490 --> 00:50:15,980
0,270 270,600 600,855 855,1125 1125,1490
place. It did not really

1799
00:50:16,030 --> 00:50:17,730
0,400 600,965 965,1160 1160,1460 1460,1700
realize what's the objective of

1800
00:50:17,730 --> 00:50:19,035
0,165 165,440 460,750 750,1040 1090,1305
the task from data, so

1801
00:50:19,035 --> 00:50:20,450
0,180 180,450 450,720 720,1050 1050,1415
it could not really associate

1802
00:50:20,710 --> 00:50:22,250
0,400 420,710 710,920 920,1190 1190,1540
anything or learn something meaningful

1803
00:50:22,300 --> 00:50:23,560
0,290 290,440 440,700
from the data.|

1804
00:50:24,080 --> 00:50:25,260
0,260 260,440 440,680 680,890 890,1180
And then here is in

1805
00:50:25,310 --> 00:50:26,515
0,350 350,620 620,845 845,1070 1070,1205
liquid neural network on the

1806
00:50:26,515 --> 00:50:27,415
0,195 195,450 450,630 630,735 735,900
same task. Look at the

1807
00:50:27,415 --> 00:50:29,305
0,285 285,665 745,1145 1315,1650 1650,1890
attention map here as the

1808
00:50:29,305 --> 00:50:31,975
0,335 355,755 1735,2135 2185,2475 2475,2670
drone is going towards that

1809
00:50:31,975 --> 00:50:34,150
0,305 1285,1560 1560,1890 1890,2040 2040,2175
target. And that's the kind

1810
00:50:34,150 --> 00:50:37,620
0,260 2200,2600 2800,3060 3060,3195 3195,3470
of flexibility that you can

1811
00:50:38,210 --> 00:50:40,480
0,335 335,670 690,1090 1800,2090 2090,2270
learn the actual cause and

1812
00:50:40,480 --> 00:50:41,880
0,180 180,315 315,450 450,740 1000,1400
effect of a task from

1813
00:50:42,140 --> 00:50:43,440
0,335 335,580
neural networks.|

1814
00:50:43,510 --> 00:50:44,835
0,400 540,830 830,1010 1130,1205 1205,1325
Now, okay, so I'm going

1815
00:50:44,835 --> 00:50:46,480
0,240 240,555 555,815
to conclude now.|

1816
00:50:46,580 --> 00:50:47,700
0,290 290,455 455,575 575,755 755,1120
I showed you these plots.

1817
00:50:47,750 --> 00:50:48,535
0,275 275,425 425,560 560,680 680,785
I showed you that there

1818
00:50:48,535 --> 00:50:50,290
0,120 120,315 315,1025 1045,1445 1465,1755
is over parameterization regime and

1819
00:50:50,290 --> 00:50:51,630
0,165 165,375 375,675 675,990 990,1340
we have an idea about

1820
00:50:51,740 --> 00:50:53,340
0,275 275,425 425,620 620,940
what kind of ah.|

1821
00:50:53,340 --> 00:50:54,540
0,270 270,510 510,825 825,1065 1065,1200
Ah, ah, benefits you would

1822
00:50:54,540 --> 00:50:55,635
0,240 240,450 450,690 690,945 945,1095
get in that regime. And

1823
00:50:55,635 --> 00:50:57,350
0,195 195,390 390,600 600,935 985,1715
what kind of, ah, intuitive

1824
00:50:57,430 --> 00:50:59,370
0,305 305,610 630,1330 1350,1715 1715,1940
understand, ah, theoretical understanding do

1825
00:50:59,370 --> 00:51:00,920
0,135 135,410 790,1065 1065,1290 1290,1550
we have for neural networks?

1826
00:51:01,420 --> 00:51:02,235
0,245 245,350 350,500 500,680 680,815
And then I showed you

1827
00:51:02,235 --> 00:51:03,080
0,120 120,240 240,360 360,585 585,845
that there are neural networks

1828
00:51:03,310 --> 00:51:04,605
0,305 305,545 545,815 815,1055 1055,1295
like liquid neural networks that

1829
00:51:04,605 --> 00:51:06,110
0,165 165,660 660,1020 1020,1200 1200,1505
have inductive biases from brains

1830
00:51:06,550 --> 00:51:08,655
0,335 335,670 1050,1385 1385,1655 1655,2105
that can actually so resolve

1831
00:51:08,655 --> 00:51:10,665
0,255 255,420 420,695 1285,1685 1705,2010
a couple of problems, for

1832
00:51:10,665 --> 00:51:12,555
0,255 255,525 525,1085 1285,1605 1605,1890
example, the robustness while being

1833
00:51:12,555 --> 00:51:14,670
0,365 835,1200 1200,1425 1425,1620 1620,2115
significantly smaller than over paramize

1834
00:51:14,670 --> 00:51:16,035
0,320 640,885 885,975 975,1140 1140,1365
networks. So it is not

1835
00:51:16,035 --> 00:51:17,100
0,180 180,420 420,675 675,870 870,1065
that you always have to

1836
00:51:17,100 --> 00:51:18,860
0,440 460,780 780,1275 1275,1500 1500,1760
dramatically over paramize neural networks,

1837
00:51:19,270 --> 00:51:20,985
0,400 780,1040 1040,1145 1145,1265 1265,1715
but you can have inductive

1838
00:51:20,985 --> 00:51:23,000
0,390 390,615 615,965 1195,1595 1615,2015
biases to actually, ah, ah,

1839
00:51:23,080 --> 00:51:24,580
0,320 320,605 605,970
gain good performance.|

1840
00:51:24,580 --> 00:51:25,880
0,165 165,315 315,590
To sum up.|

1841
00:51:25,880 --> 00:51:26,945
0,210 210,330 330,510 510,885 885,1065
The law of robustness is

1842
00:51:26,945 --> 00:51:28,145
0,300 300,555 555,795 795,990 990,1200
real. So that's something that

1843
00:51:28,145 --> 00:51:29,735
0,275 625,885 885,1020 1020,1295 1315,1590
is came out of a

1844
00:51:29,735 --> 00:51:32,030
0,275 805,1205 1255,1655 1885,2160 2160,2295
theory is um number of

1845
00:51:32,030 --> 00:51:34,040
0,440 640,1020 1020,1370 1450,1785 1785,2010
parameters. It's, it's necessarily has

1846
00:51:34,040 --> 00:51:34,850
0,135 135,255 255,450 450,660 660,810
to be large if you

1847
00:51:34,850 --> 00:51:36,220
0,135 135,255 255,500 610,990 990,1370
want to have with effective

1848
00:51:36,240 --> 00:51:37,810
0,860 860,1025 1025,1160 1160,1295 1295,1570
dimensionality. So one of the

1849
00:51:38,130 --> 00:51:39,440
0,320 320,500 500,620 620,880 990,1310
ideas that we have, I'll

1850
00:51:39,440 --> 00:51:41,080
0,135 135,360 360,630 630,1365 1365,1640
talk about effective dimensionality here.

1851
00:51:41,400 --> 00:51:43,715
0,260 260,455 455,1130 1130,1510 1920,2315
The over paramatization definitely improves

1852
00:51:43,715 --> 00:51:45,230
0,510 510,810 810,1230 1230,1380 1380,1515
generalization and robustness, but it

1853
00:51:45,230 --> 00:51:47,230
0,225 225,560 880,1305 1305,1580 1600,2000
has some socio technical challenges.|

1854
00:51:48,260 --> 00:51:50,935
0,350 350,1025 1025,1580 1580,1820 1820,2675
So inductive biases or architectural

1855
00:51:50,935 --> 00:51:51,970
0,390 390,600 600,765 765,885 885,1035
motif, why do we have

1856
00:51:51,970 --> 00:51:53,380
0,240 240,480 480,645 645,1245 1245,1410
different types of architectures and

1857
00:51:53,380 --> 00:51:54,895
0,285 285,615 615,825 825,1100 1180,1515
why studying the brain is

1858
00:51:54,895 --> 00:51:56,215
0,180 180,300 300,480 480,785 925,1320
actually a good thing is

1859
00:51:56,215 --> 00:51:58,195
0,330 330,540 540,815 835,1235 1645,1980
because we can actually get

1860
00:51:58,195 --> 00:51:59,635
0,375 375,690 690,945 945,1215 1215,1440
smarter in design neural networks

1861
00:51:59,635 --> 00:52:01,165
0,255 255,465 465,780 780,1320 1320,1530
and not just blindly over

1862
00:52:01,165 --> 00:52:03,670
0,485 925,1245 1245,1815 1815,2195 2245,2505
parameters over paramizing them. So

1863
00:52:03,670 --> 00:52:04,930
0,120 120,255 255,465 465,765 765,1260
we can really put incorporating

1864
00:52:04,930 --> 00:52:06,445
0,225 225,500 640,990 990,1305 1305,1515
some of some ideas to

1865
00:52:06,445 --> 00:52:08,350
0,165 165,485 1135,1530 1530,1680 1680,1905
really get what's going on

1866
00:52:08,350 --> 00:52:10,135
0,240 240,465 465,765 765,1040 1510,1785
and liquid neural networks, they

1867
00:52:10,135 --> 00:52:11,910
0,195 195,515 535,825 825,1440 1440,1775
can enable robust representation learning

1868
00:52:12,110 --> 00:52:13,830
0,290 290,455 455,650 650,1325 1325,1720
outside of over paramization regime.

1869
00:52:14,330 --> 00:52:15,655
0,400 570,845 845,980 980,1145 1145,1325
Ah, because of their cause

1870
00:52:15,655 --> 00:52:18,090
0,270 270,1025 1345,1695 1695,2040 2040,2435
of mechanisms they reduce ah.|

1871
00:52:18,830 --> 00:52:21,025
0,400 570,935 935,1175 1175,1600 1650,2195
Networks per. So that's speculation

1872
00:52:21,025 --> 00:52:21,760
0,180 180,300 300,450 450,570 570,735
that I have, I have

1873
00:52:21,760 --> 00:52:22,765
0,255 255,540 540,720 720,810 810,1005
to, ah, we have to

1874
00:52:22,765 --> 00:52:24,295
0,195 195,390 390,725 805,1080 1080,1530
actually think about the theoretical

1875
00:52:24,295 --> 00:52:25,525
0,435 435,675 675,870 870,1080 1080,1230
implication here. But I what

1876
00:52:25,525 --> 00:52:27,055
0,180 180,390 390,540 540,815 1255,1530
I think is that the

1877
00:52:27,055 --> 00:52:29,020
0,275 295,695 745,1145 1225,1620 1620,1965
reason why they networks can

1878
00:52:29,020 --> 00:52:31,405
0,285 285,540 540,860 970,1370 2020,2385
pass or break the, the

1879
00:52:31,405 --> 00:52:33,220
0,315 315,510 510,690 690,1265
universal law of robustness.|

1880
00:52:33,220 --> 00:52:34,980
0,260 280,680 760,1035 1035,1310 1360,1760
Is because they can extract

1881
00:52:35,120 --> 00:52:36,750
0,275 275,550 600,890 890,1180 1230,1630
a better or more minimum

1882
00:52:37,520 --> 00:52:39,130
0,245 245,440 440,740 740,1505 1505,1610
kind of effective dimensionality out

1883
00:52:39,130 --> 00:52:40,300
0,135 135,410 610,885 885,1020 1020,1170
of data. So you have

1884
00:52:40,300 --> 00:52:41,725
0,225 225,560 700,975 975,1155 1155,1425
data sets. So if the,

1885
00:52:41,725 --> 00:52:43,660
0,255 255,435 435,690 690,1560 1560,1935
if the effective dimensionality get

1886
00:52:43,660 --> 00:52:45,370
0,360 360,615 615,885 885,1470 1470,1710
reduced by a paramitized neural

1887
00:52:45,370 --> 00:52:47,020
0,260 700,975 975,1110 1110,1320 1320,1650
network, then the law robust

1888
00:52:47,020 --> 00:52:49,195
0,285 285,590 940,1340 1690,2010 2010,2175
still holds. Okay, given the

1889
00:52:49,195 --> 00:52:50,545
0,135 135,285 285,545 775,1050 1050,1350
number of data. And that's

1890
00:52:50,545 --> 00:52:51,390
0,135 135,270 270,420 420,570 570,845
the end of my presentation.

1891
00:52:51,710 --> 00:52:53,200
0,320 320,470 470,725 725,1060 1230,1490
I'm just putting here at

1892
00:52:53,200 --> 00:52:54,010
0,120 120,270 270,435 435,570 570,810
the end a couple of

1893
00:52:54,010 --> 00:52:54,955
0,375 375,645 645,765 765,855 855,945
resources. If you want to

1894
00:52:54,955 --> 00:52:55,915
0,150 150,375 375,585 585,750 750,960
get hands on with liquid

1895
00:52:55,915 --> 00:52:57,475
0,255 255,515 955,1185 1185,1320 1320,1560
neural networks we have put

1896
00:52:57,475 --> 00:52:59,245
0,335 385,675 675,870 870,1155 1155,1770
together like really good documentations

1897
00:52:59,245 --> 00:53:00,655
0,240 240,390 390,695 985,1230 1230,1410
and I think you would

1898
00:53:00,655 --> 00:53:01,960
0,335 445,765 765,990 990,1170 1170,1305
enjoy to play around with

1899
00:53:01,960 --> 00:53:03,270
0,135 135,390 390,630 630,890 910,1310
these systems for your own

1900
00:53:03,290 --> 00:53:04,080
0,400
applications.|

1901
00:53:04,120 --> 00:53:05,030
0,275 275,425 425,530 530,635 635,910
Thank you for your attention.|

