{"Data": {"TaskId": 5672337174, "Status": 2, "StatusStr": "success", "Result": "[0:9.240,0:37.160]  I'm really, really excited about this lecture because as Alexander introduced yesterday, right now we're in this tremendous age of generative AI, and today we're going to learn the foundations of deep generative modeling, where we're going to talk about building systems that can not only look for patterns in data, but can actually go a step beyond this to generate brand new data instances based on those learned patterns.\n[0:37.500,0:50.260]  This is an incredibly complex and powerful idea, and as I mentioned, it's a particular subset of deep learning that has actually really exploded in the past couple of years and this year in particular.\n[0:50.380,0:57.100]  So to start, and to demonstrate how powerful these algorithms are, let me show you.\n[0:57.100,1:0.300]  These three different faces.\n[1:0.940,1:4.400]  I want you to take a minute think.\n[1:4.400,1:7.420]  Think about which face you think is real.\n[1:7.420,1:9.880]  Raise your hand if you think it's face a.\n[1:9.880,1:14.080]  Okay, see a couple of people face b.\n[1:15.120,1:17.060]  Many more people.\n[1:17.220,1:18.860]  Face c.\n[1:20.360,1:29.600]  Second place? Well, the truth is that all of you are wrong. All three of these faces are fake.\n[1:29.600,1:41.240]  These people do not exist. These images were synthesized by deep generative models, trained on data of human faces and asked to produce new instances.\n[1:41.520,1:54.340]  Now, I think that this demonstration kind of demonstrates the power of these ideas and the power of this notion of generative modeling. So let's get a little more concrete about how we can formalize this.\n[1:54.500,2:10.080]  So far in this course, we've been looking at what we call problems of supervised learning, meaning that we're given data and associated with that data is a set of labels. Our goal is to learn a function that maps that data.\n[2:10.080,2:25.600]  To the labels. Now, we're in a course on deep learning, so we've been concerned with functional mappings that are defined by deep neural networks. But really, that function could be anything. Neural networks are powerful, but we could use other techniques as well.\n[2:26.520,2:48.100]  In contrast, there's another class of problems in machine learning that we refer to as unsupervised learning, where we take data, but now we're given only data, no labels, and our goal is to try to build some method that can understand the hidden underlying structure of that data.\n[2:48.460,3:1.540]  What this allows us to do is it gives us new insights into the foundational representation of the data and as we'll see later, actually enables us to generate new data instances.\n[3:1.540,3:13.040]  Now, this class of problems, this definition of unsupervised learning, captures the types of models that we're going to talk about today in the focus on generative modeling.\n[3:13.600,3:23.120]  Which is an example of unsupervised learning and is united by this goal of the problem where we're given only samples from a training set.\n[3:23.120,3:29.900]  And we want to learn a model that represents the distribution of the data that the model is seeing.\n[3:30.140,3:39.520]  Generative modeling takes two general forms, first density estimation and second sample generation.\n[3:39.600,3:56.240]  In density estimation, the task is given some data examples. Our goal is to train a model that learns an underlying probability distribution that describes where the data came from.\n[3:56.980,4:26.180]  With sample generation, the idea is similar, but the focus is more on actually generating new instances. Our goal with sample generation is to, again, learn this model of this underlying probability distribution, but then use that model to sample from it and generate new instances that are similar to the data that we've seen approximately falling along. Ideally that same real data distribution.\n[4:26.900,4:45.060]  Now, in both these cases of density estimation and sample generation, the underlying question is the same. Our learning task is to try to build a model that learns this probability distribution that is as close as possible to the true data distribution.\n[4:46.320,5:12.060]  Okay, so with this definition and this concept of generative modeling, what are some ways that we can actually deploy generative modeling forward in the real world for high impact applications? Well, part of the reason that generative models are so powerful is that they have this ability to uncover the underlying features in a dataset and encode it in an efficient way.\n[5:12.060,5:36.860]  So, for example, if we're considering the problem of facial detection and we're given a data set with many, many different faces starting out without inspecting this data, we may not know what the distribution of faces in this data set is with respect to features we may be caring about. For example, the pose of the head, clothing, glasses, skin tone, hair, etc.\n[5:36.860,5:45.400]  And it can be the case that our training data may be very, very biased towards particular features without us even realizing this.\n[5:45.540,5:55.980]  Using generative models, we can actually identify the distributions of these underlying features in a completely automatic way without any labeling.\n[5:55.980,6:3.920]  In order to understand what features may be overrepresented in the data, what features may be underrepresented in the data?\n[6:3.920,6:24.160]  And this is the focus of today and tomorrow's software labs, which are going to be part of the software lab competition, developing generative models that can do this task and using it to uncover and diagnose biases that can exist within facial detection models.\n[6:24.860,6:36.940]  Another really powerful example is, in the case of outlier detection, identifying rare events. So let's consider the example of self driving autonomous cars.\n[6:36.940,7:2.820]  With an autonomous car, let's say it's driving out in the real world. We really, really want to make sure that that car can be able to handle all the possible scenarios and all the possible cases it may encounter, including edge cases like a deer coming in front of the car or some unexpected rare events, not just, you know, the typical straight freeway driving that it may see the majority of the time.\n[7:3.120,7:18.460]  With generative models, we can use this idea of density estimation to be able to identify rare and anomalous events within the training data and as they're occurring, as the model sees them, for the first time.\n[7:19.360,7:33.780]  So hopefully this paints this picture of what generative modeling the underlying concept is, and a couple of different ways in which we can actually deploy these ideas for powerful and impactful real world applications.\n[7:35.020,7:48.480]  In today's lecture, we're going to focus on a broad class of generative models that we call latent variable models and specifically distill down into two subtypes of latent variable models.\n[7:48.640,7:57.680]  First things first. I've introduced this term latent variable, but I haven't told you or described to you what that actually is.\n[7:57.920,8:9.920]  I think a great example, and one of my favorite examples throughout this entire course that gets at this idea of the latent variable is this little story from plato's republic.\n[8:9.920,8:13.180]  Which is known as the myth of the cave.\n[8:13.340,8:36.080]  In this myth, there is a group of prisoners, and as part of their punishment, they're constrained to face a wall. Now the only things that prisoners can observe are shadows of objects that are passing in front of a fire that's behind them, and they're observing the casting of the shadows on the wall of this cave.\n[8:36.620,8:54.620]  To the prisoners, those shadows are the only things they see, their observations, they can measure them. They can give them names, because to them that's their reality. But they're unable to directly see the underlying objects, the true factors themselves, that are casting those shadows.\n[8:55.080,8:59.920]  Those objects here are like latent variables in machine learning.\n[8:59.960,9:13.920]  They're not directly observable, but they are the true underlying features or explanatory factors that create the observed differences and variables that we can see and observe.\n[9:14.960,9:29.380]  And this gets at the goal of generative modeling, which is to find ways that we can actually learn these hidden features, these underlying latent variables, even when we're only given observations of the observed data.\n[9:31.340,9:40.320]  So let's start by discussing a very simple generative model that tries to do this through the idea of encoding the data input.\n[9:40.320,9:43.860]  The models we're going to talk about are called auto encoders.\n[9:43.860,9:58.380]  And to take a look at how an auto encoder works, we'll go through step by step, starting with the first step of taking some raw input data and passing it through a series of neural network layers.\n[9:58.660,10:11.780]  Now, the output of this, of this first step is what we refer to as a low dimensional latent space. It's an encoded representation of those underlying features.\n[10:11.780,10:16.760]  And that's our goal in trying to train this model and predict those features.\n[10:17.020,10:27.880]  The reason a model like this is called an encoder or an auto encoder is that it's mapping the data X into this vector of latent variables z.\n[10:27.880,10:31.720]  Now, let's ask ourselves a question. Let's pause for a moment.\n[10:31.720,10:39.900]  Why may we care about having this latent variable vector z be in a low dimensional space?\n[10:40.340,10:42.480]  Anyone have any ideas?\n[10:49.620,10:50.760]  Right.\n[10:50.940,10:54.680]  Maybe there are some ideas, yes.\n[10:54.840,11:13.080]  The suggestion was that it's more efficient. Yes, that gets at it. The heart of the, of the question. The idea of having that low dimensional latent space is that it's a very efficient, compact encoding of the rich, high dimensional data that we may start with.\n[11:13.340,11:22.000]  As you pointed out, what this means is that we're able to compress data into this small feature representation of vector.\n[11:22.160,11:29.780]  That captures this compactness and richness without requiring so much memory or so much storage.\n[11:30.120,11:35.980]  So how do we actually train the network to learn this latent variable vector?\n[11:36.080,11:44.760]  Since we don't have training data, we can't explicitly observe these latent variables. Z, we need to do something more clever.\n[11:44.760,12:1.300]  What the auto encoder does is it builds a way to decode this latent variable vector back up to the original data space, trying to reconstruct the original image from that compressed, efficient latent encoding.\n[12:1.380,12:15.160]  And once again, we can use a series of neural network layers, such as convolutional layers, fully connected layers, but now to map back from that lower dimensional space back upwards to the input space.\n[12:15.660,12:26.420]  This generates a reconstructed output, which we can denote as X hat, since it's an imperfect reconstruction of our original input data.\n[12:26.940,12:43.820]  To train this network, all we have to do is compare the outputted reconstruction and the original input data and say, how do we make these as similar as possible? We can minimize the distance between that input and our reconstructed output.\n[12:43.920,13:3.940]  So, for example, for an image, we can compare the pixel wise difference between the input data and the reconstructed output, just subtracting the images from one another and squaring that difference to capture the pixel wise divergence between the input and the reconstruction.\n[13:4.860,13:20.100]  What I hope you'll notice and appreciate is in that definition of the loss, it doesn't require any labels. The only components of that loss are the original input data X and the reconstructed output X hat.\n[13:21.120,13:31.740]  So I've simplified now this diagram by abstracting away those individual neural network layers in both the encoder and decoder components of this.\n[13:31.840,13:52.840]  And again, this idea of not requiring any labels gets back to the idea of unsupervised learning, since what we've done is we've been able to learn an encoded quantity, our latent variables that we cannot observe without any explicit labels. All we started from was the raw data itself.\n[13:53.600,14:9.520]  It turns out that as as the question and answer got out, that dimensionality of the latent space has a huge impact on the quality of the generated reconstructions and how compressed that information bottleneck is.\n[14:9.920,14:19.920]  Auto encoding is a form of compression, and so the lower the dimensionality of the latent space, the less good our reconstructions are going to be.\n[14:19.920,14:26.540]  But the higher the dimensionality, the more the less efficient that encoding is going to be.\n[14:27.280,14:41.900]  So to summarize this first part, this idea of an auto encoder is using this bottleneck, compressed, hidden latent layer to try to bring the network down to learn a compact, efficient representation of the data.\n[14:41.900,14:54.580]  We don't require any labels. This is completely unsupervised. And so in this way we're able to automatically encode information within the data itself to learn this latent space.\n[14:54.940,14:59.240]  Auto encoding information, auto encoding data.\n[14:59.860,15:18.360]  Now, this is a pretty simple model, and it turns out that in practice, this idea of self encoding or auto encoding has a bit of a twist on it to allow us to actually generate new examples that are not only reconstructions of the input data itself.\n[15:18.360,15:24.020]  And this leads us to the concept of variational auto encoders, or v A.\n[15:24.520,15:41.840]  With the traditional auto encoder that we just saw, if we pay closer attention to the latent layer, which is shown in that orange salmon color, that latent layer is just a normal layer in the neural network. It's completely deterministic.\n[15:41.840,15:58.780]  What that means is once we've trained the network, once the weights are set, anytime we pass a given input in and go back through the latent layer, decode back out, we're going to get the same exact reconstruction. The weights aren't changing, it's deterministic.\n[15:59.160,16:1.060]  In contrast.\n[16:1.060,16:11.240]  Variational auto encoders ves introduce an element of randomness, a probabilistic twist on this idea of auto encoding.\n[16:11.240,16:24.340]  What this will allow us to do is to actually generate new images, similar to the new data, instances that are similar to the input data but not forced to be strict reconstructions.\n[16:24.800,16:34.260]  In practice, with a variational auto encoder, we've replaced that single deterministic layer with a random sampling operation.\n[16:35.220,16:49.440]  Now, instead of learning just the latent variables directly themselves, for each latent variable, we define a mean and a standard deviation that captures a probability distribution over that latent variable.\n[16:50.340,17:5.360]  What we've done is we've gone from a single vector of latent variable z to a vector of means, mu and a vector of standard deviations sigma that parameterize the probability distributions around those latent variables.\n[17:6.420,17:18.980]  What this will allow us to do is now sample using this element of randomness, this element of probability, to then obtain a probabilistic representation of the latent space itself.\n[17:19.460,17:34.100]  As you hopefully can tell, right, this is very, very, very similar to the auto encoder itself, but we've just added this probabilistic twist where we can sample in that intermediate space to get these samples of latent variables.\n[17:35.800,17:37.220]  Okay.\n[17:37.220,17:54.120]  Now, to get a little more into the depth of how this is actually learned, how this is actually trained with defining the v, we've eliminated this deterministic nature to now have these encoders and decoders that are probabilistic.\n[17:54.200,18:3.680]  The encoder is computing a probability distribution of the latent variable z given input data X.\n[18:3.680,18:14.820]  While the decoder is doing the inverse, trying to learn a probability distribution back in the input data space, given the latent variables z.\n[18:15.040,18:26.120]  And we define separate sets of weights, Phi and theta, to define the network weights for the encoder and decoder components of the v.\n[18:27.300,18:41.040]  All right, so when we get now to how we actually optimize and learn the network weights in the va, first step is to define a loss function, right? That's the core element to training a neural network.\n[18:41.420,18:48.440]  Our loss is going to be a function of the data and a function of the neural network weights, just like before.\n[18:48.660,18:54.260]  But we have these two components, these two terms that define our va loss.\n[18:54.260,19:3.640]  First, we see the reconstruction loss just like before, where the goal is to capture the difference between our input data and the reconstructed output.\n[19:3.640,19:10.940]  And now for the ve, we've introduced a second term to the loss, what we call the regularization term.\n[19:11.140,19:24.440]  Often, you'll maybe even see this referred to as a ve loss and we'll go into, we'll go into describing what this regularization term means and what it's doing.\n[19:25.320,19:42.140]  To do that and to understand, remember and, and keep in mind that in all neural network operations, our goal is to try to optimize the network weights with respect to the data with respect to minimizing this objective loss.\n[19:42.140,19:50.480]  And so here we're concerned with the network weights Phi and theta, that define the weights of the encoder and the decoder.\n[19:51.140,20:20.680]  We consider these two terms. First, the reconstruction loss, again, the reconstruction loss is very, very similar, same as before, you can think of it as the error or the likelihood that effectively captures the difference between your input and your outputs. And again, we can trade this in an unsupervised way, not requiring any labels to force the latent space and the network to learn how to effectively reconstruct the input data.\n[20:21.780,20:30.560]  The second term, the regularization term, is now where things get a bit more interesting. So let's go on into this in a little bit more detail.\n[20:30.660,20:40.280]  Because we have this probability distribution and we're trying to compute this encoding and then decode back up.\n[20:40.280,21:4.320]  As part of regularizing, we want to take that inference over the latent distribution and constrain it to behave nicely, if you will. The way we do that is we place what we call a prior on the latent distribution. And what this is is some initial hypothesis or guess about what that latent variable space may look like.\n[21:4.460,21:12.600]  This helps us and helps the network to enforce a latent space that roughly tries to follow this prior distribution.\n[21:12.740,21:17.120]  And this prior is denoted as p of z, right.\n[21:17.400,21:32.640]  That term d, that's effectively the regularization term. It's capturing a distance between our encoding of the latent variables and our prior hypothesis about what the structure of that latent space should look like.\n[21:32.640,21:44.980]  So over the course of training, we're trying to enforce that. Each of those latent variables adapts a prob, adapts a probability distribution that's similar to that prior.\n[21:46.780,22:4.700]  A common choice when training vas and developing these models is to enforce the latent variables to be roughly standard normal gouging distributions, meaning that they are centered around mean zero and they have a standard deviation of one.\n[22:5.200,22:23.040]  What this allows us to do is to encourage the encoder to put the latent variables roughly around a centered space, distributing the encoding smoothly so that we don't get too much divergence away from that smooth space.\n[22:23.140,22:29.760]  Which can occur if the network tries to cheat and try to simply memorize the data.\n[22:29.960,22:45.860]  By placing the gaussian standard normal prior on the latent space, we can define a concrete mathematical term that captures the distance the divergence between our encoded latent variables and this prior.\n[22:45.860,23:8.420]  And this is called the K L divergence when our prior is a standard normal. The kl divergence takes the form of the equation that I'm showing up on the screen. But what I want you to really get away come away with is that the concept of trying to smooth things out and to.\n[23:8.780,23:17.080]  Capture this divergence, and this difference between the prior and the latent encoding, is all this kl term is trying to capture.\n[23:17.520,23:34.600]  So it's a bit of math, and I I acknowledge that. But what I want to next go into is really what is the intuition behind this regularization operation, why do we do this? And why does the normal prior, in particular, work effectively for v.\n[23:34.800,23:42.480]  So let's consider what properties we want our latent space to adopt and for this regularization to achieve.\n[23:42.940,24:2.880]  The first is this goal of continuity. We don't. And what we mean by continuity is that if there are points in the latent space that are close together, ideally after decoding, we should recover two reconstructions that are similar in content that make sense that they're close together.\n[24:3.180,24:7.220]  The second key property is this idea of completeness.\n[24:7.240,24:17.120]  We don't want there to be gaps in the Lane space. We want to be able to decode and sample from the Lane space in a way that is smooth and a way that is connected.\n[24:17.840,24:38.500]  To get more concrete, let's ask what could be the consequences of not regularizing our latent space at all? Well, if we don't regularize, we can end up with instances where there are points that are close in the latent space, but don't end up with similar decodings or similar reconstructions.\n[24:38.600,24:49.060]  Similarly, we could have points that don't lead to meaningful reconstructions at all. They're somehow encoded, but we can't decode effectively.\n[24:49.340,25:0.280]  Regularization allows us to realize points that end up close into latent space and also are similarly reconstructed and meaningfully reconstructed.\n[25:2.060,25:17.880]  Okay, so continuing with this example, the example that I showed there and I didn't get into details, was showing these shapes, these shapes of different colors and that were trying to be encoded in some lower dimensional space.\n[25:18.960,25:35.740]  With regularization, we are able to achieve this by trying to minimize that regularization term. It's not sufficient to just employ the reconstruction loss alone to achieve this continuity and this completeness.\n[25:36.480,25:47.540]  Because of the fact that without regularization, just encoding and reconstructing does not guarantee the properties of continuity and completeness.\n[25:47.840,25:50.380]  We overcome this.\n[25:50.460,26:2.480]  These issues of having potentially pointed distributions, having discontinuities having disparate means that could end up in the latent space without the effect of regularization.\n[26:2.720,26:14.240]  We overcome this by now regularizing the mean and the variance of the encoded latent distributions according to that normal prior.\n[26:14.340,26:31.940]  What this allows is for the learned distributions of those latent variables to effectively overlap in the latent space, because everything is regularized to have, according to this prior, of mean zero, standard deviation one, and that centers the means.\n[26:31.940,26:38.480]  Regularizes the variances for each of those independent latent variable distributions.\n[26:38.680,26:54.360]  Together, the effect of this regularization in net is that we can achieve continuity and completeness in the latent space. Points and distances that are close should correspond to similar reconstructions that we get out.\n[26:54.880,27:8.160]  So hopefully this gets at some of the intuition behind the idea of the ve behind the idea of the regularization and trying to enforce the structured normal prior on the latent space.\n[27:9.400,27:32.480]  With this in hand, with the two components of our loss function reconstructing the inputs regularizing learning to try to achieve continuity and completeness, we can now think about how we define a forward pass through the network, going from an input example and being able to decode and sample from the latent variables to look at new examples.\n[27:32.900,27:40.420]  Our last critical step is how the actual back propagation training algorithm is defined and how we achieve this.\n[27:41.020,27:52.880]  The key, as I introduce with ves is this notion of randomness of sampling that we have introduced by defining these probability distributions over each of the latent variables.\n[27:53.320,28:4.240]  The problem this gives us is that we cannot back propagate directly through anything that has an element of sampling anything that has an element of randomness.\n[28:5.000,28:16.580]  Back propagation requires completely deterministic nodes, deterministic layers to be able to successfully apply gradient descent and the back propagation algorithm.\n[28:17.700,28:28.740]  The breakthrough idea that enabled va to be trained completely end to end was this idea of re-parameterriization within that sampling layer.\n[28:28.760,28:34.400]  And I'll give you the key idea about how this operation works. It's actually really quite level.\n[28:34.400,28:35.940]  Quite clever.\n[28:36.140,28:44.880]  So, as I said, when we have a notion of randomness of probability, we can't sample directly through that layer.\n[28:45.400,28:54.040]  Instead, with parameterriization, what we do is we redefine how a latent variable vector is sampled.\n[28:54.040,29:25.160]  As a sum of a fixed deterministic mean mu a fixed vector of standard deviation sigma. And now the trick is that we divert all the randomness, all the sampling to a random constant epsilon that's drawn from a normal distribution. So mean itself is fixed, standard deviation is fixed, all the randomness and the sampling occurs according to that epsilon constant.\n[29:25.200,29:36.160]  We can then scale the mean and standard deviation by that random constant to re-achieve the sampling operation within the latent variables themselves.\n[29:37.040,29:46.540]  What this actually looks like, and an illustration that breaks down this concept of reperatization and divergence, is as follows.\n[29:46.540,30:14.060]  So looking, looking here, right, what I've shown is these completely deterministic steps in blue and the sampling random steps in orange originally. If our latent variables are what effectively are capturing the randomness, the sampling themselves, we have this problem in that we can't back propagate. We can't train directly through anything that has stochasticity that has randomness.\n[30:14.520,30:37.960]  What Rep parameterriization allows us to do is it shifts this diagram where now we've completely diverted that sampling operation off to the side, to this constant epsilon, which is drawn from a normal prior. And now when we look back at our latent variable, it is deterministic with respect to that sampling operation.\n[30:38.360,30:52.220]  What this means is that we can back propagate to update our network weights completely end to end, without having to worry about direct randomness, direct stochasticity within those latent variables c.\n[30:52.860,31:4.280]  This trick is really, really powerful because it enabled the ability to train these vas completely end to end in through back propagation algorithm.\n[31:5.000,31:15.480]  All right. So at this point, we've gone through the core architecture of vas. We've introduced these two terms of the loss. We've seen how we can train it end to end.\n[31:15.480,31:21.460]  Now let's consider what these latent variables are actually capturing and what they represent.\n[31:22.320,31:47.180]  When we impose this distributional prior, what it allows us to do is to sample effectively from the latent space and actually slowly perturb the value of single latent variables, keeping the other ones fixed. And what you can observe, and what you can see here is that by doing that perturbation that tuning of the value of the latent variables.\n[31:47.180,32:9.940]  We can run the decoder of the va every time, reconstruct the output every time we do that tuning. And what you'll see hopefully with this example with the face is that an individual latent variable is capturing something semantically informative, something meaningful. And we see that by this perturbation, by this tuning.\n[32:10.040,32:21.060]  In this example, the face, as you hopefully can appreciate, is shifting. The pose is shifting, and all this is driven by is the perturbation of a single latent variable.\n[32:21.120,32:27.520]  Tuning the value of that latent variable and seeing how that affects the decoded reconstruction.\n[32:28.060,32:46.400]  The network is actually able to learn these different encoded features, these different latent variables, such that by perturbing the values of them individually, we can interpret and make sense of what those latent variables mean and what they represent.\n[32:46.620,33:8.320]  To make this more concrete, we can consider even multiple latent variables simultaneously, compare one against the other, and ideally, we want those latent features to be as independent as possible in order to get at the most compact and richest representation and compact encoding.\n[33:8.320,33:13.940]  So here again, in this example of faces, we're walking along two axes.\n[33:13.940,33:21.640]  Head pose on the X axis and what appears to be kind of a notion of a smile on the y axis.\n[33:21.640,33:34.020]  And you can see that with these reconstructions, we can actually perturb these features to be able to perturb the end effect in the reconstructed space.\n[33:34.320,33:49.400]  And so ultimately, with with AV, our goal is to try to enforce as much information to be captured in that encoding as possible. We want these latent features to be independent and ideally disentangled.\n[33:50.020,33:59.600]  It turns out that there is a very clever and simple way to try to encourage this independence and this disentanglement.\n[33:59.880,34:15.680]  While this may look a little complicated with the math and a bit scary, I will break this down with the idea of how a very simple concept enforces this independent latent encoding and this disentanglement.\n[34:16.100,34:25.100]  All this term is showing is those two components of the loss, the reconstruction term, the regularization term. That's what I want you to focus on.\n[34:25.600,34:34.300]  The idea of latent space disentanglement really arose with this concept of Beta Beta ves.\n[34:34.300,34:50.560]  What Beta vas do is they introduce this parameter Beta and what it is it's awaiting constant, the awaiting constant controls, how powerful that regularization term is in the overall loss of the v.\n[34:50.560,35:5.160]  And it turns out that by increasing the value of Beta, you can try to encourage greater disentanglement, more efficient encoding to enforce these latent variables to be uncorrelated with each other.\n[35:5.400,35:34.420]  Now, if you're interested in mathematically why Beta v enforce this disentanglement there are many papers in the literature and proofs and discussions as to why this occurs, and we can point you in those directions, but to get a sense of what this actually affects downstream when we look at face reconstruction as a task of interest with a standard v no Beta term, or rather a Beta of one.\n[35:34.660,35:58.080]  You can hopefully appreciate that the features of the rotation of the head, the pose and the rotation of the head is also actually ends up being correlated with smile and the facial, the mouth expression in the mouth position. In that as the head pose is changing, the apparent smile or the position of the mouth is also changing.\n[35:58.500,36:24.600]  But with Beta ves empirically we can observe that with imposing these Beta values much, much, much greater than one, we can try to enforce greater disentanglement, where now we can consider only a single latent variable head pose and the smile, the position of the mouth in these images is more constant compared to the standard v.\n[36:26.140,36:49.440]  All right, so this is really all the core math, the core operations, the core architecture of the a that we're going to cover in today's lecture and in this class in general to close this section. And as a final note, I want to remind you back to the motivating example that I introduced at the beginning of this lecture, facial detection.\n[36:49.440,37:15.780]  Where now hopefully you've understood this concept of latent variable learning and encoding, and how this may be useful for a task like facial detection, where we may want to learn those distributions of the underlying features in the data, and indeed, you're going to get hands on practice in the software labs to build variational auto encoders that can automatically uncover.\n[37:15.980,37:27.640]  Features underlying facial detection data sets and use this to actually understand underlying and hidden biases that may exist with those data and with those models.\n[37:27.820,37:53.380]  And it doesn't just stop there. Tomorrow we'll have a very, very exciting guest lecture on robust and trustworthy deep learning, which will take this concept a step further to realize how we can use this idea of generative models and latent variable learning to not only uncover and diagnose biases, but actually solve and mitigate some of those harmful effects of those biases in.\n[37:53.380,37:57.520]  Neural networks for facial detection and other applications.\n[37:57.760,38:16.120]  All right, so to summarize quickly the key points of vas we've gone through how they're able to compress data into this compact encoded representation. From this representation, we can generate reconstructions of the input in a completely unsupervised fashion.\n[38:16.940,38:39.120]  We can train them end to end using the parameterurization trick. We can understand the semantic interpretation of individual latent variables by perturbing their values. And finally, we can sample from the latent space to generate new examples by passing back up through the decoder.\n[38:39.860,38:55.000]  So v are looking at this idea of latent variable encoding and density estimation as their core problem. What if now we only focus on the quality of the generated samples, and that's the task that we care more about.\n[38:55.560,39:3.400]  For that, we're going to transition to a new type of generative model called a generative adversarial network, or gam.\n[39:3.940,39:22.600]  Where with gans, our goal is really that we care more about how well we generate new instances that are similar to the existing data, meaning that we want to try to sample from a potentially very complex distribution that the model is trying to approximate.\n[39:23.180,39:34.440]  It can be extremely, extremely difficult to learn that distribution directly because it's complex, it's high dimensional and we want to be able to get around that complexity.\n[39:34.440,39:53.360]  What ganss do is they say, okay, what if we start from something super, super simple? As simple as it can get completely random noise? Could we build a neural network architecture that can learn to generate synthetic examples from complete random noise?\n[39:54.020,40:7.840]  And this is the underlying concept of gans, where the goal is to train this generator network that learns a transformation from noise to the training data distribution.\n[40:7.840,40:14.640]  With the goal of making the generated examples as close to the real deo as possible.\n[40:14.780,40:28.440]  With gans, the breakthrough idea here was to interface these two neural networks together, one being a generator and one being a discriminator.\n[40:28.440,40:35.460]  And these two components, the generator and discriminator, are at war, at competition with each other.\n[40:35.460,40:46.760]  Specifically, the goal of the generator network is to look at random noise and try to produce an imitation of the data that's as close to real as possible.\n[40:46.940,40:58.340]  The discriminator then takes the output of the generator as well as some real data examples, and tries to learn a classification decision.\n[40:58.440,41:1.480]  Distinguishing real from fake.\n[41:1.480,41:21.740]  And effectively in the g, these two components are going back and forth, competing each other, trying to force the discriminator to better learn this distinction between real and fake, while the generator is trying to fool and outperform the ability of the discriminator to make that classification.\n[41:22.620,41:42.760]  So that's the overlying concept. But what I'm really excited about is the next example, which is one of my absolute favorite illustrations and walkthroughs in this class. And it gets at the intuition behind gans, how they work and the underlying concept.\n[41:42.760,41:48.720]  We're going to look at a one d example, points on a line, right? That's the data that we're working with.\n[41:48.720,41:57.460]  And again, the generator starts from random noise, produces some fake data. They're going to fall somewhere on this one dimensional line.\n[41:57.740,42:2.720]  Now the next step is the discriminator then sees these points.\n[42:2.820,42:6.160]  And it also sees some real data.\n[42:6.360,42:16.560]  The goal of the discriminator is to be trained to output a probability that an instance it sees is real or fake.\n[42:17.060,42:38.560]  And initially in the beginning before training, it's not trained right. So its predictions may not be very good. But over the course of training, you're going to train it and it hopefully will start increasing the probability for those examples that are real and decreasing the probability for those examples that are fake.\n[42:38.680,42:42.260]  Overall goal is to predict what is real.\n[42:42.260,42:52.480]  Until eventually the discriminator reaches this point where it has a perfect separation, perfect classification of real versus fake.\n[42:52.820,43:4.140]  Okay, so at this point, the discriminator thinks, okay, I've done my job, now we go back to the generator and it sees the examples of where the real data lie.\n[43:4.140,43:13.640]  And it can be forced to start moving its generated fake data closer and closer, increasingly closer to the real data.\n[43:14.180,43:27.680]  We can then go back to the discriminator, which receives these newly synthesized examples from the generator, and repeats that same process of estimating the probability that any given point is real.\n[43:28.060,43:36.080]  And learning to increase the probability of the true real examples decrease the probability of the fake points.\n[43:36.300,43:40.020]  Adjusting, adjusting over the course of its training.\n[43:40.460,43:49.480]  And finally, we can go back and repeat to the generator again one last time. The generator starts moving those fake points closer.\n[43:49.480,43:57.660]  Closer and closer to the real data, such that the fake data is almost following the distribution of the real data.\n[43:58.020,44:6.800]  At this point, it becomes very, very hard for the discriminator to distinguish between what is real and what is fake.\n[44:6.800,44:13.400]  While the generator will continue to try to create fake data points to fool the discriminator.\n[44:13.900,44:27.320]  This is really the key concept, the underlying intuition behind how the components of the Gan are essentially competing with each other, going back and forth between the generator and the discriminator.\n[44:27.560,44:50.960]  And in fact, this is this intuitive concept is how the Gan is trained in practice, where the generator first tries to synthesize new examples, synthetic examples to fool the discriminator. And the goal of the discriminator is to take both the fake examples and the real data to try to identify the synthesized instances.\n[44:51.880,44:56.240]  In training, what this means is that the objective.\n[44:56.240,45:9.340]  The loss for the generator and discriminator have to be at odds with each other. They're adversarial, and that is what gives rise to the component of adversarial in generative adversarial network.\n[45:9.860,45:28.300]  These adversarial objectives are then put together to then define what it means to arrive at a stable global optimum, where the generator is capable of producing the true data distribution that would completely fool the discriminator.\n[45:30.100,45:37.040]  Concretely, this can be defined mathematically in terms of a loss objective and again.\n[45:37.180,45:52.520]  Though I'm, I'm showing math, I can, we can distill this down and go through what each of these terms reflect in terms of that core intuitive idea and conceptual idea that hopefully that one d example conveyed.\n[45:52.920,46:9.060]  So we'll first consider the perspective of the discriminator d its goal is to maximize probability that its decisions in its decisions that real data are classified real fake data classified as fake.\n[46:9.140,46:23.760]  So here the first term g of z is the generator's output, and d of g of z is the discriminator's estimate of that generated output as being fake.\n[46:25.100,46:33.780]  D of X X is the real data, and so d of X is the estimate of the probability that a real instance is fake.\n[46:33.780,46:39.280]  One minus d of X is the estimate that that real instance is real.\n[46:39.360,46:54.320]  So here in both these cases, the discriminator is producing a decision about fake data, real data. And together it wants to try to maximize the probability that it's getting answers correct, right?\n[46:56.080,47:3.540]  Now with the generator, we have those same exact terms, but keep in mind the generator is never.\n[47:3.540,47:12.900]  Able to affect anything that the discriminator decision is actually doing, besides generating new data examples.\n[47:12.900,47:23.640]  So for the generator, its objective is simply to minimize the probability that the generated data is identified as fake.\n[47:24.580,47:36.220]  Together, we want to then put this together to define what it means for the generator to synthesize fake images that hopefully fool the discriminator.\n[47:36.960,48:2.940]  All in all, right, this term, besides the math, besides the particularities of this definition, what I want you to get away from this, from this section on gans, is that we have this dual competing objective where the generator is trying to synthesize these synthetic examples that ideally fool the best discriminator possible.\n[48:2.940,48:7.680]  And in doing so, the goal is to build up a network.\n[48:7.680,48:21.420]  VIA this adversarial training, this adversarial competition to use the generator to create new data that best mimics the true data distribution and its completely synthetic new instances.\n[48:22.900,48:35.740]  What this amounts to in practice is that after the training process, you can look exclusively at the generator component and use it to then create new data instances.\n[48:37.120,48:57.300]  All this is done by starting from random noise and trying to learn a model that goes from random noise to the real data distribution. And effectively what gans are doing is learning a function that transforms that distribution of random noise to some target.\n[48:57.380,49:11.640]  What this mapping does is it allows us to take a particular observation of noise in that noise space and map it to some output, a particular output in our target data space.\n[49:12.060,49:26.280]  And in turn, if we consider some other random sample of noise, if we feed it through the generator of g, it's going to produce a completely new instance falling somewhere else on that true data distribution manifold.\n[49:26.280,49:42.240]  And indeed, what we can actually do is interpolate and traverse between trajectories in the noise space that then map to traversals and interpolations in the target data space.\n[49:42.240,49:56.880]  And this is really, really cool because now you can think about an initial point and a target point and all the steps that are going to take you to synthesize and go between those images in that target data distribution.\n[49:57.580,50:7.200]  So hopefully this gives a sense of this concept of generative modeling for the purpose of creating new data instances.\n[50:7.200,50:17.300]  And that notion of interpolation and data transformation leads very nicely to some of the recent advances and applications of gans.\n[50:17.300,50:36.360]  Where one particularly commonly employed idea is to try to iteratively grow again to get more and more detailed image generations, progressively adding layers over the course of training to then refine the examples generated by the generator.\n[50:36.860,50:54.300]  And this is the approach that was used to generate those synthetic, those images of those synthetic faces that I showed at the beginning of this lecture, this idea of using g that is refined iteratively to produce higher resolution images.\n[50:54.820,51:17.320]  Another way we can extend this concept is to extend the Gan architecture to consider particular tasks and impose further structure on the network itself. One particular idea is to say, okay, what if we have a particular label or some factor that we want to condition the generation on.\n[51:17.720,51:23.180]  We call the c and it supplied to both the generator and the discriminator.\n[51:23.460,51:47.080]  What this will allow us to achieve is paired translation between different types of data. So, for example, we can have images of a street view and we can have images of the segmentation of that street view and we can build again that can directly translate between the street view and the segmentation.\n[51:47.080,51:51.640]  Let's make this more concrete by considering some particular examples.\n[51:51.640,51:57.940]  So what I just described was going from a segmentation label to a street scene.\n[51:57.940,52:20.180]  We can also translate between a satellite view aerial satellite image to what is the roadmap equivalent of that aerial satellite image or a particular annotation or labels of the image of a building to the actual visual realization and visual facade of that building.\n[52:20.180,52:24.800]  We can translate between different lighting conditions day to night.\n[52:24.880,52:31.400]  Black and white to color outlines to a colored photo.\n[52:31.400,52:53.800]  All these cases, and I think in particular the, the most interesting and impactful to me is this translation between street view and aerial view. And this is used to consider, for example, if you have data from Google maps, how you can go between a street view of the map to the aerial image of that.\n[52:55.180,53:12.240]  Finally, again extending the same concept of translation between one domain to another, another idea is that of completely unpaired translation, and this uses a particular Gan architecture called cyan.\n[53:12.280,53:47.540]  So in this video that I'm showing here, the model takes as input a bunch of images in one domain. And it doesn't necessarily have to have a corresponding image in another target domain, but it is trained to try to generate examples in that target domain that roughly correspond to the source domain, transferring the style of the source onto the target and vice versa. So this example is showing the translation of images in horse domain to zebra domain.\n[53:47.920,54:0.740]  The concept here is this cyclic dependency, right? You have two gans that are connected together VIA this cyclic loss, transforming between one domain and another.\n[54:1.180,54:25.080]  And really like all the examples that we've seen so far in this lecture, the intuition is this idea of distribution transformation. Normally with g, you're going from noise to some target with the cycle. Again, you're trying to go from some source distribution, some data manifold X to a target distribution, another data manifold y.\n[54:25.260,54:35.840]  And this is really, really not only cool, but also powerful in thinking about how we can translate across these different distributions flexibly.\n[54:35.840,54:44.200]  And in fact, this allows us to do transformations not only to images, but to speech and audio as well.\n[54:44.200,54:50.760]  So in the case of speech and audio, turns out that you can take sound waves. Represent.\n[54:50.760,55:9.300]  Compactly in a spectrogram image and use a cycle g to then translate and transform speech from one person's voice in one domain to another person's voice in another domain, right? These are two independent data distributions that we define.\n[55:9.540,55:36.920]  Maybe you're getting a sense of where I'm hinting at. Maybe not, but in fact, this was exactly how we developed the model to synthesize the audio behind Obama's voice that we saw in yesterday's introductory lecture. What we did was we trained a cycle g to take data in Alexander's voice and transform it into data in the manifold of Obama's voice.\n[55:37.360,55:54.620]  So we can visualize how that spectrogram waveform looks like for Alexander's voice versus Obama's voice that was completely synthesized using this cycle approach.\n[55:55.360,55:56.680]  The.\n[55:59.120,56:2.500]  Here at MIT.\n[56:3.160,56:24.600]  I replayed it, okay, but basically what we did was Alexander spoke that exact phrase that was played yesterday, and we had the train cycle again, model, and we can deploy it then on that exact audio to transform it from the domain of Alexander's voice to Obama s voice.\n[56:24.600,56:29.400]  Generating the synthetic audio that was played for that video clip.\n[56:29.400,56:36.860]  Okay, before I accidentally played again, I.\n[56:36.860,57:6.420]  Jump now to the summary slide. So today in this lecture we've learned deep generative models specifically talking mostly about latent variable models, auto encoders, variational auto encoders where our goal is to learn this low dimensional latent encoding of the data, as well as generative adversarial networks where we have these competing generator and discriminator components that are trying to synthesize synthetic examples.\n[57:7.440,57:30.400]  We've talked about these core foundational generative methods, but it turns out, as I alluded to in the beginning of the lecture, that in this past year in particular, we've seen truly, truly tremendous advances in generative modeling, many of which have not been from those two methods, those two foundational methods that we described.\n[57:30.400,57:34.480]  But rather a new approach called diffusion modeling.\n[57:34.480,57:45.780]  Diffusion models are driving are the driving tools behind the tremendous advances in generative AI that we've seen in this past year in particular.\n[57:46.000,58:0.660]  These gans, they're learning these transformations, these encodings, but they're largely restricted to generating examples that fall similar to the data space that they've seen before.\n[58:1.200,58:18.900]  Diffusion models have this ability to now hallucinate and envision and imagine completely new objects and instances, which we as humans may not have seen or even thought about parts of the design space that are not covered by the training data.\n[58:18.900,58:31.240]  So an example here is this AI generated art, which art, if you will, which was created by a diffusion model, and I think not only does this get at.\n[58:31.240,58:51.920]  Some of the limits and capabilities of these powerful models, but also questions about what does it mean to create new instances? What are the limits and bounds of these models, and how do they, how can we think about their advances with respect to human capabilities and human intelligence?\n[58:52.380,59:19.840]  And so I'm, I'm really excited that on thursday in lecture seven on new frontiers in deep learning, we're going to take a really deep dive into diffusion models, talk about their fundamentals, talk about not only applications to images, but other fields as well, in which we're seeing these models really start to make transformative advances because they are indeed at the very cutting edge and very much the new frontier of generative AI today.\n[59:20.340,59:22.940]  All right. So with that.\n[59:22.960,59:46.960]  Tease and and hopefully set the stage for lecture seven on thursday and conclude and remind you all that we have now about an hour for open office hour. Time for you to work on your software labs. Come to us, ask any questions you may have as well as the tas who will be here as well.\n[59:46.960,59:52.057]  Thank you so much.\n", "ErrorMsg": "", "ResultDetail": [{"FinalSentence": "I'm really, really excited about this lecture because as Alexander introduced yesterday, right now we're in this tremendous age of generative AI, and today we're going to learn the foundations of deep generative modeling, where we're going to talk about building systems that can not only look for patterns in data, but can actually go a step beyond this to generate brand new data instances based on those learned patterns.", "SliceSentence": "I'm really really excited about this lecture because as Alexander introduced yesterday right now we're in this tremendous age of generative AI and today we're going to learn the foundations of deep generative modeling where we're going to talk about building systems that can not only look for patterns in data but can actually go a step beyond this to generate brand new data instances based on those learned patterns", "StartMs": 9240, "EndMs": 37160, "WordsNum": 70, "Words": [{"Word": "I'm", "OffsetStartMs": 220, "OffsetEndMs": 600}, {"Word": "really", "OffsetStartMs": 600, "OffsetEndMs": 780}, {"Word": "really", "OffsetStartMs": 780, "OffsetEndMs": 1080}, {"Word": "excited", "OffsetStartMs": 1080, "OffsetEndMs": 1455}, {"Word": "about", "OffsetStartMs": 1455, "OffsetEndMs": 1785}, {"Word": "this", "OffsetStartMs": 1785, "OffsetEndMs": 2085}, {"Word": "lecture", "OffsetStartMs": 2085, "OffsetEndMs": 2450}, {"Word": "because", "OffsetStartMs": 2590, "OffsetEndMs": 2955}, {"Word": "as", "OffsetStartMs": 2955, "OffsetEndMs": 3320}, {"Word": "Alexander", "OffsetStartMs": 3400, "OffsetEndMs": 3800}, {"Word": "introduced", "OffsetStartMs": 3910, "OffsetEndMs": 4310}, {"Word": "yesterday", "OffsetStartMs": 4810, "OffsetEndMs": 5210}, {"Word": "right", "OffsetStartMs": 6340, "OffsetEndMs": 6645}, {"Word": "now", "OffsetStartMs": 6645, "OffsetEndMs": 6900}, {"Word": "we're", "OffsetStartMs": 6900, "OffsetEndMs": 7140}, {"Word": "in", "OffsetStartMs": 7140, "OffsetEndMs": 7230}, {"Word": "this", "OffsetStartMs": 7230, "OffsetEndMs": 7440}, {"Word": "tremendous", "OffsetStartMs": 7440, "OffsetEndMs": 7790}, {"Word": "age", "OffsetStartMs": 7960, "OffsetEndMs": 8355}, {"Word": "of", "OffsetStartMs": 8355, "OffsetEndMs": 8715}, {"Word": "generative", "OffsetStartMs": 8715, "OffsetEndMs": 9360}, {"Word": "AI", "OffsetStartMs": 9360, "OffsetEndMs": 9740}, {"Word": "and", "OffsetStartMs": 10180, "OffsetEndMs": 10485}, {"Word": "today", "OffsetStartMs": 10485, "OffsetEndMs": 10770}, {"Word": "we're", "OffsetStartMs": 10770, "OffsetEndMs": 11070}, {"Word": "going", "OffsetStartMs": 11070, "OffsetEndMs": 11205}, {"Word": "to", "OffsetStartMs": 11205, "OffsetEndMs": 11400}, {"Word": "learn", "OffsetStartMs": 11400, "OffsetEndMs": 11670}, {"Word": "the", "OffsetStartMs": 11670, "OffsetEndMs": 11910}, {"Word": "foundations", "OffsetStartMs": 11910, "OffsetEndMs": 12410}, {"Word": "of", "OffsetStartMs": 12610, "OffsetEndMs": 12990}, {"Word": "deep", "OffsetStartMs": 12990, "OffsetEndMs": 13320}, {"Word": "generative", "OffsetStartMs": 13320, "OffsetEndMs": 13830}, {"Word": "modeling", "OffsetStartMs": 13830, "OffsetEndMs": 14390}, {"Word": "where", "OffsetStartMs": 14650, "OffsetEndMs": 14940}, {"Word": "we're", "OffsetStartMs": 14940, "OffsetEndMs": 15165}, {"Word": "going", "OffsetStartMs": 15165, "OffsetEndMs": 15315}, {"Word": "to", "OffsetStartMs": 15315, "OffsetEndMs": 15495}, {"Word": "talk", "OffsetStartMs": 15495, "OffsetEndMs": 15750}, {"Word": "about", "OffsetStartMs": 15750, "OffsetEndMs": 16050}, {"Word": "building", "OffsetStartMs": 16050, "OffsetEndMs": 16365}, {"Word": "systems", "OffsetStartMs": 16365, "OffsetEndMs": 16760}, {"Word": "that", "OffsetStartMs": 17350, "OffsetEndMs": 17640}, {"Word": "can", "OffsetStartMs": 17640, "OffsetEndMs": 17790}, {"Word": "not", "OffsetStartMs": 17790, "OffsetEndMs": 17970}, {"Word": "only", "OffsetStartMs": 17970, "OffsetEndMs": 18285}, {"Word": "look", "OffsetStartMs": 18285, "OffsetEndMs": 18630}, {"Word": "for", "OffsetStartMs": 18630, "OffsetEndMs": 18945}, {"Word": "patterns", "OffsetStartMs": 18945, "OffsetEndMs": 19310}, {"Word": "in", "OffsetStartMs": 19360, "OffsetEndMs": 19650}, {"Word": "data", "OffsetStartMs": 19650, "OffsetEndMs": 19940}, {"Word": "but", "OffsetStartMs": 20470, "OffsetEndMs": 20745}, {"Word": "can", "OffsetStartMs": 20745, "OffsetEndMs": 20985}, {"Word": "actually", "OffsetStartMs": 20985, "OffsetEndMs": 21240}, {"Word": "go", "OffsetStartMs": 21240, "OffsetEndMs": 21390}, {"Word": "a", "OffsetStartMs": 21390, "OffsetEndMs": 21540}, {"Word": "step", "OffsetStartMs": 21540, "OffsetEndMs": 21795}, {"Word": "beyond", "OffsetStartMs": 21795, "OffsetEndMs": 22110}, {"Word": "this", "OffsetStartMs": 22110, "OffsetEndMs": 22460}, {"Word": "to", "OffsetStartMs": 22810, "OffsetEndMs": 23115}, {"Word": "generate", "OffsetStartMs": 23115, "OffsetEndMs": 23420}, {"Word": "brand", "OffsetStartMs": 23590, "OffsetEndMs": 23970}, {"Word": "new", "OffsetStartMs": 23970, "OffsetEndMs": 24350}, {"Word": "data", "OffsetStartMs": 24490, "OffsetEndMs": 24885}, {"Word": "instances", "OffsetStartMs": 24885, "OffsetEndMs": 25730}, {"Word": "based", "OffsetStartMs": 25840, "OffsetEndMs": 26220}, {"Word": "on", "OffsetStartMs": 26220, "OffsetEndMs": 26490}, {"Word": "those", "OffsetStartMs": 26490, "OffsetEndMs": 26685}, {"Word": "learned", "OffsetStartMs": 26685, "OffsetEndMs": 26940}, {"Word": "patterns", "OffsetStartMs": 26940, "OffsetEndMs": 27290}], "SpeechSpeed": 15.0}, {"FinalSentence": "This is an incredibly complex and powerful idea, and as I mentioned, it's a particular subset of deep learning that has actually really exploded in the past couple of years and this year in particular.", "SliceSentence": "This is an incredibly complex and powerful idea and as I mentioned it's a particular subset of deep learning that has actually really exploded in the past couple of years and this year in particular", "StartMs": 37500, "EndMs": 50260, "WordsNum": 35, "Words": [{"Word": "This", "OffsetStartMs": 190, "OffsetEndMs": 540}, {"Word": "is", "OffsetStartMs": 540, "OffsetEndMs": 750}, {"Word": "an", "OffsetStartMs": 750, "OffsetEndMs": 1010}, {"Word": "incredibly", "OffsetStartMs": 1150, "OffsetEndMs": 1550}, {"Word": "complex", "OffsetStartMs": 1780, "OffsetEndMs": 2145}, {"Word": "and", "OffsetStartMs": 2145, "OffsetEndMs": 2415}, {"Word": "powerful", "OffsetStartMs": 2415, "OffsetEndMs": 2720}, {"Word": "idea", "OffsetStartMs": 2980, "OffsetEndMs": 3330}, {"Word": "and", "OffsetStartMs": 3330, "OffsetEndMs": 3570}, {"Word": "as", "OffsetStartMs": 3570, "OffsetEndMs": 3720}, {"Word": "I", "OffsetStartMs": 3720, "OffsetEndMs": 3855}, {"Word": "mentioned", "OffsetStartMs": 3855, "OffsetEndMs": 4110}, {"Word": "it's", "OffsetStartMs": 4110, "OffsetEndMs": 4395}, {"Word": "a", "OffsetStartMs": 4395, "OffsetEndMs": 4575}, {"Word": "particular", "OffsetStartMs": 4575, "OffsetEndMs": 4940}, {"Word": "subset", "OffsetStartMs": 4990, "OffsetEndMs": 5460}, {"Word": "of", "OffsetStartMs": 5460, "OffsetEndMs": 5610}, {"Word": "deep", "OffsetStartMs": 5610, "OffsetEndMs": 5805}, {"Word": "learning", "OffsetStartMs": 5805, "OffsetEndMs": 6110}, {"Word": "that", "OffsetStartMs": 6490, "OffsetEndMs": 6795}, {"Word": "has", "OffsetStartMs": 6795, "OffsetEndMs": 7100}, {"Word": "actually", "OffsetStartMs": 7480, "OffsetEndMs": 7845}, {"Word": "really", "OffsetStartMs": 7845, "OffsetEndMs": 8210}, {"Word": "exploded", "OffsetStartMs": 8410, "OffsetEndMs": 9050}, {"Word": "in", "OffsetStartMs": 9280, "OffsetEndMs": 9540}, {"Word": "the", "OffsetStartMs": 9540, "OffsetEndMs": 9690}, {"Word": "past", "OffsetStartMs": 9690, "OffsetEndMs": 9930}, {"Word": "couple", "OffsetStartMs": 9930, "OffsetEndMs": 10185}, {"Word": "of", "OffsetStartMs": 10185, "OffsetEndMs": 10365}, {"Word": "years", "OffsetStartMs": 10365, "OffsetEndMs": 10575}, {"Word": "and", "OffsetStartMs": 10575, "OffsetEndMs": 10815}, {"Word": "this", "OffsetStartMs": 10815, "OffsetEndMs": 11040}, {"Word": "year", "OffsetStartMs": 11040, "OffsetEndMs": 11295}, {"Word": "in", "OffsetStartMs": 11295, "OffsetEndMs": 11580}, {"Word": "particular", "OffsetStartMs": 11580, "OffsetEndMs": 11930}], "SpeechSpeed": 15.5}, {"FinalSentence": "So to start, and to demonstrate how powerful these algorithms are, let me show you.", "SliceSentence": "So to start and to demonstrate how powerful these algorithms are let me show you", "StartMs": 50380, "EndMs": 57100, "WordsNum": 15, "Words": [{"Word": "So", "OffsetStartMs": 160, "OffsetEndMs": 560}, {"Word": "to", "OffsetStartMs": 910, "OffsetEndMs": 1200}, {"Word": "start", "OffsetStartMs": 1200, "OffsetEndMs": 1440}, {"Word": "and", "OffsetStartMs": 1440, "OffsetEndMs": 1680}, {"Word": "to", "OffsetStartMs": 1680, "OffsetEndMs": 1970}, {"Word": "demonstrate", "OffsetStartMs": 2050, "OffsetEndMs": 2400}, {"Word": "how", "OffsetStartMs": 2400, "OffsetEndMs": 2700}, {"Word": "powerful", "OffsetStartMs": 2700, "OffsetEndMs": 3045}, {"Word": "these", "OffsetStartMs": 3045, "OffsetEndMs": 3435}, {"Word": "algorithms", "OffsetStartMs": 3435, "OffsetEndMs": 3870}, {"Word": "are", "OffsetStartMs": 3870, "OffsetEndMs": 4190}, {"Word": "let", "OffsetStartMs": 4750, "OffsetEndMs": 5025}, {"Word": "me", "OffsetStartMs": 5025, "OffsetEndMs": 5220}, {"Word": "show", "OffsetStartMs": 5220, "OffsetEndMs": 5445}, {"Word": "you", "OffsetStartMs": 5445, "OffsetEndMs": 5750}], "SpeechSpeed": 11.9}, {"FinalSentence": "These three different faces.", "SliceSentence": "These three different faces", "StartMs": 57100, "EndMs": 60300, "WordsNum": 4, "Words": [{"Word": "These", "OffsetStartMs": 190, "OffsetEndMs": 590}, {"Word": "three", "OffsetStartMs": 910, "OffsetEndMs": 1310}, {"Word": "different", "OffsetStartMs": 1510, "OffsetEndMs": 1890}, {"Word": "faces", "OffsetStartMs": 1890, "OffsetEndMs": 2270}], "SpeechSpeed": 8.4}, {"FinalSentence": "I want you to take a minute think.", "SliceSentence": "I want you to take a minute think", "StartMs": 60940, "EndMs": 64400, "WordsNum": 8, "Words": [{"Word": "I", "OffsetStartMs": 70, "OffsetEndMs": 345}, {"Word": "want", "OffsetStartMs": 345, "OffsetEndMs": 495}, {"Word": "you", "OffsetStartMs": 495, "OffsetEndMs": 645}, {"Word": "to", "OffsetStartMs": 645, "OffsetEndMs": 795}, {"Word": "take", "OffsetStartMs": 795, "OffsetEndMs": 930}, {"Word": "a", "OffsetStartMs": 930, "OffsetEndMs": 1035}, {"Word": "minute", "OffsetStartMs": 1035, "OffsetEndMs": 1280}, {"Word": "think", "OffsetStartMs": 1720, "OffsetEndMs": 2120}], "SpeechSpeed": 9.5}, {"FinalSentence": "Think about which face you think is real.", "SliceSentence": "Think about which face you think is real", "StartMs": 64400, "EndMs": 67420, "WordsNum": 8, "Words": [{"Word": "Think", "OffsetStartMs": 0, "OffsetEndMs": 210}, {"Word": "about", "OffsetStartMs": 210, "OffsetEndMs": 450}, {"Word": "which", "OffsetStartMs": 450, "OffsetEndMs": 720}, {"Word": "face", "OffsetStartMs": 720, "OffsetEndMs": 1070}, {"Word": "you", "OffsetStartMs": 1090, "OffsetEndMs": 1380}, {"Word": "think", "OffsetStartMs": 1380, "OffsetEndMs": 1605}, {"Word": "is", "OffsetStartMs": 1605, "OffsetEndMs": 1875}, {"Word": "real", "OffsetStartMs": 1875, "OffsetEndMs": 2210}], "SpeechSpeed": 13.2}, {"FinalSentence": "Raise your hand if you think it's face a.", "SliceSentence": "Raise your hand if you think it 's face a", "StartMs": 67420, "EndMs": 69880, "WordsNum": 10, "Words": [{"Word": "Raise", "OffsetStartMs": 0, "OffsetEndMs": 240}, {"Word": "your", "OffsetStartMs": 240, "OffsetEndMs": 405}, {"Word": "hand", "OffsetStartMs": 405, "OffsetEndMs": 615}, {"Word": "if", "OffsetStartMs": 615, "OffsetEndMs": 825}, {"Word": "you", "OffsetStartMs": 825, "OffsetEndMs": 945}, {"Word": "think", "OffsetStartMs": 945, "OffsetEndMs": 1065}, {"Word": "it", "OffsetStartMs": 1065, "OffsetEndMs": 1155}, {"Word": "'s", "OffsetStartMs": 1155, "OffsetEndMs": 1245}, {"Word": "face", "OffsetStartMs": 1245, "OffsetEndMs": 1455}, {"Word": "a", "OffsetStartMs": 1455, "OffsetEndMs": 1790}], "SpeechSpeed": 16.3}, {"FinalSentence": "Okay, see a couple of people face b.", "SliceSentence": "Okay see a couple of people face b", "StartMs": 69880, "EndMs": 74080, "WordsNum": 8, "Words": [{"Word": "Okay", "OffsetStartMs": 850, "OffsetEndMs": 1230}, {"Word": "see", "OffsetStartMs": 1230, "OffsetEndMs": 1440}, {"Word": "a", "OffsetStartMs": 1440, "OffsetEndMs": 1530}, {"Word": "couple", "OffsetStartMs": 1530, "OffsetEndMs": 1680}, {"Word": "of", "OffsetStartMs": 1680, "OffsetEndMs": 1845}, {"Word": "people", "OffsetStartMs": 1845, "OffsetEndMs": 2120}, {"Word": "face", "OffsetStartMs": 2680, "OffsetEndMs": 3030}, {"Word": "b", "OffsetStartMs": 3030, "OffsetEndMs": 3380}], "SpeechSpeed": 8.1}, {"FinalSentence": "Many more people.", "SliceSentence": "Many more people", "StartMs": 75120, "EndMs": 77060, "WordsNum": 3, "Words": [{"Word": "Many", "OffsetStartMs": 220, "OffsetEndMs": 525}, {"Word": "more", "OffsetStartMs": 525, "OffsetEndMs": 750}, {"Word": "people", "OffsetStartMs": 750, "OffsetEndMs": 1070}], "SpeechSpeed": 8.2}, {"FinalSentence": "Face c.", "SliceSentence": "Face c", "StartMs": 77220, "EndMs": 78860, "WordsNum": 2, "Words": [{"Word": "Face", "OffsetStartMs": 100, "OffsetEndMs": 450}, {"Word": "c", "OffsetStartMs": 450, "OffsetEndMs": 800}], "SpeechSpeed": 3.7}, {"FinalSentence": "Second place? Well, the truth is that all of you are wrong. All three of these faces are fake.", "SliceSentence": "Second place Well the truth is that all of you are wrong . Allthree of these faces are fake", "StartMs": 80360, "EndMs": 89600, "WordsNum": 19, "Words": [{"Word": "Second", "OffsetStartMs": 700, "OffsetEndMs": 1065}, {"Word": "place", "OffsetStartMs": 1065, "OffsetEndMs": 1430}, {"Word": "Well", "OffsetStartMs": 2260, "OffsetEndMs": 2565}, {"Word": "the", "OffsetStartMs": 2565, "OffsetEndMs": 2775}, {"Word": "truth", "OffsetStartMs": 2775, "OffsetEndMs": 2985}, {"Word": "is", "OffsetStartMs": 2985, "OffsetEndMs": 3270}, {"Word": "that", "OffsetStartMs": 3270, "OffsetEndMs": 3650}, {"Word": "all", "OffsetStartMs": 3850, "OffsetEndMs": 4125}, {"Word": "of", "OffsetStartMs": 4125, "OffsetEndMs": 4275}, {"Word": "you", "OffsetStartMs": 4275, "OffsetEndMs": 4545}, {"Word": "are", "OffsetStartMs": 4545, "OffsetEndMs": 4860}, {"Word": "wrong", "OffsetStartMs": 4860, "OffsetEndMs": 5180}, {"Word": ".", "OffsetStartMs": 6310, "OffsetEndMs": 6660}, {"Word": "Allthree", "OffsetStartMs": 6660, "OffsetEndMs": 6870}, {"Word": "of", "OffsetStartMs": 6870, "OffsetEndMs": 6990}, {"Word": "these", "OffsetStartMs": 6990, "OffsetEndMs": 7170}, {"Word": "faces", "OffsetStartMs": 7170, "OffsetEndMs": 7490}, {"Word": "are", "OffsetStartMs": 7720, "OffsetEndMs": 8055}, {"Word": "fake", "OffsetStartMs": 8055, "OffsetEndMs": 8390}], "SpeechSpeed": 9.7}, {"FinalSentence": "These people do not exist. These images were synthesized by deep generative models, trained on data of human faces and asked to produce new instances.", "SliceSentence": "These people do not exist . Theseimages were synthesized by deep generative models trained on data of human faces and asked to produce new instances", "StartMs": 89600, "EndMs": 101240, "WordsNum": 25, "Words": [{"Word": "These", "OffsetStartMs": 220, "OffsetEndMs": 600}, {"Word": "people", "OffsetStartMs": 600, "OffsetEndMs": 960}, {"Word": "do", "OffsetStartMs": 960, "OffsetEndMs": 1230}, {"Word": "not", "OffsetStartMs": 1230, "OffsetEndMs": 1515}, {"Word": "exist", "OffsetStartMs": 1515, "OffsetEndMs": 1910}, {"Word": ".", "OffsetStartMs": 2230, "OffsetEndMs": 2550}, {"Word": "Theseimages", "OffsetStartMs": 2550, "OffsetEndMs": 2870}, {"Word": "were", "OffsetStartMs": 2980, "OffsetEndMs": 3300}, {"Word": "synthesized", "OffsetStartMs": 3300, "OffsetEndMs": 4010}, {"Word": "by", "OffsetStartMs": 4030, "OffsetEndMs": 4365}, {"Word": "deep", "OffsetStartMs": 4365, "OffsetEndMs": 4620}, {"Word": "generative", "OffsetStartMs": 4620, "OffsetEndMs": 5070}, {"Word": "models", "OffsetStartMs": 5070, "OffsetEndMs": 5360}, {"Word": "trained", "OffsetStartMs": 5890, "OffsetEndMs": 6290}, {"Word": "on", "OffsetStartMs": 6400, "OffsetEndMs": 6720}, {"Word": "data", "OffsetStartMs": 6720, "OffsetEndMs": 7020}, {"Word": "of", "OffsetStartMs": 7020, "OffsetEndMs": 7290}, {"Word": "human", "OffsetStartMs": 7290, "OffsetEndMs": 7545}, {"Word": "faces", "OffsetStartMs": 7545, "OffsetEndMs": 7910}, {"Word": "and", "OffsetStartMs": 8200, "OffsetEndMs": 8505}, {"Word": "asked", "OffsetStartMs": 8505, "OffsetEndMs": 8810}, {"Word": "to", "OffsetStartMs": 9040, "OffsetEndMs": 9390}, {"Word": "produce", "OffsetStartMs": 9390, "OffsetEndMs": 9740}, {"Word": "new", "OffsetStartMs": 9970, "OffsetEndMs": 10290}, {"Word": "instances", "OffsetStartMs": 10290, "OffsetEndMs": 11060}], "SpeechSpeed": 12.6}, {"FinalSentence": "Now, I think that this demonstration kind of demonstrates the power of these ideas and the power of this notion of generative modeling. So let's get a little more concrete about how we can formalize this.", "SliceSentence": "Now I think that this demonstration kind of demonstrates the power of these ideas and the power of this notion of generative modeling . Solet's get a little more concrete about how we can formalize this", "StartMs": 101520, "EndMs": 114340, "WordsNum": 36, "Words": [{"Word": "Now", "OffsetStartMs": 130, "OffsetEndMs": 435}, {"Word": "I", "OffsetStartMs": 435, "OffsetEndMs": 645}, {"Word": "think", "OffsetStartMs": 645, "OffsetEndMs": 855}, {"Word": "that", "OffsetStartMs": 855, "OffsetEndMs": 1050}, {"Word": "this", "OffsetStartMs": 1050, "OffsetEndMs": 1335}, {"Word": "demonstration", "OffsetStartMs": 1335, "OffsetEndMs": 2055}, {"Word": "kind", "OffsetStartMs": 2055, "OffsetEndMs": 2310}, {"Word": "of", "OffsetStartMs": 2310, "OffsetEndMs": 2445}, {"Word": "demonstrates", "OffsetStartMs": 2445, "OffsetEndMs": 3110}, {"Word": "the", "OffsetStartMs": 3400, "OffsetEndMs": 3720}, {"Word": "power", "OffsetStartMs": 3720, "OffsetEndMs": 4040}, {"Word": "of", "OffsetStartMs": 4090, "OffsetEndMs": 4380}, {"Word": "these", "OffsetStartMs": 4380, "OffsetEndMs": 4665}, {"Word": "ideas", "OffsetStartMs": 4665, "OffsetEndMs": 5060}, {"Word": "and", "OffsetStartMs": 5380, "OffsetEndMs": 5640}, {"Word": "the", "OffsetStartMs": 5640, "OffsetEndMs": 5790}, {"Word": "power", "OffsetStartMs": 5790, "OffsetEndMs": 5985}, {"Word": "of", "OffsetStartMs": 5985, "OffsetEndMs": 6150}, {"Word": "this", "OffsetStartMs": 6150, "OffsetEndMs": 6315}, {"Word": "notion", "OffsetStartMs": 6315, "OffsetEndMs": 6585}, {"Word": "of", "OffsetStartMs": 6585, "OffsetEndMs": 6825}, {"Word": "generative", "OffsetStartMs": 6825, "OffsetEndMs": 7245}, {"Word": "modeling", "OffsetStartMs": 7245, "OffsetEndMs": 7790}, {"Word": ".", "OffsetStartMs": 8320, "OffsetEndMs": 8700}, {"Word": "Solet's", "OffsetStartMs": 8700, "OffsetEndMs": 9060}, {"Word": "get", "OffsetStartMs": 9060, "OffsetEndMs": 9210}, {"Word": "a", "OffsetStartMs": 9210, "OffsetEndMs": 9360}, {"Word": "little", "OffsetStartMs": 9360, "OffsetEndMs": 9525}, {"Word": "more", "OffsetStartMs": 9525, "OffsetEndMs": 9830}, {"Word": "concrete", "OffsetStartMs": 10120, "OffsetEndMs": 10485}, {"Word": "about", "OffsetStartMs": 10485, "OffsetEndMs": 10800}, {"Word": "how", "OffsetStartMs": 10800, "OffsetEndMs": 11055}, {"Word": "we", "OffsetStartMs": 11055, "OffsetEndMs": 11220}, {"Word": "can", "OffsetStartMs": 11220, "OffsetEndMs": 11385}, {"Word": "formalize", "OffsetStartMs": 11385, "OffsetEndMs": 11850}, {"Word": "this", "OffsetStartMs": 11850, "OffsetEndMs": 12200}], "SpeechSpeed": 15.7}, {"FinalSentence": "So far in this course, we've been looking at what we call problems of supervised learning, meaning that we're given data and associated with that data is a set of labels. Our goal is to learn a function that maps that data.", "SliceSentence": "So far in this course we've been looking at what we call problems of supervised learning meaning that we're given data and associated with that data is a set of labels . Ourgoal is to learn a function that maps that data", "StartMs": 114500, "EndMs": 130080, "WordsNum": 42, "Words": [{"Word": "So", "OffsetStartMs": 190, "OffsetEndMs": 480}, {"Word": "far", "OffsetStartMs": 480, "OffsetEndMs": 645}, {"Word": "in", "OffsetStartMs": 645, "OffsetEndMs": 780}, {"Word": "this", "OffsetStartMs": 780, "OffsetEndMs": 960}, {"Word": "course", "OffsetStartMs": 960, "OffsetEndMs": 1280}, {"Word": "we've", "OffsetStartMs": 1450, "OffsetEndMs": 1785}, {"Word": "been", "OffsetStartMs": 1785, "OffsetEndMs": 1935}, {"Word": "looking", "OffsetStartMs": 1935, "OffsetEndMs": 2205}, {"Word": "at", "OffsetStartMs": 2205, "OffsetEndMs": 2475}, {"Word": "what", "OffsetStartMs": 2475, "OffsetEndMs": 2670}, {"Word": "we", "OffsetStartMs": 2670, "OffsetEndMs": 2865}, {"Word": "call", "OffsetStartMs": 2865, "OffsetEndMs": 3135}, {"Word": "problems", "OffsetStartMs": 3135, "OffsetEndMs": 3500}, {"Word": "of", "OffsetStartMs": 3610, "OffsetEndMs": 4010}, {"Word": "supervised", "OffsetStartMs": 4300, "OffsetEndMs": 4730}, {"Word": "learning", "OffsetStartMs": 4750, "OffsetEndMs": 5150}, {"Word": "meaning", "OffsetStartMs": 5890, "OffsetEndMs": 6255}, {"Word": "that", "OffsetStartMs": 6255, "OffsetEndMs": 6510}, {"Word": "we're", "OffsetStartMs": 6510, "OffsetEndMs": 6750}, {"Word": "given", "OffsetStartMs": 6750, "OffsetEndMs": 6945}, {"Word": "data", "OffsetStartMs": 6945, "OffsetEndMs": 7280}, {"Word": "and", "OffsetStartMs": 7870, "OffsetEndMs": 8250}, {"Word": "associated", "OffsetStartMs": 8250, "OffsetEndMs": 8630}, {"Word": "with", "OffsetStartMs": 8770, "OffsetEndMs": 9060}, {"Word": "that", "OffsetStartMs": 9060, "OffsetEndMs": 9255}, {"Word": "data", "OffsetStartMs": 9255, "OffsetEndMs": 9525}, {"Word": "is", "OffsetStartMs": 9525, "OffsetEndMs": 9750}, {"Word": "a", "OffsetStartMs": 9750, "OffsetEndMs": 9885}, {"Word": "set", "OffsetStartMs": 9885, "OffsetEndMs": 10020}, {"Word": "of", "OffsetStartMs": 10020, "OffsetEndMs": 10155}, {"Word": "labels", "OffsetStartMs": 10155, "OffsetEndMs": 10640}, {"Word": ".", "OffsetStartMs": 11440, "OffsetEndMs": 11775}, {"Word": "Ourgoal", "OffsetStartMs": 11775, "OffsetEndMs": 12075}, {"Word": "is", "OffsetStartMs": 12075, "OffsetEndMs": 12345}, {"Word": "to", "OffsetStartMs": 12345, "OffsetEndMs": 12525}, {"Word": "learn", "OffsetStartMs": 12525, "OffsetEndMs": 12765}, {"Word": "a", "OffsetStartMs": 12765, "OffsetEndMs": 13035}, {"Word": "function", "OffsetStartMs": 13035, "OffsetEndMs": 13340}, {"Word": "that", "OffsetStartMs": 13630, "OffsetEndMs": 13965}, {"Word": "maps", "OffsetStartMs": 13965, "OffsetEndMs": 14280}, {"Word": "that", "OffsetStartMs": 14280, "OffsetEndMs": 14565}, {"Word": "data", "OffsetStartMs": 14565, "OffsetEndMs": 14870}], "SpeechSpeed": 14.1}, {"FinalSentence": "To the labels. Now, we're in a course on deep learning, so we've been concerned with functional mappings that are defined by deep neural networks. But really, that function could be anything. Neural networks are powerful, but we could use other techniques as well.", "SliceSentence": "To the labels . Nowwe're in a course on deep learning so we've been concerned with functional mappings that are defined by deep neural networks . Butreally that function could be anything . Neuralnetworks are powerful but we could use other techniques as well", "StartMs": 130080, "EndMs": 145600, "WordsNum": 44, "Words": [{"Word": "To", "OffsetStartMs": 0, "OffsetEndMs": 380}, {"Word": "the", "OffsetStartMs": 400, "OffsetEndMs": 645}, {"Word": "labels", "OffsetStartMs": 645, "OffsetEndMs": 1100}, {"Word": ".", "OffsetStartMs": 1690, "OffsetEndMs": 2090}, {"Word": "Nowwe're", "OffsetStartMs": 2290, "OffsetEndMs": 2610}, {"Word": "in", "OffsetStartMs": 2610, "OffsetEndMs": 2670}, {"Word": "a", "OffsetStartMs": 2670, "OffsetEndMs": 2790}, {"Word": "course", "OffsetStartMs": 2790, "OffsetEndMs": 3080}, {"Word": "on", "OffsetStartMs": 3130, "OffsetEndMs": 3465}, {"Word": "deep", "OffsetStartMs": 3465, "OffsetEndMs": 3690}, {"Word": "learning", "OffsetStartMs": 3690, "OffsetEndMs": 3980}, {"Word": "so", "OffsetStartMs": 4060, "OffsetEndMs": 4380}, {"Word": "we've", "OffsetStartMs": 4380, "OffsetEndMs": 4635}, {"Word": "been", "OffsetStartMs": 4635, "OffsetEndMs": 4875}, {"Word": "concerned", "OffsetStartMs": 4875, "OffsetEndMs": 5250}, {"Word": "with", "OffsetStartMs": 5250, "OffsetEndMs": 5595}, {"Word": "functional", "OffsetStartMs": 5595, "OffsetEndMs": 6195}, {"Word": "mappings", "OffsetStartMs": 6195, "OffsetEndMs": 6615}, {"Word": "that", "OffsetStartMs": 6615, "OffsetEndMs": 6780}, {"Word": "are", "OffsetStartMs": 6780, "OffsetEndMs": 7005}, {"Word": "defined", "OffsetStartMs": 7005, "OffsetEndMs": 7335}, {"Word": "by", "OffsetStartMs": 7335, "OffsetEndMs": 7650}, {"Word": "deep", "OffsetStartMs": 7650, "OffsetEndMs": 7905}, {"Word": "neural", "OffsetStartMs": 7905, "OffsetEndMs": 8160}, {"Word": "networks", "OffsetStartMs": 8160, "OffsetEndMs": 8420}, {"Word": ".", "OffsetStartMs": 9100, "OffsetEndMs": 9375}, {"Word": "Butreally", "OffsetStartMs": 9375, "OffsetEndMs": 9630}, {"Word": "that", "OffsetStartMs": 9630, "OffsetEndMs": 9930}, {"Word": "function", "OffsetStartMs": 9930, "OffsetEndMs": 10250}, {"Word": "could", "OffsetStartMs": 10270, "OffsetEndMs": 10530}, {"Word": "be", "OffsetStartMs": 10530, "OffsetEndMs": 10770}, {"Word": "anything", "OffsetStartMs": 10770, "OffsetEndMs": 11150}, {"Word": ".", "OffsetStartMs": 11200, "OffsetEndMs": 11565}, {"Word": "Neuralnetworks", "OffsetStartMs": 11565, "OffsetEndMs": 11805}, {"Word": "are", "OffsetStartMs": 11805, "OffsetEndMs": 12060}, {"Word": "powerful", "OffsetStartMs": 12060, "OffsetEndMs": 12350}, {"Word": "but", "OffsetStartMs": 12430, "OffsetEndMs": 12830}, {"Word": "we", "OffsetStartMs": 13090, "OffsetEndMs": 13365}, {"Word": "could", "OffsetStartMs": 13365, "OffsetEndMs": 13500}, {"Word": "use", "OffsetStartMs": 13500, "OffsetEndMs": 13665}, {"Word": "other", "OffsetStartMs": 13665, "OffsetEndMs": 13920}, {"Word": "techniques", "OffsetStartMs": 13920, "OffsetEndMs": 14270}, {"Word": "as", "OffsetStartMs": 14350, "OffsetEndMs": 14655}, {"Word": "well", "OffsetStartMs": 14655, "OffsetEndMs": 14960}], "SpeechSpeed": 16.5}, {"FinalSentence": "In contrast, there's another class of problems in machine learning that we refer to as unsupervised learning, where we take data, but now we're given only data, no labels, and our goal is to try to build some method that can understand the hidden underlying structure of that data.", "SliceSentence": "In contrast there's another class of problems in machine learning that we refer to as unsupervised learning where we take data but now we're given only data no labels and our goal is to try to build some method that can understand the hidden underlying structure of that data", "StartMs": 146520, "EndMs": 168100, "WordsNum": 49, "Words": [{"Word": "In", "OffsetStartMs": 100, "OffsetEndMs": 435}, {"Word": "contrast", "OffsetStartMs": 435, "OffsetEndMs": 770}, {"Word": "there's", "OffsetStartMs": 1000, "OffsetEndMs": 1395}, {"Word": "another", "OffsetStartMs": 1395, "OffsetEndMs": 1695}, {"Word": "class", "OffsetStartMs": 1695, "OffsetEndMs": 2010}, {"Word": "of", "OffsetStartMs": 2010, "OffsetEndMs": 2235}, {"Word": "problems", "OffsetStartMs": 2235, "OffsetEndMs": 2540}, {"Word": "in", "OffsetStartMs": 2680, "OffsetEndMs": 3030}, {"Word": "machine", "OffsetStartMs": 3030, "OffsetEndMs": 3285}, {"Word": "learning", "OffsetStartMs": 3285, "OffsetEndMs": 3590}, {"Word": "that", "OffsetStartMs": 4060, "OffsetEndMs": 4365}, {"Word": "we", "OffsetStartMs": 4365, "OffsetEndMs": 4530}, {"Word": "refer", "OffsetStartMs": 4530, "OffsetEndMs": 4790}, {"Word": "to", "OffsetStartMs": 4810, "OffsetEndMs": 5100}, {"Word": "as", "OffsetStartMs": 5100, "OffsetEndMs": 5355}, {"Word": "unsupervised", "OffsetStartMs": 5355, "OffsetEndMs": 6225}, {"Word": "learning", "OffsetStartMs": 6225, "OffsetEndMs": 6560}, {"Word": "where", "OffsetStartMs": 7180, "OffsetEndMs": 7580}, {"Word": "we", "OffsetStartMs": 8020, "OffsetEndMs": 8340}, {"Word": "take", "OffsetStartMs": 8340, "OffsetEndMs": 8660}, {"Word": "data", "OffsetStartMs": 8770, "OffsetEndMs": 9170}, {"Word": "but", "OffsetStartMs": 9610, "OffsetEndMs": 9915}, {"Word": "now", "OffsetStartMs": 9915, "OffsetEndMs": 10220}, {"Word": "we're", "OffsetStartMs": 10510, "OffsetEndMs": 10845}, {"Word": "given", "OffsetStartMs": 10845, "OffsetEndMs": 11055}, {"Word": "only", "OffsetStartMs": 11055, "OffsetEndMs": 11400}, {"Word": "data", "OffsetStartMs": 11400, "OffsetEndMs": 11780}, {"Word": "no", "OffsetStartMs": 12310, "OffsetEndMs": 12615}, {"Word": "labels", "OffsetStartMs": 12615, "OffsetEndMs": 13100}, {"Word": "and", "OffsetStartMs": 13540, "OffsetEndMs": 13830}, {"Word": "our", "OffsetStartMs": 13830, "OffsetEndMs": 14070}, {"Word": "goal", "OffsetStartMs": 14070, "OffsetEndMs": 14385}, {"Word": "is", "OffsetStartMs": 14385, "OffsetEndMs": 14670}, {"Word": "to", "OffsetStartMs": 14670, "OffsetEndMs": 14895}, {"Word": "try", "OffsetStartMs": 14895, "OffsetEndMs": 15200}, {"Word": "to", "OffsetStartMs": 15220, "OffsetEndMs": 15585}, {"Word": "build", "OffsetStartMs": 15585, "OffsetEndMs": 15915}, {"Word": "some", "OffsetStartMs": 15915, "OffsetEndMs": 16170}, {"Word": "method", "OffsetStartMs": 16170, "OffsetEndMs": 16460}, {"Word": "that", "OffsetStartMs": 16870, "OffsetEndMs": 17145}, {"Word": "can", "OffsetStartMs": 17145, "OffsetEndMs": 17420}, {"Word": "understand", "OffsetStartMs": 17650, "OffsetEndMs": 18050}, {"Word": "the", "OffsetStartMs": 18070, "OffsetEndMs": 18405}, {"Word": "hidden", "OffsetStartMs": 18405, "OffsetEndMs": 18740}, {"Word": "underlying", "OffsetStartMs": 19000, "OffsetEndMs": 19400}, {"Word": "structure", "OffsetStartMs": 19780, "OffsetEndMs": 20160}, {"Word": "of", "OffsetStartMs": 20160, "OffsetEndMs": 20415}, {"Word": "that", "OffsetStartMs": 20415, "OffsetEndMs": 20595}, {"Word": "data", "OffsetStartMs": 20595, "OffsetEndMs": 20900}], "SpeechSpeed": 12.7}, {"FinalSentence": "What this allows us to do is it gives us new insights into the foundational representation of the data and as we'll see later, actually enables us to generate new data instances.", "SliceSentence": "What this allows us to do is it gives us new insights into the foundational representation of the data and as we'll see later actually enables us to generate new data instances", "StartMs": 168460, "EndMs": 181540, "WordsNum": 32, "Words": [{"Word": "What", "OffsetStartMs": 130, "OffsetEndMs": 435}, {"Word": "this", "OffsetStartMs": 435, "OffsetEndMs": 675}, {"Word": "allows", "OffsetStartMs": 675, "OffsetEndMs": 930}, {"Word": "us", "OffsetStartMs": 930, "OffsetEndMs": 1155}, {"Word": "to", "OffsetStartMs": 1155, "OffsetEndMs": 1320}, {"Word": "do", "OffsetStartMs": 1320, "OffsetEndMs": 1545}, {"Word": "is", "OffsetStartMs": 1545, "OffsetEndMs": 1785}, {"Word": "it", "OffsetStartMs": 1785, "OffsetEndMs": 1950}, {"Word": "gives", "OffsetStartMs": 1950, "OffsetEndMs": 2175}, {"Word": "us", "OffsetStartMs": 2175, "OffsetEndMs": 2460}, {"Word": "new", "OffsetStartMs": 2460, "OffsetEndMs": 2810}, {"Word": "insights", "OffsetStartMs": 2950, "OffsetEndMs": 3405}, {"Word": "into", "OffsetStartMs": 3405, "OffsetEndMs": 3710}, {"Word": "the", "OffsetStartMs": 3790, "OffsetEndMs": 4065}, {"Word": "foundational", "OffsetStartMs": 4065, "OffsetEndMs": 4580}, {"Word": "representation", "OffsetStartMs": 4600, "OffsetEndMs": 5540}, {"Word": "of", "OffsetStartMs": 5950, "OffsetEndMs": 6255}, {"Word": "the", "OffsetStartMs": 6255, "OffsetEndMs": 6420}, {"Word": "data", "OffsetStartMs": 6420, "OffsetEndMs": 6680}, {"Word": "and", "OffsetStartMs": 7240, "OffsetEndMs": 7605}, {"Word": "as", "OffsetStartMs": 7605, "OffsetEndMs": 7875}, {"Word": "we'll", "OffsetStartMs": 7875, "OffsetEndMs": 8130}, {"Word": "see", "OffsetStartMs": 8130, "OffsetEndMs": 8295}, {"Word": "later", "OffsetStartMs": 8295, "OffsetEndMs": 8600}, {"Word": "actually", "OffsetStartMs": 9550, "OffsetEndMs": 9825}, {"Word": "enables", "OffsetStartMs": 9825, "OffsetEndMs": 10215}, {"Word": "us", "OffsetStartMs": 10215, "OffsetEndMs": 10485}, {"Word": "to", "OffsetStartMs": 10485, "OffsetEndMs": 10680}, {"Word": "generate", "OffsetStartMs": 10680, "OffsetEndMs": 10970}, {"Word": "new", "OffsetStartMs": 11110, "OffsetEndMs": 11445}, {"Word": "data", "OffsetStartMs": 11445, "OffsetEndMs": 11730}, {"Word": "instances", "OffsetStartMs": 11730, "OffsetEndMs": 12500}], "SpeechSpeed": 13.5}, {"FinalSentence": "Now, this class of problems, this definition of unsupervised learning, captures the types of models that we're going to talk about today in the focus on generative modeling.", "SliceSentence": "Now this class of problems this definition of unsupervised learning captures the types of models that we're going to talk about today in the focus on generative modeling", "StartMs": 181540, "EndMs": 193040, "WordsNum": 28, "Words": [{"Word": "Now", "OffsetStartMs": 250, "OffsetEndMs": 540}, {"Word": "this", "OffsetStartMs": 540, "OffsetEndMs": 780}, {"Word": "class", "OffsetStartMs": 780, "OffsetEndMs": 1035}, {"Word": "of", "OffsetStartMs": 1035, "OffsetEndMs": 1245}, {"Word": "problems", "OffsetStartMs": 1245, "OffsetEndMs": 1550}, {"Word": "this", "OffsetStartMs": 1990, "OffsetEndMs": 2390}, {"Word": "definition", "OffsetStartMs": 2620, "OffsetEndMs": 3020}, {"Word": "of", "OffsetStartMs": 3280, "OffsetEndMs": 3570}, {"Word": "unsupervised", "OffsetStartMs": 3570, "OffsetEndMs": 4335}, {"Word": "learning", "OffsetStartMs": 4335, "OffsetEndMs": 4670}, {"Word": "captures", "OffsetStartMs": 5170, "OffsetEndMs": 5880}, {"Word": "the", "OffsetStartMs": 5880, "OffsetEndMs": 6225}, {"Word": "types", "OffsetStartMs": 6225, "OffsetEndMs": 6495}, {"Word": "of", "OffsetStartMs": 6495, "OffsetEndMs": 6675}, {"Word": "models", "OffsetStartMs": 6675, "OffsetEndMs": 6945}, {"Word": "that", "OffsetStartMs": 6945, "OffsetEndMs": 7215}, {"Word": "we're", "OffsetStartMs": 7215, "OffsetEndMs": 7410}, {"Word": "going", "OffsetStartMs": 7410, "OffsetEndMs": 7530}, {"Word": "to", "OffsetStartMs": 7530, "OffsetEndMs": 7695}, {"Word": "talk", "OffsetStartMs": 7695, "OffsetEndMs": 7875}, {"Word": "about", "OffsetStartMs": 7875, "OffsetEndMs": 8100}, {"Word": "today", "OffsetStartMs": 8100, "OffsetEndMs": 8420}, {"Word": "in", "OffsetStartMs": 8710, "OffsetEndMs": 8985}, {"Word": "the", "OffsetStartMs": 8985, "OffsetEndMs": 9120}, {"Word": "focus", "OffsetStartMs": 9120, "OffsetEndMs": 9380}, {"Word": "on", "OffsetStartMs": 9430, "OffsetEndMs": 9830}, {"Word": "generative", "OffsetStartMs": 9970, "OffsetEndMs": 10530}, {"Word": "modeling", "OffsetStartMs": 10530, "OffsetEndMs": 11030}], "SpeechSpeed": 14.7}, {"FinalSentence": "Which is an example of unsupervised learning and is united by this goal of the problem where we're given only samples from a training set.", "SliceSentence": "Which is an example of unsupervised learning and is united by this goal of the problem where we're given only samples from a training set", "StartMs": 193600, "EndMs": 203120, "WordsNum": 25, "Words": [{"Word": "Which", "OffsetStartMs": 100, "OffsetEndMs": 375}, {"Word": "is", "OffsetStartMs": 375, "OffsetEndMs": 510}, {"Word": "an", "OffsetStartMs": 510, "OffsetEndMs": 735}, {"Word": "example", "OffsetStartMs": 735, "OffsetEndMs": 1095}, {"Word": "of", "OffsetStartMs": 1095, "OffsetEndMs": 1350}, {"Word": "unsupervised", "OffsetStartMs": 1350, "OffsetEndMs": 2040}, {"Word": "learning", "OffsetStartMs": 2040, "OffsetEndMs": 2360}, {"Word": "and", "OffsetStartMs": 2620, "OffsetEndMs": 2970}, {"Word": "is", "OffsetStartMs": 2970, "OffsetEndMs": 3315}, {"Word": "united", "OffsetStartMs": 3315, "OffsetEndMs": 3690}, {"Word": "by", "OffsetStartMs": 3690, "OffsetEndMs": 3960}, {"Word": "this", "OffsetStartMs": 3960, "OffsetEndMs": 4185}, {"Word": "goal", "OffsetStartMs": 4185, "OffsetEndMs": 4520}, {"Word": "of", "OffsetStartMs": 5200, "OffsetEndMs": 5535}, {"Word": "the", "OffsetStartMs": 5535, "OffsetEndMs": 5760}, {"Word": "problem", "OffsetStartMs": 5760, "OffsetEndMs": 6050}, {"Word": "where", "OffsetStartMs": 6070, "OffsetEndMs": 6390}, {"Word": "we're", "OffsetStartMs": 6390, "OffsetEndMs": 6645}, {"Word": "given", "OffsetStartMs": 6645, "OffsetEndMs": 6885}, {"Word": "only", "OffsetStartMs": 6885, "OffsetEndMs": 7280}, {"Word": "samples", "OffsetStartMs": 7300, "OffsetEndMs": 7905}, {"Word": "from", "OffsetStartMs": 7905, "OffsetEndMs": 8130}, {"Word": "a", "OffsetStartMs": 8130, "OffsetEndMs": 8280}, {"Word": "training", "OffsetStartMs": 8280, "OffsetEndMs": 8550}, {"Word": "set", "OffsetStartMs": 8550, "OffsetEndMs": 8930}], "SpeechSpeed": 14.4}, {"FinalSentence": "And we want to learn a model that represents the distribution of the data that the model is seeing.", "SliceSentence": "And we want to learn a model that represents the distribution of the data that the model is seeing", "StartMs": 203120, "EndMs": 209900, "WordsNum": 19, "Words": [{"Word": "And", "OffsetStartMs": 0, "OffsetEndMs": 300}, {"Word": "we", "OffsetStartMs": 300, "OffsetEndMs": 495}, {"Word": "want", "OffsetStartMs": 495, "OffsetEndMs": 690}, {"Word": "to", "OffsetStartMs": 690, "OffsetEndMs": 900}, {"Word": "learn", "OffsetStartMs": 900, "OffsetEndMs": 1140}, {"Word": "a", "OffsetStartMs": 1140, "OffsetEndMs": 1395}, {"Word": "model", "OffsetStartMs": 1395, "OffsetEndMs": 1700}, {"Word": "that", "OffsetStartMs": 1780, "OffsetEndMs": 2085}, {"Word": "represents", "OffsetStartMs": 2085, "OffsetEndMs": 2390}, {"Word": "the", "OffsetStartMs": 2800, "OffsetEndMs": 3195}, {"Word": "distribution", "OffsetStartMs": 3195, "OffsetEndMs": 3590}, {"Word": "of", "OffsetStartMs": 4030, "OffsetEndMs": 4335}, {"Word": "the", "OffsetStartMs": 4335, "OffsetEndMs": 4515}, {"Word": "data", "OffsetStartMs": 4515, "OffsetEndMs": 4740}, {"Word": "that", "OffsetStartMs": 4740, "OffsetEndMs": 5055}, {"Word": "the", "OffsetStartMs": 5055, "OffsetEndMs": 5280}, {"Word": "model", "OffsetStartMs": 5280, "OffsetEndMs": 5490}, {"Word": "is", "OffsetStartMs": 5490, "OffsetEndMs": 5745}, {"Word": "seeing", "OffsetStartMs": 5745, "OffsetEndMs": 6050}], "SpeechSpeed": 14.5}, {"FinalSentence": "Generative modeling takes two general forms, first density estimation and second sample generation.", "SliceSentence": "Generative modeling takes two general forms first density estimation and second sample generation", "StartMs": 210140, "EndMs": 219520, "WordsNum": 13, "Words": [{"Word": "Generative", "OffsetStartMs": 130, "OffsetEndMs": 675}, {"Word": "modeling", "OffsetStartMs": 675, "OffsetEndMs": 1190}, {"Word": "takes", "OffsetStartMs": 1360, "OffsetEndMs": 1760}, {"Word": "two", "OffsetStartMs": 2350, "OffsetEndMs": 2750}, {"Word": "general", "OffsetStartMs": 2770, "OffsetEndMs": 3165}, {"Word": "forms", "OffsetStartMs": 3165, "OffsetEndMs": 3560}, {"Word": "first", "OffsetStartMs": 4510, "OffsetEndMs": 4910}, {"Word": "density", "OffsetStartMs": 5140, "OffsetEndMs": 5850}, {"Word": "estimation", "OffsetStartMs": 5850, "OffsetEndMs": 6290}, {"Word": "and", "OffsetStartMs": 6610, "OffsetEndMs": 6975}, {"Word": "second", "OffsetStartMs": 6975, "OffsetEndMs": 7340}, {"Word": "sample", "OffsetStartMs": 7510, "OffsetEndMs": 7905}, {"Word": "generation", "OffsetStartMs": 7905, "OffsetEndMs": 8300}], "SpeechSpeed": 10.3}, {"FinalSentence": "In density estimation, the task is given some data examples. Our goal is to train a model that learns an underlying probability distribution that describes where the data came from.", "SliceSentence": "In density estimation the task is given some data examples . Ourgoal is to train a model that learns an underlying probability distribution that describes where the data came from", "StartMs": 219600, "EndMs": 236240, "WordsNum": 30, "Words": [{"Word": "In", "OffsetStartMs": 160, "OffsetEndMs": 450}, {"Word": "density", "OffsetStartMs": 450, "OffsetEndMs": 1050}, {"Word": "estimation", "OffsetStartMs": 1050, "OffsetEndMs": 1490}, {"Word": "the", "OffsetStartMs": 1510, "OffsetEndMs": 1815}, {"Word": "task", "OffsetStartMs": 1815, "OffsetEndMs": 2120}, {"Word": "is", "OffsetStartMs": 2140, "OffsetEndMs": 2540}, {"Word": "given", "OffsetStartMs": 3220, "OffsetEndMs": 3615}, {"Word": "some", "OffsetStartMs": 3615, "OffsetEndMs": 4010}, {"Word": "data", "OffsetStartMs": 4210, "OffsetEndMs": 4610}, {"Word": "examples", "OffsetStartMs": 4630, "OffsetEndMs": 5030}, {"Word": ".", "OffsetStartMs": 5890, "OffsetEndMs": 6225}, {"Word": "Ourgoal", "OffsetStartMs": 6225, "OffsetEndMs": 6560}, {"Word": "is", "OffsetStartMs": 6580, "OffsetEndMs": 6945}, {"Word": "to", "OffsetStartMs": 6945, "OffsetEndMs": 7260}, {"Word": "train", "OffsetStartMs": 7260, "OffsetEndMs": 7515}, {"Word": "a", "OffsetStartMs": 7515, "OffsetEndMs": 7695}, {"Word": "model", "OffsetStartMs": 7695, "OffsetEndMs": 7970}, {"Word": "that", "OffsetStartMs": 8440, "OffsetEndMs": 8805}, {"Word": "learns", "OffsetStartMs": 8805, "OffsetEndMs": 9315}, {"Word": "an", "OffsetStartMs": 9315, "OffsetEndMs": 9570}, {"Word": "underlying", "OffsetStartMs": 9570, "OffsetEndMs": 9920}, {"Word": "probability", "OffsetStartMs": 10540, "OffsetEndMs": 11240}, {"Word": "distribution", "OffsetStartMs": 11470, "OffsetEndMs": 11870}, {"Word": "that", "OffsetStartMs": 12580, "OffsetEndMs": 12980}, {"Word": "describes", "OffsetStartMs": 13060, "OffsetEndMs": 13790}, {"Word": "where", "OffsetStartMs": 14440, "OffsetEndMs": 14775}, {"Word": "the", "OffsetStartMs": 14775, "OffsetEndMs": 14985}, {"Word": "data", "OffsetStartMs": 14985, "OffsetEndMs": 15260}, {"Word": "came", "OffsetStartMs": 15430, "OffsetEndMs": 15765}, {"Word": "from", "OffsetStartMs": 15765, "OffsetEndMs": 16100}], "SpeechSpeed": 10.7}, {"FinalSentence": "With sample generation, the idea is similar, but the focus is more on actually generating new instances. Our goal with sample generation is to, again, learn this model of this underlying probability distribution, but then use that model to sample from it and generate new instances that are similar to the data that we've seen approximately falling along. Ideally that same real data distribution.", "SliceSentence": "With sample generation the idea is similar but the focus is more on actually generating new instances . Ourgoal with sample generation is to again learn this model of this underlying probability distribution but then use that model to sample from it and generate new instances that are similar to the data that we've seen approximately falling along . Ideallythat same real data distribution", "StartMs": 236980, "EndMs": 266180, "WordsNum": 64, "Words": [{"Word": "With", "OffsetStartMs": 100, "OffsetEndMs": 450}, {"Word": "sample", "OffsetStartMs": 450, "OffsetEndMs": 795}, {"Word": "generation", "OffsetStartMs": 795, "OffsetEndMs": 1190}, {"Word": "the", "OffsetStartMs": 1870, "OffsetEndMs": 2235}, {"Word": "idea", "OffsetStartMs": 2235, "OffsetEndMs": 2550}, {"Word": "is", "OffsetStartMs": 2550, "OffsetEndMs": 2900}, {"Word": "similar", "OffsetStartMs": 3070, "OffsetEndMs": 3470}, {"Word": "but", "OffsetStartMs": 3580, "OffsetEndMs": 3900}, {"Word": "the", "OffsetStartMs": 3900, "OffsetEndMs": 4095}, {"Word": "focus", "OffsetStartMs": 4095, "OffsetEndMs": 4370}, {"Word": "is", "OffsetStartMs": 4390, "OffsetEndMs": 4710}, {"Word": "more", "OffsetStartMs": 4710, "OffsetEndMs": 4995}, {"Word": "on", "OffsetStartMs": 4995, "OffsetEndMs": 5360}, {"Word": "actually", "OffsetStartMs": 5500, "OffsetEndMs": 5805}, {"Word": "generating", "OffsetStartMs": 5805, "OffsetEndMs": 6300}, {"Word": "new", "OffsetStartMs": 6300, "OffsetEndMs": 6570}, {"Word": "instances", "OffsetStartMs": 6570, "OffsetEndMs": 7310}, {"Word": ".", "OffsetStartMs": 8140, "OffsetEndMs": 8445}, {"Word": "Ourgoal", "OffsetStartMs": 8445, "OffsetEndMs": 8670}, {"Word": "with", "OffsetStartMs": 8670, "OffsetEndMs": 8910}, {"Word": "sample", "OffsetStartMs": 8910, "OffsetEndMs": 9225}, {"Word": "generation", "OffsetStartMs": 9225, "OffsetEndMs": 9620}, {"Word": "is", "OffsetStartMs": 10000, "OffsetEndMs": 10290}, {"Word": "to", "OffsetStartMs": 10290, "OffsetEndMs": 10580}, {"Word": "again", "OffsetStartMs": 10690, "OffsetEndMs": 11090}, {"Word": "learn", "OffsetStartMs": 11320, "OffsetEndMs": 11640}, {"Word": "this", "OffsetStartMs": 11640, "OffsetEndMs": 11880}, {"Word": "model", "OffsetStartMs": 11880, "OffsetEndMs": 12180}, {"Word": "of", "OffsetStartMs": 12180, "OffsetEndMs": 12435}, {"Word": "this", "OffsetStartMs": 12435, "OffsetEndMs": 12615}, {"Word": "underlying", "OffsetStartMs": 12615, "OffsetEndMs": 12920}, {"Word": "probability", "OffsetStartMs": 13270, "OffsetEndMs": 13940}, {"Word": "distribution", "OffsetStartMs": 14080, "OffsetEndMs": 14480}, {"Word": "but", "OffsetStartMs": 15370, "OffsetEndMs": 15645}, {"Word": "then", "OffsetStartMs": 15645, "OffsetEndMs": 15855}, {"Word": "use", "OffsetStartMs": 15855, "OffsetEndMs": 16125}, {"Word": "that", "OffsetStartMs": 16125, "OffsetEndMs": 16380}, {"Word": "model", "OffsetStartMs": 16380, "OffsetEndMs": 16700}, {"Word": "to", "OffsetStartMs": 16990, "OffsetEndMs": 17340}, {"Word": "sample", "OffsetStartMs": 17340, "OffsetEndMs": 17690}, {"Word": "from", "OffsetStartMs": 17740, "OffsetEndMs": 18015}, {"Word": "it", "OffsetStartMs": 18015, "OffsetEndMs": 18195}, {"Word": "and", "OffsetStartMs": 18195, "OffsetEndMs": 18420}, {"Word": "generate", "OffsetStartMs": 18420, "OffsetEndMs": 18740}, {"Word": "new", "OffsetStartMs": 18880, "OffsetEndMs": 19200}, {"Word": "instances", "OffsetStartMs": 19200, "OffsetEndMs": 20000}, {"Word": "that", "OffsetStartMs": 20350, "OffsetEndMs": 20700}, {"Word": "are", "OffsetStartMs": 20700, "OffsetEndMs": 21045}, {"Word": "similar", "OffsetStartMs": 21045, "OffsetEndMs": 21440}, {"Word": "to", "OffsetStartMs": 21760, "OffsetEndMs": 22110}, {"Word": "the", "OffsetStartMs": 22110, "OffsetEndMs": 22320}, {"Word": "data", "OffsetStartMs": 22320, "OffsetEndMs": 22530}, {"Word": "that", "OffsetStartMs": 22530, "OffsetEndMs": 22770}, {"Word": "we've", "OffsetStartMs": 22770, "OffsetEndMs": 23025}, {"Word": "seen", "OffsetStartMs": 23025, "OffsetEndMs": 23300}, {"Word": "approximately", "OffsetStartMs": 23890, "OffsetEndMs": 24290}, {"Word": "falling", "OffsetStartMs": 24550, "OffsetEndMs": 24950}, {"Word": "along", "OffsetStartMs": 25150, "OffsetEndMs": 25550}, {"Word": ".", "OffsetStartMs": 25720, "OffsetEndMs": 26385}, {"Word": "Ideallythat", "OffsetStartMs": 26385, "OffsetEndMs": 26655}, {"Word": "same", "OffsetStartMs": 26655, "OffsetEndMs": 27020}, {"Word": "real", "OffsetStartMs": 27220, "OffsetEndMs": 27620}, {"Word": "data", "OffsetStartMs": 27700, "OffsetEndMs": 28100}, {"Word": "distribution", "OffsetStartMs": 28180, "OffsetEndMs": 28580}], "SpeechSpeed": 13.3}, {"FinalSentence": "Now, in both these cases of density estimation and sample generation, the underlying question is the same. Our learning task is to try to build a model that learns this probability distribution that is as close as possible to the true data distribution.", "SliceSentence": "Now in both these cases of density estimation and sample generation the underlying question is the same . Ourlearning task is to try to build a model that learns this probability distribution that is as close as possible to the true data distribution", "StartMs": 266900, "EndMs": 285060, "WordsNum": 43, "Words": [{"Word": "Now", "OffsetStartMs": 160, "OffsetEndMs": 450}, {"Word": "in", "OffsetStartMs": 450, "OffsetEndMs": 630}, {"Word": "both", "OffsetStartMs": 630, "OffsetEndMs": 840}, {"Word": "these", "OffsetStartMs": 840, "OffsetEndMs": 1080}, {"Word": "cases", "OffsetStartMs": 1080, "OffsetEndMs": 1400}, {"Word": "of", "OffsetStartMs": 1420, "OffsetEndMs": 1725}, {"Word": "density", "OffsetStartMs": 1725, "OffsetEndMs": 2280}, {"Word": "estimation", "OffsetStartMs": 2280, "OffsetEndMs": 2685}, {"Word": "and", "OffsetStartMs": 2685, "OffsetEndMs": 2940}, {"Word": "sample", "OffsetStartMs": 2940, "OffsetEndMs": 3225}, {"Word": "generation", "OffsetStartMs": 3225, "OffsetEndMs": 3620}, {"Word": "the", "OffsetStartMs": 4360, "OffsetEndMs": 4635}, {"Word": "underlying", "OffsetStartMs": 4635, "OffsetEndMs": 4910}, {"Word": "question", "OffsetStartMs": 5110, "OffsetEndMs": 5460}, {"Word": "is", "OffsetStartMs": 5460, "OffsetEndMs": 5685}, {"Word": "the", "OffsetStartMs": 5685, "OffsetEndMs": 5835}, {"Word": "same", "OffsetStartMs": 5835, "OffsetEndMs": 6110}, {"Word": ".", "OffsetStartMs": 6850, "OffsetEndMs": 7200}, {"Word": "Ourlearning", "OffsetStartMs": 7200, "OffsetEndMs": 7550}, {"Word": "task", "OffsetStartMs": 7570, "OffsetEndMs": 7970}, {"Word": "is", "OffsetStartMs": 8020, "OffsetEndMs": 8355}, {"Word": "to", "OffsetStartMs": 8355, "OffsetEndMs": 8625}, {"Word": "try", "OffsetStartMs": 8625, "OffsetEndMs": 8955}, {"Word": "to", "OffsetStartMs": 8955, "OffsetEndMs": 9350}, {"Word": "build", "OffsetStartMs": 9370, "OffsetEndMs": 9675}, {"Word": "a", "OffsetStartMs": 9675, "OffsetEndMs": 9855}, {"Word": "model", "OffsetStartMs": 9855, "OffsetEndMs": 10130}, {"Word": "that", "OffsetStartMs": 10270, "OffsetEndMs": 10605}, {"Word": "learns", "OffsetStartMs": 10605, "OffsetEndMs": 11025}, {"Word": "this", "OffsetStartMs": 11025, "OffsetEndMs": 11220}, {"Word": "probability", "OffsetStartMs": 11220, "OffsetEndMs": 11810}, {"Word": "distribution", "OffsetStartMs": 12280, "OffsetEndMs": 12680}, {"Word": "that", "OffsetStartMs": 13090, "OffsetEndMs": 13365}, {"Word": "is", "OffsetStartMs": 13365, "OffsetEndMs": 13545}, {"Word": "as", "OffsetStartMs": 13545, "OffsetEndMs": 13830}, {"Word": "close", "OffsetStartMs": 13830, "OffsetEndMs": 14115}, {"Word": "as", "OffsetStartMs": 14115, "OffsetEndMs": 14340}, {"Word": "possible", "OffsetStartMs": 14340, "OffsetEndMs": 14660}, {"Word": "to", "OffsetStartMs": 15340, "OffsetEndMs": 15660}, {"Word": "the", "OffsetStartMs": 15660, "OffsetEndMs": 15900}, {"Word": "true", "OffsetStartMs": 15900, "OffsetEndMs": 16220}, {"Word": "data", "OffsetStartMs": 16300, "OffsetEndMs": 16700}, {"Word": "distribution", "OffsetStartMs": 16960, "OffsetEndMs": 17360}], "SpeechSpeed": 13.7}, {"FinalSentence": "Okay, so with this definition and this concept of generative modeling, what are some ways that we can actually deploy generative modeling forward in the real world for high impact applications? Well, part of the reason that generative models are so powerful is that they have this ability to uncover the underlying features in a dataset and encode it in an efficient way.", "SliceSentence": "Okay so with this definition and this concept of generative modeling what are some ways that we can actually deploy generative modeling forward in the real world for high impact applications Well part of the reason that generative models are so powerful is that they have this ability to uncover the underlying features in a dataset and encode it in an efficient way", "StartMs": 286320, "EndMs": 312060, "WordsNum": 63, "Words": [{"Word": "Okay", "OffsetStartMs": 220, "OffsetEndMs": 620}, {"Word": "so", "OffsetStartMs": 1090, "OffsetEndMs": 1490}, {"Word": "with", "OffsetStartMs": 1570, "OffsetEndMs": 1860}, {"Word": "this", "OffsetStartMs": 1860, "OffsetEndMs": 2055}, {"Word": "definition", "OffsetStartMs": 2055, "OffsetEndMs": 2360}, {"Word": "and", "OffsetStartMs": 2500, "OffsetEndMs": 2775}, {"Word": "this", "OffsetStartMs": 2775, "OffsetEndMs": 2970}, {"Word": "concept", "OffsetStartMs": 2970, "OffsetEndMs": 3270}, {"Word": "of", "OffsetStartMs": 3270, "OffsetEndMs": 3555}, {"Word": "generative", "OffsetStartMs": 3555, "OffsetEndMs": 4005}, {"Word": "modeling", "OffsetStartMs": 4005, "OffsetEndMs": 4550}, {"Word": "what", "OffsetStartMs": 5110, "OffsetEndMs": 5370}, {"Word": "are", "OffsetStartMs": 5370, "OffsetEndMs": 5550}, {"Word": "some", "OffsetStartMs": 5550, "OffsetEndMs": 5850}, {"Word": "ways", "OffsetStartMs": 5850, "OffsetEndMs": 6165}, {"Word": "that", "OffsetStartMs": 6165, "OffsetEndMs": 6360}, {"Word": "we", "OffsetStartMs": 6360, "OffsetEndMs": 6480}, {"Word": "can", "OffsetStartMs": 6480, "OffsetEndMs": 6740}, {"Word": "actually", "OffsetStartMs": 6790, "OffsetEndMs": 7190}, {"Word": "deploy", "OffsetStartMs": 7390, "OffsetEndMs": 7725}, {"Word": "generative", "OffsetStartMs": 7725, "OffsetEndMs": 8175}, {"Word": "modeling", "OffsetStartMs": 8175, "OffsetEndMs": 8595}, {"Word": "forward", "OffsetStartMs": 8595, "OffsetEndMs": 8930}, {"Word": "in", "OffsetStartMs": 9310, "OffsetEndMs": 9600}, {"Word": "the", "OffsetStartMs": 9600, "OffsetEndMs": 9765}, {"Word": "real", "OffsetStartMs": 9765, "OffsetEndMs": 9975}, {"Word": "world", "OffsetStartMs": 9975, "OffsetEndMs": 10290}, {"Word": "for", "OffsetStartMs": 10290, "OffsetEndMs": 10590}, {"Word": "high", "OffsetStartMs": 10590, "OffsetEndMs": 10910}, {"Word": "impact", "OffsetStartMs": 11020, "OffsetEndMs": 11420}, {"Word": "applications", "OffsetStartMs": 11710, "OffsetEndMs": 12110}, {"Word": "Well", "OffsetStartMs": 13450, "OffsetEndMs": 13850}, {"Word": "part", "OffsetStartMs": 14320, "OffsetEndMs": 14595}, {"Word": "of", "OffsetStartMs": 14595, "OffsetEndMs": 14730}, {"Word": "the", "OffsetStartMs": 14730, "OffsetEndMs": 14850}, {"Word": "reason", "OffsetStartMs": 14850, "OffsetEndMs": 15090}, {"Word": "that", "OffsetStartMs": 15090, "OffsetEndMs": 15360}, {"Word": "generative", "OffsetStartMs": 15360, "OffsetEndMs": 15795}, {"Word": "models", "OffsetStartMs": 15795, "OffsetEndMs": 16070}, {"Word": "are", "OffsetStartMs": 16420, "OffsetEndMs": 16740}, {"Word": "so", "OffsetStartMs": 16740, "OffsetEndMs": 16995}, {"Word": "powerful", "OffsetStartMs": 16995, "OffsetEndMs": 17330}, {"Word": "is", "OffsetStartMs": 17590, "OffsetEndMs": 17865}, {"Word": "that", "OffsetStartMs": 17865, "OffsetEndMs": 18015}, {"Word": "they", "OffsetStartMs": 18015, "OffsetEndMs": 18210}, {"Word": "have", "OffsetStartMs": 18210, "OffsetEndMs": 18465}, {"Word": "this", "OffsetStartMs": 18465, "OffsetEndMs": 18795}, {"Word": "ability", "OffsetStartMs": 18795, "OffsetEndMs": 19190}, {"Word": "to", "OffsetStartMs": 19600, "OffsetEndMs": 19890}, {"Word": "uncover", "OffsetStartMs": 19890, "OffsetEndMs": 20550}, {"Word": "the", "OffsetStartMs": 20550, "OffsetEndMs": 20730}, {"Word": "underlying", "OffsetStartMs": 20730, "OffsetEndMs": 21020}, {"Word": "features", "OffsetStartMs": 21340, "OffsetEndMs": 21740}, {"Word": "in", "OffsetStartMs": 22090, "OffsetEndMs": 22365}, {"Word": "a", "OffsetStartMs": 22365, "OffsetEndMs": 22515}, {"Word": "dataset", "OffsetStartMs": 22515, "OffsetEndMs": 23090}, {"Word": "and", "OffsetStartMs": 23170, "OffsetEndMs": 23460}, {"Word": "encode", "OffsetStartMs": 23460, "OffsetEndMs": 23940}, {"Word": "it", "OffsetStartMs": 23940, "OffsetEndMs": 24075}, {"Word": "in", "OffsetStartMs": 24075, "OffsetEndMs": 24240}, {"Word": "an", "OffsetStartMs": 24240, "OffsetEndMs": 24465}, {"Word": "efficient", "OffsetStartMs": 24465, "OffsetEndMs": 24795}, {"Word": "way", "OffsetStartMs": 24795, "OffsetEndMs": 25160}], "SpeechSpeed": 14.2}, {"FinalSentence": "So, for example, if we're considering the problem of facial detection and we're given a data set with many, many different faces starting out without inspecting this data, we may not know what the distribution of faces in this data set is with respect to features we may be caring about. For example, the pose of the head, clothing, glasses, skin tone, hair, etc.", "SliceSentence": "So for example if we're considering the problem of facial detection and we're given a data set with many many different faces starting out without inspecting this data we may not know what the distribution of faces in this data set is with respect to features we may be caring about . Forexample the pose of the head clothing glasses skin tone hair etc", "StartMs": 312060, "EndMs": 336860, "WordsNum": 64, "Words": [{"Word": "So", "OffsetStartMs": 130, "OffsetEndMs": 405}, {"Word": "for", "OffsetStartMs": 405, "OffsetEndMs": 555}, {"Word": "example", "OffsetStartMs": 555, "OffsetEndMs": 830}, {"Word": "if", "OffsetStartMs": 910, "OffsetEndMs": 1200}, {"Word": "we're", "OffsetStartMs": 1200, "OffsetEndMs": 1530}, {"Word": "considering", "OffsetStartMs": 1530, "OffsetEndMs": 1815}, {"Word": "the", "OffsetStartMs": 1815, "OffsetEndMs": 2040}, {"Word": "problem", "OffsetStartMs": 2040, "OffsetEndMs": 2330}, {"Word": "of", "OffsetStartMs": 2380, "OffsetEndMs": 2760}, {"Word": "facial", "OffsetStartMs": 2760, "OffsetEndMs": 3255}, {"Word": "detection", "OffsetStartMs": 3255, "OffsetEndMs": 3830}, {"Word": "and", "OffsetStartMs": 4210, "OffsetEndMs": 4500}, {"Word": "we're", "OffsetStartMs": 4500, "OffsetEndMs": 4695}, {"Word": "given", "OffsetStartMs": 4695, "OffsetEndMs": 4845}, {"Word": "a", "OffsetStartMs": 4845, "OffsetEndMs": 5025}, {"Word": "data", "OffsetStartMs": 5025, "OffsetEndMs": 5250}, {"Word": "set", "OffsetStartMs": 5250, "OffsetEndMs": 5580}, {"Word": "with", "OffsetStartMs": 5580, "OffsetEndMs": 5955}, {"Word": "many", "OffsetStartMs": 5955, "OffsetEndMs": 6285}, {"Word": "many", "OffsetStartMs": 6285, "OffsetEndMs": 6555}, {"Word": "different", "OffsetStartMs": 6555, "OffsetEndMs": 6840}, {"Word": "faces", "OffsetStartMs": 6840, "OffsetEndMs": 7190}, {"Word": "starting", "OffsetStartMs": 8170, "OffsetEndMs": 8520}, {"Word": "out", "OffsetStartMs": 8520, "OffsetEndMs": 8805}, {"Word": "without", "OffsetStartMs": 8805, "OffsetEndMs": 9140}, {"Word": "inspecting", "OffsetStartMs": 9280, "OffsetEndMs": 9795}, {"Word": "this", "OffsetStartMs": 9795, "OffsetEndMs": 9975}, {"Word": "data", "OffsetStartMs": 9975, "OffsetEndMs": 10245}, {"Word": "we", "OffsetStartMs": 10245, "OffsetEndMs": 10515}, {"Word": "may", "OffsetStartMs": 10515, "OffsetEndMs": 10725}, {"Word": "not", "OffsetStartMs": 10725, "OffsetEndMs": 10965}, {"Word": "know", "OffsetStartMs": 10965, "OffsetEndMs": 11300}, {"Word": "what", "OffsetStartMs": 11650, "OffsetEndMs": 11955}, {"Word": "the", "OffsetStartMs": 11955, "OffsetEndMs": 12210}, {"Word": "distribution", "OffsetStartMs": 12210, "OffsetEndMs": 12560}, {"Word": "of", "OffsetStartMs": 12580, "OffsetEndMs": 12855}, {"Word": "faces", "OffsetStartMs": 12855, "OffsetEndMs": 13130}, {"Word": "in", "OffsetStartMs": 13210, "OffsetEndMs": 13470}, {"Word": "this", "OffsetStartMs": 13470, "OffsetEndMs": 13635}, {"Word": "data", "OffsetStartMs": 13635, "OffsetEndMs": 13875}, {"Word": "set", "OffsetStartMs": 13875, "OffsetEndMs": 14130}, {"Word": "is", "OffsetStartMs": 14130, "OffsetEndMs": 14450}, {"Word": "with", "OffsetStartMs": 14650, "OffsetEndMs": 15045}, {"Word": "respect", "OffsetStartMs": 15045, "OffsetEndMs": 15390}, {"Word": "to", "OffsetStartMs": 15390, "OffsetEndMs": 15690}, {"Word": "features", "OffsetStartMs": 15690, "OffsetEndMs": 16020}, {"Word": "we", "OffsetStartMs": 16020, "OffsetEndMs": 16275}, {"Word": "may", "OffsetStartMs": 16275, "OffsetEndMs": 16440}, {"Word": "be", "OffsetStartMs": 16440, "OffsetEndMs": 16710}, {"Word": "caring", "OffsetStartMs": 16710, "OffsetEndMs": 17160}, {"Word": "about", "OffsetStartMs": 17160, "OffsetEndMs": 17450}, {"Word": ".", "OffsetStartMs": 17710, "OffsetEndMs": 18000}, {"Word": "Forexample", "OffsetStartMs": 18000, "OffsetEndMs": 18290}, {"Word": "the", "OffsetStartMs": 18340, "OffsetEndMs": 18615}, {"Word": "pose", "OffsetStartMs": 18615, "OffsetEndMs": 18870}, {"Word": "of", "OffsetStartMs": 18870, "OffsetEndMs": 19080}, {"Word": "the", "OffsetStartMs": 19080, "OffsetEndMs": 19215}, {"Word": "head", "OffsetStartMs": 19215, "OffsetEndMs": 19490}, {"Word": "clothing", "OffsetStartMs": 20080, "OffsetEndMs": 20480}, {"Word": "glasses", "OffsetStartMs": 20710, "OffsetEndMs": 21110}, {"Word": "skin", "OffsetStartMs": 21430, "OffsetEndMs": 21765}, {"Word": "tone", "OffsetStartMs": 21765, "OffsetEndMs": 22100}, {"Word": "hair", "OffsetStartMs": 22360, "OffsetEndMs": 22760}, {"Word": "etc", "OffsetStartMs": 23020, "OffsetEndMs": 23570}], "SpeechSpeed": 14.2}, {"FinalSentence": "And it can be the case that our training data may be very, very biased towards particular features without us even realizing this.", "SliceSentence": "And it can be the case that our training data may be very very biased towards particular features without us even realizing this", "StartMs": 336860, "EndMs": 345400, "WordsNum": 23, "Words": [{"Word": "And", "OffsetStartMs": 0, "OffsetEndMs": 105}, {"Word": "it", "OffsetStartMs": 105, "OffsetEndMs": 300}, {"Word": "can", "OffsetStartMs": 300, "OffsetEndMs": 540}, {"Word": "be", "OffsetStartMs": 540, "OffsetEndMs": 705}, {"Word": "the", "OffsetStartMs": 705, "OffsetEndMs": 855}, {"Word": "case", "OffsetStartMs": 855, "OffsetEndMs": 1080}, {"Word": "that", "OffsetStartMs": 1080, "OffsetEndMs": 1320}, {"Word": "our", "OffsetStartMs": 1320, "OffsetEndMs": 1560}, {"Word": "training", "OffsetStartMs": 1560, "OffsetEndMs": 1875}, {"Word": "data", "OffsetStartMs": 1875, "OffsetEndMs": 2220}, {"Word": "may", "OffsetStartMs": 2220, "OffsetEndMs": 2475}, {"Word": "be", "OffsetStartMs": 2475, "OffsetEndMs": 2670}, {"Word": "very", "OffsetStartMs": 2670, "OffsetEndMs": 2940}, {"Word": "very", "OffsetStartMs": 2940, "OffsetEndMs": 3240}, {"Word": "biased", "OffsetStartMs": 3240, "OffsetEndMs": 3830}, {"Word": "towards", "OffsetStartMs": 4150, "OffsetEndMs": 4550}, {"Word": "particular", "OffsetStartMs": 4630, "OffsetEndMs": 5030}, {"Word": "features", "OffsetStartMs": 5080, "OffsetEndMs": 5480}, {"Word": "without", "OffsetStartMs": 5830, "OffsetEndMs": 6230}, {"Word": "us", "OffsetStartMs": 6280, "OffsetEndMs": 6630}, {"Word": "even", "OffsetStartMs": 6630, "OffsetEndMs": 6960}, {"Word": "realizing", "OffsetStartMs": 6960, "OffsetEndMs": 7485}, {"Word": "this", "OffsetStartMs": 7485, "OffsetEndMs": 7880}], "SpeechSpeed": 15.0}, {"FinalSentence": "Using generative models, we can actually identify the distributions of these underlying features in a completely automatic way without any labeling.", "SliceSentence": "Using generative models we can actually identify the distributions of these underlying features in a completely automatic way without any labeling", "StartMs": 345540, "EndMs": 355980, "WordsNum": 21, "Words": [{"Word": "Using", "OffsetStartMs": 160, "OffsetEndMs": 555}, {"Word": "generative", "OffsetStartMs": 555, "OffsetEndMs": 1140}, {"Word": "models", "OffsetStartMs": 1140, "OffsetEndMs": 1430}, {"Word": "we", "OffsetStartMs": 1570, "OffsetEndMs": 1815}, {"Word": "can", "OffsetStartMs": 1815, "OffsetEndMs": 2060}, {"Word": "actually", "OffsetStartMs": 2140, "OffsetEndMs": 2540}, {"Word": "identify", "OffsetStartMs": 3070, "OffsetEndMs": 3375}, {"Word": "the", "OffsetStartMs": 3375, "OffsetEndMs": 3660}, {"Word": "distributions", "OffsetStartMs": 3660, "OffsetEndMs": 4190}, {"Word": "of", "OffsetStartMs": 4270, "OffsetEndMs": 4545}, {"Word": "these", "OffsetStartMs": 4545, "OffsetEndMs": 4725}, {"Word": "underlying", "OffsetStartMs": 4725, "OffsetEndMs": 5030}, {"Word": "features", "OffsetStartMs": 5320, "OffsetEndMs": 5720}, {"Word": "in", "OffsetStartMs": 5740, "OffsetEndMs": 5985}, {"Word": "a", "OffsetStartMs": 5985, "OffsetEndMs": 6225}, {"Word": "completely", "OffsetStartMs": 6225, "OffsetEndMs": 6620}, {"Word": "automatic", "OffsetStartMs": 7270, "OffsetEndMs": 7650}, {"Word": "way", "OffsetStartMs": 7650, "OffsetEndMs": 8030}, {"Word": "without", "OffsetStartMs": 8380, "OffsetEndMs": 8780}, {"Word": "any", "OffsetStartMs": 8800, "OffsetEndMs": 9150}, {"Word": "labeling", "OffsetStartMs": 9150, "OffsetEndMs": 9770}], "SpeechSpeed": 14.0}, {"FinalSentence": "In order to understand what features may be overrepresented in the data, what features may be underrepresented in the data?", "SliceSentence": "In order to understand what features may be overrepresented in the data what features may be underrepresented in the data", "StartMs": 355980, "EndMs": 363920, "WordsNum": 20, "Words": [{"Word": "In", "OffsetStartMs": 0, "OffsetEndMs": 165}, {"Word": "order", "OffsetStartMs": 165, "OffsetEndMs": 465}, {"Word": "to", "OffsetStartMs": 465, "OffsetEndMs": 830}, {"Word": "understand", "OffsetStartMs": 880, "OffsetEndMs": 1275}, {"Word": "what", "OffsetStartMs": 1275, "OffsetEndMs": 1590}, {"Word": "features", "OffsetStartMs": 1590, "OffsetEndMs": 1905}, {"Word": "may", "OffsetStartMs": 1905, "OffsetEndMs": 2175}, {"Word": "be", "OffsetStartMs": 2175, "OffsetEndMs": 2340}, {"Word": "overrepresented", "OffsetStartMs": 2340, "OffsetEndMs": 3195}, {"Word": "in", "OffsetStartMs": 3195, "OffsetEndMs": 3420}, {"Word": "the", "OffsetStartMs": 3420, "OffsetEndMs": 3570}, {"Word": "data", "OffsetStartMs": 3570, "OffsetEndMs": 3830}, {"Word": "what", "OffsetStartMs": 4480, "OffsetEndMs": 4800}, {"Word": "features", "OffsetStartMs": 4800, "OffsetEndMs": 5120}, {"Word": "may", "OffsetStartMs": 5200, "OffsetEndMs": 5475}, {"Word": "be", "OffsetStartMs": 5475, "OffsetEndMs": 5685}, {"Word": "underrepresented", "OffsetStartMs": 5685, "OffsetEndMs": 6585}, {"Word": "in", "OffsetStartMs": 6585, "OffsetEndMs": 6825}, {"Word": "the", "OffsetStartMs": 6825, "OffsetEndMs": 6960}, {"Word": "data", "OffsetStartMs": 6960, "OffsetEndMs": 7220}], "SpeechSpeed": 15.2}, {"FinalSentence": "And this is the focus of today and tomorrow's software labs, which are going to be part of the software lab competition, developing generative models that can do this task and using it to uncover and diagnose biases that can exist within facial detection models.", "SliceSentence": "And this is the focus of today and tomorrow's software labs which are going to be part of the software lab competition developing generative models that can do this task and using it to uncover and diagnose biases that can exist within facial detection models", "StartMs": 363920, "EndMs": 384160, "WordsNum": 45, "Words": [{"Word": "And", "OffsetStartMs": 130, "OffsetEndMs": 420}, {"Word": "this", "OffsetStartMs": 420, "OffsetEndMs": 705}, {"Word": "is", "OffsetStartMs": 705, "OffsetEndMs": 975}, {"Word": "the", "OffsetStartMs": 975, "OffsetEndMs": 1140}, {"Word": "focus", "OffsetStartMs": 1140, "OffsetEndMs": 1430}, {"Word": "of", "OffsetStartMs": 1600, "OffsetEndMs": 2000}, {"Word": "today", "OffsetStartMs": 2380, "OffsetEndMs": 2760}, {"Word": "and", "OffsetStartMs": 2760, "OffsetEndMs": 3090}, {"Word": "tomorrow's", "OffsetStartMs": 3090, "OffsetEndMs": 3705}, {"Word": "software", "OffsetStartMs": 3705, "OffsetEndMs": 4070}, {"Word": "labs", "OffsetStartMs": 4120, "OffsetEndMs": 4695}, {"Word": "which", "OffsetStartMs": 4695, "OffsetEndMs": 4950}, {"Word": "are", "OffsetStartMs": 4950, "OffsetEndMs": 5270}, {"Word": "going", "OffsetStartMs": 5440, "OffsetEndMs": 5775}, {"Word": "to", "OffsetStartMs": 5775, "OffsetEndMs": 5955}, {"Word": "be", "OffsetStartMs": 5955, "OffsetEndMs": 6200}, {"Word": "part", "OffsetStartMs": 6220, "OffsetEndMs": 6525}, {"Word": "of", "OffsetStartMs": 6525, "OffsetEndMs": 6705}, {"Word": "the", "OffsetStartMs": 6705, "OffsetEndMs": 6960}, {"Word": "software", "OffsetStartMs": 6960, "OffsetEndMs": 7320}, {"Word": "lab", "OffsetStartMs": 7320, "OffsetEndMs": 7700}, {"Word": "competition", "OffsetStartMs": 7870, "OffsetEndMs": 8270}, {"Word": "developing", "OffsetStartMs": 9010, "OffsetEndMs": 9410}, {"Word": "generative", "OffsetStartMs": 9940, "OffsetEndMs": 10500}, {"Word": "models", "OffsetStartMs": 10500, "OffsetEndMs": 10770}, {"Word": "that", "OffsetStartMs": 10770, "OffsetEndMs": 11025}, {"Word": "can", "OffsetStartMs": 11025, "OffsetEndMs": 11205}, {"Word": "do", "OffsetStartMs": 11205, "OffsetEndMs": 11415}, {"Word": "this", "OffsetStartMs": 11415, "OffsetEndMs": 11640}, {"Word": "task", "OffsetStartMs": 11640, "OffsetEndMs": 11960}, {"Word": "and", "OffsetStartMs": 12280, "OffsetEndMs": 12585}, {"Word": "using", "OffsetStartMs": 12585, "OffsetEndMs": 12855}, {"Word": "it", "OffsetStartMs": 12855, "OffsetEndMs": 13095}, {"Word": "to", "OffsetStartMs": 13095, "OffsetEndMs": 13230}, {"Word": "uncover", "OffsetStartMs": 13230, "OffsetEndMs": 13890}, {"Word": "and", "OffsetStartMs": 13890, "OffsetEndMs": 14085}, {"Word": "diagnose", "OffsetStartMs": 14085, "OffsetEndMs": 14690}, {"Word": "biases", "OffsetStartMs": 14830, "OffsetEndMs": 15620}, {"Word": "that", "OffsetStartMs": 15760, "OffsetEndMs": 16035}, {"Word": "can", "OffsetStartMs": 16035, "OffsetEndMs": 16290}, {"Word": "exist", "OffsetStartMs": 16290, "OffsetEndMs": 16670}, {"Word": "within", "OffsetStartMs": 16870, "OffsetEndMs": 17235}, {"Word": "facial", "OffsetStartMs": 17235, "OffsetEndMs": 17810}, {"Word": "detection", "OffsetStartMs": 17980, "OffsetEndMs": 18435}, {"Word": "models", "OffsetStartMs": 18435, "OffsetEndMs": 18710}], "SpeechSpeed": 12.8}, {"FinalSentence": "Another really powerful example is, in the case of outlier detection, identifying rare events. So let's consider the example of self driving autonomous cars.", "SliceSentence": "Another really powerful example is in the case of outlier detection identifying rare events . Solet's consider the example of self driving autonomous cars", "StartMs": 384860, "EndMs": 396940, "WordsNum": 24, "Words": [{"Word": "Another", "OffsetStartMs": 190, "OffsetEndMs": 540}, {"Word": "really", "OffsetStartMs": 540, "OffsetEndMs": 840}, {"Word": "powerful", "OffsetStartMs": 840, "OffsetEndMs": 1190}, {"Word": "example", "OffsetStartMs": 1360, "OffsetEndMs": 1760}, {"Word": "is", "OffsetStartMs": 1780, "OffsetEndMs": 2115}, {"Word": "in", "OffsetStartMs": 2115, "OffsetEndMs": 2325}, {"Word": "the", "OffsetStartMs": 2325, "OffsetEndMs": 2490}, {"Word": "case", "OffsetStartMs": 2490, "OffsetEndMs": 2745}, {"Word": "of", "OffsetStartMs": 2745, "OffsetEndMs": 3090}, {"Word": "outlier", "OffsetStartMs": 3090, "OffsetEndMs": 3825}, {"Word": "detection", "OffsetStartMs": 3825, "OffsetEndMs": 4430}, {"Word": "identifying", "OffsetStartMs": 5200, "OffsetEndMs": 5940}, {"Word": "rare", "OffsetStartMs": 5940, "OffsetEndMs": 6300}, {"Word": "events", "OffsetStartMs": 6300, "OffsetEndMs": 6680}, {"Word": ".", "OffsetStartMs": 7480, "OffsetEndMs": 7785}, {"Word": "Solet's", "OffsetStartMs": 7785, "OffsetEndMs": 8160}, {"Word": "consider", "OffsetStartMs": 8160, "OffsetEndMs": 8430}, {"Word": "the", "OffsetStartMs": 8430, "OffsetEndMs": 8670}, {"Word": "example", "OffsetStartMs": 8670, "OffsetEndMs": 8990}, {"Word": "of", "OffsetStartMs": 9070, "OffsetEndMs": 9470}, {"Word": "self", "OffsetStartMs": 9580, "OffsetEndMs": 9915}, {"Word": "driving", "OffsetStartMs": 9915, "OffsetEndMs": 10250}, {"Word": "autonomous", "OffsetStartMs": 10300, "OffsetEndMs": 11025}, {"Word": "cars", "OffsetStartMs": 11025, "OffsetEndMs": 11360}], "SpeechSpeed": 12.7}, {"FinalSentence": "With an autonomous car, let's say it's driving out in the real world. We really, really want to make sure that that car can be able to handle all the possible scenarios and all the possible cases it may encounter, including edge cases like a deer coming in front of the car or some unexpected rare events, not just, you know, the typical straight freeway driving that it may see the majority of the time.", "SliceSentence": "With an autonomous car let's say it's driving out in the real world . Wereally really want to make sure that that car can be able to handle all the possible scenarios and all the possible cases it may encounter including edge cases like a deer coming in front of the car or some unexpected rare events not just you know the typical straight freeway driving that it may see the majority of the time", "StartMs": 396940, "EndMs": 422820, "WordsNum": 75, "Words": [{"Word": "With", "OffsetStartMs": 100, "OffsetEndMs": 360}, {"Word": "an", "OffsetStartMs": 360, "OffsetEndMs": 480}, {"Word": "autonomous", "OffsetStartMs": 480, "OffsetEndMs": 990}, {"Word": "car", "OffsetStartMs": 990, "OffsetEndMs": 1280}, {"Word": "let's", "OffsetStartMs": 1420, "OffsetEndMs": 1755}, {"Word": "say", "OffsetStartMs": 1755, "OffsetEndMs": 1845}, {"Word": "it's", "OffsetStartMs": 1845, "OffsetEndMs": 2010}, {"Word": "driving", "OffsetStartMs": 2010, "OffsetEndMs": 2235}, {"Word": "out", "OffsetStartMs": 2235, "OffsetEndMs": 2535}, {"Word": "in", "OffsetStartMs": 2535, "OffsetEndMs": 2730}, {"Word": "the", "OffsetStartMs": 2730, "OffsetEndMs": 2850}, {"Word": "real", "OffsetStartMs": 2850, "OffsetEndMs": 3030}, {"Word": "world", "OffsetStartMs": 3030, "OffsetEndMs": 3350}, {"Word": ".", "OffsetStartMs": 3850, "OffsetEndMs": 4200}, {"Word": "Wereally", "OffsetStartMs": 4200, "OffsetEndMs": 4500}, {"Word": "really", "OffsetStartMs": 4500, "OffsetEndMs": 4785}, {"Word": "want", "OffsetStartMs": 4785, "OffsetEndMs": 5040}, {"Word": "to", "OffsetStartMs": 5040, "OffsetEndMs": 5205}, {"Word": "make", "OffsetStartMs": 5205, "OffsetEndMs": 5400}, {"Word": "sure", "OffsetStartMs": 5400, "OffsetEndMs": 5670}, {"Word": "that", "OffsetStartMs": 5670, "OffsetEndMs": 5880}, {"Word": "that", "OffsetStartMs": 5880, "OffsetEndMs": 6135}, {"Word": "car", "OffsetStartMs": 6135, "OffsetEndMs": 6500}, {"Word": "can", "OffsetStartMs": 6760, "OffsetEndMs": 7050}, {"Word": "be", "OffsetStartMs": 7050, "OffsetEndMs": 7215}, {"Word": "able", "OffsetStartMs": 7215, "OffsetEndMs": 7470}, {"Word": "to", "OffsetStartMs": 7470, "OffsetEndMs": 7740}, {"Word": "handle", "OffsetStartMs": 7740, "OffsetEndMs": 8030}, {"Word": "all", "OffsetStartMs": 8170, "OffsetEndMs": 8505}, {"Word": "the", "OffsetStartMs": 8505, "OffsetEndMs": 8715}, {"Word": "possible", "OffsetStartMs": 8715, "OffsetEndMs": 8990}, {"Word": "scenarios", "OffsetStartMs": 9070, "OffsetEndMs": 9705}, {"Word": "and", "OffsetStartMs": 9705, "OffsetEndMs": 9885}, {"Word": "all", "OffsetStartMs": 9885, "OffsetEndMs": 10095}, {"Word": "the", "OffsetStartMs": 10095, "OffsetEndMs": 10275}, {"Word": "possible", "OffsetStartMs": 10275, "OffsetEndMs": 10550}, {"Word": "cases", "OffsetStartMs": 10630, "OffsetEndMs": 11010}, {"Word": "it", "OffsetStartMs": 11010, "OffsetEndMs": 11265}, {"Word": "may", "OffsetStartMs": 11265, "OffsetEndMs": 11520}, {"Word": "encounter", "OffsetStartMs": 11520, "OffsetEndMs": 12170}, {"Word": "including", "OffsetStartMs": 12760, "OffsetEndMs": 13160}, {"Word": "edge", "OffsetStartMs": 13180, "OffsetEndMs": 13530}, {"Word": "cases", "OffsetStartMs": 13530, "OffsetEndMs": 13880}, {"Word": "like", "OffsetStartMs": 14020, "OffsetEndMs": 14420}, {"Word": "a", "OffsetStartMs": 14590, "OffsetEndMs": 14895}, {"Word": "deer", "OffsetStartMs": 14895, "OffsetEndMs": 15255}, {"Word": "coming", "OffsetStartMs": 15255, "OffsetEndMs": 15495}, {"Word": "in", "OffsetStartMs": 15495, "OffsetEndMs": 15690}, {"Word": "front", "OffsetStartMs": 15690, "OffsetEndMs": 15870}, {"Word": "of", "OffsetStartMs": 15870, "OffsetEndMs": 16020}, {"Word": "the", "OffsetStartMs": 16020, "OffsetEndMs": 16185}, {"Word": "car", "OffsetStartMs": 16185, "OffsetEndMs": 16490}, {"Word": "or", "OffsetStartMs": 16720, "OffsetEndMs": 17025}, {"Word": "some", "OffsetStartMs": 17025, "OffsetEndMs": 17310}, {"Word": "unexpected", "OffsetStartMs": 17310, "OffsetEndMs": 17690}, {"Word": "rare", "OffsetStartMs": 18070, "OffsetEndMs": 18435}, {"Word": "events", "OffsetStartMs": 18435, "OffsetEndMs": 18800}, {"Word": "not", "OffsetStartMs": 19360, "OffsetEndMs": 19695}, {"Word": "just", "OffsetStartMs": 19695, "OffsetEndMs": 20025}, {"Word": "you", "OffsetStartMs": 20025, "OffsetEndMs": 20280}, {"Word": "know", "OffsetStartMs": 20280, "OffsetEndMs": 20430}, {"Word": "the", "OffsetStartMs": 20430, "OffsetEndMs": 20610}, {"Word": "typical", "OffsetStartMs": 20610, "OffsetEndMs": 20900}, {"Word": "straight", "OffsetStartMs": 21100, "OffsetEndMs": 21500}, {"Word": "freeway", "OffsetStartMs": 21580, "OffsetEndMs": 22080}, {"Word": "driving", "OffsetStartMs": 22080, "OffsetEndMs": 22400}, {"Word": "that", "OffsetStartMs": 22510, "OffsetEndMs": 22910}, {"Word": "it", "OffsetStartMs": 22990, "OffsetEndMs": 23265}, {"Word": "may", "OffsetStartMs": 23265, "OffsetEndMs": 23505}, {"Word": "see", "OffsetStartMs": 23505, "OffsetEndMs": 23870}, {"Word": "the", "OffsetStartMs": 24130, "OffsetEndMs": 24375}, {"Word": "majority", "OffsetStartMs": 24375, "OffsetEndMs": 24620}, {"Word": "of", "OffsetStartMs": 24640, "OffsetEndMs": 24915}, {"Word": "the", "OffsetStartMs": 24915, "OffsetEndMs": 25065}, {"Word": "time", "OffsetStartMs": 25065, "OffsetEndMs": 25340}], "SpeechSpeed": 15.3}, {"FinalSentence": "With generative models, we can use this idea of density estimation to be able to identify rare and anomalous events within the training data and as they're occurring, as the model sees them, for the first time.", "SliceSentence": "With generative models we can use this idea of density estimation to be able to identify rare and anomalous events within the training data and as they're occurring as the model sees them for the first time", "StartMs": 423120, "EndMs": 438460, "WordsNum": 37, "Words": [{"Word": "With", "OffsetStartMs": 130, "OffsetEndMs": 480}, {"Word": "generative", "OffsetStartMs": 480, "OffsetEndMs": 990}, {"Word": "models", "OffsetStartMs": 990, "OffsetEndMs": 1280}, {"Word": "we", "OffsetStartMs": 1480, "OffsetEndMs": 1755}, {"Word": "can", "OffsetStartMs": 1755, "OffsetEndMs": 1935}, {"Word": "use", "OffsetStartMs": 1935, "OffsetEndMs": 2160}, {"Word": "this", "OffsetStartMs": 2160, "OffsetEndMs": 2475}, {"Word": "idea", "OffsetStartMs": 2475, "OffsetEndMs": 2820}, {"Word": "of", "OffsetStartMs": 2820, "OffsetEndMs": 3150}, {"Word": "density", "OffsetStartMs": 3150, "OffsetEndMs": 3855}, {"Word": "estimation", "OffsetStartMs": 3855, "OffsetEndMs": 4340}, {"Word": "to", "OffsetStartMs": 4510, "OffsetEndMs": 4785}, {"Word": "be", "OffsetStartMs": 4785, "OffsetEndMs": 4950}, {"Word": "able", "OffsetStartMs": 4950, "OffsetEndMs": 5240}, {"Word": "to", "OffsetStartMs": 5320, "OffsetEndMs": 5720}, {"Word": "identify", "OffsetStartMs": 6400, "OffsetEndMs": 6800}, {"Word": "rare", "OffsetStartMs": 7090, "OffsetEndMs": 7490}, {"Word": "and", "OffsetStartMs": 7540, "OffsetEndMs": 7845}, {"Word": "anomalous", "OffsetStartMs": 7845, "OffsetEndMs": 8625}, {"Word": "events", "OffsetStartMs": 8625, "OffsetEndMs": 8990}, {"Word": "within", "OffsetStartMs": 9700, "OffsetEndMs": 10100}, {"Word": "the", "OffsetStartMs": 10120, "OffsetEndMs": 10395}, {"Word": "training", "OffsetStartMs": 10395, "OffsetEndMs": 10635}, {"Word": "data", "OffsetStartMs": 10635, "OffsetEndMs": 11000}, {"Word": "and", "OffsetStartMs": 11140, "OffsetEndMs": 11540}, {"Word": "as", "OffsetStartMs": 11680, "OffsetEndMs": 12000}, {"Word": "they're", "OffsetStartMs": 12000, "OffsetEndMs": 12375}, {"Word": "occurring", "OffsetStartMs": 12375, "OffsetEndMs": 12780}, {"Word": "as", "OffsetStartMs": 12780, "OffsetEndMs": 12990}, {"Word": "the", "OffsetStartMs": 12990, "OffsetEndMs": 13140}, {"Word": "model", "OffsetStartMs": 13140, "OffsetEndMs": 13380}, {"Word": "sees", "OffsetStartMs": 13380, "OffsetEndMs": 13650}, {"Word": "them", "OffsetStartMs": 13650, "OffsetEndMs": 13890}, {"Word": "for", "OffsetStartMs": 13890, "OffsetEndMs": 14100}, {"Word": "the", "OffsetStartMs": 14100, "OffsetEndMs": 14220}, {"Word": "first", "OffsetStartMs": 14220, "OffsetEndMs": 14430}, {"Word": "time", "OffsetStartMs": 14430, "OffsetEndMs": 14780}], "SpeechSpeed": 13.4}, {"FinalSentence": "So hopefully this paints this picture of what generative modeling the underlying concept is, and a couple of different ways in which we can actually deploy these ideas for powerful and impactful real world applications.", "SliceSentence": "So hopefully this paints this picture of what generative modeling the underlying concept is and a couple of different ways in which we can actually deploy these ideas for powerful and impactful real world applications", "StartMs": 439360, "EndMs": 453780, "WordsNum": 35, "Words": [{"Word": "So", "OffsetStartMs": 130, "OffsetEndMs": 530}, {"Word": "hopefully", "OffsetStartMs": 550, "OffsetEndMs": 930}, {"Word": "this", "OffsetStartMs": 930, "OffsetEndMs": 1260}, {"Word": "paints", "OffsetStartMs": 1260, "OffsetEndMs": 1590}, {"Word": "this", "OffsetStartMs": 1590, "OffsetEndMs": 1755}, {"Word": "picture", "OffsetStartMs": 1755, "OffsetEndMs": 2060}, {"Word": "of", "OffsetStartMs": 2140, "OffsetEndMs": 2540}, {"Word": "what", "OffsetStartMs": 3160, "OffsetEndMs": 3525}, {"Word": "generative", "OffsetStartMs": 3525, "OffsetEndMs": 4035}, {"Word": "modeling", "OffsetStartMs": 4035, "OffsetEndMs": 4395}, {"Word": "the", "OffsetStartMs": 4395, "OffsetEndMs": 4545}, {"Word": "underlying", "OffsetStartMs": 4545, "OffsetEndMs": 4820}, {"Word": "concept", "OffsetStartMs": 5050, "OffsetEndMs": 5450}, {"Word": "is", "OffsetStartMs": 5530, "OffsetEndMs": 5930}, {"Word": "and", "OffsetStartMs": 5950, "OffsetEndMs": 6300}, {"Word": "a", "OffsetStartMs": 6300, "OffsetEndMs": 6525}, {"Word": "couple", "OffsetStartMs": 6525, "OffsetEndMs": 6720}, {"Word": "of", "OffsetStartMs": 6720, "OffsetEndMs": 6915}, {"Word": "different", "OffsetStartMs": 6915, "OffsetEndMs": 7140}, {"Word": "ways", "OffsetStartMs": 7140, "OffsetEndMs": 7455}, {"Word": "in", "OffsetStartMs": 7455, "OffsetEndMs": 7695}, {"Word": "which", "OffsetStartMs": 7695, "OffsetEndMs": 7860}, {"Word": "we", "OffsetStartMs": 7860, "OffsetEndMs": 8010}, {"Word": "can", "OffsetStartMs": 8010, "OffsetEndMs": 8270}, {"Word": "actually", "OffsetStartMs": 8350, "OffsetEndMs": 8750}, {"Word": "deploy", "OffsetStartMs": 8980, "OffsetEndMs": 9300}, {"Word": "these", "OffsetStartMs": 9300, "OffsetEndMs": 9600}, {"Word": "ideas", "OffsetStartMs": 9600, "OffsetEndMs": 9980}, {"Word": "for", "OffsetStartMs": 10240, "OffsetEndMs": 10640}, {"Word": "powerful", "OffsetStartMs": 10900, "OffsetEndMs": 11300}, {"Word": "and", "OffsetStartMs": 11410, "OffsetEndMs": 11775}, {"Word": "impactful", "OffsetStartMs": 11775, "OffsetEndMs": 12375}, {"Word": "real", "OffsetStartMs": 12375, "OffsetEndMs": 12690}, {"Word": "world", "OffsetStartMs": 12690, "OffsetEndMs": 13010}, {"Word": "applications", "OffsetStartMs": 13300, "OffsetEndMs": 13700}], "SpeechSpeed": 15.0}, {"FinalSentence": "In today's lecture, we're going to focus on a broad class of generative models that we call latent variable models and specifically distill down into two subtypes of latent variable models.", "SliceSentence": "In today's lecture we're going to focus on a broad class of generative models that we call latent variable models and specifically distill down into two subtypes of latent variable models", "StartMs": 455020, "EndMs": 468480, "WordsNum": 31, "Words": [{"Word": "In", "OffsetStartMs": 40, "OffsetEndMs": 345}, {"Word": "today's", "OffsetStartMs": 345, "OffsetEndMs": 750}, {"Word": "lecture", "OffsetStartMs": 750, "OffsetEndMs": 975}, {"Word": "we're", "OffsetStartMs": 975, "OffsetEndMs": 1260}, {"Word": "going", "OffsetStartMs": 1260, "OffsetEndMs": 1380}, {"Word": "to", "OffsetStartMs": 1380, "OffsetEndMs": 1560}, {"Word": "focus", "OffsetStartMs": 1560, "OffsetEndMs": 1850}, {"Word": "on", "OffsetStartMs": 1960, "OffsetEndMs": 2360}, {"Word": "a", "OffsetStartMs": 2650, "OffsetEndMs": 2955}, {"Word": "broad", "OffsetStartMs": 2955, "OffsetEndMs": 3260}, {"Word": "class", "OffsetStartMs": 3280, "OffsetEndMs": 3630}, {"Word": "of", "OffsetStartMs": 3630, "OffsetEndMs": 3870}, {"Word": "generative", "OffsetStartMs": 3870, "OffsetEndMs": 4275}, {"Word": "models", "OffsetStartMs": 4275, "OffsetEndMs": 4530}, {"Word": "that", "OffsetStartMs": 4530, "OffsetEndMs": 4800}, {"Word": "we", "OffsetStartMs": 4800, "OffsetEndMs": 4995}, {"Word": "call", "OffsetStartMs": 4995, "OffsetEndMs": 5250}, {"Word": "latent", "OffsetStartMs": 5250, "OffsetEndMs": 5715}, {"Word": "variable", "OffsetStartMs": 5715, "OffsetEndMs": 6020}, {"Word": "models", "OffsetStartMs": 6100, "OffsetEndMs": 6500}, {"Word": "and", "OffsetStartMs": 7030, "OffsetEndMs": 7350}, {"Word": "specifically", "OffsetStartMs": 7350, "OffsetEndMs": 7670}, {"Word": "distill", "OffsetStartMs": 7960, "OffsetEndMs": 8460}, {"Word": "down", "OffsetStartMs": 8460, "OffsetEndMs": 8745}, {"Word": "into", "OffsetStartMs": 8745, "OffsetEndMs": 9110}, {"Word": "two", "OffsetStartMs": 9190, "OffsetEndMs": 9590}, {"Word": "subtypes", "OffsetStartMs": 10120, "OffsetEndMs": 10890}, {"Word": "of", "OffsetStartMs": 10890, "OffsetEndMs": 11130}, {"Word": "latent", "OffsetStartMs": 11130, "OffsetEndMs": 11475}, {"Word": "variable", "OffsetStartMs": 11475, "OffsetEndMs": 11750}, {"Word": "models", "OffsetStartMs": 11800, "OffsetEndMs": 12200}], "SpeechSpeed": 13.9}, {"FinalSentence": "First things first. I've introduced this term latent variable, but I haven't told you or described to you what that actually is.", "SliceSentence": "First things first .I've introduced this term latent variable but I haven't told you or described to you what that actually is", "StartMs": 468640, "EndMs": 477680, "WordsNum": 22, "Words": [{"Word": "First", "OffsetStartMs": 100, "OffsetEndMs": 420}, {"Word": "things", "OffsetStartMs": 420, "OffsetEndMs": 660}, {"Word": "first", "OffsetStartMs": 660, "OffsetEndMs": 980}, {"Word": ".I've", "OffsetStartMs": 1510, "OffsetEndMs": 2025}, {"Word": "introduced", "OffsetStartMs": 2025, "OffsetEndMs": 2325}, {"Word": "this", "OffsetStartMs": 2325, "OffsetEndMs": 2565}, {"Word": "term", "OffsetStartMs": 2565, "OffsetEndMs": 2850}, {"Word": "latent", "OffsetStartMs": 2850, "OffsetEndMs": 3225}, {"Word": "variable", "OffsetStartMs": 3225, "OffsetEndMs": 3500}, {"Word": "but", "OffsetStartMs": 4060, "OffsetEndMs": 4365}, {"Word": "I", "OffsetStartMs": 4365, "OffsetEndMs": 4575}, {"Word": "haven't", "OffsetStartMs": 4575, "OffsetEndMs": 5060}, {"Word": "told", "OffsetStartMs": 5230, "OffsetEndMs": 5565}, {"Word": "you", "OffsetStartMs": 5565, "OffsetEndMs": 5775}, {"Word": "or", "OffsetStartMs": 5775, "OffsetEndMs": 6030}, {"Word": "described", "OffsetStartMs": 6030, "OffsetEndMs": 6410}, {"Word": "to", "OffsetStartMs": 6520, "OffsetEndMs": 6750}, {"Word": "you", "OffsetStartMs": 6750, "OffsetEndMs": 6980}, {"Word": "what", "OffsetStartMs": 7090, "OffsetEndMs": 7425}, {"Word": "that", "OffsetStartMs": 7425, "OffsetEndMs": 7760}, {"Word": "actually", "OffsetStartMs": 7780, "OffsetEndMs": 8085}, {"Word": "is", "OffsetStartMs": 8085, "OffsetEndMs": 8390}], "SpeechSpeed": 13.8}, {"FinalSentence": "I think a great example, and one of my favorite examples throughout this entire course that gets at this idea of the latent variable is this little story from plato's republic.", "SliceSentence": "I think a great example and one of my favorite examples throughout this entire course that gets at this idea of the latent variable is this little story from plato's republic", "StartMs": 477920, "EndMs": 489920, "WordsNum": 31, "Words": [{"Word": "I", "OffsetStartMs": 430, "OffsetEndMs": 735}, {"Word": "think", "OffsetStartMs": 735, "OffsetEndMs": 915}, {"Word": "a", "OffsetStartMs": 915, "OffsetEndMs": 1095}, {"Word": "great", "OffsetStartMs": 1095, "OffsetEndMs": 1395}, {"Word": "example", "OffsetStartMs": 1395, "OffsetEndMs": 1740}, {"Word": "and", "OffsetStartMs": 1740, "OffsetEndMs": 1980}, {"Word": "one", "OffsetStartMs": 1980, "OffsetEndMs": 2130}, {"Word": "of", "OffsetStartMs": 2130, "OffsetEndMs": 2265}, {"Word": "my", "OffsetStartMs": 2265, "OffsetEndMs": 2445}, {"Word": "favorite", "OffsetStartMs": 2445, "OffsetEndMs": 2750}, {"Word": "examples", "OffsetStartMs": 2770, "OffsetEndMs": 3170}, {"Word": "throughout", "OffsetStartMs": 3550, "OffsetEndMs": 3855}, {"Word": "this", "OffsetStartMs": 3855, "OffsetEndMs": 4140}, {"Word": "entire", "OffsetStartMs": 4140, "OffsetEndMs": 4515}, {"Word": "course", "OffsetStartMs": 4515, "OffsetEndMs": 4910}, {"Word": "that", "OffsetStartMs": 5680, "OffsetEndMs": 6080}, {"Word": "gets", "OffsetStartMs": 6220, "OffsetEndMs": 6525}, {"Word": "at", "OffsetStartMs": 6525, "OffsetEndMs": 6705}, {"Word": "this", "OffsetStartMs": 6705, "OffsetEndMs": 6945}, {"Word": "idea", "OffsetStartMs": 6945, "OffsetEndMs": 7170}, {"Word": "of", "OffsetStartMs": 7170, "OffsetEndMs": 7305}, {"Word": "the", "OffsetStartMs": 7305, "OffsetEndMs": 7455}, {"Word": "latent", "OffsetStartMs": 7455, "OffsetEndMs": 7785}, {"Word": "variable", "OffsetStartMs": 7785, "OffsetEndMs": 8060}, {"Word": "is", "OffsetStartMs": 8530, "OffsetEndMs": 8820}, {"Word": "this", "OffsetStartMs": 8820, "OffsetEndMs": 9030}, {"Word": "little", "OffsetStartMs": 9030, "OffsetEndMs": 9330}, {"Word": "story", "OffsetStartMs": 9330, "OffsetEndMs": 9710}, {"Word": "from", "OffsetStartMs": 9730, "OffsetEndMs": 10095}, {"Word": "plato's", "OffsetStartMs": 10095, "OffsetEndMs": 10850}, {"Word": "republic", "OffsetStartMs": 10900, "OffsetEndMs": 11300}], "SpeechSpeed": 14.5}, {"FinalSentence": "Which is known as the myth of the cave.", "SliceSentence": "Which is known as the myth of the cave", "StartMs": 489920, "EndMs": 493180, "WordsNum": 9, "Words": [{"Word": "Which", "OffsetStartMs": 40, "OffsetEndMs": 375}, {"Word": "is", "OffsetStartMs": 375, "OffsetEndMs": 630}, {"Word": "known", "OffsetStartMs": 630, "OffsetEndMs": 900}, {"Word": "as", "OffsetStartMs": 900, "OffsetEndMs": 1250}, {"Word": "the", "OffsetStartMs": 1270, "OffsetEndMs": 1545}, {"Word": "myth", "OffsetStartMs": 1545, "OffsetEndMs": 1770}, {"Word": "of", "OffsetStartMs": 1770, "OffsetEndMs": 1980}, {"Word": "the", "OffsetStartMs": 1980, "OffsetEndMs": 2130}, {"Word": "cave", "OffsetStartMs": 2130, "OffsetEndMs": 2420}], "SpeechSpeed": 11.7}, {"FinalSentence": "In this myth, there is a group of prisoners, and as part of their punishment, they're constrained to face a wall. Now the only things that prisoners can observe are shadows of objects that are passing in front of a fire that's behind them, and they're observing the casting of the shadows on the wall of this cave.", "SliceSentence": "In this myth there is a group of prisoners and as part of their punishment they're constrained to face a wall . Nowthe only things that prisoners can observe are shadows of objects that are passing in front of a fire that's behind them and they're observing the casting of the shadows on the wall of this cave", "StartMs": 493340, "EndMs": 516080, "WordsNum": 58, "Words": [{"Word": "In", "OffsetStartMs": 70, "OffsetEndMs": 360}, {"Word": "this", "OffsetStartMs": 360, "OffsetEndMs": 555}, {"Word": "myth", "OffsetStartMs": 555, "OffsetEndMs": 860}, {"Word": "there", "OffsetStartMs": 1000, "OffsetEndMs": 1260}, {"Word": "is", "OffsetStartMs": 1260, "OffsetEndMs": 1395}, {"Word": "a", "OffsetStartMs": 1395, "OffsetEndMs": 1560}, {"Word": "group", "OffsetStartMs": 1560, "OffsetEndMs": 1770}, {"Word": "of", "OffsetStartMs": 1770, "OffsetEndMs": 2010}, {"Word": "prisoners", "OffsetStartMs": 2010, "OffsetEndMs": 2540}, {"Word": "and", "OffsetStartMs": 3040, "OffsetEndMs": 3345}, {"Word": "as", "OffsetStartMs": 3345, "OffsetEndMs": 3570}, {"Word": "part", "OffsetStartMs": 3570, "OffsetEndMs": 3780}, {"Word": "of", "OffsetStartMs": 3780, "OffsetEndMs": 3945}, {"Word": "their", "OffsetStartMs": 3945, "OffsetEndMs": 4155}, {"Word": "punishment", "OffsetStartMs": 4155, "OffsetEndMs": 4785}, {"Word": "they're", "OffsetStartMs": 4785, "OffsetEndMs": 5130}, {"Word": "constrained", "OffsetStartMs": 5130, "OffsetEndMs": 5660}, {"Word": "to", "OffsetStartMs": 5770, "OffsetEndMs": 6105}, {"Word": "face", "OffsetStartMs": 6105, "OffsetEndMs": 6330}, {"Word": "a", "OffsetStartMs": 6330, "OffsetEndMs": 6480}, {"Word": "wall", "OffsetStartMs": 6480, "OffsetEndMs": 6740}, {"Word": ".", "OffsetStartMs": 7630, "OffsetEndMs": 8030}, {"Word": "Nowthe", "OffsetStartMs": 8230, "OffsetEndMs": 8505}, {"Word": "only", "OffsetStartMs": 8505, "OffsetEndMs": 8775}, {"Word": "things", "OffsetStartMs": 8775, "OffsetEndMs": 9135}, {"Word": "that", "OffsetStartMs": 9135, "OffsetEndMs": 9420}, {"Word": "prisoners", "OffsetStartMs": 9420, "OffsetEndMs": 9885}, {"Word": "can", "OffsetStartMs": 9885, "OffsetEndMs": 10185}, {"Word": "observe", "OffsetStartMs": 10185, "OffsetEndMs": 10550}, {"Word": "are", "OffsetStartMs": 10960, "OffsetEndMs": 11360}, {"Word": "shadows", "OffsetStartMs": 11470, "OffsetEndMs": 12110}, {"Word": "of", "OffsetStartMs": 12130, "OffsetEndMs": 12530}, {"Word": "objects", "OffsetStartMs": 12700, "OffsetEndMs": 13100}, {"Word": "that", "OffsetStartMs": 13540, "OffsetEndMs": 13860}, {"Word": "are", "OffsetStartMs": 13860, "OffsetEndMs": 14180}, {"Word": "passing", "OffsetStartMs": 14320, "OffsetEndMs": 14720}, {"Word": "in", "OffsetStartMs": 14740, "OffsetEndMs": 15045}, {"Word": "front", "OffsetStartMs": 15045, "OffsetEndMs": 15255}, {"Word": "of", "OffsetStartMs": 15255, "OffsetEndMs": 15405}, {"Word": "a", "OffsetStartMs": 15405, "OffsetEndMs": 15555}, {"Word": "fire", "OffsetStartMs": 15555, "OffsetEndMs": 15855}, {"Word": "that's", "OffsetStartMs": 15855, "OffsetEndMs": 16275}, {"Word": "behind", "OffsetStartMs": 16275, "OffsetEndMs": 16545}, {"Word": "them", "OffsetStartMs": 16545, "OffsetEndMs": 16880}, {"Word": "and", "OffsetStartMs": 17260, "OffsetEndMs": 17535}, {"Word": "they're", "OffsetStartMs": 17535, "OffsetEndMs": 17865}, {"Word": "observing", "OffsetStartMs": 17865, "OffsetEndMs": 18230}, {"Word": "the", "OffsetStartMs": 18400, "OffsetEndMs": 18705}, {"Word": "casting", "OffsetStartMs": 18705, "OffsetEndMs": 19215}, {"Word": "of", "OffsetStartMs": 19215, "OffsetEndMs": 19350}, {"Word": "the", "OffsetStartMs": 19350, "OffsetEndMs": 19500}, {"Word": "shadows", "OffsetStartMs": 19500, "OffsetEndMs": 19970}, {"Word": "on", "OffsetStartMs": 20260, "OffsetEndMs": 20660}, {"Word": "the", "OffsetStartMs": 20770, "OffsetEndMs": 21060}, {"Word": "wall", "OffsetStartMs": 21060, "OffsetEndMs": 21315}, {"Word": "of", "OffsetStartMs": 21315, "OffsetEndMs": 21555}, {"Word": "this", "OffsetStartMs": 21555, "OffsetEndMs": 21765}, {"Word": "cave", "OffsetStartMs": 21765, "OffsetEndMs": 22100}], "SpeechSpeed": 13.5}, {"FinalSentence": "To the prisoners, those shadows are the only things they see, their observations, they can measure them. They can give them names, because to them that's their reality. But they're unable to directly see the underlying objects, the true factors themselves, that are casting those shadows.", "SliceSentence": "To the prisoners those shadows are the only things they see their observations they can measure them . Theycan give them names because to them that's their reality . Butthey're unable to directly see the underlying objects the true factors themselves that are casting those shadows", "StartMs": 516620, "EndMs": 534620, "WordsNum": 46, "Words": [{"Word": "To", "OffsetStartMs": 160, "OffsetEndMs": 405}, {"Word": "the", "OffsetStartMs": 405, "OffsetEndMs": 525}, {"Word": "prisoners", "OffsetStartMs": 525, "OffsetEndMs": 990}, {"Word": "those", "OffsetStartMs": 990, "OffsetEndMs": 1275}, {"Word": "shadows", "OffsetStartMs": 1275, "OffsetEndMs": 1770}, {"Word": "are", "OffsetStartMs": 1770, "OffsetEndMs": 1965}, {"Word": "the", "OffsetStartMs": 1965, "OffsetEndMs": 2100}, {"Word": "only", "OffsetStartMs": 2100, "OffsetEndMs": 2340}, {"Word": "things", "OffsetStartMs": 2340, "OffsetEndMs": 2625}, {"Word": "they", "OffsetStartMs": 2625, "OffsetEndMs": 2865}, {"Word": "see", "OffsetStartMs": 2865, "OffsetEndMs": 3180}, {"Word": "their", "OffsetStartMs": 3180, "OffsetEndMs": 3555}, {"Word": "observations", "OffsetStartMs": 3555, "OffsetEndMs": 4100}, {"Word": "they", "OffsetStartMs": 4420, "OffsetEndMs": 4695}, {"Word": "can", "OffsetStartMs": 4695, "OffsetEndMs": 4845}, {"Word": "measure", "OffsetStartMs": 4845, "OffsetEndMs": 5070}, {"Word": "them", "OffsetStartMs": 5070, "OffsetEndMs": 5340}, {"Word": ".", "OffsetStartMs": 5340, "OffsetEndMs": 5520}, {"Word": "Theycan", "OffsetStartMs": 5520, "OffsetEndMs": 5670}, {"Word": "give", "OffsetStartMs": 5670, "OffsetEndMs": 5835}, {"Word": "them", "OffsetStartMs": 5835, "OffsetEndMs": 6000}, {"Word": "names", "OffsetStartMs": 6000, "OffsetEndMs": 6290}, {"Word": "because", "OffsetStartMs": 6790, "OffsetEndMs": 7110}, {"Word": "to", "OffsetStartMs": 7110, "OffsetEndMs": 7290}, {"Word": "them", "OffsetStartMs": 7290, "OffsetEndMs": 7550}, {"Word": "that's", "OffsetStartMs": 7600, "OffsetEndMs": 8100}, {"Word": "their", "OffsetStartMs": 8100, "OffsetEndMs": 8340}, {"Word": "reality", "OffsetStartMs": 8340, "OffsetEndMs": 8660}, {"Word": ".", "OffsetStartMs": 9760, "OffsetEndMs": 10160}, {"Word": "Butthey're", "OffsetStartMs": 10180, "OffsetEndMs": 10635}, {"Word": "unable", "OffsetStartMs": 10635, "OffsetEndMs": 10980}, {"Word": "to", "OffsetStartMs": 10980, "OffsetEndMs": 11310}, {"Word": "directly", "OffsetStartMs": 11310, "OffsetEndMs": 11660}, {"Word": "see", "OffsetStartMs": 11800, "OffsetEndMs": 12200}, {"Word": "the", "OffsetStartMs": 12310, "OffsetEndMs": 12600}, {"Word": "underlying", "OffsetStartMs": 12600, "OffsetEndMs": 12890}, {"Word": "objects", "OffsetStartMs": 13810, "OffsetEndMs": 14190}, {"Word": "the", "OffsetStartMs": 14190, "OffsetEndMs": 14505}, {"Word": "true", "OffsetStartMs": 14505, "OffsetEndMs": 14760}, {"Word": "factors", "OffsetStartMs": 14760, "OffsetEndMs": 15080}, {"Word": "themselves", "OffsetStartMs": 15340, "OffsetEndMs": 15720}, {"Word": "that", "OffsetStartMs": 15720, "OffsetEndMs": 15960}, {"Word": "are", "OffsetStartMs": 15960, "OffsetEndMs": 16185}, {"Word": "casting", "OffsetStartMs": 16185, "OffsetEndMs": 16740}, {"Word": "those", "OffsetStartMs": 16740, "OffsetEndMs": 16950}, {"Word": "shadows", "OffsetStartMs": 16950, "OffsetEndMs": 17450}], "SpeechSpeed": 15.5}, {"FinalSentence": "Those objects here are like latent variables in machine learning.", "SliceSentence": "Those objects here are like latent variables in machine learning", "StartMs": 535080, "EndMs": 539920, "WordsNum": 10, "Words": [{"Word": "Those", "OffsetStartMs": 100, "OffsetEndMs": 500}, {"Word": "objects", "OffsetStartMs": 700, "OffsetEndMs": 1095}, {"Word": "here", "OffsetStartMs": 1095, "OffsetEndMs": 1470}, {"Word": "are", "OffsetStartMs": 1470, "OffsetEndMs": 1850}, {"Word": "like", "OffsetStartMs": 1870, "OffsetEndMs": 2270}, {"Word": "latent", "OffsetStartMs": 2380, "OffsetEndMs": 2835}, {"Word": "variables", "OffsetStartMs": 2835, "OffsetEndMs": 3300}, {"Word": "in", "OffsetStartMs": 3300, "OffsetEndMs": 3540}, {"Word": "machine", "OffsetStartMs": 3540, "OffsetEndMs": 3780}, {"Word": "learning", "OffsetStartMs": 3780, "OffsetEndMs": 4070}], "SpeechSpeed": 13.2}, {"FinalSentence": "They're not directly observable, but they are the true underlying features or explanatory factors that create the observed differences and variables that we can see and observe.", "SliceSentence": "They're not directly observable but they are the true underlying features or explanatory factors that create the observed differences and variables that we can see and observe", "StartMs": 539960, "EndMs": 553920, "WordsNum": 27, "Words": [{"Word": "They're", "OffsetStartMs": 70, "OffsetEndMs": 405}, {"Word": "not", "OffsetStartMs": 405, "OffsetEndMs": 615}, {"Word": "directly", "OffsetStartMs": 615, "OffsetEndMs": 980}, {"Word": "observable", "OffsetStartMs": 1030, "OffsetEndMs": 1730}, {"Word": "but", "OffsetStartMs": 2200, "OffsetEndMs": 2550}, {"Word": "they", "OffsetStartMs": 2550, "OffsetEndMs": 2760}, {"Word": "are", "OffsetStartMs": 2760, "OffsetEndMs": 3015}, {"Word": "the", "OffsetStartMs": 3015, "OffsetEndMs": 3345}, {"Word": "true", "OffsetStartMs": 3345, "OffsetEndMs": 3615}, {"Word": "underlying", "OffsetStartMs": 3615, "OffsetEndMs": 3950}, {"Word": "features", "OffsetStartMs": 4240, "OffsetEndMs": 4640}, {"Word": "or", "OffsetStartMs": 4930, "OffsetEndMs": 5330}, {"Word": "explanatory", "OffsetStartMs": 5560, "OffsetEndMs": 6285}, {"Word": "factors", "OffsetStartMs": 6285, "OffsetEndMs": 6620}, {"Word": "that", "OffsetStartMs": 6760, "OffsetEndMs": 7160}, {"Word": "create", "OffsetStartMs": 7600, "OffsetEndMs": 7965}, {"Word": "the", "OffsetStartMs": 7965, "OffsetEndMs": 8310}, {"Word": "observed", "OffsetStartMs": 8310, "OffsetEndMs": 8690}, {"Word": "differences", "OffsetStartMs": 8710, "OffsetEndMs": 9110}, {"Word": "and", "OffsetStartMs": 9880, "OffsetEndMs": 10280}, {"Word": "variables", "OffsetStartMs": 10360, "OffsetEndMs": 11010}, {"Word": "that", "OffsetStartMs": 11010, "OffsetEndMs": 11360}, {"Word": "we", "OffsetStartMs": 11470, "OffsetEndMs": 11745}, {"Word": "can", "OffsetStartMs": 11745, "OffsetEndMs": 11940}, {"Word": "see", "OffsetStartMs": 11940, "OffsetEndMs": 12240}, {"Word": "and", "OffsetStartMs": 12240, "OffsetEndMs": 12570}, {"Word": "observe", "OffsetStartMs": 12570, "OffsetEndMs": 12920}], "SpeechSpeed": 12.5}, {"FinalSentence": "And this gets at the goal of generative modeling, which is to find ways that we can actually learn these hidden features, these underlying latent variables, even when we're only given observations of the observed data.", "SliceSentence": "And this gets at the goal of generative modeling which is to find ways that we can actually learn these hidden features these underlying latent variables even when we're only given observations of the observed data", "StartMs": 554960, "EndMs": 569380, "WordsNum": 36, "Words": [{"Word": "And", "OffsetStartMs": 70, "OffsetEndMs": 360}, {"Word": "this", "OffsetStartMs": 360, "OffsetEndMs": 650}, {"Word": "gets", "OffsetStartMs": 1120, "OffsetEndMs": 1410}, {"Word": "at", "OffsetStartMs": 1410, "OffsetEndMs": 1700}, {"Word": "the", "OffsetStartMs": 1780, "OffsetEndMs": 2070}, {"Word": "goal", "OffsetStartMs": 2070, "OffsetEndMs": 2360}, {"Word": "of", "OffsetStartMs": 2410, "OffsetEndMs": 2715}, {"Word": "generative", "OffsetStartMs": 2715, "OffsetEndMs": 3165}, {"Word": "modeling", "OffsetStartMs": 3165, "OffsetEndMs": 3680}, {"Word": "which", "OffsetStartMs": 3970, "OffsetEndMs": 4260}, {"Word": "is", "OffsetStartMs": 4260, "OffsetEndMs": 4425}, {"Word": "to", "OffsetStartMs": 4425, "OffsetEndMs": 4590}, {"Word": "find", "OffsetStartMs": 4590, "OffsetEndMs": 4845}, {"Word": "ways", "OffsetStartMs": 4845, "OffsetEndMs": 5175}, {"Word": "that", "OffsetStartMs": 5175, "OffsetEndMs": 5400}, {"Word": "we", "OffsetStartMs": 5400, "OffsetEndMs": 5520}, {"Word": "can", "OffsetStartMs": 5520, "OffsetEndMs": 5780}, {"Word": "actually", "OffsetStartMs": 5830, "OffsetEndMs": 6165}, {"Word": "learn", "OffsetStartMs": 6165, "OffsetEndMs": 6450}, {"Word": "these", "OffsetStartMs": 6450, "OffsetEndMs": 6720}, {"Word": "hidden", "OffsetStartMs": 6720, "OffsetEndMs": 7005}, {"Word": "features", "OffsetStartMs": 7005, "OffsetEndMs": 7370}, {"Word": "these", "OffsetStartMs": 7480, "OffsetEndMs": 7800}, {"Word": "underlying", "OffsetStartMs": 7800, "OffsetEndMs": 8120}, {"Word": "latent", "OffsetStartMs": 8350, "OffsetEndMs": 8790}, {"Word": "variables", "OffsetStartMs": 8790, "OffsetEndMs": 9380}, {"Word": "even", "OffsetStartMs": 9700, "OffsetEndMs": 10080}, {"Word": "when", "OffsetStartMs": 10080, "OffsetEndMs": 10365}, {"Word": "we're", "OffsetStartMs": 10365, "OffsetEndMs": 10605}, {"Word": "only", "OffsetStartMs": 10605, "OffsetEndMs": 10845}, {"Word": "given", "OffsetStartMs": 10845, "OffsetEndMs": 11240}, {"Word": "observations", "OffsetStartMs": 11590, "OffsetEndMs": 12140}, {"Word": "of", "OffsetStartMs": 12340, "OffsetEndMs": 12705}, {"Word": "the", "OffsetStartMs": 12705, "OffsetEndMs": 13020}, {"Word": "observed", "OffsetStartMs": 13020, "OffsetEndMs": 13370}, {"Word": "data", "OffsetStartMs": 13390, "OffsetEndMs": 13790}], "SpeechSpeed": 14.8}, {"FinalSentence": "So let's start by discussing a very simple generative model that tries to do this through the idea of encoding the data input.", "SliceSentence": "So let's start by discussing a very simple generative model that tries to do this through the idea of encoding the data input", "StartMs": 571340, "EndMs": 580320, "WordsNum": 23, "Words": [{"Word": "So", "OffsetStartMs": 190, "OffsetEndMs": 590}, {"Word": "let's", "OffsetStartMs": 910, "OffsetEndMs": 1350}, {"Word": "start", "OffsetStartMs": 1350, "OffsetEndMs": 1560}, {"Word": "by", "OffsetStartMs": 1560, "OffsetEndMs": 1880}, {"Word": "discussing", "OffsetStartMs": 1900, "OffsetEndMs": 2280}, {"Word": "a", "OffsetStartMs": 2280, "OffsetEndMs": 2565}, {"Word": "very", "OffsetStartMs": 2565, "OffsetEndMs": 2850}, {"Word": "simple", "OffsetStartMs": 2850, "OffsetEndMs": 3165}, {"Word": "generative", "OffsetStartMs": 3165, "OffsetEndMs": 3645}, {"Word": "model", "OffsetStartMs": 3645, "OffsetEndMs": 3900}, {"Word": "that", "OffsetStartMs": 3900, "OffsetEndMs": 4230}, {"Word": "tries", "OffsetStartMs": 4230, "OffsetEndMs": 4545}, {"Word": "to", "OffsetStartMs": 4545, "OffsetEndMs": 4770}, {"Word": "do", "OffsetStartMs": 4770, "OffsetEndMs": 4890}, {"Word": "this", "OffsetStartMs": 4890, "OffsetEndMs": 5150}, {"Word": "through", "OffsetStartMs": 5470, "OffsetEndMs": 5745}, {"Word": "the", "OffsetStartMs": 5745, "OffsetEndMs": 5985}, {"Word": "idea", "OffsetStartMs": 5985, "OffsetEndMs": 6285}, {"Word": "of", "OffsetStartMs": 6285, "OffsetEndMs": 6525}, {"Word": "encoding", "OffsetStartMs": 6525, "OffsetEndMs": 7250}, {"Word": "the", "OffsetStartMs": 7270, "OffsetEndMs": 7545}, {"Word": "data", "OffsetStartMs": 7545, "OffsetEndMs": 7820}, {"Word": "input", "OffsetStartMs": 7900, "OffsetEndMs": 8300}], "SpeechSpeed": 13.9}, {"FinalSentence": "The models we're going to talk about are called auto encoders.", "SliceSentence": "The models we 're going to talk about are called auto encoders", "StartMs": 580320, "EndMs": 583860, "WordsNum": 12, "Words": [{"Word": "The", "OffsetStartMs": 0, "OffsetEndMs": 120}, {"Word": "models", "OffsetStartMs": 120, "OffsetEndMs": 360}, {"Word": "we", "OffsetStartMs": 360, "OffsetEndMs": 570}, {"Word": "'re", "OffsetStartMs": 570, "OffsetEndMs": 645}, {"Word": "going", "OffsetStartMs": 645, "OffsetEndMs": 780}, {"Word": "to", "OffsetStartMs": 780, "OffsetEndMs": 930}, {"Word": "talk", "OffsetStartMs": 930, "OffsetEndMs": 1125}, {"Word": "about", "OffsetStartMs": 1125, "OffsetEndMs": 1380}, {"Word": "are", "OffsetStartMs": 1380, "OffsetEndMs": 1635}, {"Word": "called", "OffsetStartMs": 1635, "OffsetEndMs": 1935}, {"Word": "auto", "OffsetStartMs": 1935, "OffsetEndMs": 2235}, {"Word": "encoders", "OffsetStartMs": 2235, "OffsetEndMs": 2900}], "SpeechSpeed": 17.2}, {"FinalSentence": "And to take a look at how an auto encoder works, we'll go through step by step, starting with the first step of taking some raw input data and passing it through a series of neural network layers.", "SliceSentence": "And to take a look at how an auto encoder works we'll go through step by step starting with the first step of taking some raw input data and passing it through a series of neural network layers", "StartMs": 583860, "EndMs": 598380, "WordsNum": 38, "Words": [{"Word": "And", "OffsetStartMs": 190, "OffsetEndMs": 495}, {"Word": "to", "OffsetStartMs": 495, "OffsetEndMs": 660}, {"Word": "take", "OffsetStartMs": 660, "OffsetEndMs": 795}, {"Word": "a", "OffsetStartMs": 795, "OffsetEndMs": 945}, {"Word": "look", "OffsetStartMs": 945, "OffsetEndMs": 1170}, {"Word": "at", "OffsetStartMs": 1170, "OffsetEndMs": 1485}, {"Word": "how", "OffsetStartMs": 1485, "OffsetEndMs": 1770}, {"Word": "an", "OffsetStartMs": 1770, "OffsetEndMs": 1980}, {"Word": "auto", "OffsetStartMs": 1980, "OffsetEndMs": 2235}, {"Word": "encoder", "OffsetStartMs": 2235, "OffsetEndMs": 2805}, {"Word": "works", "OffsetStartMs": 2805, "OffsetEndMs": 3080}, {"Word": "we'll", "OffsetStartMs": 3430, "OffsetEndMs": 3735}, {"Word": "go", "OffsetStartMs": 3735, "OffsetEndMs": 3900}, {"Word": "through", "OffsetStartMs": 3900, "OffsetEndMs": 4125}, {"Word": "step", "OffsetStartMs": 4125, "OffsetEndMs": 4320}, {"Word": "by", "OffsetStartMs": 4320, "OffsetEndMs": 4530}, {"Word": "step", "OffsetStartMs": 4530, "OffsetEndMs": 4850}, {"Word": "starting", "OffsetStartMs": 5470, "OffsetEndMs": 5870}, {"Word": "with", "OffsetStartMs": 5890, "OffsetEndMs": 6290}, {"Word": "the", "OffsetStartMs": 6430, "OffsetEndMs": 6830}, {"Word": "first", "OffsetStartMs": 7300, "OffsetEndMs": 7650}, {"Word": "step", "OffsetStartMs": 7650, "OffsetEndMs": 7935}, {"Word": "of", "OffsetStartMs": 7935, "OffsetEndMs": 8205}, {"Word": "taking", "OffsetStartMs": 8205, "OffsetEndMs": 8535}, {"Word": "some", "OffsetStartMs": 8535, "OffsetEndMs": 8880}, {"Word": "raw", "OffsetStartMs": 8880, "OffsetEndMs": 9230}, {"Word": "input", "OffsetStartMs": 9310, "OffsetEndMs": 9600}, {"Word": "data", "OffsetStartMs": 9600, "OffsetEndMs": 9890}, {"Word": "and", "OffsetStartMs": 10570, "OffsetEndMs": 10950}, {"Word": "passing", "OffsetStartMs": 10950, "OffsetEndMs": 11310}, {"Word": "it", "OffsetStartMs": 11310, "OffsetEndMs": 11595}, {"Word": "through", "OffsetStartMs": 11595, "OffsetEndMs": 11835}, {"Word": "a", "OffsetStartMs": 11835, "OffsetEndMs": 12135}, {"Word": "series", "OffsetStartMs": 12135, "OffsetEndMs": 12495}, {"Word": "of", "OffsetStartMs": 12495, "OffsetEndMs": 12885}, {"Word": "neural", "OffsetStartMs": 12885, "OffsetEndMs": 13230}, {"Word": "network", "OffsetStartMs": 13230, "OffsetEndMs": 13470}, {"Word": "layers", "OffsetStartMs": 13470, "OffsetEndMs": 14000}], "SpeechSpeed": 13.3}, {"FinalSentence": "Now, the output of this, of this first step is what we refer to as a low dimensional latent space. It's an encoded representation of those underlying features.", "SliceSentence": "Now the output of this of this first step is what we refer to as a low dimensional latent space .It's an encoded representation of those underlying features", "StartMs": 598660, "EndMs": 611780, "WordsNum": 28, "Words": [{"Word": "Now", "OffsetStartMs": 160, "OffsetEndMs": 560}, {"Word": "the", "OffsetStartMs": 730, "OffsetEndMs": 1130}, {"Word": "output", "OffsetStartMs": 1270, "OffsetEndMs": 1665}, {"Word": "of", "OffsetStartMs": 1665, "OffsetEndMs": 1995}, {"Word": "this", "OffsetStartMs": 1995, "OffsetEndMs": 2330}, {"Word": "of", "OffsetStartMs": 3100, "OffsetEndMs": 3375}, {"Word": "this", "OffsetStartMs": 3375, "OffsetEndMs": 3650}, {"Word": "first", "OffsetStartMs": 3730, "OffsetEndMs": 4080}, {"Word": "step", "OffsetStartMs": 4080, "OffsetEndMs": 4430}, {"Word": "is", "OffsetStartMs": 4660, "OffsetEndMs": 5010}, {"Word": "what", "OffsetStartMs": 5010, "OffsetEndMs": 5235}, {"Word": "we", "OffsetStartMs": 5235, "OffsetEndMs": 5385}, {"Word": "refer", "OffsetStartMs": 5385, "OffsetEndMs": 5660}, {"Word": "to", "OffsetStartMs": 5710, "OffsetEndMs": 6015}, {"Word": "as", "OffsetStartMs": 6015, "OffsetEndMs": 6195}, {"Word": "a", "OffsetStartMs": 6195, "OffsetEndMs": 6360}, {"Word": "low", "OffsetStartMs": 6360, "OffsetEndMs": 6585}, {"Word": "dimensional", "OffsetStartMs": 6585, "OffsetEndMs": 7260}, {"Word": "latent", "OffsetStartMs": 7260, "OffsetEndMs": 7650}, {"Word": "space", "OffsetStartMs": 7650, "OffsetEndMs": 7970}, {"Word": ".It's", "OffsetStartMs": 8410, "OffsetEndMs": 8730}, {"Word": "an", "OffsetStartMs": 8730, "OffsetEndMs": 8850}, {"Word": "encoded", "OffsetStartMs": 8850, "OffsetEndMs": 9650}, {"Word": "representation", "OffsetStartMs": 9850, "OffsetEndMs": 10755}, {"Word": "of", "OffsetStartMs": 10755, "OffsetEndMs": 11070}, {"Word": "those", "OffsetStartMs": 11070, "OffsetEndMs": 11325}, {"Word": "underlying", "OffsetStartMs": 11325, "OffsetEndMs": 11660}, {"Word": "features", "OffsetStartMs": 11920, "OffsetEndMs": 12320}], "SpeechSpeed": 11.8}, {"FinalSentence": "And that's our goal in trying to train this model and predict those features.", "SliceSentence": "And that 's our goal in trying to train this model and predict those features", "StartMs": 611780, "EndMs": 616760, "WordsNum": 15, "Words": [{"Word": "And", "OffsetStartMs": 0, "OffsetEndMs": 270}, {"Word": "that", "OffsetStartMs": 270, "OffsetEndMs": 420}, {"Word": "'s", "OffsetStartMs": 420, "OffsetEndMs": 525}, {"Word": "our", "OffsetStartMs": 525, "OffsetEndMs": 675}, {"Word": "goal", "OffsetStartMs": 675, "OffsetEndMs": 930}, {"Word": "in", "OffsetStartMs": 930, "OffsetEndMs": 1245}, {"Word": "trying", "OffsetStartMs": 1245, "OffsetEndMs": 1575}, {"Word": "to", "OffsetStartMs": 1575, "OffsetEndMs": 1920}, {"Word": "train", "OffsetStartMs": 1920, "OffsetEndMs": 2190}, {"Word": "this", "OffsetStartMs": 2190, "OffsetEndMs": 2385}, {"Word": "model", "OffsetStartMs": 2385, "OffsetEndMs": 2655}, {"Word": "and", "OffsetStartMs": 2655, "OffsetEndMs": 2925}, {"Word": "predict", "OffsetStartMs": 2925, "OffsetEndMs": 3210}, {"Word": "those", "OffsetStartMs": 3210, "OffsetEndMs": 3525}, {"Word": "features", "OffsetStartMs": 3525, "OffsetEndMs": 3860}], "SpeechSpeed": 15.3}, {"FinalSentence": "The reason a model like this is called an encoder or an auto encoder is that it's mapping the data X into this vector of latent variables z.", "SliceSentence": "The reason a model like this is called an encoder or an auto encoder is that it's mapping the data X into this vector of latent variables z", "StartMs": 617020, "EndMs": 627880, "WordsNum": 28, "Words": [{"Word": "The", "OffsetStartMs": 100, "OffsetEndMs": 360}, {"Word": "reason", "OffsetStartMs": 360, "OffsetEndMs": 555}, {"Word": "a", "OffsetStartMs": 555, "OffsetEndMs": 735}, {"Word": "model", "OffsetStartMs": 735, "OffsetEndMs": 915}, {"Word": "like", "OffsetStartMs": 915, "OffsetEndMs": 1155}, {"Word": "this", "OffsetStartMs": 1155, "OffsetEndMs": 1350}, {"Word": "is", "OffsetStartMs": 1350, "OffsetEndMs": 1545}, {"Word": "called", "OffsetStartMs": 1545, "OffsetEndMs": 1740}, {"Word": "an", "OffsetStartMs": 1740, "OffsetEndMs": 2025}, {"Word": "encoder", "OffsetStartMs": 2025, "OffsetEndMs": 2685}, {"Word": "or", "OffsetStartMs": 2685, "OffsetEndMs": 2745}, {"Word": "an", "OffsetStartMs": 2745, "OffsetEndMs": 2880}, {"Word": "auto", "OffsetStartMs": 2880, "OffsetEndMs": 3120}, {"Word": "encoder", "OffsetStartMs": 3120, "OffsetEndMs": 3770}, {"Word": "is", "OffsetStartMs": 4060, "OffsetEndMs": 4395}, {"Word": "that", "OffsetStartMs": 4395, "OffsetEndMs": 4725}, {"Word": "it's", "OffsetStartMs": 4725, "OffsetEndMs": 5100}, {"Word": "mapping", "OffsetStartMs": 5100, "OffsetEndMs": 5520}, {"Word": "the", "OffsetStartMs": 5520, "OffsetEndMs": 5670}, {"Word": "data", "OffsetStartMs": 5670, "OffsetEndMs": 5930}, {"Word": "X", "OffsetStartMs": 6220, "OffsetEndMs": 6620}, {"Word": "into", "OffsetStartMs": 7090, "OffsetEndMs": 7440}, {"Word": "this", "OffsetStartMs": 7440, "OffsetEndMs": 7710}, {"Word": "vector", "OffsetStartMs": 7710, "OffsetEndMs": 8085}, {"Word": "of", "OffsetStartMs": 8085, "OffsetEndMs": 8385}, {"Word": "latent", "OffsetStartMs": 8385, "OffsetEndMs": 8775}, {"Word": "variables", "OffsetStartMs": 8775, "OffsetEndMs": 9380}, {"Word": "z", "OffsetStartMs": 9550, "OffsetEndMs": 9950}], "SpeechSpeed": 12.8}, {"FinalSentence": "Now, let's ask ourselves a question. Let's pause for a moment.", "SliceSentence": "Now let 's ask ourselves a question . Let's pause for a moment", "StartMs": 627880, "EndMs": 631720, "WordsNum": 13, "Words": [{"Word": "Now", "OffsetStartMs": 70, "OffsetEndMs": 470}, {"Word": "let", "OffsetStartMs": 760, "OffsetEndMs": 990}, {"Word": "'s", "OffsetStartMs": 990, "OffsetEndMs": 1065}, {"Word": "ask", "OffsetStartMs": 1065, "OffsetEndMs": 1305}, {"Word": "ourselves", "OffsetStartMs": 1305, "OffsetEndMs": 1590}, {"Word": "a", "OffsetStartMs": 1590, "OffsetEndMs": 1740}, {"Word": "question", "OffsetStartMs": 1740, "OffsetEndMs": 1965}, {"Word": ".", "OffsetStartMs": 1965, "OffsetEndMs": 2145}, {"Word": "Let's", "OffsetStartMs": 2145, "OffsetEndMs": 2250}, {"Word": "pause", "OffsetStartMs": 2250, "OffsetEndMs": 2475}, {"Word": "for", "OffsetStartMs": 2475, "OffsetEndMs": 2640}, {"Word": "a", "OffsetStartMs": 2640, "OffsetEndMs": 2715}, {"Word": "moment", "OffsetStartMs": 2715, "OffsetEndMs": 2960}], "SpeechSpeed": 15.4}, {"FinalSentence": "Why may we care about having this latent variable vector z be in a low dimensional space?", "SliceSentence": "Why may we care about having this latent variable vector z be in a low dimensional space", "StartMs": 631720, "EndMs": 639900, "WordsNum": 17, "Words": [{"Word": "Why", "OffsetStartMs": 0, "OffsetEndMs": 285}, {"Word": "may", "OffsetStartMs": 285, "OffsetEndMs": 585}, {"Word": "we", "OffsetStartMs": 585, "OffsetEndMs": 885}, {"Word": "care", "OffsetStartMs": 885, "OffsetEndMs": 1250}, {"Word": "about", "OffsetStartMs": 1390, "OffsetEndMs": 1790}, {"Word": "having", "OffsetStartMs": 2350, "OffsetEndMs": 2750}, {"Word": "this", "OffsetStartMs": 2770, "OffsetEndMs": 3150}, {"Word": "latent", "OffsetStartMs": 3150, "OffsetEndMs": 3600}, {"Word": "variable", "OffsetStartMs": 3600, "OffsetEndMs": 3890}, {"Word": "vector", "OffsetStartMs": 3910, "OffsetEndMs": 4340}, {"Word": "z", "OffsetStartMs": 4360, "OffsetEndMs": 4760}, {"Word": "be", "OffsetStartMs": 4930, "OffsetEndMs": 5310}, {"Word": "in", "OffsetStartMs": 5310, "OffsetEndMs": 5550}, {"Word": "a", "OffsetStartMs": 5550, "OffsetEndMs": 5700}, {"Word": "low", "OffsetStartMs": 5700, "OffsetEndMs": 5925}, {"Word": "dimensional", "OffsetStartMs": 5925, "OffsetEndMs": 6615}, {"Word": "space", "OffsetStartMs": 6615, "OffsetEndMs": 6950}], "SpeechSpeed": 10.8}, {"FinalSentence": "Anyone have any ideas?", "SliceSentence": "Anyone have any ideas", "StartMs": 640340, "EndMs": 642480, "WordsNum": 4, "Words": [{"Word": "Anyone", "OffsetStartMs": 280, "OffsetEndMs": 555}, {"Word": "have", "OffsetStartMs": 555, "OffsetEndMs": 690}, {"Word": "any", "OffsetStartMs": 690, "OffsetEndMs": 930}, {"Word": "ideas", "OffsetStartMs": 930, "OffsetEndMs": 1310}], "SpeechSpeed": 9.8}, {"FinalSentence": "Right.", "SliceSentence": "Right", "StartMs": 649620, "EndMs": 650760, "WordsNum": 1, "Words": [{"Word": "Right", "OffsetStartMs": 250, "OffsetEndMs": 650}], "SpeechSpeed": 4.4}, {"FinalSentence": "Maybe there are some ideas, yes.", "SliceSentence": "Maybe there are some ideas yes", "StartMs": 650940, "EndMs": 654680, "WordsNum": 6, "Words": [{"Word": "Maybe", "OffsetStartMs": 130, "OffsetEndMs": 465}, {"Word": "there", "OffsetStartMs": 465, "OffsetEndMs": 660}, {"Word": "are", "OffsetStartMs": 660, "OffsetEndMs": 825}, {"Word": "some", "OffsetStartMs": 825, "OffsetEndMs": 1125}, {"Word": "ideas", "OffsetStartMs": 1125, "OffsetEndMs": 1520}, {"Word": "yes", "OffsetStartMs": 2350, "OffsetEndMs": 2750}], "SpeechSpeed": 8.0}, {"FinalSentence": "The suggestion was that it's more efficient. Yes, that gets at it. The heart of the, of the question. The idea of having that low dimensional latent space is that it's a very efficient, compact encoding of the rich, high dimensional data that we may start with.", "SliceSentence": "The suggestion was that it's more efficient . Yesthat gets at it . Theheart of the of the question . Theidea of having that low dimensional latent space is that it's a very efficient compact encoding of the rich high dimensional data that we may start with", "StartMs": 654840, "EndMs": 673080, "WordsNum": 47, "Words": [{"Word": "The", "OffsetStartMs": 2230, "OffsetEndMs": 2535}, {"Word": "suggestion", "OffsetStartMs": 2535, "OffsetEndMs": 2910}, {"Word": "was", "OffsetStartMs": 2910, "OffsetEndMs": 3030}, {"Word": "that", "OffsetStartMs": 3030, "OffsetEndMs": 3150}, {"Word": "it's", "OffsetStartMs": 3150, "OffsetEndMs": 3360}, {"Word": "more", "OffsetStartMs": 3360, "OffsetEndMs": 3570}, {"Word": "efficient", "OffsetStartMs": 3570, "OffsetEndMs": 3920}, {"Word": ".", "OffsetStartMs": 3970, "OffsetEndMs": 4370}, {"Word": "Yesthat", "OffsetStartMs": 4480, "OffsetEndMs": 5000}, {"Word": "gets", "OffsetStartMs": 5500, "OffsetEndMs": 5790}, {"Word": "at", "OffsetStartMs": 5790, "OffsetEndMs": 5940}, {"Word": "it", "OffsetStartMs": 5940, "OffsetEndMs": 6135}, {"Word": ".", "OffsetStartMs": 6135, "OffsetEndMs": 6330}, {"Word": "Theheart", "OffsetStartMs": 6330, "OffsetEndMs": 6480}, {"Word": "of", "OffsetStartMs": 6480, "OffsetEndMs": 6615}, {"Word": "the", "OffsetStartMs": 6615, "OffsetEndMs": 6825}, {"Word": "of", "OffsetStartMs": 6825, "OffsetEndMs": 7095}, {"Word": "the", "OffsetStartMs": 7095, "OffsetEndMs": 7260}, {"Word": "question", "OffsetStartMs": 7260, "OffsetEndMs": 7520}, {"Word": ".", "OffsetStartMs": 8080, "OffsetEndMs": 8430}, {"Word": "Theidea", "OffsetStartMs": 8430, "OffsetEndMs": 8640}, {"Word": "of", "OffsetStartMs": 8640, "OffsetEndMs": 8820}, {"Word": "having", "OffsetStartMs": 8820, "OffsetEndMs": 9090}, {"Word": "that", "OffsetStartMs": 9090, "OffsetEndMs": 9360}, {"Word": "low", "OffsetStartMs": 9360, "OffsetEndMs": 9585}, {"Word": "dimensional", "OffsetStartMs": 9585, "OffsetEndMs": 10140}, {"Word": "latent", "OffsetStartMs": 10140, "OffsetEndMs": 10485}, {"Word": "space", "OffsetStartMs": 10485, "OffsetEndMs": 10755}, {"Word": "is", "OffsetStartMs": 10755, "OffsetEndMs": 10995}, {"Word": "that", "OffsetStartMs": 10995, "OffsetEndMs": 11145}, {"Word": "it's", "OffsetStartMs": 11145, "OffsetEndMs": 11310}, {"Word": "a", "OffsetStartMs": 11310, "OffsetEndMs": 11445}, {"Word": "very", "OffsetStartMs": 11445, "OffsetEndMs": 11750}, {"Word": "efficient", "OffsetStartMs": 11830, "OffsetEndMs": 12230}, {"Word": "compact", "OffsetStartMs": 12550, "OffsetEndMs": 13155}, {"Word": "encoding", "OffsetStartMs": 13155, "OffsetEndMs": 13880}, {"Word": "of", "OffsetStartMs": 14140, "OffsetEndMs": 14505}, {"Word": "the", "OffsetStartMs": 14505, "OffsetEndMs": 14775}, {"Word": "rich", "OffsetStartMs": 14775, "OffsetEndMs": 15080}, {"Word": "high", "OffsetStartMs": 15490, "OffsetEndMs": 15795}, {"Word": "dimensional", "OffsetStartMs": 15795, "OffsetEndMs": 16320}, {"Word": "data", "OffsetStartMs": 16320, "OffsetEndMs": 16545}, {"Word": "that", "OffsetStartMs": 16545, "OffsetEndMs": 16740}, {"Word": "we", "OffsetStartMs": 16740, "OffsetEndMs": 16875}, {"Word": "may", "OffsetStartMs": 16875, "OffsetEndMs": 17085}, {"Word": "start", "OffsetStartMs": 17085, "OffsetEndMs": 17340}, {"Word": "with", "OffsetStartMs": 17340, "OffsetEndMs": 17660}], "SpeechSpeed": 13.9}, {"FinalSentence": "As you pointed out, what this means is that we're able to compress data into this small feature representation of vector.", "SliceSentence": "As you pointed out what this means is that we're able to compress data into this small feature representation of vector", "StartMs": 673340, "EndMs": 682000, "WordsNum": 21, "Words": [{"Word": "As", "OffsetStartMs": 70, "OffsetEndMs": 420}, {"Word": "you", "OffsetStartMs": 420, "OffsetEndMs": 675}, {"Word": "pointed", "OffsetStartMs": 675, "OffsetEndMs": 915}, {"Word": "out", "OffsetStartMs": 915, "OffsetEndMs": 1250}, {"Word": "what", "OffsetStartMs": 1780, "OffsetEndMs": 2070}, {"Word": "this", "OffsetStartMs": 2070, "OffsetEndMs": 2265}, {"Word": "means", "OffsetStartMs": 2265, "OffsetEndMs": 2490}, {"Word": "is", "OffsetStartMs": 2490, "OffsetEndMs": 2685}, {"Word": "that", "OffsetStartMs": 2685, "OffsetEndMs": 2835}, {"Word": "we're", "OffsetStartMs": 2835, "OffsetEndMs": 3060}, {"Word": "able", "OffsetStartMs": 3060, "OffsetEndMs": 3300}, {"Word": "to", "OffsetStartMs": 3300, "OffsetEndMs": 3540}, {"Word": "compress", "OffsetStartMs": 3540, "OffsetEndMs": 4020}, {"Word": "data", "OffsetStartMs": 4020, "OffsetEndMs": 4370}, {"Word": "into", "OffsetStartMs": 4690, "OffsetEndMs": 5040}, {"Word": "this", "OffsetStartMs": 5040, "OffsetEndMs": 5355}, {"Word": "small", "OffsetStartMs": 5355, "OffsetEndMs": 5720}, {"Word": "feature", "OffsetStartMs": 6070, "OffsetEndMs": 6420}, {"Word": "representation", "OffsetStartMs": 6420, "OffsetEndMs": 7185}, {"Word": "of", "OffsetStartMs": 7185, "OffsetEndMs": 7425}, {"Word": "vector", "OffsetStartMs": 7425, "OffsetEndMs": 7760}], "SpeechSpeed": 13.7}, {"FinalSentence": "That captures this compactness and richness without requiring so much memory or so much storage.", "SliceSentence": "That captures this compactness and richness without requiring so much memory or so much storage", "StartMs": 682160, "EndMs": 689780, "WordsNum": 15, "Words": [{"Word": "That", "OffsetStartMs": 220, "OffsetEndMs": 620}, {"Word": "captures", "OffsetStartMs": 1060, "OffsetEndMs": 1620}, {"Word": "this", "OffsetStartMs": 1620, "OffsetEndMs": 1815}, {"Word": "compactness", "OffsetStartMs": 1815, "OffsetEndMs": 2460}, {"Word": "and", "OffsetStartMs": 2460, "OffsetEndMs": 2670}, {"Word": "richness", "OffsetStartMs": 2670, "OffsetEndMs": 3230}, {"Word": "without", "OffsetStartMs": 3730, "OffsetEndMs": 4130}, {"Word": "requiring", "OffsetStartMs": 4690, "OffsetEndMs": 5120}, {"Word": "so", "OffsetStartMs": 5140, "OffsetEndMs": 5400}, {"Word": "much", "OffsetStartMs": 5400, "OffsetEndMs": 5580}, {"Word": "memory", "OffsetStartMs": 5580, "OffsetEndMs": 5880}, {"Word": "or", "OffsetStartMs": 5880, "OffsetEndMs": 6165}, {"Word": "so", "OffsetStartMs": 6165, "OffsetEndMs": 6330}, {"Word": "much", "OffsetStartMs": 6330, "OffsetEndMs": 6510}, {"Word": "storage", "OffsetStartMs": 6510, "OffsetEndMs": 6830}], "SpeechSpeed": 12.5}, {"FinalSentence": "So how do we actually train the network to learn this latent variable vector?", "SliceSentence": "So how do we actually train the network to learn this latent variable vector", "StartMs": 690120, "EndMs": 695980, "WordsNum": 14, "Words": [{"Word": "So", "OffsetStartMs": 130, "OffsetEndMs": 530}, {"Word": "how", "OffsetStartMs": 610, "OffsetEndMs": 930}, {"Word": "do", "OffsetStartMs": 930, "OffsetEndMs": 1095}, {"Word": "we", "OffsetStartMs": 1095, "OffsetEndMs": 1335}, {"Word": "actually", "OffsetStartMs": 1335, "OffsetEndMs": 1665}, {"Word": "train", "OffsetStartMs": 1665, "OffsetEndMs": 1920}, {"Word": "the", "OffsetStartMs": 1920, "OffsetEndMs": 2100}, {"Word": "network", "OffsetStartMs": 2100, "OffsetEndMs": 2360}, {"Word": "to", "OffsetStartMs": 2590, "OffsetEndMs": 2970}, {"Word": "learn", "OffsetStartMs": 2970, "OffsetEndMs": 3285}, {"Word": "this", "OffsetStartMs": 3285, "OffsetEndMs": 3525}, {"Word": "latent", "OffsetStartMs": 3525, "OffsetEndMs": 3855}, {"Word": "variable", "OffsetStartMs": 3855, "OffsetEndMs": 4125}, {"Word": "vector", "OffsetStartMs": 4125, "OffsetEndMs": 4550}], "SpeechSpeed": 13.0}, {"FinalSentence": "Since we don't have training data, we can't explicitly observe these latent variables. Z, we need to do something more clever.", "SliceSentence": "Since we don't have training data we can't explicitly observe these latent variables . Zwe need to do something more clever", "StartMs": 696080, "EndMs": 704760, "WordsNum": 21, "Words": [{"Word": "Since", "OffsetStartMs": 190, "OffsetEndMs": 510}, {"Word": "we", "OffsetStartMs": 510, "OffsetEndMs": 705}, {"Word": "don't", "OffsetStartMs": 705, "OffsetEndMs": 960}, {"Word": "have", "OffsetStartMs": 960, "OffsetEndMs": 1170}, {"Word": "training", "OffsetStartMs": 1170, "OffsetEndMs": 1485}, {"Word": "data", "OffsetStartMs": 1485, "OffsetEndMs": 1815}, {"Word": "we", "OffsetStartMs": 1815, "OffsetEndMs": 2100}, {"Word": "can't", "OffsetStartMs": 2100, "OffsetEndMs": 2550}, {"Word": "explicitly", "OffsetStartMs": 2550, "OffsetEndMs": 3200}, {"Word": "observe", "OffsetStartMs": 3220, "OffsetEndMs": 3600}, {"Word": "these", "OffsetStartMs": 3600, "OffsetEndMs": 3900}, {"Word": "latent", "OffsetStartMs": 3900, "OffsetEndMs": 4245}, {"Word": "variables", "OffsetStartMs": 4245, "OffsetEndMs": 4710}, {"Word": ".", "OffsetStartMs": 4710, "OffsetEndMs": 5030}, {"Word": "Zwe", "OffsetStartMs": 5650, "OffsetEndMs": 5970}, {"Word": "need", "OffsetStartMs": 5970, "OffsetEndMs": 6210}, {"Word": "to", "OffsetStartMs": 6210, "OffsetEndMs": 6390}, {"Word": "do", "OffsetStartMs": 6390, "OffsetEndMs": 6585}, {"Word": "something", "OffsetStartMs": 6585, "OffsetEndMs": 6920}, {"Word": "more", "OffsetStartMs": 7210, "OffsetEndMs": 7530}, {"Word": "clever", "OffsetStartMs": 7530, "OffsetEndMs": 7850}], "SpeechSpeed": 14.1}, {"FinalSentence": "What the auto encoder does is it builds a way to decode this latent variable vector back up to the original data space, trying to reconstruct the original image from that compressed, efficient latent encoding.", "SliceSentence": "What the auto encoder does is it builds a way to decode this latent variable vector back up to the original data space trying to reconstruct the original image from that compressed efficient latent encoding", "StartMs": 704760, "EndMs": 721300, "WordsNum": 35, "Words": [{"Word": "What", "OffsetStartMs": 10, "OffsetEndMs": 315}, {"Word": "the", "OffsetStartMs": 315, "OffsetEndMs": 480}, {"Word": "auto", "OffsetStartMs": 480, "OffsetEndMs": 675}, {"Word": "encoder", "OffsetStartMs": 675, "OffsetEndMs": 1230}, {"Word": "does", "OffsetStartMs": 1230, "OffsetEndMs": 1520}, {"Word": "is", "OffsetStartMs": 1570, "OffsetEndMs": 1965}, {"Word": "it", "OffsetStartMs": 1965, "OffsetEndMs": 2360}, {"Word": "builds", "OffsetStartMs": 2800, "OffsetEndMs": 3500}, {"Word": "a", "OffsetStartMs": 3550, "OffsetEndMs": 3840}, {"Word": "way", "OffsetStartMs": 3840, "OffsetEndMs": 4110}, {"Word": "to", "OffsetStartMs": 4110, "OffsetEndMs": 4425}, {"Word": "decode", "OffsetStartMs": 4425, "OffsetEndMs": 5210}, {"Word": "this", "OffsetStartMs": 5350, "OffsetEndMs": 5750}, {"Word": "latent", "OffsetStartMs": 5770, "OffsetEndMs": 6270}, {"Word": "variable", "OffsetStartMs": 6270, "OffsetEndMs": 6560}, {"Word": "vector", "OffsetStartMs": 6580, "OffsetEndMs": 7010}, {"Word": "back", "OffsetStartMs": 7570, "OffsetEndMs": 7950}, {"Word": "up", "OffsetStartMs": 7950, "OffsetEndMs": 8310}, {"Word": "to", "OffsetStartMs": 8310, "OffsetEndMs": 8535}, {"Word": "the", "OffsetStartMs": 8535, "OffsetEndMs": 8715}, {"Word": "original", "OffsetStartMs": 8715, "OffsetEndMs": 9050}, {"Word": "data", "OffsetStartMs": 9100, "OffsetEndMs": 9495}, {"Word": "space", "OffsetStartMs": 9495, "OffsetEndMs": 9890}, {"Word": "trying", "OffsetStartMs": 10540, "OffsetEndMs": 10905}, {"Word": "to", "OffsetStartMs": 10905, "OffsetEndMs": 11190}, {"Word": "reconstruct", "OffsetStartMs": 11190, "OffsetEndMs": 11910}, {"Word": "the", "OffsetStartMs": 11910, "OffsetEndMs": 12225}, {"Word": "original", "OffsetStartMs": 12225, "OffsetEndMs": 12540}, {"Word": "image", "OffsetStartMs": 12540, "OffsetEndMs": 12920}, {"Word": "from", "OffsetStartMs": 13330, "OffsetEndMs": 13635}, {"Word": "that", "OffsetStartMs": 13635, "OffsetEndMs": 13875}, {"Word": "compressed", "OffsetStartMs": 13875, "OffsetEndMs": 14420}, {"Word": "efficient", "OffsetStartMs": 14560, "OffsetEndMs": 14960}, {"Word": "latent", "OffsetStartMs": 14980, "OffsetEndMs": 15435}, {"Word": "encoding", "OffsetStartMs": 15435, "OffsetEndMs": 16070}], "SpeechSpeed": 12.5}, {"FinalSentence": "And once again, we can use a series of neural network layers, such as convolutional layers, fully connected layers, but now to map back from that lower dimensional space back upwards to the input space.", "SliceSentence": "And once again we can use a series of neural network layers such as convolutional layers fully connected layers but now to map back from that lower dimensional space back upwards to the input space", "StartMs": 721380, "EndMs": 735160, "WordsNum": 35, "Words": [{"Word": "And", "OffsetStartMs": 100, "OffsetEndMs": 405}, {"Word": "once", "OffsetStartMs": 405, "OffsetEndMs": 660}, {"Word": "again", "OffsetStartMs": 660, "OffsetEndMs": 1010}, {"Word": "we", "OffsetStartMs": 1030, "OffsetEndMs": 1305}, {"Word": "can", "OffsetStartMs": 1305, "OffsetEndMs": 1485}, {"Word": "use", "OffsetStartMs": 1485, "OffsetEndMs": 1755}, {"Word": "a", "OffsetStartMs": 1755, "OffsetEndMs": 2010}, {"Word": "series", "OffsetStartMs": 2010, "OffsetEndMs": 2280}, {"Word": "of", "OffsetStartMs": 2280, "OffsetEndMs": 2535}, {"Word": "neural", "OffsetStartMs": 2535, "OffsetEndMs": 2790}, {"Word": "network", "OffsetStartMs": 2790, "OffsetEndMs": 3045}, {"Word": "layers", "OffsetStartMs": 3045, "OffsetEndMs": 3650}, {"Word": "such", "OffsetStartMs": 3970, "OffsetEndMs": 4245}, {"Word": "as", "OffsetStartMs": 4245, "OffsetEndMs": 4440}, {"Word": "convolutional", "OffsetStartMs": 4440, "OffsetEndMs": 5175}, {"Word": "layers", "OffsetStartMs": 5175, "OffsetEndMs": 5625}, {"Word": "fully", "OffsetStartMs": 5625, "OffsetEndMs": 6000}, {"Word": "connected", "OffsetStartMs": 6000, "OffsetEndMs": 6360}, {"Word": "layers", "OffsetStartMs": 6360, "OffsetEndMs": 6890}, {"Word": "but", "OffsetStartMs": 7210, "OffsetEndMs": 7500}, {"Word": "now", "OffsetStartMs": 7500, "OffsetEndMs": 7790}, {"Word": "to", "OffsetStartMs": 7810, "OffsetEndMs": 8130}, {"Word": "map", "OffsetStartMs": 8130, "OffsetEndMs": 8450}, {"Word": "back", "OffsetStartMs": 8470, "OffsetEndMs": 8870}, {"Word": "from", "OffsetStartMs": 9070, "OffsetEndMs": 9375}, {"Word": "that", "OffsetStartMs": 9375, "OffsetEndMs": 9585}, {"Word": "lower", "OffsetStartMs": 9585, "OffsetEndMs": 9855}, {"Word": "dimensional", "OffsetStartMs": 9855, "OffsetEndMs": 10485}, {"Word": "space", "OffsetStartMs": 10485, "OffsetEndMs": 10820}, {"Word": "back", "OffsetStartMs": 11050, "OffsetEndMs": 11400}, {"Word": "upwards", "OffsetStartMs": 11400, "OffsetEndMs": 11990}, {"Word": "to", "OffsetStartMs": 12010, "OffsetEndMs": 12285}, {"Word": "the", "OffsetStartMs": 12285, "OffsetEndMs": 12525}, {"Word": "input", "OffsetStartMs": 12525, "OffsetEndMs": 12810}, {"Word": "space", "OffsetStartMs": 12810, "OffsetEndMs": 13130}], "SpeechSpeed": 14.3}, {"FinalSentence": "This generates a reconstructed output, which we can denote as X hat, since it's an imperfect reconstruction of our original input data.", "SliceSentence": "This generates a reconstructed output which we can denote as X hat since it's an imperfect reconstruction of our original input data", "StartMs": 735660, "EndMs": 746420, "WordsNum": 22, "Words": [{"Word": "This", "OffsetStartMs": 220, "OffsetEndMs": 620}, {"Word": "generates", "OffsetStartMs": 970, "OffsetEndMs": 1560}, {"Word": "a", "OffsetStartMs": 1560, "OffsetEndMs": 1830}, {"Word": "reconstructed", "OffsetStartMs": 1830, "OffsetEndMs": 2780}, {"Word": "output", "OffsetStartMs": 2830, "OffsetEndMs": 3230}, {"Word": "which", "OffsetStartMs": 3250, "OffsetEndMs": 3555}, {"Word": "we", "OffsetStartMs": 3555, "OffsetEndMs": 3720}, {"Word": "can", "OffsetStartMs": 3720, "OffsetEndMs": 3870}, {"Word": "denote", "OffsetStartMs": 3870, "OffsetEndMs": 4200}, {"Word": "as", "OffsetStartMs": 4200, "OffsetEndMs": 4515}, {"Word": "X", "OffsetStartMs": 4515, "OffsetEndMs": 4860}, {"Word": "hat", "OffsetStartMs": 4860, "OffsetEndMs": 5210}, {"Word": "since", "OffsetStartMs": 5740, "OffsetEndMs": 6075}, {"Word": "it's", "OffsetStartMs": 6075, "OffsetEndMs": 6330}, {"Word": "an", "OffsetStartMs": 6330, "OffsetEndMs": 6560}, {"Word": "imperfect", "OffsetStartMs": 6610, "OffsetEndMs": 7190}, {"Word": "reconstruction", "OffsetStartMs": 7240, "OffsetEndMs": 8000}, {"Word": "of", "OffsetStartMs": 8020, "OffsetEndMs": 8370}, {"Word": "our", "OffsetStartMs": 8370, "OffsetEndMs": 8720}, {"Word": "original", "OffsetStartMs": 8860, "OffsetEndMs": 9260}, {"Word": "input", "OffsetStartMs": 9460, "OffsetEndMs": 9765}, {"Word": "data", "OffsetStartMs": 9765, "OffsetEndMs": 10070}], "SpeechSpeed": 12.3}, {"FinalSentence": "To train this network, all we have to do is compare the outputted reconstruction and the original input data and say, how do we make these as similar as possible? We can minimize the distance between that input and our reconstructed output.", "SliceSentence": "To train this network all we have to do is compare the outputted reconstruction and the original input data and say how do we make these as similar as possible We can minimize the distance between that input and our reconstructed output", "StartMs": 746940, "EndMs": 763820, "WordsNum": 42, "Words": [{"Word": "To", "OffsetStartMs": 130, "OffsetEndMs": 435}, {"Word": "train", "OffsetStartMs": 435, "OffsetEndMs": 675}, {"Word": "this", "OffsetStartMs": 675, "OffsetEndMs": 960}, {"Word": "network", "OffsetStartMs": 960, "OffsetEndMs": 1310}, {"Word": "all", "OffsetStartMs": 2050, "OffsetEndMs": 2355}, {"Word": "we", "OffsetStartMs": 2355, "OffsetEndMs": 2535}, {"Word": "have", "OffsetStartMs": 2535, "OffsetEndMs": 2715}, {"Word": "to", "OffsetStartMs": 2715, "OffsetEndMs": 2880}, {"Word": "do", "OffsetStartMs": 2880, "OffsetEndMs": 3090}, {"Word": "is", "OffsetStartMs": 3090, "OffsetEndMs": 3440}, {"Word": "compare", "OffsetStartMs": 3550, "OffsetEndMs": 3950}, {"Word": "the", "OffsetStartMs": 4210, "OffsetEndMs": 4610}, {"Word": "outputted", "OffsetStartMs": 4780, "OffsetEndMs": 5160}, {"Word": "reconstruction", "OffsetStartMs": 5160, "OffsetEndMs": 5840}, {"Word": "and", "OffsetStartMs": 6100, "OffsetEndMs": 6420}, {"Word": "the", "OffsetStartMs": 6420, "OffsetEndMs": 6645}, {"Word": "original", "OffsetStartMs": 6645, "OffsetEndMs": 6950}, {"Word": "input", "OffsetStartMs": 7090, "OffsetEndMs": 7380}, {"Word": "data", "OffsetStartMs": 7380, "OffsetEndMs": 7670}, {"Word": "and", "OffsetStartMs": 7960, "OffsetEndMs": 8265}, {"Word": "say", "OffsetStartMs": 8265, "OffsetEndMs": 8570}, {"Word": "how", "OffsetStartMs": 9100, "OffsetEndMs": 9390}, {"Word": "do", "OffsetStartMs": 9390, "OffsetEndMs": 9510}, {"Word": "we", "OffsetStartMs": 9510, "OffsetEndMs": 9630}, {"Word": "make", "OffsetStartMs": 9630, "OffsetEndMs": 9825}, {"Word": "these", "OffsetStartMs": 9825, "OffsetEndMs": 10050}, {"Word": "as", "OffsetStartMs": 10050, "OffsetEndMs": 10320}, {"Word": "similar", "OffsetStartMs": 10320, "OffsetEndMs": 10635}, {"Word": "as", "OffsetStartMs": 10635, "OffsetEndMs": 10920}, {"Word": "possible", "OffsetStartMs": 10920, "OffsetEndMs": 11240}, {"Word": "We", "OffsetStartMs": 11410, "OffsetEndMs": 11685}, {"Word": "can", "OffsetStartMs": 11685, "OffsetEndMs": 11865}, {"Word": "minimize", "OffsetStartMs": 11865, "OffsetEndMs": 12390}, {"Word": "the", "OffsetStartMs": 12390, "OffsetEndMs": 12615}, {"Word": "distance", "OffsetStartMs": 12615, "OffsetEndMs": 12890}, {"Word": "between", "OffsetStartMs": 13600, "OffsetEndMs": 13890}, {"Word": "that", "OffsetStartMs": 13890, "OffsetEndMs": 14180}, {"Word": "input", "OffsetStartMs": 14230, "OffsetEndMs": 14580}, {"Word": "and", "OffsetStartMs": 14580, "OffsetEndMs": 14880}, {"Word": "our", "OffsetStartMs": 14880, "OffsetEndMs": 15150}, {"Word": "reconstructed", "OffsetStartMs": 15150, "OffsetEndMs": 16040}, {"Word": "output", "OffsetStartMs": 16060, "OffsetEndMs": 16460}], "SpeechSpeed": 14.0}, {"FinalSentence": "So, for example, for an image, we can compare the pixel wise difference between the input data and the reconstructed output, just subtracting the images from one another and squaring that difference to capture the pixel wise divergence between the input and the reconstruction.", "SliceSentence": "So for example for an image we can compare the pixel wise difference between the input data and the reconstructed output just subtracting the images from one another and squaring that difference to capture the pixel wise divergence between the input and the reconstruction", "StartMs": 763920, "EndMs": 783940, "WordsNum": 44, "Words": [{"Word": "So", "OffsetStartMs": 160, "OffsetEndMs": 450}, {"Word": "for", "OffsetStartMs": 450, "OffsetEndMs": 630}, {"Word": "example", "OffsetStartMs": 630, "OffsetEndMs": 900}, {"Word": "for", "OffsetStartMs": 900, "OffsetEndMs": 1110}, {"Word": "an", "OffsetStartMs": 1110, "OffsetEndMs": 1200}, {"Word": "image", "OffsetStartMs": 1200, "OffsetEndMs": 1460}, {"Word": "we", "OffsetStartMs": 1930, "OffsetEndMs": 2205}, {"Word": "can", "OffsetStartMs": 2205, "OffsetEndMs": 2480}, {"Word": "compare", "OffsetStartMs": 2500, "OffsetEndMs": 2850}, {"Word": "the", "OffsetStartMs": 2850, "OffsetEndMs": 3105}, {"Word": "pixel", "OffsetStartMs": 3105, "OffsetEndMs": 3510}, {"Word": "wise", "OffsetStartMs": 3510, "OffsetEndMs": 3780}, {"Word": "difference", "OffsetStartMs": 3780, "OffsetEndMs": 4160}, {"Word": "between", "OffsetStartMs": 5290, "OffsetEndMs": 5610}, {"Word": "the", "OffsetStartMs": 5610, "OffsetEndMs": 5880}, {"Word": "input", "OffsetStartMs": 5880, "OffsetEndMs": 6120}, {"Word": "data", "OffsetStartMs": 6120, "OffsetEndMs": 6410}, {"Word": "and", "OffsetStartMs": 6670, "OffsetEndMs": 6960}, {"Word": "the", "OffsetStartMs": 6960, "OffsetEndMs": 7110}, {"Word": "reconstructed", "OffsetStartMs": 7110, "OffsetEndMs": 7875}, {"Word": "output", "OffsetStartMs": 7875, "OffsetEndMs": 8270}, {"Word": "just", "OffsetStartMs": 8530, "OffsetEndMs": 8880}, {"Word": "subtracting", "OffsetStartMs": 8880, "OffsetEndMs": 9630}, {"Word": "the", "OffsetStartMs": 9630, "OffsetEndMs": 9765}, {"Word": "images", "OffsetStartMs": 9765, "OffsetEndMs": 10010}, {"Word": "from", "OffsetStartMs": 10060, "OffsetEndMs": 10380}, {"Word": "one", "OffsetStartMs": 10380, "OffsetEndMs": 10620}, {"Word": "another", "OffsetStartMs": 10620, "OffsetEndMs": 10940}, {"Word": "and", "OffsetStartMs": 11290, "OffsetEndMs": 11655}, {"Word": "squaring", "OffsetStartMs": 11655, "OffsetEndMs": 12015}, {"Word": "that", "OffsetStartMs": 12015, "OffsetEndMs": 12285}, {"Word": "difference", "OffsetStartMs": 12285, "OffsetEndMs": 12590}, {"Word": "to", "OffsetStartMs": 12910, "OffsetEndMs": 13310}, {"Word": "capture", "OffsetStartMs": 13570, "OffsetEndMs": 13970}, {"Word": "the", "OffsetStartMs": 14050, "OffsetEndMs": 14340}, {"Word": "pixel", "OffsetStartMs": 14340, "OffsetEndMs": 14760}, {"Word": "wise", "OffsetStartMs": 14760, "OffsetEndMs": 15050}, {"Word": "divergence", "OffsetStartMs": 15310, "OffsetEndMs": 16100}, {"Word": "between", "OffsetStartMs": 16450, "OffsetEndMs": 16755}, {"Word": "the", "OffsetStartMs": 16755, "OffsetEndMs": 17040}, {"Word": "input", "OffsetStartMs": 17040, "OffsetEndMs": 17420}, {"Word": "and", "OffsetStartMs": 17530, "OffsetEndMs": 17850}, {"Word": "the", "OffsetStartMs": 17850, "OffsetEndMs": 18015}, {"Word": "reconstruction", "OffsetStartMs": 18015, "OffsetEndMs": 18590}], "SpeechSpeed": 13.6}, {"FinalSentence": "What I hope you'll notice and appreciate is in that definition of the loss, it doesn't require any labels. The only components of that loss are the original input data X and the reconstructed output X hat.", "SliceSentence": "What I hope you'll notice and appreciate is in that definition of the loss it doesn't require any labels . Theonly components of that loss are the original input data X and the reconstructed output X hat", "StartMs": 784860, "EndMs": 800100, "WordsNum": 37, "Words": [{"Word": "What", "OffsetStartMs": 130, "OffsetEndMs": 525}, {"Word": "I", "OffsetStartMs": 525, "OffsetEndMs": 825}, {"Word": "hope", "OffsetStartMs": 825, "OffsetEndMs": 1020}, {"Word": "you'll", "OffsetStartMs": 1020, "OffsetEndMs": 1245}, {"Word": "notice", "OffsetStartMs": 1245, "OffsetEndMs": 1425}, {"Word": "and", "OffsetStartMs": 1425, "OffsetEndMs": 1695}, {"Word": "appreciate", "OffsetStartMs": 1695, "OffsetEndMs": 2030}, {"Word": "is", "OffsetStartMs": 2110, "OffsetEndMs": 2430}, {"Word": "in", "OffsetStartMs": 2430, "OffsetEndMs": 2640}, {"Word": "that", "OffsetStartMs": 2640, "OffsetEndMs": 2835}, {"Word": "definition", "OffsetStartMs": 2835, "OffsetEndMs": 3140}, {"Word": "of", "OffsetStartMs": 3280, "OffsetEndMs": 3555}, {"Word": "the", "OffsetStartMs": 3555, "OffsetEndMs": 3705}, {"Word": "loss", "OffsetStartMs": 3705, "OffsetEndMs": 3980}, {"Word": "it", "OffsetStartMs": 4930, "OffsetEndMs": 5220}, {"Word": "doesn't", "OffsetStartMs": 5220, "OffsetEndMs": 5685}, {"Word": "require", "OffsetStartMs": 5685, "OffsetEndMs": 6075}, {"Word": "any", "OffsetStartMs": 6075, "OffsetEndMs": 6450}, {"Word": "labels", "OffsetStartMs": 6450, "OffsetEndMs": 7070}, {"Word": ".", "OffsetStartMs": 7090, "OffsetEndMs": 7380}, {"Word": "Theonly", "OffsetStartMs": 7380, "OffsetEndMs": 7670}, {"Word": "components", "OffsetStartMs": 7990, "OffsetEndMs": 8385}, {"Word": "of", "OffsetStartMs": 8385, "OffsetEndMs": 8685}, {"Word": "that", "OffsetStartMs": 8685, "OffsetEndMs": 8910}, {"Word": "loss", "OffsetStartMs": 8910, "OffsetEndMs": 9230}, {"Word": "are", "OffsetStartMs": 9520, "OffsetEndMs": 9810}, {"Word": "the", "OffsetStartMs": 9810, "OffsetEndMs": 10020}, {"Word": "original", "OffsetStartMs": 10020, "OffsetEndMs": 10340}, {"Word": "input", "OffsetStartMs": 10510, "OffsetEndMs": 10800}, {"Word": "data", "OffsetStartMs": 10800, "OffsetEndMs": 11040}, {"Word": "X", "OffsetStartMs": 11040, "OffsetEndMs": 11390}, {"Word": "and", "OffsetStartMs": 11890, "OffsetEndMs": 12225}, {"Word": "the", "OffsetStartMs": 12225, "OffsetEndMs": 12420}, {"Word": "reconstructed", "OffsetStartMs": 12420, "OffsetEndMs": 13250}, {"Word": "output", "OffsetStartMs": 13300, "OffsetEndMs": 13700}, {"Word": "X", "OffsetStartMs": 13900, "OffsetEndMs": 14250}, {"Word": "hat", "OffsetStartMs": 14250, "OffsetEndMs": 14600}], "SpeechSpeed": 13.3}, {"FinalSentence": "So I've simplified now this diagram by abstracting away those individual neural network layers in both the encoder and decoder components of this.", "SliceSentence": "So I've simplified now this diagram by abstracting away those individual neural network layers in both the encoder and decoder components of this", "StartMs": 801120, "EndMs": 811740, "WordsNum": 23, "Words": [{"Word": "So", "OffsetStartMs": 160, "OffsetEndMs": 560}, {"Word": "I've", "OffsetStartMs": 1210, "OffsetEndMs": 1620}, {"Word": "simplified", "OffsetStartMs": 1620, "OffsetEndMs": 2100}, {"Word": "now", "OffsetStartMs": 2100, "OffsetEndMs": 2325}, {"Word": "this", "OffsetStartMs": 2325, "OffsetEndMs": 2535}, {"Word": "diagram", "OffsetStartMs": 2535, "OffsetEndMs": 3000}, {"Word": "by", "OffsetStartMs": 3000, "OffsetEndMs": 3320}, {"Word": "abstracting", "OffsetStartMs": 3550, "OffsetEndMs": 4080}, {"Word": "away", "OffsetStartMs": 4080, "OffsetEndMs": 4320}, {"Word": "those", "OffsetStartMs": 4320, "OffsetEndMs": 4640}, {"Word": "individual", "OffsetStartMs": 4900, "OffsetEndMs": 5280}, {"Word": "neural", "OffsetStartMs": 5280, "OffsetEndMs": 5625}, {"Word": "network", "OffsetStartMs": 5625, "OffsetEndMs": 5900}, {"Word": "layers", "OffsetStartMs": 5920, "OffsetEndMs": 6450}, {"Word": "in", "OffsetStartMs": 6450, "OffsetEndMs": 6705}, {"Word": "both", "OffsetStartMs": 6705, "OffsetEndMs": 7005}, {"Word": "the", "OffsetStartMs": 7005, "OffsetEndMs": 7290}, {"Word": "encoder", "OffsetStartMs": 7290, "OffsetEndMs": 7905}, {"Word": "and", "OffsetStartMs": 7905, "OffsetEndMs": 8210}, {"Word": "decoder", "OffsetStartMs": 8380, "OffsetEndMs": 9060}, {"Word": "components", "OffsetStartMs": 9060, "OffsetEndMs": 9375}, {"Word": "of", "OffsetStartMs": 9375, "OffsetEndMs": 9630}, {"Word": "this", "OffsetStartMs": 9630, "OffsetEndMs": 9920}], "SpeechSpeed": 13.7}, {"FinalSentence": "And again, this idea of not requiring any labels gets back to the idea of unsupervised learning, since what we've done is we've been able to learn an encoded quantity, our latent variables that we cannot observe without any explicit labels. All we started from was the raw data itself.", "SliceSentence": "And again this idea of not requiring any labels gets back to the idea of unsupervised learning since what we've done is we've been able to learn an encoded quantity our latent variables that we cannot observe without any explicit labels . Allwe started from was the raw data itself", "StartMs": 811840, "EndMs": 832840, "WordsNum": 50, "Words": [{"Word": "And", "OffsetStartMs": 160, "OffsetEndMs": 480}, {"Word": "again", "OffsetStartMs": 480, "OffsetEndMs": 800}, {"Word": "this", "OffsetStartMs": 1120, "OffsetEndMs": 1520}, {"Word": "idea", "OffsetStartMs": 1570, "OffsetEndMs": 1905}, {"Word": "of", "OffsetStartMs": 1905, "OffsetEndMs": 2160}, {"Word": "not", "OffsetStartMs": 2160, "OffsetEndMs": 2480}, {"Word": "requiring", "OffsetStartMs": 2500, "OffsetEndMs": 2910}, {"Word": "any", "OffsetStartMs": 2910, "OffsetEndMs": 3225}, {"Word": "labels", "OffsetStartMs": 3225, "OffsetEndMs": 3720}, {"Word": "gets", "OffsetStartMs": 3720, "OffsetEndMs": 4005}, {"Word": "back", "OffsetStartMs": 4005, "OffsetEndMs": 4305}, {"Word": "to", "OffsetStartMs": 4305, "OffsetEndMs": 4515}, {"Word": "the", "OffsetStartMs": 4515, "OffsetEndMs": 4755}, {"Word": "idea", "OffsetStartMs": 4755, "OffsetEndMs": 5145}, {"Word": "of", "OffsetStartMs": 5145, "OffsetEndMs": 5540}, {"Word": "unsupervised", "OffsetStartMs": 5650, "OffsetEndMs": 6555}, {"Word": "learning", "OffsetStartMs": 6555, "OffsetEndMs": 6890}, {"Word": "since", "OffsetStartMs": 7450, "OffsetEndMs": 7850}, {"Word": "what", "OffsetStartMs": 7900, "OffsetEndMs": 8175}, {"Word": "we've", "OffsetStartMs": 8175, "OffsetEndMs": 8415}, {"Word": "done", "OffsetStartMs": 8415, "OffsetEndMs": 8625}, {"Word": "is", "OffsetStartMs": 8625, "OffsetEndMs": 8880}, {"Word": "we've", "OffsetStartMs": 8880, "OffsetEndMs": 9135}, {"Word": "been", "OffsetStartMs": 9135, "OffsetEndMs": 9285}, {"Word": "able", "OffsetStartMs": 9285, "OffsetEndMs": 9585}, {"Word": "to", "OffsetStartMs": 9585, "OffsetEndMs": 9855}, {"Word": "learn", "OffsetStartMs": 9855, "OffsetEndMs": 10125}, {"Word": "an", "OffsetStartMs": 10125, "OffsetEndMs": 10440}, {"Word": "encoded", "OffsetStartMs": 10440, "OffsetEndMs": 11085}, {"Word": "quantity", "OffsetStartMs": 11085, "OffsetEndMs": 11780}, {"Word": "our", "OffsetStartMs": 12130, "OffsetEndMs": 12435}, {"Word": "latent", "OffsetStartMs": 12435, "OffsetEndMs": 12780}, {"Word": "variables", "OffsetStartMs": 12780, "OffsetEndMs": 13340}, {"Word": "that", "OffsetStartMs": 13810, "OffsetEndMs": 14100}, {"Word": "we", "OffsetStartMs": 14100, "OffsetEndMs": 14295}, {"Word": "cannot", "OffsetStartMs": 14295, "OffsetEndMs": 14600}, {"Word": "observe", "OffsetStartMs": 14740, "OffsetEndMs": 15140}, {"Word": "without", "OffsetStartMs": 15280, "OffsetEndMs": 15680}, {"Word": "any", "OffsetStartMs": 15790, "OffsetEndMs": 16190}, {"Word": "explicit", "OffsetStartMs": 16300, "OffsetEndMs": 16785}, {"Word": "labels", "OffsetStartMs": 16785, "OffsetEndMs": 17270}, {"Word": ".", "OffsetStartMs": 17470, "OffsetEndMs": 17775}, {"Word": "Allwe", "OffsetStartMs": 17775, "OffsetEndMs": 17985}, {"Word": "started", "OffsetStartMs": 17985, "OffsetEndMs": 18240}, {"Word": "from", "OffsetStartMs": 18240, "OffsetEndMs": 18555}, {"Word": "was", "OffsetStartMs": 18555, "OffsetEndMs": 18810}, {"Word": "the", "OffsetStartMs": 18810, "OffsetEndMs": 18975}, {"Word": "raw", "OffsetStartMs": 18975, "OffsetEndMs": 19185}, {"Word": "data", "OffsetStartMs": 19185, "OffsetEndMs": 19520}, {"Word": "itself", "OffsetStartMs": 19600, "OffsetEndMs": 20000}], "SpeechSpeed": 13.3}, {"FinalSentence": "It turns out that as as the question and answer got out, that dimensionality of the latent space has a huge impact on the quality of the generated reconstructions and how compressed that information bottleneck is.", "SliceSentence": "It turns out that as as the question and answer got out that dimensionality of the latent space has a huge impact on the quality of the generated reconstructions and how compressed that information bottleneck is", "StartMs": 833600, "EndMs": 849520, "WordsNum": 36, "Words": [{"Word": "It", "OffsetStartMs": 190, "OffsetEndMs": 495}, {"Word": "turns", "OffsetStartMs": 495, "OffsetEndMs": 720}, {"Word": "out", "OffsetStartMs": 720, "OffsetEndMs": 975}, {"Word": "that", "OffsetStartMs": 975, "OffsetEndMs": 1230}, {"Word": "as", "OffsetStartMs": 1230, "OffsetEndMs": 1550}, {"Word": "as", "OffsetStartMs": 1660, "OffsetEndMs": 1980}, {"Word": "the", "OffsetStartMs": 1980, "OffsetEndMs": 2175}, {"Word": "question", "OffsetStartMs": 2175, "OffsetEndMs": 2385}, {"Word": "and", "OffsetStartMs": 2385, "OffsetEndMs": 2595}, {"Word": "answer", "OffsetStartMs": 2595, "OffsetEndMs": 2870}, {"Word": "got", "OffsetStartMs": 3280, "OffsetEndMs": 3570}, {"Word": "out", "OffsetStartMs": 3570, "OffsetEndMs": 3860}, {"Word": "that", "OffsetStartMs": 4060, "OffsetEndMs": 4365}, {"Word": "dimensionality", "OffsetStartMs": 4365, "OffsetEndMs": 5340}, {"Word": "of", "OffsetStartMs": 5340, "OffsetEndMs": 5535}, {"Word": "the", "OffsetStartMs": 5535, "OffsetEndMs": 5700}, {"Word": "latent", "OffsetStartMs": 5700, "OffsetEndMs": 6060}, {"Word": "space", "OffsetStartMs": 6060, "OffsetEndMs": 6380}, {"Word": "has", "OffsetStartMs": 6670, "OffsetEndMs": 7005}, {"Word": "a", "OffsetStartMs": 7005, "OffsetEndMs": 7275}, {"Word": "huge", "OffsetStartMs": 7275, "OffsetEndMs": 7610}, {"Word": "impact", "OffsetStartMs": 8140, "OffsetEndMs": 8475}, {"Word": "on", "OffsetStartMs": 8475, "OffsetEndMs": 8700}, {"Word": "the", "OffsetStartMs": 8700, "OffsetEndMs": 8925}, {"Word": "quality", "OffsetStartMs": 8925, "OffsetEndMs": 9260}, {"Word": "of", "OffsetStartMs": 9370, "OffsetEndMs": 9675}, {"Word": "the", "OffsetStartMs": 9675, "OffsetEndMs": 9870}, {"Word": "generated", "OffsetStartMs": 9870, "OffsetEndMs": 10160}, {"Word": "reconstructions", "OffsetStartMs": 10300, "OffsetEndMs": 11270}, {"Word": "and", "OffsetStartMs": 11560, "OffsetEndMs": 11960}, {"Word": "how", "OffsetStartMs": 12040, "OffsetEndMs": 12440}, {"Word": "compressed", "OffsetStartMs": 12850, "OffsetEndMs": 13440}, {"Word": "that", "OffsetStartMs": 13440, "OffsetEndMs": 13820}, {"Word": "information", "OffsetStartMs": 13930, "OffsetEndMs": 14325}, {"Word": "bottleneck", "OffsetStartMs": 14325, "OffsetEndMs": 14970}, {"Word": "is", "OffsetStartMs": 14970, "OffsetEndMs": 15260}], "SpeechSpeed": 13.3}, {"FinalSentence": "Auto encoding is a form of compression, and so the lower the dimensionality of the latent space, the less good our reconstructions are going to be.", "SliceSentence": "Auto encoding is a form of compression and so the lower the dimensionality of the latent space the less good our reconstructions are going to be", "StartMs": 849920, "EndMs": 859920, "WordsNum": 26, "Words": [{"Word": "Auto", "OffsetStartMs": 100, "OffsetEndMs": 435}, {"Word": "encoding", "OffsetStartMs": 435, "OffsetEndMs": 1005}, {"Word": "is", "OffsetStartMs": 1005, "OffsetEndMs": 1185}, {"Word": "a", "OffsetStartMs": 1185, "OffsetEndMs": 1335}, {"Word": "form", "OffsetStartMs": 1335, "OffsetEndMs": 1500}, {"Word": "of", "OffsetStartMs": 1500, "OffsetEndMs": 1680}, {"Word": "compression", "OffsetStartMs": 1680, "OffsetEndMs": 2120}, {"Word": "and", "OffsetStartMs": 2380, "OffsetEndMs": 2700}, {"Word": "so", "OffsetStartMs": 2700, "OffsetEndMs": 2985}, {"Word": "the", "OffsetStartMs": 2985, "OffsetEndMs": 3240}, {"Word": "lower", "OffsetStartMs": 3240, "OffsetEndMs": 3510}, {"Word": "the", "OffsetStartMs": 3510, "OffsetEndMs": 3735}, {"Word": "dimensionality", "OffsetStartMs": 3735, "OffsetEndMs": 4620}, {"Word": "of", "OffsetStartMs": 4620, "OffsetEndMs": 4815}, {"Word": "the", "OffsetStartMs": 4815, "OffsetEndMs": 4980}, {"Word": "latent", "OffsetStartMs": 4980, "OffsetEndMs": 5280}, {"Word": "space", "OffsetStartMs": 5280, "OffsetEndMs": 5600}, {"Word": "the", "OffsetStartMs": 6070, "OffsetEndMs": 6375}, {"Word": "less", "OffsetStartMs": 6375, "OffsetEndMs": 6680}, {"Word": "good", "OffsetStartMs": 6880, "OffsetEndMs": 7245}, {"Word": "our", "OffsetStartMs": 7245, "OffsetEndMs": 7560}, {"Word": "reconstructions", "OffsetStartMs": 7560, "OffsetEndMs": 8450}, {"Word": "are", "OffsetStartMs": 8470, "OffsetEndMs": 8760}, {"Word": "going", "OffsetStartMs": 8760, "OffsetEndMs": 8955}, {"Word": "to", "OffsetStartMs": 8955, "OffsetEndMs": 9105}, {"Word": "be", "OffsetStartMs": 9105, "OffsetEndMs": 9350}], "SpeechSpeed": 14.4}, {"FinalSentence": "But the higher the dimensionality, the more the less efficient that encoding is going to be.", "SliceSentence": "But the higher the dimensionality the more the less efficient that encoding is going to be", "StartMs": 859920, "EndMs": 866540, "WordsNum": 16, "Words": [{"Word": "But", "OffsetStartMs": 0, "OffsetEndMs": 195}, {"Word": "the", "OffsetStartMs": 195, "OffsetEndMs": 390}, {"Word": "higher", "OffsetStartMs": 390, "OffsetEndMs": 680}, {"Word": "the", "OffsetStartMs": 880, "OffsetEndMs": 1125}, {"Word": "dimensionality", "OffsetStartMs": 1125, "OffsetEndMs": 2060}, {"Word": "the", "OffsetStartMs": 2080, "OffsetEndMs": 2355}, {"Word": "more", "OffsetStartMs": 2355, "OffsetEndMs": 2630}, {"Word": "the", "OffsetStartMs": 3400, "OffsetEndMs": 3675}, {"Word": "less", "OffsetStartMs": 3675, "OffsetEndMs": 3945}, {"Word": "efficient", "OffsetStartMs": 3945, "OffsetEndMs": 4305}, {"Word": "that", "OffsetStartMs": 4305, "OffsetEndMs": 4560}, {"Word": "encoding", "OffsetStartMs": 4560, "OffsetEndMs": 5025}, {"Word": "is", "OffsetStartMs": 5025, "OffsetEndMs": 5205}, {"Word": "going", "OffsetStartMs": 5205, "OffsetEndMs": 5400}, {"Word": "to", "OffsetStartMs": 5400, "OffsetEndMs": 5550}, {"Word": "be", "OffsetStartMs": 5550, "OffsetEndMs": 5810}], "SpeechSpeed": 13.6}, {"FinalSentence": "So to summarize this first part, this idea of an auto encoder is using this bottleneck, compressed, hidden latent layer to try to bring the network down to learn a compact, efficient representation of the data.", "SliceSentence": "So to summarize this first part this idea of an auto encoder is using this bottleneck compressed hidden latent layer to try to bring the network down to learn a compact efficient representation of the data", "StartMs": 867280, "EndMs": 881900, "WordsNum": 36, "Words": [{"Word": "So", "OffsetStartMs": 160, "OffsetEndMs": 495}, {"Word": "to", "OffsetStartMs": 495, "OffsetEndMs": 705}, {"Word": "summarize", "OffsetStartMs": 705, "OffsetEndMs": 1080}, {"Word": "this", "OffsetStartMs": 1080, "OffsetEndMs": 1400}, {"Word": "first", "OffsetStartMs": 1810, "OffsetEndMs": 2145}, {"Word": "part", "OffsetStartMs": 2145, "OffsetEndMs": 2480}, {"Word": "this", "OffsetStartMs": 2710, "OffsetEndMs": 3090}, {"Word": "idea", "OffsetStartMs": 3090, "OffsetEndMs": 3330}, {"Word": "of", "OffsetStartMs": 3330, "OffsetEndMs": 3450}, {"Word": "an", "OffsetStartMs": 3450, "OffsetEndMs": 3600}, {"Word": "auto", "OffsetStartMs": 3600, "OffsetEndMs": 3825}, {"Word": "encoder", "OffsetStartMs": 3825, "OffsetEndMs": 4365}, {"Word": "is", "OffsetStartMs": 4365, "OffsetEndMs": 4575}, {"Word": "using", "OffsetStartMs": 4575, "OffsetEndMs": 4905}, {"Word": "this", "OffsetStartMs": 4905, "OffsetEndMs": 5250}, {"Word": "bottleneck", "OffsetStartMs": 5250, "OffsetEndMs": 6050}, {"Word": "compressed", "OffsetStartMs": 6250, "OffsetEndMs": 6860}, {"Word": "hidden", "OffsetStartMs": 7060, "OffsetEndMs": 7425}, {"Word": "latent", "OffsetStartMs": 7425, "OffsetEndMs": 7830}, {"Word": "layer", "OffsetStartMs": 7830, "OffsetEndMs": 8120}, {"Word": "to", "OffsetStartMs": 8470, "OffsetEndMs": 8775}, {"Word": "try", "OffsetStartMs": 8775, "OffsetEndMs": 9030}, {"Word": "to", "OffsetStartMs": 9030, "OffsetEndMs": 9345}, {"Word": "bring", "OffsetStartMs": 9345, "OffsetEndMs": 9630}, {"Word": "the", "OffsetStartMs": 9630, "OffsetEndMs": 9825}, {"Word": "network", "OffsetStartMs": 9825, "OffsetEndMs": 10095}, {"Word": "down", "OffsetStartMs": 10095, "OffsetEndMs": 10470}, {"Word": "to", "OffsetStartMs": 10470, "OffsetEndMs": 10725}, {"Word": "learn", "OffsetStartMs": 10725, "OffsetEndMs": 10935}, {"Word": "a", "OffsetStartMs": 10935, "OffsetEndMs": 11205}, {"Word": "compact", "OffsetStartMs": 11205, "OffsetEndMs": 11810}, {"Word": "efficient", "OffsetStartMs": 12190, "OffsetEndMs": 12540}, {"Word": "representation", "OffsetStartMs": 12540, "OffsetEndMs": 13275}, {"Word": "of", "OffsetStartMs": 13275, "OffsetEndMs": 13485}, {"Word": "the", "OffsetStartMs": 13485, "OffsetEndMs": 13620}, {"Word": "data", "OffsetStartMs": 13620, "OffsetEndMs": 13880}], "SpeechSpeed": 14.0}, {"FinalSentence": "We don't require any labels. This is completely unsupervised. And so in this way we're able to automatically encode information within the data itself to learn this latent space.", "SliceSentence": "We don't require any labels . Thisis completely unsupervised . Andso in this way we're able to automatically encode information within the data itself to learn this latent space", "StartMs": 881900, "EndMs": 894580, "WordsNum": 29, "Words": [{"Word": "We", "OffsetStartMs": 100, "OffsetEndMs": 390}, {"Word": "don't", "OffsetStartMs": 390, "OffsetEndMs": 860}, {"Word": "require", "OffsetStartMs": 1030, "OffsetEndMs": 1365}, {"Word": "any", "OffsetStartMs": 1365, "OffsetEndMs": 1650}, {"Word": "labels", "OffsetStartMs": 1650, "OffsetEndMs": 2100}, {"Word": ".", "OffsetStartMs": 2100, "OffsetEndMs": 2280}, {"Word": "Thisis", "OffsetStartMs": 2280, "OffsetEndMs": 2520}, {"Word": "completely", "OffsetStartMs": 2520, "OffsetEndMs": 2850}, {"Word": "unsupervised", "OffsetStartMs": 2850, "OffsetEndMs": 3710}, {"Word": ".", "OffsetStartMs": 4180, "OffsetEndMs": 4485}, {"Word": "Andso", "OffsetStartMs": 4485, "OffsetEndMs": 4710}, {"Word": "in", "OffsetStartMs": 4710, "OffsetEndMs": 4920}, {"Word": "this", "OffsetStartMs": 4920, "OffsetEndMs": 5115}, {"Word": "way", "OffsetStartMs": 5115, "OffsetEndMs": 5340}, {"Word": "we're", "OffsetStartMs": 5340, "OffsetEndMs": 5595}, {"Word": "able", "OffsetStartMs": 5595, "OffsetEndMs": 5805}, {"Word": "to", "OffsetStartMs": 5805, "OffsetEndMs": 6170}, {"Word": "automatically", "OffsetStartMs": 6280, "OffsetEndMs": 6680}, {"Word": "encode", "OffsetStartMs": 6730, "OffsetEndMs": 7460}, {"Word": "information", "OffsetStartMs": 7480, "OffsetEndMs": 7880}, {"Word": "within", "OffsetStartMs": 8920, "OffsetEndMs": 9285}, {"Word": "the", "OffsetStartMs": 9285, "OffsetEndMs": 9510}, {"Word": "data", "OffsetStartMs": 9510, "OffsetEndMs": 9770}, {"Word": "itself", "OffsetStartMs": 9880, "OffsetEndMs": 10280}, {"Word": "to", "OffsetStartMs": 10300, "OffsetEndMs": 10635}, {"Word": "learn", "OffsetStartMs": 10635, "OffsetEndMs": 10965}, {"Word": "this", "OffsetStartMs": 10965, "OffsetEndMs": 11265}, {"Word": "latent", "OffsetStartMs": 11265, "OffsetEndMs": 11670}, {"Word": "space", "OffsetStartMs": 11670, "OffsetEndMs": 11990}], "SpeechSpeed": 13.8}, {"FinalSentence": "Auto encoding information, auto encoding data.", "SliceSentence": "Auto encoding information auto encoding data", "StartMs": 894940, "EndMs": 899240, "WordsNum": 6, "Words": [{"Word": "Auto", "OffsetStartMs": 70, "OffsetEndMs": 420}, {"Word": "encoding", "OffsetStartMs": 420, "OffsetEndMs": 1100}, {"Word": "information", "OffsetStartMs": 2020, "OffsetEndMs": 2385}, {"Word": "auto", "OffsetStartMs": 2385, "OffsetEndMs": 2670}, {"Word": "encoding", "OffsetStartMs": 2670, "OffsetEndMs": 3210}, {"Word": "data", "OffsetStartMs": 3210, "OffsetEndMs": 3500}], "SpeechSpeed": 10.2}, {"FinalSentence": "Now, this is a pretty simple model, and it turns out that in practice, this idea of self encoding or auto encoding has a bit of a twist on it to allow us to actually generate new examples that are not only reconstructions of the input data itself.", "SliceSentence": "Now this is a pretty simple model and it turns out that in practice this idea of self encoding or auto encoding has a bit of a twist on it to allow us to actually generate new examples that are not only reconstructions of the input data itself", "StartMs": 899860, "EndMs": 918360, "WordsNum": 48, "Words": [{"Word": "Now", "OffsetStartMs": 100, "OffsetEndMs": 465}, {"Word": "this", "OffsetStartMs": 465, "OffsetEndMs": 705}, {"Word": "is", "OffsetStartMs": 705, "OffsetEndMs": 980}, {"Word": "a", "OffsetStartMs": 1120, "OffsetEndMs": 1425}, {"Word": "pretty", "OffsetStartMs": 1425, "OffsetEndMs": 1680}, {"Word": "simple", "OffsetStartMs": 1680, "OffsetEndMs": 2030}, {"Word": "model", "OffsetStartMs": 2200, "OffsetEndMs": 2600}, {"Word": "and", "OffsetStartMs": 3340, "OffsetEndMs": 3600}, {"Word": "it", "OffsetStartMs": 3600, "OffsetEndMs": 3750}, {"Word": "turns", "OffsetStartMs": 3750, "OffsetEndMs": 3945}, {"Word": "out", "OffsetStartMs": 3945, "OffsetEndMs": 4200}, {"Word": "that", "OffsetStartMs": 4200, "OffsetEndMs": 4455}, {"Word": "in", "OffsetStartMs": 4455, "OffsetEndMs": 4680}, {"Word": "practice", "OffsetStartMs": 4680, "OffsetEndMs": 5000}, {"Word": "this", "OffsetStartMs": 5080, "OffsetEndMs": 5480}, {"Word": "idea", "OffsetStartMs": 5680, "OffsetEndMs": 6000}, {"Word": "of", "OffsetStartMs": 6000, "OffsetEndMs": 6320}, {"Word": "self", "OffsetStartMs": 6520, "OffsetEndMs": 6810}, {"Word": "encoding", "OffsetStartMs": 6810, "OffsetEndMs": 7380}, {"Word": "or", "OffsetStartMs": 7380, "OffsetEndMs": 7560}, {"Word": "auto", "OffsetStartMs": 7560, "OffsetEndMs": 7785}, {"Word": "encoding", "OffsetStartMs": 7785, "OffsetEndMs": 8480}, {"Word": "has", "OffsetStartMs": 8560, "OffsetEndMs": 8865}, {"Word": "a", "OffsetStartMs": 8865, "OffsetEndMs": 9030}, {"Word": "bit", "OffsetStartMs": 9030, "OffsetEndMs": 9150}, {"Word": "of", "OffsetStartMs": 9150, "OffsetEndMs": 9255}, {"Word": "a", "OffsetStartMs": 9255, "OffsetEndMs": 9420}, {"Word": "twist", "OffsetStartMs": 9420, "OffsetEndMs": 9750}, {"Word": "on", "OffsetStartMs": 9750, "OffsetEndMs": 10020}, {"Word": "it", "OffsetStartMs": 10020, "OffsetEndMs": 10310}, {"Word": "to", "OffsetStartMs": 10660, "OffsetEndMs": 10995}, {"Word": "allow", "OffsetStartMs": 10995, "OffsetEndMs": 11250}, {"Word": "us", "OffsetStartMs": 11250, "OffsetEndMs": 11460}, {"Word": "to", "OffsetStartMs": 11460, "OffsetEndMs": 11745}, {"Word": "actually", "OffsetStartMs": 11745, "OffsetEndMs": 12075}, {"Word": "generate", "OffsetStartMs": 12075, "OffsetEndMs": 12410}, {"Word": "new", "OffsetStartMs": 13240, "OffsetEndMs": 13640}, {"Word": "examples", "OffsetStartMs": 13690, "OffsetEndMs": 14090}, {"Word": "that", "OffsetStartMs": 14230, "OffsetEndMs": 14505}, {"Word": "are", "OffsetStartMs": 14505, "OffsetEndMs": 14685}, {"Word": "not", "OffsetStartMs": 14685, "OffsetEndMs": 14925}, {"Word": "only", "OffsetStartMs": 14925, "OffsetEndMs": 15260}, {"Word": "reconstructions", "OffsetStartMs": 15580, "OffsetEndMs": 16560}, {"Word": "of", "OffsetStartMs": 16560, "OffsetEndMs": 16785}, {"Word": "the", "OffsetStartMs": 16785, "OffsetEndMs": 16995}, {"Word": "input", "OffsetStartMs": 16995, "OffsetEndMs": 17205}, {"Word": "data", "OffsetStartMs": 17205, "OffsetEndMs": 17480}, {"Word": "itself", "OffsetStartMs": 17530, "OffsetEndMs": 17930}], "SpeechSpeed": 13.1}, {"FinalSentence": "And this leads us to the concept of variational auto encoders, or v A.", "SliceSentence": "And this leads us to the concept of variational auto encoders or v A", "StartMs": 918360, "EndMs": 924020, "WordsNum": 14, "Words": [{"Word": "And", "OffsetStartMs": 40, "OffsetEndMs": 330}, {"Word": "this", "OffsetStartMs": 330, "OffsetEndMs": 525}, {"Word": "leads", "OffsetStartMs": 525, "OffsetEndMs": 720}, {"Word": "us", "OffsetStartMs": 720, "OffsetEndMs": 960}, {"Word": "to", "OffsetStartMs": 960, "OffsetEndMs": 1155}, {"Word": "the", "OffsetStartMs": 1155, "OffsetEndMs": 1290}, {"Word": "concept", "OffsetStartMs": 1290, "OffsetEndMs": 1580}, {"Word": "of", "OffsetStartMs": 1690, "OffsetEndMs": 1995}, {"Word": "variational", "OffsetStartMs": 1995, "OffsetEndMs": 2570}, {"Word": "auto", "OffsetStartMs": 2590, "OffsetEndMs": 2925}, {"Word": "encoders", "OffsetStartMs": 2925, "OffsetEndMs": 3555}, {"Word": "or", "OffsetStartMs": 3555, "OffsetEndMs": 3915}, {"Word": "v", "OffsetStartMs": 3915, "OffsetEndMs": 4230}, {"Word": "A", "OffsetStartMs": 4230, "OffsetEndMs": 4550}], "SpeechSpeed": 12.0}, {"FinalSentence": "With the traditional auto encoder that we just saw, if we pay closer attention to the latent layer, which is shown in that orange salmon color, that latent layer is just a normal layer in the neural network. It's completely deterministic.", "SliceSentence": "With the traditional auto encoder that we just saw if we pay closer attention to the latent layer which is shown in that orange salmon color that latent layer is just a normal layer in the neural network .It's completely deterministic", "StartMs": 924520, "EndMs": 941840, "WordsNum": 41, "Words": [{"Word": "With", "OffsetStartMs": 100, "OffsetEndMs": 405}, {"Word": "the", "OffsetStartMs": 405, "OffsetEndMs": 660}, {"Word": "traditional", "OffsetStartMs": 660, "OffsetEndMs": 1005}, {"Word": "auto", "OffsetStartMs": 1005, "OffsetEndMs": 1320}, {"Word": "encoder", "OffsetStartMs": 1320, "OffsetEndMs": 1965}, {"Word": "that", "OffsetStartMs": 1965, "OffsetEndMs": 2160}, {"Word": "we", "OffsetStartMs": 2160, "OffsetEndMs": 2325}, {"Word": "just", "OffsetStartMs": 2325, "OffsetEndMs": 2505}, {"Word": "saw", "OffsetStartMs": 2505, "OffsetEndMs": 2810}, {"Word": "if", "OffsetStartMs": 3430, "OffsetEndMs": 3720}, {"Word": "we", "OffsetStartMs": 3720, "OffsetEndMs": 3930}, {"Word": "pay", "OffsetStartMs": 3930, "OffsetEndMs": 4250}, {"Word": "closer", "OffsetStartMs": 4300, "OffsetEndMs": 4700}, {"Word": "attention", "OffsetStartMs": 5140, "OffsetEndMs": 5540}, {"Word": "to", "OffsetStartMs": 5620, "OffsetEndMs": 5880}, {"Word": "the", "OffsetStartMs": 5880, "OffsetEndMs": 6015}, {"Word": "latent", "OffsetStartMs": 6015, "OffsetEndMs": 6360}, {"Word": "layer", "OffsetStartMs": 6360, "OffsetEndMs": 6620}, {"Word": "which", "OffsetStartMs": 7060, "OffsetEndMs": 7350}, {"Word": "is", "OffsetStartMs": 7350, "OffsetEndMs": 7545}, {"Word": "shown", "OffsetStartMs": 7545, "OffsetEndMs": 7785}, {"Word": "in", "OffsetStartMs": 7785, "OffsetEndMs": 7995}, {"Word": "that", "OffsetStartMs": 7995, "OffsetEndMs": 8270}, {"Word": "orange", "OffsetStartMs": 8500, "OffsetEndMs": 8900}, {"Word": "salmon", "OffsetStartMs": 8950, "OffsetEndMs": 9405}, {"Word": "color", "OffsetStartMs": 9405, "OffsetEndMs": 9710}, {"Word": "that", "OffsetStartMs": 10630, "OffsetEndMs": 10950}, {"Word": "latent", "OffsetStartMs": 10950, "OffsetEndMs": 11340}, {"Word": "layer", "OffsetStartMs": 11340, "OffsetEndMs": 11595}, {"Word": "is", "OffsetStartMs": 11595, "OffsetEndMs": 11865}, {"Word": "just", "OffsetStartMs": 11865, "OffsetEndMs": 12075}, {"Word": "a", "OffsetStartMs": 12075, "OffsetEndMs": 12300}, {"Word": "normal", "OffsetStartMs": 12300, "OffsetEndMs": 12620}, {"Word": "layer", "OffsetStartMs": 13090, "OffsetEndMs": 13490}, {"Word": "in", "OffsetStartMs": 13540, "OffsetEndMs": 13830}, {"Word": "the", "OffsetStartMs": 13830, "OffsetEndMs": 13980}, {"Word": "neural", "OffsetStartMs": 13980, "OffsetEndMs": 14205}, {"Word": "network", "OffsetStartMs": 14205, "OffsetEndMs": 14480}, {"Word": ".It's", "OffsetStartMs": 14830, "OffsetEndMs": 15350}, {"Word": "completely", "OffsetStartMs": 15370, "OffsetEndMs": 15770}, {"Word": "deterministic", "OffsetStartMs": 15970, "OffsetEndMs": 16820}], "SpeechSpeed": 13.5}, {"FinalSentence": "What that means is once we've trained the network, once the weights are set, anytime we pass a given input in and go back through the latent layer, decode back out, we're going to get the same exact reconstruction. The weights aren't changing, it's deterministic.", "SliceSentence": "What that means is once we've trained the network once the weights are set anytime we pass a given input in and go back through the latent layer decode back out we're going to get the same exact reconstruction . Theweights aren't changing it's deterministic", "StartMs": 941840, "EndMs": 958780, "WordsNum": 45, "Words": [{"Word": "What", "OffsetStartMs": 10, "OffsetEndMs": 300}, {"Word": "that", "OffsetStartMs": 300, "OffsetEndMs": 480}, {"Word": "means", "OffsetStartMs": 480, "OffsetEndMs": 705}, {"Word": "is", "OffsetStartMs": 705, "OffsetEndMs": 1040}, {"Word": "once", "OffsetStartMs": 1120, "OffsetEndMs": 1485}, {"Word": "we've", "OffsetStartMs": 1485, "OffsetEndMs": 1845}, {"Word": "trained", "OffsetStartMs": 1845, "OffsetEndMs": 2025}, {"Word": "the", "OffsetStartMs": 2025, "OffsetEndMs": 2190}, {"Word": "network", "OffsetStartMs": 2190, "OffsetEndMs": 2450}, {"Word": "once", "OffsetStartMs": 2530, "OffsetEndMs": 2865}, {"Word": "the", "OffsetStartMs": 2865, "OffsetEndMs": 3060}, {"Word": "weights", "OffsetStartMs": 3060, "OffsetEndMs": 3330}, {"Word": "are", "OffsetStartMs": 3330, "OffsetEndMs": 3510}, {"Word": "set", "OffsetStartMs": 3510, "OffsetEndMs": 3830}, {"Word": "anytime", "OffsetStartMs": 4270, "OffsetEndMs": 4950}, {"Word": "we", "OffsetStartMs": 4950, "OffsetEndMs": 5190}, {"Word": "pass", "OffsetStartMs": 5190, "OffsetEndMs": 5510}, {"Word": "a", "OffsetStartMs": 5620, "OffsetEndMs": 5895}, {"Word": "given", "OffsetStartMs": 5895, "OffsetEndMs": 6170}, {"Word": "input", "OffsetStartMs": 6280, "OffsetEndMs": 6570}, {"Word": "in", "OffsetStartMs": 6570, "OffsetEndMs": 6860}, {"Word": "and", "OffsetStartMs": 7270, "OffsetEndMs": 7670}, {"Word": "go", "OffsetStartMs": 7720, "OffsetEndMs": 8010}, {"Word": "back", "OffsetStartMs": 8010, "OffsetEndMs": 8295}, {"Word": "through", "OffsetStartMs": 8295, "OffsetEndMs": 8565}, {"Word": "the", "OffsetStartMs": 8565, "OffsetEndMs": 8700}, {"Word": "latent", "OffsetStartMs": 8700, "OffsetEndMs": 9015}, {"Word": "layer", "OffsetStartMs": 9015, "OffsetEndMs": 9290}, {"Word": "decode", "OffsetStartMs": 9760, "OffsetEndMs": 10290}, {"Word": "back", "OffsetStartMs": 10290, "OffsetEndMs": 10455}, {"Word": "out", "OffsetStartMs": 10455, "OffsetEndMs": 10760}, {"Word": "we're", "OffsetStartMs": 10960, "OffsetEndMs": 11310}, {"Word": "going", "OffsetStartMs": 11310, "OffsetEndMs": 11490}, {"Word": "to", "OffsetStartMs": 11490, "OffsetEndMs": 11655}, {"Word": "get", "OffsetStartMs": 11655, "OffsetEndMs": 11805}, {"Word": "the", "OffsetStartMs": 11805, "OffsetEndMs": 12015}, {"Word": "same", "OffsetStartMs": 12015, "OffsetEndMs": 12320}, {"Word": "exact", "OffsetStartMs": 12400, "OffsetEndMs": 12750}, {"Word": "reconstruction", "OffsetStartMs": 12750, "OffsetEndMs": 13460}, {"Word": ".", "OffsetStartMs": 13810, "OffsetEndMs": 14085}, {"Word": "Theweights", "OffsetStartMs": 14085, "OffsetEndMs": 14370}, {"Word": "aren't", "OffsetStartMs": 14370, "OffsetEndMs": 14670}, {"Word": "changing", "OffsetStartMs": 14670, "OffsetEndMs": 14960}, {"Word": "it's", "OffsetStartMs": 15190, "OffsetEndMs": 15660}, {"Word": "deterministic", "OffsetStartMs": 15660, "OffsetEndMs": 16430}], "SpeechSpeed": 15.1}, {"FinalSentence": "In contrast.", "SliceSentence": "In contrast", "StartMs": 959160, "EndMs": 961060, "WordsNum": 2, "Words": [{"Word": "In", "OffsetStartMs": 70, "OffsetEndMs": 405}, {"Word": "contrast", "OffsetStartMs": 405, "OffsetEndMs": 740}], "SpeechSpeed": 5.8}, {"FinalSentence": "Variational auto encoders ves introduce an element of randomness, a probabilistic twist on this idea of auto encoding.", "SliceSentence": "Variational auto encoders ves introduce an element of randomness a probabilistic twist on this idea of auto encoding", "StartMs": 961060, "EndMs": 971240, "WordsNum": 18, "Words": [{"Word": "Variational", "OffsetStartMs": 0, "OffsetEndMs": 590}, {"Word": "auto", "OffsetStartMs": 610, "OffsetEndMs": 945}, {"Word": "encoders", "OffsetStartMs": 945, "OffsetEndMs": 1550}, {"Word": "ves", "OffsetStartMs": 1600, "OffsetEndMs": 2330}, {"Word": "introduce", "OffsetStartMs": 3340, "OffsetEndMs": 3720}, {"Word": "an", "OffsetStartMs": 3720, "OffsetEndMs": 4100}, {"Word": "element", "OffsetStartMs": 4510, "OffsetEndMs": 4905}, {"Word": "of", "OffsetStartMs": 4905, "OffsetEndMs": 5190}, {"Word": "randomness", "OffsetStartMs": 5190, "OffsetEndMs": 5835}, {"Word": "a", "OffsetStartMs": 5835, "OffsetEndMs": 6075}, {"Word": "probabilistic", "OffsetStartMs": 6075, "OffsetEndMs": 6975}, {"Word": "twist", "OffsetStartMs": 6975, "OffsetEndMs": 7340}, {"Word": "on", "OffsetStartMs": 7660, "OffsetEndMs": 7980}, {"Word": "this", "OffsetStartMs": 7980, "OffsetEndMs": 8295}, {"Word": "idea", "OffsetStartMs": 8295, "OffsetEndMs": 8565}, {"Word": "of", "OffsetStartMs": 8565, "OffsetEndMs": 8730}, {"Word": "auto", "OffsetStartMs": 8730, "OffsetEndMs": 8940}, {"Word": "encoding", "OffsetStartMs": 8940, "OffsetEndMs": 9620}], "SpeechSpeed": 11.4}, {"FinalSentence": "What this will allow us to do is to actually generate new images, similar to the new data, instances that are similar to the input data but not forced to be strict reconstructions.", "SliceSentence": "What this will allow us to do is to actually generate new images similar to the new data instances that are similar to the input data but not forced to be strict reconstructions", "StartMs": 971240, "EndMs": 984340, "WordsNum": 33, "Words": [{"Word": "What", "OffsetStartMs": 0, "OffsetEndMs": 285}, {"Word": "this", "OffsetStartMs": 285, "OffsetEndMs": 480}, {"Word": "will", "OffsetStartMs": 480, "OffsetEndMs": 705}, {"Word": "allow", "OffsetStartMs": 705, "OffsetEndMs": 975}, {"Word": "us", "OffsetStartMs": 975, "OffsetEndMs": 1215}, {"Word": "to", "OffsetStartMs": 1215, "OffsetEndMs": 1380}, {"Word": "do", "OffsetStartMs": 1380, "OffsetEndMs": 1575}, {"Word": "is", "OffsetStartMs": 1575, "OffsetEndMs": 1785}, {"Word": "to", "OffsetStartMs": 1785, "OffsetEndMs": 2025}, {"Word": "actually", "OffsetStartMs": 2025, "OffsetEndMs": 2295}, {"Word": "generate", "OffsetStartMs": 2295, "OffsetEndMs": 2600}, {"Word": "new", "OffsetStartMs": 2800, "OffsetEndMs": 3120}, {"Word": "images", "OffsetStartMs": 3120, "OffsetEndMs": 3440}, {"Word": "similar", "OffsetStartMs": 4180, "OffsetEndMs": 4580}, {"Word": "to", "OffsetStartMs": 4660, "OffsetEndMs": 4950}, {"Word": "the", "OffsetStartMs": 4950, "OffsetEndMs": 5235}, {"Word": "new", "OffsetStartMs": 5235, "OffsetEndMs": 5630}, {"Word": "data", "OffsetStartMs": 5710, "OffsetEndMs": 6030}, {"Word": "instances", "OffsetStartMs": 6030, "OffsetEndMs": 6800}, {"Word": "that", "OffsetStartMs": 7090, "OffsetEndMs": 7365}, {"Word": "are", "OffsetStartMs": 7365, "OffsetEndMs": 7590}, {"Word": "similar", "OffsetStartMs": 7590, "OffsetEndMs": 7940}, {"Word": "to", "OffsetStartMs": 7960, "OffsetEndMs": 8205}, {"Word": "the", "OffsetStartMs": 8205, "OffsetEndMs": 8385}, {"Word": "input", "OffsetStartMs": 8385, "OffsetEndMs": 8610}, {"Word": "data", "OffsetStartMs": 8610, "OffsetEndMs": 8900}, {"Word": "but", "OffsetStartMs": 9370, "OffsetEndMs": 9770}, {"Word": "not", "OffsetStartMs": 9850, "OffsetEndMs": 10245}, {"Word": "forced", "OffsetStartMs": 10245, "OffsetEndMs": 10605}, {"Word": "to", "OffsetStartMs": 10605, "OffsetEndMs": 10830}, {"Word": "be", "OffsetStartMs": 10830, "OffsetEndMs": 11090}, {"Word": "strict", "OffsetStartMs": 11110, "OffsetEndMs": 11510}, {"Word": "reconstructions", "OffsetStartMs": 11560, "OffsetEndMs": 12530}], "SpeechSpeed": 13.5}, {"FinalSentence": "In practice, with a variational auto encoder, we've replaced that single deterministic layer with a random sampling operation.", "SliceSentence": "In practice with a variational auto encoder we've replaced that single deterministic layer with a random sampling operation", "StartMs": 984800, "EndMs": 994260, "WordsNum": 18, "Words": [{"Word": "In", "OffsetStartMs": 70, "OffsetEndMs": 390}, {"Word": "practice", "OffsetStartMs": 390, "OffsetEndMs": 710}, {"Word": "with", "OffsetStartMs": 910, "OffsetEndMs": 1170}, {"Word": "a", "OffsetStartMs": 1170, "OffsetEndMs": 1290}, {"Word": "variational", "OffsetStartMs": 1290, "OffsetEndMs": 1755}, {"Word": "auto", "OffsetStartMs": 1755, "OffsetEndMs": 2055}, {"Word": "encoder", "OffsetStartMs": 2055, "OffsetEndMs": 2720}, {"Word": "we've", "OffsetStartMs": 3070, "OffsetEndMs": 3570}, {"Word": "replaced", "OffsetStartMs": 3570, "OffsetEndMs": 3885}, {"Word": "that", "OffsetStartMs": 3885, "OffsetEndMs": 4185}, {"Word": "single", "OffsetStartMs": 4185, "OffsetEndMs": 4550}, {"Word": "deterministic", "OffsetStartMs": 4870, "OffsetEndMs": 5580}, {"Word": "layer", "OffsetStartMs": 5580, "OffsetEndMs": 5870}, {"Word": "with", "OffsetStartMs": 6130, "OffsetEndMs": 6530}, {"Word": "a", "OffsetStartMs": 6700, "OffsetEndMs": 7020}, {"Word": "random", "OffsetStartMs": 7020, "OffsetEndMs": 7340}, {"Word": "sampling", "OffsetStartMs": 7510, "OffsetEndMs": 8180}, {"Word": "operation", "OffsetStartMs": 8260, "OffsetEndMs": 8660}], "SpeechSpeed": 13.0}, {"FinalSentence": "Now, instead of learning just the latent variables directly themselves, for each latent variable, we define a mean and a standard deviation that captures a probability distribution over that latent variable.", "SliceSentence": "Now instead of learning just the latent variables directly themselves for each latent variable we define a mean and a standard deviation that captures a probability distribution over that latent variable", "StartMs": 995220, "EndMs": 1009440, "WordsNum": 31, "Words": [{"Word": "Now", "OffsetStartMs": 160, "OffsetEndMs": 560}, {"Word": "instead", "OffsetStartMs": 970, "OffsetEndMs": 1290}, {"Word": "of", "OffsetStartMs": 1290, "OffsetEndMs": 1530}, {"Word": "learning", "OffsetStartMs": 1530, "OffsetEndMs": 1850}, {"Word": "just", "OffsetStartMs": 1870, "OffsetEndMs": 2220}, {"Word": "the", "OffsetStartMs": 2220, "OffsetEndMs": 2430}, {"Word": "latent", "OffsetStartMs": 2430, "OffsetEndMs": 2715}, {"Word": "variables", "OffsetStartMs": 2715, "OffsetEndMs": 3195}, {"Word": "directly", "OffsetStartMs": 3195, "OffsetEndMs": 3530}, {"Word": "themselves", "OffsetStartMs": 3700, "OffsetEndMs": 4100}, {"Word": "for", "OffsetStartMs": 4540, "OffsetEndMs": 4860}, {"Word": "each", "OffsetStartMs": 4860, "OffsetEndMs": 5130}, {"Word": "latent", "OffsetStartMs": 5130, "OffsetEndMs": 5505}, {"Word": "variable", "OffsetStartMs": 5505, "OffsetEndMs": 5780}, {"Word": "we", "OffsetStartMs": 6100, "OffsetEndMs": 6465}, {"Word": "define", "OffsetStartMs": 6465, "OffsetEndMs": 6780}, {"Word": "a", "OffsetStartMs": 6780, "OffsetEndMs": 7020}, {"Word": "mean", "OffsetStartMs": 7020, "OffsetEndMs": 7310}, {"Word": "and", "OffsetStartMs": 7510, "OffsetEndMs": 7860}, {"Word": "a", "OffsetStartMs": 7860, "OffsetEndMs": 8115}, {"Word": "standard", "OffsetStartMs": 8115, "OffsetEndMs": 8400}, {"Word": "deviation", "OffsetStartMs": 8400, "OffsetEndMs": 9020}, {"Word": "that", "OffsetStartMs": 9460, "OffsetEndMs": 9780}, {"Word": "captures", "OffsetStartMs": 9780, "OffsetEndMs": 10290}, {"Word": "a", "OffsetStartMs": 10290, "OffsetEndMs": 10515}, {"Word": "probability", "OffsetStartMs": 10515, "OffsetEndMs": 11120}, {"Word": "distribution", "OffsetStartMs": 11290, "OffsetEndMs": 11690}, {"Word": "over", "OffsetStartMs": 11950, "OffsetEndMs": 12350}, {"Word": "that", "OffsetStartMs": 12520, "OffsetEndMs": 12825}, {"Word": "latent", "OffsetStartMs": 12825, "OffsetEndMs": 13185}, {"Word": "variable", "OffsetStartMs": 13185, "OffsetEndMs": 13460}], "SpeechSpeed": 14.3}, {"FinalSentence": "What we've done is we've gone from a single vector of latent variable z to a vector of means, mu and a vector of standard deviations sigma that parameterize the probability distributions around those latent variables.", "SliceSentence": "What we've done is we've gone from a single vector of latent variable z to a vector of means mu and a vector of standard deviations sigma that parameterize the probability distributions around those latent variables", "StartMs": 1010340, "EndMs": 1025360, "WordsNum": 36, "Words": [{"Word": "What", "OffsetStartMs": 100, "OffsetEndMs": 375}, {"Word": "we've", "OffsetStartMs": 375, "OffsetEndMs": 585}, {"Word": "done", "OffsetStartMs": 585, "OffsetEndMs": 720}, {"Word": "is", "OffsetStartMs": 720, "OffsetEndMs": 900}, {"Word": "we've", "OffsetStartMs": 900, "OffsetEndMs": 1125}, {"Word": "gone", "OffsetStartMs": 1125, "OffsetEndMs": 1290}, {"Word": "from", "OffsetStartMs": 1290, "OffsetEndMs": 1455}, {"Word": "a", "OffsetStartMs": 1455, "OffsetEndMs": 1605}, {"Word": "single", "OffsetStartMs": 1605, "OffsetEndMs": 1905}, {"Word": "vector", "OffsetStartMs": 1905, "OffsetEndMs": 2265}, {"Word": "of", "OffsetStartMs": 2265, "OffsetEndMs": 2460}, {"Word": "latent", "OffsetStartMs": 2460, "OffsetEndMs": 2775}, {"Word": "variable", "OffsetStartMs": 2775, "OffsetEndMs": 3050}, {"Word": "z", "OffsetStartMs": 3160, "OffsetEndMs": 3560}, {"Word": "to", "OffsetStartMs": 4000, "OffsetEndMs": 4320}, {"Word": "a", "OffsetStartMs": 4320, "OffsetEndMs": 4530}, {"Word": "vector", "OffsetStartMs": 4530, "OffsetEndMs": 4815}, {"Word": "of", "OffsetStartMs": 4815, "OffsetEndMs": 5040}, {"Word": "means", "OffsetStartMs": 5040, "OffsetEndMs": 5330}, {"Word": "mu", "OffsetStartMs": 5500, "OffsetEndMs": 5900}, {"Word": "and", "OffsetStartMs": 6310, "OffsetEndMs": 6660}, {"Word": "a", "OffsetStartMs": 6660, "OffsetEndMs": 6885}, {"Word": "vector", "OffsetStartMs": 6885, "OffsetEndMs": 7190}, {"Word": "of", "OffsetStartMs": 7210, "OffsetEndMs": 7610}, {"Word": "standard", "OffsetStartMs": 7630, "OffsetEndMs": 8025}, {"Word": "deviations", "OffsetStartMs": 8025, "OffsetEndMs": 8660}, {"Word": "sigma", "OffsetStartMs": 9010, "OffsetEndMs": 9590}, {"Word": "that", "OffsetStartMs": 9820, "OffsetEndMs": 10185}, {"Word": "parameterize", "OffsetStartMs": 10185, "OffsetEndMs": 10980}, {"Word": "the", "OffsetStartMs": 10980, "OffsetEndMs": 11250}, {"Word": "probability", "OffsetStartMs": 11250, "OffsetEndMs": 11810}, {"Word": "distributions", "OffsetStartMs": 11950, "OffsetEndMs": 12500}, {"Word": "around", "OffsetStartMs": 12730, "OffsetEndMs": 13095}, {"Word": "those", "OffsetStartMs": 13095, "OffsetEndMs": 13460}, {"Word": "latent", "OffsetStartMs": 13480, "OffsetEndMs": 13905}, {"Word": "variables", "OffsetStartMs": 13905, "OffsetEndMs": 14450}], "SpeechSpeed": 14.3}, {"FinalSentence": "What this will allow us to do is now sample using this element of randomness, this element of probability, to then obtain a probabilistic representation of the latent space itself.", "SliceSentence": "What this will allow us to do is now sample using this element of randomness this element of probability to then obtain a probabilistic representation of the latent space itself", "StartMs": 1026420, "EndMs": 1038980, "WordsNum": 30, "Words": [{"Word": "What", "OffsetStartMs": 100, "OffsetEndMs": 390}, {"Word": "this", "OffsetStartMs": 390, "OffsetEndMs": 570}, {"Word": "will", "OffsetStartMs": 570, "OffsetEndMs": 780}, {"Word": "allow", "OffsetStartMs": 780, "OffsetEndMs": 990}, {"Word": "us", "OffsetStartMs": 990, "OffsetEndMs": 1185}, {"Word": "to", "OffsetStartMs": 1185, "OffsetEndMs": 1350}, {"Word": "do", "OffsetStartMs": 1350, "OffsetEndMs": 1485}, {"Word": "is", "OffsetStartMs": 1485, "OffsetEndMs": 1665}, {"Word": "now", "OffsetStartMs": 1665, "OffsetEndMs": 1970}, {"Word": "sample", "OffsetStartMs": 2020, "OffsetEndMs": 2420}, {"Word": "using", "OffsetStartMs": 3160, "OffsetEndMs": 3540}, {"Word": "this", "OffsetStartMs": 3540, "OffsetEndMs": 3920}, {"Word": "element", "OffsetStartMs": 4000, "OffsetEndMs": 4400}, {"Word": "of", "OffsetStartMs": 4420, "OffsetEndMs": 4695}, {"Word": "randomness", "OffsetStartMs": 4695, "OffsetEndMs": 5265}, {"Word": "this", "OffsetStartMs": 5265, "OffsetEndMs": 5460}, {"Word": "element", "OffsetStartMs": 5460, "OffsetEndMs": 5745}, {"Word": "of", "OffsetStartMs": 5745, "OffsetEndMs": 6030}, {"Word": "probability", "OffsetStartMs": 6030, "OffsetEndMs": 6590}, {"Word": "to", "OffsetStartMs": 7090, "OffsetEndMs": 7365}, {"Word": "then", "OffsetStartMs": 7365, "OffsetEndMs": 7640}, {"Word": "obtain", "OffsetStartMs": 7810, "OffsetEndMs": 8415}, {"Word": "a", "OffsetStartMs": 8415, "OffsetEndMs": 8685}, {"Word": "probabilistic", "OffsetStartMs": 8685, "OffsetEndMs": 9480}, {"Word": "representation", "OffsetStartMs": 9480, "OffsetEndMs": 10220}, {"Word": "of", "OffsetStartMs": 10270, "OffsetEndMs": 10665}, {"Word": "the", "OffsetStartMs": 10665, "OffsetEndMs": 10920}, {"Word": "latent", "OffsetStartMs": 10920, "OffsetEndMs": 11250}, {"Word": "space", "OffsetStartMs": 11250, "OffsetEndMs": 11535}, {"Word": "itself", "OffsetStartMs": 11535, "OffsetEndMs": 11930}], "SpeechSpeed": 14.1}, {"FinalSentence": "As you hopefully can tell, right, this is very, very, very similar to the auto encoder itself, but we've just added this probabilistic twist where we can sample in that intermediate space to get these samples of latent variables.", "SliceSentence": "As you hopefully can tell right this is very very very similar to the auto encoder itself but we've just added this probabilistic twist where we can sample in that intermediate space to get these samples of latent variables", "StartMs": 1039460, "EndMs": 1054100, "WordsNum": 39, "Words": [{"Word": "As", "OffsetStartMs": 130, "OffsetEndMs": 435}, {"Word": "you", "OffsetStartMs": 435, "OffsetEndMs": 600}, {"Word": "hopefully", "OffsetStartMs": 600, "OffsetEndMs": 825}, {"Word": "can", "OffsetStartMs": 825, "OffsetEndMs": 1095}, {"Word": "tell", "OffsetStartMs": 1095, "OffsetEndMs": 1305}, {"Word": "right", "OffsetStartMs": 1305, "OffsetEndMs": 1545}, {"Word": "this", "OffsetStartMs": 1545, "OffsetEndMs": 1740}, {"Word": "is", "OffsetStartMs": 1740, "OffsetEndMs": 1965}, {"Word": "very", "OffsetStartMs": 1965, "OffsetEndMs": 2310}, {"Word": "very", "OffsetStartMs": 2310, "OffsetEndMs": 2610}, {"Word": "very", "OffsetStartMs": 2610, "OffsetEndMs": 2880}, {"Word": "similar", "OffsetStartMs": 2880, "OffsetEndMs": 3230}, {"Word": "to", "OffsetStartMs": 3340, "OffsetEndMs": 3645}, {"Word": "the", "OffsetStartMs": 3645, "OffsetEndMs": 3810}, {"Word": "auto", "OffsetStartMs": 3810, "OffsetEndMs": 4005}, {"Word": "encoder", "OffsetStartMs": 4005, "OffsetEndMs": 4590}, {"Word": "itself", "OffsetStartMs": 4590, "OffsetEndMs": 4940}, {"Word": "but", "OffsetStartMs": 5380, "OffsetEndMs": 5745}, {"Word": "we've", "OffsetStartMs": 5745, "OffsetEndMs": 6075}, {"Word": "just", "OffsetStartMs": 6075, "OffsetEndMs": 6225}, {"Word": "added", "OffsetStartMs": 6225, "OffsetEndMs": 6510}, {"Word": "this", "OffsetStartMs": 6510, "OffsetEndMs": 6810}, {"Word": "probabilistic", "OffsetStartMs": 6810, "OffsetEndMs": 7590}, {"Word": "twist", "OffsetStartMs": 7590, "OffsetEndMs": 7940}, {"Word": "where", "OffsetStartMs": 8260, "OffsetEndMs": 8550}, {"Word": "we", "OffsetStartMs": 8550, "OffsetEndMs": 8715}, {"Word": "can", "OffsetStartMs": 8715, "OffsetEndMs": 8925}, {"Word": "sample", "OffsetStartMs": 8925, "OffsetEndMs": 9260}, {"Word": "in", "OffsetStartMs": 9310, "OffsetEndMs": 9570}, {"Word": "that", "OffsetStartMs": 9570, "OffsetEndMs": 9735}, {"Word": "intermediate", "OffsetStartMs": 9735, "OffsetEndMs": 10485}, {"Word": "space", "OffsetStartMs": 10485, "OffsetEndMs": 10820}, {"Word": "to", "OffsetStartMs": 11470, "OffsetEndMs": 11870}, {"Word": "get", "OffsetStartMs": 12070, "OffsetEndMs": 12375}, {"Word": "these", "OffsetStartMs": 12375, "OffsetEndMs": 12585}, {"Word": "samples", "OffsetStartMs": 12585, "OffsetEndMs": 13020}, {"Word": "of", "OffsetStartMs": 13020, "OffsetEndMs": 13215}, {"Word": "latent", "OffsetStartMs": 13215, "OffsetEndMs": 13530}, {"Word": "variables", "OffsetStartMs": 13530, "OffsetEndMs": 14090}], "SpeechSpeed": 15.2}, {"FinalSentence": "Okay.", "SliceSentence": "Okay", "StartMs": 1055800, "EndMs": 1057220, "WordsNum": 1, "Words": [{"Word": "Okay", "OffsetStartMs": 220, "OffsetEndMs": 620}], "SpeechSpeed": 2.8}, {"FinalSentence": "Now, to get a little more into the depth of how this is actually learned, how this is actually trained with defining the v, we've eliminated this deterministic nature to now have these encoders and decoders that are probabilistic.", "SliceSentence": "Now to get a little more into the depth of how this is actually learned how this is actually trained with defining the v we've eliminated this deterministic nature to now have these encoders and decoders that are probabilistic", "StartMs": 1057220, "EndMs": 1074120, "WordsNum": 39, "Words": [{"Word": "Now", "OffsetStartMs": 130, "OffsetEndMs": 530}, {"Word": "to", "OffsetStartMs": 1090, "OffsetEndMs": 1395}, {"Word": "get", "OffsetStartMs": 1395, "OffsetEndMs": 1590}, {"Word": "a", "OffsetStartMs": 1590, "OffsetEndMs": 1755}, {"Word": "little", "OffsetStartMs": 1755, "OffsetEndMs": 1950}, {"Word": "more", "OffsetStartMs": 1950, "OffsetEndMs": 2175}, {"Word": "into", "OffsetStartMs": 2175, "OffsetEndMs": 2445}, {"Word": "the", "OffsetStartMs": 2445, "OffsetEndMs": 2685}, {"Word": "depth", "OffsetStartMs": 2685, "OffsetEndMs": 2925}, {"Word": "of", "OffsetStartMs": 2925, "OffsetEndMs": 3290}, {"Word": "how", "OffsetStartMs": 3400, "OffsetEndMs": 3705}, {"Word": "this", "OffsetStartMs": 3705, "OffsetEndMs": 3885}, {"Word": "is", "OffsetStartMs": 3885, "OffsetEndMs": 4140}, {"Word": "actually", "OffsetStartMs": 4140, "OffsetEndMs": 4425}, {"Word": "learned", "OffsetStartMs": 4425, "OffsetEndMs": 4710}, {"Word": "how", "OffsetStartMs": 4710, "OffsetEndMs": 4980}, {"Word": "this", "OffsetStartMs": 4980, "OffsetEndMs": 5145}, {"Word": "is", "OffsetStartMs": 5145, "OffsetEndMs": 5385}, {"Word": "actually", "OffsetStartMs": 5385, "OffsetEndMs": 5700}, {"Word": "trained", "OffsetStartMs": 5700, "OffsetEndMs": 6050}, {"Word": "with", "OffsetStartMs": 7000, "OffsetEndMs": 7400}, {"Word": "defining", "OffsetStartMs": 7420, "OffsetEndMs": 7935}, {"Word": "the", "OffsetStartMs": 7935, "OffsetEndMs": 8100}, {"Word": "v", "OffsetStartMs": 8100, "OffsetEndMs": 8390}, {"Word": "we've", "OffsetStartMs": 9010, "OffsetEndMs": 9525}, {"Word": "eliminated", "OffsetStartMs": 9525, "OffsetEndMs": 10110}, {"Word": "this", "OffsetStartMs": 10110, "OffsetEndMs": 10490}, {"Word": "deterministic", "OffsetStartMs": 10540, "OffsetEndMs": 11265}, {"Word": "nature", "OffsetStartMs": 11265, "OffsetEndMs": 11570}, {"Word": "to", "OffsetStartMs": 12160, "OffsetEndMs": 12435}, {"Word": "now", "OffsetStartMs": 12435, "OffsetEndMs": 12705}, {"Word": "have", "OffsetStartMs": 12705, "OffsetEndMs": 13020}, {"Word": "these", "OffsetStartMs": 13020, "OffsetEndMs": 13260}, {"Word": "encoders", "OffsetStartMs": 13260, "OffsetEndMs": 13920}, {"Word": "and", "OffsetStartMs": 13920, "OffsetEndMs": 14145}, {"Word": "decoders", "OffsetStartMs": 14145, "OffsetEndMs": 14715}, {"Word": "that", "OffsetStartMs": 14715, "OffsetEndMs": 14955}, {"Word": "are", "OffsetStartMs": 14955, "OffsetEndMs": 15290}, {"Word": "probabilistic", "OffsetStartMs": 15430, "OffsetEndMs": 16460}], "SpeechSpeed": 13.4}, {"FinalSentence": "The encoder is computing a probability distribution of the latent variable z given input data X.", "SliceSentence": "The encoder is computing a probability distribution of the latent variable z given input data X", "StartMs": 1074200, "EndMs": 1083680, "WordsNum": 16, "Words": [{"Word": "The", "OffsetStartMs": 220, "OffsetEndMs": 510}, {"Word": "encoder", "OffsetStartMs": 510, "OffsetEndMs": 1250}, {"Word": "is", "OffsetStartMs": 1420, "OffsetEndMs": 1820}, {"Word": "computing", "OffsetStartMs": 2350, "OffsetEndMs": 2805}, {"Word": "a", "OffsetStartMs": 2805, "OffsetEndMs": 3015}, {"Word": "probability", "OffsetStartMs": 3015, "OffsetEndMs": 3620}, {"Word": "distribution", "OffsetStartMs": 3730, "OffsetEndMs": 4130}, {"Word": "of", "OffsetStartMs": 4900, "OffsetEndMs": 5220}, {"Word": "the", "OffsetStartMs": 5220, "OffsetEndMs": 5400}, {"Word": "latent", "OffsetStartMs": 5400, "OffsetEndMs": 5730}, {"Word": "variable", "OffsetStartMs": 5730, "OffsetEndMs": 6020}, {"Word": "z", "OffsetStartMs": 6130, "OffsetEndMs": 6530}, {"Word": "given", "OffsetStartMs": 6790, "OffsetEndMs": 7190}, {"Word": "input", "OffsetStartMs": 7690, "OffsetEndMs": 7980}, {"Word": "data", "OffsetStartMs": 7980, "OffsetEndMs": 8250}, {"Word": "X", "OffsetStartMs": 8250, "OffsetEndMs": 8630}], "SpeechSpeed": 10.0}, {"FinalSentence": "While the decoder is doing the inverse, trying to learn a probability distribution back in the input data space, given the latent variables z.", "SliceSentence": "While the decoder is doing the inverse trying to learn a probability distribution back in the input data space given the latent variables z", "StartMs": 1083680, "EndMs": 1094820, "WordsNum": 24, "Words": [{"Word": "While", "OffsetStartMs": 0, "OffsetEndMs": 225}, {"Word": "the", "OffsetStartMs": 225, "OffsetEndMs": 420}, {"Word": "decoder", "OffsetStartMs": 420, "OffsetEndMs": 1035}, {"Word": "is", "OffsetStartMs": 1035, "OffsetEndMs": 1320}, {"Word": "doing", "OffsetStartMs": 1320, "OffsetEndMs": 1640}, {"Word": "the", "OffsetStartMs": 1780, "OffsetEndMs": 2025}, {"Word": "inverse", "OffsetStartMs": 2025, "OffsetEndMs": 2450}, {"Word": "trying", "OffsetStartMs": 2830, "OffsetEndMs": 3165}, {"Word": "to", "OffsetStartMs": 3165, "OffsetEndMs": 3375}, {"Word": "learn", "OffsetStartMs": 3375, "OffsetEndMs": 3615}, {"Word": "a", "OffsetStartMs": 3615, "OffsetEndMs": 3885}, {"Word": "probability", "OffsetStartMs": 3885, "OffsetEndMs": 4490}, {"Word": "distribution", "OffsetStartMs": 4600, "OffsetEndMs": 5000}, {"Word": "back", "OffsetStartMs": 5980, "OffsetEndMs": 6360}, {"Word": "in", "OffsetStartMs": 6360, "OffsetEndMs": 6630}, {"Word": "the", "OffsetStartMs": 6630, "OffsetEndMs": 6900}, {"Word": "input", "OffsetStartMs": 6900, "OffsetEndMs": 7170}, {"Word": "data", "OffsetStartMs": 7170, "OffsetEndMs": 7455}, {"Word": "space", "OffsetStartMs": 7455, "OffsetEndMs": 7850}, {"Word": "given", "OffsetStartMs": 8290, "OffsetEndMs": 8690}, {"Word": "the", "OffsetStartMs": 9010, "OffsetEndMs": 9270}, {"Word": "latent", "OffsetStartMs": 9270, "OffsetEndMs": 9615}, {"Word": "variables", "OffsetStartMs": 9615, "OffsetEndMs": 10215}, {"Word": "z", "OffsetStartMs": 10215, "OffsetEndMs": 10610}], "SpeechSpeed": 12.5}, {"FinalSentence": "And we define separate sets of weights, Phi and theta, to define the network weights for the encoder and decoder components of the v.", "SliceSentence": "And we define separate sets of weights Phi and theta to define the network weights for the encoder and decoder components of the v", "StartMs": 1095040, "EndMs": 1106120, "WordsNum": 24, "Words": [{"Word": "And", "OffsetStartMs": 160, "OffsetEndMs": 420}, {"Word": "we", "OffsetStartMs": 420, "OffsetEndMs": 645}, {"Word": "define", "OffsetStartMs": 645, "OffsetEndMs": 1005}, {"Word": "separate", "OffsetStartMs": 1005, "OffsetEndMs": 1400}, {"Word": "sets", "OffsetStartMs": 1420, "OffsetEndMs": 1725}, {"Word": "of", "OffsetStartMs": 1725, "OffsetEndMs": 1920}, {"Word": "weights", "OffsetStartMs": 1920, "OffsetEndMs": 2390}, {"Word": "Phi", "OffsetStartMs": 2890, "OffsetEndMs": 3380}, {"Word": "and", "OffsetStartMs": 3490, "OffsetEndMs": 3810}, {"Word": "theta", "OffsetStartMs": 3810, "OffsetEndMs": 4310}, {"Word": "to", "OffsetStartMs": 4390, "OffsetEndMs": 4755}, {"Word": "define", "OffsetStartMs": 4755, "OffsetEndMs": 5085}, {"Word": "the", "OffsetStartMs": 5085, "OffsetEndMs": 5450}, {"Word": "network", "OffsetStartMs": 5470, "OffsetEndMs": 5870}, {"Word": "weights", "OffsetStartMs": 5920, "OffsetEndMs": 6420}, {"Word": "for", "OffsetStartMs": 6420, "OffsetEndMs": 6630}, {"Word": "the", "OffsetStartMs": 6630, "OffsetEndMs": 6795}, {"Word": "encoder", "OffsetStartMs": 6795, "OffsetEndMs": 7515}, {"Word": "and", "OffsetStartMs": 7515, "OffsetEndMs": 7815}, {"Word": "decoder", "OffsetStartMs": 7815, "OffsetEndMs": 8480}, {"Word": "components", "OffsetStartMs": 8860, "OffsetEndMs": 9260}, {"Word": "of", "OffsetStartMs": 9460, "OffsetEndMs": 9780}, {"Word": "the", "OffsetStartMs": 9780, "OffsetEndMs": 9975}, {"Word": "v", "OffsetStartMs": 9975, "OffsetEndMs": 10250}], "SpeechSpeed": 11.7}, {"FinalSentence": "All right, so when we get now to how we actually optimize and learn the network weights in the va, first step is to define a loss function, right? That's the core element to training a neural network.", "SliceSentence": "All right so when we get now to how we actually optimize and learn the network weights in the va first step is to define a loss function right That's the core element to training a neural network", "StartMs": 1107300, "EndMs": 1121040, "WordsNum": 38, "Words": [{"Word": "All", "OffsetStartMs": 70, "OffsetEndMs": 315}, {"Word": "right", "OffsetStartMs": 315, "OffsetEndMs": 560}, {"Word": "so", "OffsetStartMs": 1030, "OffsetEndMs": 1430}, {"Word": "when", "OffsetStartMs": 1600, "OffsetEndMs": 1905}, {"Word": "we", "OffsetStartMs": 1905, "OffsetEndMs": 2100}, {"Word": "get", "OffsetStartMs": 2100, "OffsetEndMs": 2340}, {"Word": "now", "OffsetStartMs": 2340, "OffsetEndMs": 2690}, {"Word": "to", "OffsetStartMs": 2770, "OffsetEndMs": 3060}, {"Word": "how", "OffsetStartMs": 3060, "OffsetEndMs": 3240}, {"Word": "we", "OffsetStartMs": 3240, "OffsetEndMs": 3530}, {"Word": "actually", "OffsetStartMs": 3550, "OffsetEndMs": 3950}, {"Word": "optimize", "OffsetStartMs": 4300, "OffsetEndMs": 4770}, {"Word": "and", "OffsetStartMs": 4770, "OffsetEndMs": 5070}, {"Word": "learn", "OffsetStartMs": 5070, "OffsetEndMs": 5390}, {"Word": "the", "OffsetStartMs": 5620, "OffsetEndMs": 5880}, {"Word": "network", "OffsetStartMs": 5880, "OffsetEndMs": 6135}, {"Word": "weights", "OffsetStartMs": 6135, "OffsetEndMs": 6570}, {"Word": "in", "OffsetStartMs": 6570, "OffsetEndMs": 6735}, {"Word": "the", "OffsetStartMs": 6735, "OffsetEndMs": 6870}, {"Word": "va", "OffsetStartMs": 6870, "OffsetEndMs": 7220}, {"Word": "first", "OffsetStartMs": 8140, "OffsetEndMs": 8460}, {"Word": "step", "OffsetStartMs": 8460, "OffsetEndMs": 8715}, {"Word": "is", "OffsetStartMs": 8715, "OffsetEndMs": 8955}, {"Word": "to", "OffsetStartMs": 8955, "OffsetEndMs": 9195}, {"Word": "define", "OffsetStartMs": 9195, "OffsetEndMs": 9450}, {"Word": "a", "OffsetStartMs": 9450, "OffsetEndMs": 9630}, {"Word": "loss", "OffsetStartMs": 9630, "OffsetEndMs": 9825}, {"Word": "function", "OffsetStartMs": 9825, "OffsetEndMs": 10140}, {"Word": "right", "OffsetStartMs": 10140, "OffsetEndMs": 10410}, {"Word": "That's", "OffsetStartMs": 10410, "OffsetEndMs": 10695}, {"Word": "the", "OffsetStartMs": 10695, "OffsetEndMs": 10875}, {"Word": "core", "OffsetStartMs": 10875, "OffsetEndMs": 11180}, {"Word": "element", "OffsetStartMs": 11350, "OffsetEndMs": 11750}, {"Word": "to", "OffsetStartMs": 11830, "OffsetEndMs": 12135}, {"Word": "training", "OffsetStartMs": 12135, "OffsetEndMs": 12375}, {"Word": "a", "OffsetStartMs": 12375, "OffsetEndMs": 12585}, {"Word": "neural", "OffsetStartMs": 12585, "OffsetEndMs": 12810}, {"Word": "network", "OffsetStartMs": 12810, "OffsetEndMs": 13070}], "SpeechSpeed": 14.2}, {"FinalSentence": "Our loss is going to be a function of the data and a function of the neural network weights, just like before.", "SliceSentence": "Our loss is going to be a function of the data and a function of the neural network weights just like before", "StartMs": 1121420, "EndMs": 1128440, "WordsNum": 22, "Words": [{"Word": "Our", "OffsetStartMs": 70, "OffsetEndMs": 390}, {"Word": "loss", "OffsetStartMs": 390, "OffsetEndMs": 690}, {"Word": "is", "OffsetStartMs": 690, "OffsetEndMs": 960}, {"Word": "going", "OffsetStartMs": 960, "OffsetEndMs": 1155}, {"Word": "to", "OffsetStartMs": 1155, "OffsetEndMs": 1305}, {"Word": "be", "OffsetStartMs": 1305, "OffsetEndMs": 1470}, {"Word": "a", "OffsetStartMs": 1470, "OffsetEndMs": 1680}, {"Word": "function", "OffsetStartMs": 1680, "OffsetEndMs": 1935}, {"Word": "of", "OffsetStartMs": 1935, "OffsetEndMs": 2175}, {"Word": "the", "OffsetStartMs": 2175, "OffsetEndMs": 2310}, {"Word": "data", "OffsetStartMs": 2310, "OffsetEndMs": 2570}, {"Word": "and", "OffsetStartMs": 2860, "OffsetEndMs": 3240}, {"Word": "a", "OffsetStartMs": 3240, "OffsetEndMs": 3495}, {"Word": "function", "OffsetStartMs": 3495, "OffsetEndMs": 3770}, {"Word": "of", "OffsetStartMs": 4030, "OffsetEndMs": 4320}, {"Word": "the", "OffsetStartMs": 4320, "OffsetEndMs": 4485}, {"Word": "neural", "OffsetStartMs": 4485, "OffsetEndMs": 4695}, {"Word": "network", "OffsetStartMs": 4695, "OffsetEndMs": 4970}, {"Word": "weights", "OffsetStartMs": 5020, "OffsetEndMs": 5570}, {"Word": "just", "OffsetStartMs": 5590, "OffsetEndMs": 5880}, {"Word": "like", "OffsetStartMs": 5880, "OffsetEndMs": 6060}, {"Word": "before", "OffsetStartMs": 6060, "OffsetEndMs": 6350}], "SpeechSpeed": 15.4}, {"FinalSentence": "But we have these two components, these two terms that define our va loss.", "SliceSentence": "But we have these two components these two terms that define our va loss", "StartMs": 1128660, "EndMs": 1134260, "WordsNum": 14, "Words": [{"Word": "But", "OffsetStartMs": 70, "OffsetEndMs": 450}, {"Word": "we", "OffsetStartMs": 450, "OffsetEndMs": 735}, {"Word": "have", "OffsetStartMs": 735, "OffsetEndMs": 930}, {"Word": "these", "OffsetStartMs": 930, "OffsetEndMs": 1215}, {"Word": "two", "OffsetStartMs": 1215, "OffsetEndMs": 1610}, {"Word": "components", "OffsetStartMs": 1780, "OffsetEndMs": 2180}, {"Word": "these", "OffsetStartMs": 2290, "OffsetEndMs": 2655}, {"Word": "two", "OffsetStartMs": 2655, "OffsetEndMs": 2955}, {"Word": "terms", "OffsetStartMs": 2955, "OffsetEndMs": 3240}, {"Word": "that", "OffsetStartMs": 3240, "OffsetEndMs": 3555}, {"Word": "define", "OffsetStartMs": 3555, "OffsetEndMs": 3825}, {"Word": "our", "OffsetStartMs": 3825, "OffsetEndMs": 4035}, {"Word": "va", "OffsetStartMs": 4035, "OffsetEndMs": 4380}, {"Word": "loss", "OffsetStartMs": 4380, "OffsetEndMs": 4730}], "SpeechSpeed": 12.9}, {"FinalSentence": "First, we see the reconstruction loss just like before, where the goal is to capture the difference between our input data and the reconstructed output.", "SliceSentence": "First we see the reconstruction loss just like before where the goal is to capture the difference between our input data and the reconstructed output", "StartMs": 1134260, "EndMs": 1143640, "WordsNum": 25, "Words": [{"Word": "First", "OffsetStartMs": 10, "OffsetEndMs": 390}, {"Word": "we", "OffsetStartMs": 390, "OffsetEndMs": 675}, {"Word": "see", "OffsetStartMs": 675, "OffsetEndMs": 870}, {"Word": "the", "OffsetStartMs": 870, "OffsetEndMs": 1035}, {"Word": "reconstruction", "OffsetStartMs": 1035, "OffsetEndMs": 1680}, {"Word": "loss", "OffsetStartMs": 1680, "OffsetEndMs": 2060}, {"Word": "just", "OffsetStartMs": 2170, "OffsetEndMs": 2475}, {"Word": "like", "OffsetStartMs": 2475, "OffsetEndMs": 2670}, {"Word": "before", "OffsetStartMs": 2670, "OffsetEndMs": 2960}, {"Word": "where", "OffsetStartMs": 3580, "OffsetEndMs": 3870}, {"Word": "the", "OffsetStartMs": 3870, "OffsetEndMs": 4020}, {"Word": "goal", "OffsetStartMs": 4020, "OffsetEndMs": 4170}, {"Word": "is", "OffsetStartMs": 4170, "OffsetEndMs": 4350}, {"Word": "to", "OffsetStartMs": 4350, "OffsetEndMs": 4545}, {"Word": "capture", "OffsetStartMs": 4545, "OffsetEndMs": 4850}, {"Word": "the", "OffsetStartMs": 4870, "OffsetEndMs": 5130}, {"Word": "difference", "OffsetStartMs": 5130, "OffsetEndMs": 5390}, {"Word": "between", "OffsetStartMs": 5620, "OffsetEndMs": 5895}, {"Word": "our", "OffsetStartMs": 5895, "OffsetEndMs": 6165}, {"Word": "input", "OffsetStartMs": 6165, "OffsetEndMs": 6435}, {"Word": "data", "OffsetStartMs": 6435, "OffsetEndMs": 6710}, {"Word": "and", "OffsetStartMs": 7000, "OffsetEndMs": 7305}, {"Word": "the", "OffsetStartMs": 7305, "OffsetEndMs": 7470}, {"Word": "reconstructed", "OffsetStartMs": 7470, "OffsetEndMs": 8210}, {"Word": "output", "OffsetStartMs": 8260, "OffsetEndMs": 8660}], "SpeechSpeed": 15.9}, {"FinalSentence": "And now for the ve, we've introduced a second term to the loss, what we call the regularization term.", "SliceSentence": "And now for the ve we've introduced a second term to the loss what we call the regularization term", "StartMs": 1143640, "EndMs": 1150940, "WordsNum": 19, "Words": [{"Word": "And", "OffsetStartMs": 40, "OffsetEndMs": 360}, {"Word": "now", "OffsetStartMs": 360, "OffsetEndMs": 680}, {"Word": "for", "OffsetStartMs": 730, "OffsetEndMs": 1005}, {"Word": "the", "OffsetStartMs": 1005, "OffsetEndMs": 1140}, {"Word": "ve", "OffsetStartMs": 1140, "OffsetEndMs": 1575}, {"Word": "we've", "OffsetStartMs": 1575, "OffsetEndMs": 1970}, {"Word": "introduced", "OffsetStartMs": 2020, "OffsetEndMs": 2370}, {"Word": "a", "OffsetStartMs": 2370, "OffsetEndMs": 2625}, {"Word": "second", "OffsetStartMs": 2625, "OffsetEndMs": 2930}, {"Word": "term", "OffsetStartMs": 2950, "OffsetEndMs": 3270}, {"Word": "to", "OffsetStartMs": 3270, "OffsetEndMs": 3450}, {"Word": "the", "OffsetStartMs": 3450, "OffsetEndMs": 3555}, {"Word": "loss", "OffsetStartMs": 3555, "OffsetEndMs": 3800}, {"Word": "what", "OffsetStartMs": 4330, "OffsetEndMs": 4605}, {"Word": "we", "OffsetStartMs": 4605, "OffsetEndMs": 4830}, {"Word": "call", "OffsetStartMs": 4830, "OffsetEndMs": 5145}, {"Word": "the", "OffsetStartMs": 5145, "OffsetEndMs": 5385}, {"Word": "regularization", "OffsetStartMs": 5385, "OffsetEndMs": 6170}, {"Word": "term", "OffsetStartMs": 6220, "OffsetEndMs": 6620}], "SpeechSpeed": 13.4}, {"FinalSentence": "Often, you'll maybe even see this referred to as a ve loss and we'll go into, we'll go into describing what this regularization term means and what it's doing.", "SliceSentence": "Often you'll maybe even see this referred to as a ve loss and we'll go into we'll go into describing what this regularization term means and what it 's doing", "StartMs": 1151140, "EndMs": 1164440, "WordsNum": 30, "Words": [{"Word": "Often", "OffsetStartMs": 70, "OffsetEndMs": 450}, {"Word": "you'll", "OffsetStartMs": 450, "OffsetEndMs": 825}, {"Word": "maybe", "OffsetStartMs": 825, "OffsetEndMs": 1050}, {"Word": "even", "OffsetStartMs": 1050, "OffsetEndMs": 1350}, {"Word": "see", "OffsetStartMs": 1350, "OffsetEndMs": 1575}, {"Word": "this", "OffsetStartMs": 1575, "OffsetEndMs": 1845}, {"Word": "referred", "OffsetStartMs": 1845, "OffsetEndMs": 2190}, {"Word": "to", "OffsetStartMs": 2190, "OffsetEndMs": 2445}, {"Word": "as", "OffsetStartMs": 2445, "OffsetEndMs": 2715}, {"Word": "a", "OffsetStartMs": 2715, "OffsetEndMs": 2970}, {"Word": "ve", "OffsetStartMs": 2970, "OffsetEndMs": 3360}, {"Word": "loss", "OffsetStartMs": 3360, "OffsetEndMs": 3650}, {"Word": "and", "OffsetStartMs": 4540, "OffsetEndMs": 4815}, {"Word": "we'll", "OffsetStartMs": 4815, "OffsetEndMs": 5010}, {"Word": "go", "OffsetStartMs": 5010, "OffsetEndMs": 5175}, {"Word": "into", "OffsetStartMs": 5175, "OffsetEndMs": 5480}, {"Word": "we'll", "OffsetStartMs": 6190, "OffsetEndMs": 6525}, {"Word": "go", "OffsetStartMs": 6525, "OffsetEndMs": 6645}, {"Word": "into", "OffsetStartMs": 6645, "OffsetEndMs": 6920}, {"Word": "describing", "OffsetStartMs": 7060, "OffsetEndMs": 7605}, {"Word": "what", "OffsetStartMs": 7605, "OffsetEndMs": 7860}, {"Word": "this", "OffsetStartMs": 7860, "OffsetEndMs": 8070}, {"Word": "regularization", "OffsetStartMs": 8070, "OffsetEndMs": 9980}, {"Word": "term", "OffsetStartMs": 10000, "OffsetEndMs": 10400}, {"Word": "means", "OffsetStartMs": 10570, "OffsetEndMs": 10970}, {"Word": "and", "OffsetStartMs": 11050, "OffsetEndMs": 11355}, {"Word": "what", "OffsetStartMs": 11355, "OffsetEndMs": 11520}, {"Word": "it", "OffsetStartMs": 11520, "OffsetEndMs": 11625}, {"Word": "'s", "OffsetStartMs": 11625, "OffsetEndMs": 11760}, {"Word": "doing", "OffsetStartMs": 11760, "OffsetEndMs": 12050}], "SpeechSpeed": 11.7}, {"FinalSentence": "To do that and to understand, remember and, and keep in mind that in all neural network operations, our goal is to try to optimize the network weights with respect to the data with respect to minimizing this objective loss.", "SliceSentence": "To do that and to understand remember and and keep in mind that in all neural network operations our goal is to try to optimize the network weights with respect to the data with respect to minimizing this objective loss", "StartMs": 1165320, "EndMs": 1182140, "WordsNum": 40, "Words": [{"Word": "To", "OffsetStartMs": 100, "OffsetEndMs": 360}, {"Word": "do", "OffsetStartMs": 360, "OffsetEndMs": 480}, {"Word": "that", "OffsetStartMs": 480, "OffsetEndMs": 630}, {"Word": "and", "OffsetStartMs": 630, "OffsetEndMs": 810}, {"Word": "to", "OffsetStartMs": 810, "OffsetEndMs": 1100}, {"Word": "understand", "OffsetStartMs": 1120, "OffsetEndMs": 1520}, {"Word": "remember", "OffsetStartMs": 1570, "OffsetEndMs": 1970}, {"Word": "and", "OffsetStartMs": 1990, "OffsetEndMs": 2390}, {"Word": "and", "OffsetStartMs": 2440, "OffsetEndMs": 2840}, {"Word": "keep", "OffsetStartMs": 3670, "OffsetEndMs": 3930}, {"Word": "in", "OffsetStartMs": 3930, "OffsetEndMs": 4065}, {"Word": "mind", "OffsetStartMs": 4065, "OffsetEndMs": 4340}, {"Word": "that", "OffsetStartMs": 4780, "OffsetEndMs": 5115}, {"Word": "in", "OffsetStartMs": 5115, "OffsetEndMs": 5355}, {"Word": "all", "OffsetStartMs": 5355, "OffsetEndMs": 5625}, {"Word": "neural", "OffsetStartMs": 5625, "OffsetEndMs": 5940}, {"Word": "network", "OffsetStartMs": 5940, "OffsetEndMs": 6200}, {"Word": "operations", "OffsetStartMs": 6490, "OffsetEndMs": 6890}, {"Word": "our", "OffsetStartMs": 7060, "OffsetEndMs": 7380}, {"Word": "goal", "OffsetStartMs": 7380, "OffsetEndMs": 7700}, {"Word": "is", "OffsetStartMs": 7810, "OffsetEndMs": 8115}, {"Word": "to", "OffsetStartMs": 8115, "OffsetEndMs": 8340}, {"Word": "try", "OffsetStartMs": 8340, "OffsetEndMs": 8580}, {"Word": "to", "OffsetStartMs": 8580, "OffsetEndMs": 8900}, {"Word": "optimize", "OffsetStartMs": 8950, "OffsetEndMs": 9465}, {"Word": "the", "OffsetStartMs": 9465, "OffsetEndMs": 9705}, {"Word": "network", "OffsetStartMs": 9705, "OffsetEndMs": 9950}, {"Word": "weights", "OffsetStartMs": 10030, "OffsetEndMs": 10580}, {"Word": "with", "OffsetStartMs": 10810, "OffsetEndMs": 11210}, {"Word": "respect", "OffsetStartMs": 11230, "OffsetEndMs": 11630}, {"Word": "to", "OffsetStartMs": 12100, "OffsetEndMs": 12450}, {"Word": "the", "OffsetStartMs": 12450, "OffsetEndMs": 12660}, {"Word": "data", "OffsetStartMs": 12660, "OffsetEndMs": 12920}, {"Word": "with", "OffsetStartMs": 13360, "OffsetEndMs": 13755}, {"Word": "respect", "OffsetStartMs": 13755, "OffsetEndMs": 14085}, {"Word": "to", "OffsetStartMs": 14085, "OffsetEndMs": 14340}, {"Word": "minimizing", "OffsetStartMs": 14340, "OffsetEndMs": 14900}, {"Word": "this", "OffsetStartMs": 14920, "OffsetEndMs": 15300}, {"Word": "objective", "OffsetStartMs": 15300, "OffsetEndMs": 15660}, {"Word": "loss", "OffsetStartMs": 15660, "OffsetEndMs": 16040}], "SpeechSpeed": 13.0}, {"FinalSentence": "And so here we're concerned with the network weights Phi and theta, that define the weights of the encoder and the decoder.", "SliceSentence": "And so here we're concerned with the network weights Phi and theta that define the weights of the encoder and the decoder", "StartMs": 1182140, "EndMs": 1190480, "WordsNum": 22, "Words": [{"Word": "And", "OffsetStartMs": 0, "OffsetEndMs": 195}, {"Word": "so", "OffsetStartMs": 195, "OffsetEndMs": 390}, {"Word": "here", "OffsetStartMs": 390, "OffsetEndMs": 630}, {"Word": "we're", "OffsetStartMs": 630, "OffsetEndMs": 990}, {"Word": "concerned", "OffsetStartMs": 990, "OffsetEndMs": 1275}, {"Word": "with", "OffsetStartMs": 1275, "OffsetEndMs": 1485}, {"Word": "the", "OffsetStartMs": 1485, "OffsetEndMs": 1620}, {"Word": "network", "OffsetStartMs": 1620, "OffsetEndMs": 1880}, {"Word": "weights", "OffsetStartMs": 1900, "OffsetEndMs": 2480}, {"Word": "Phi", "OffsetStartMs": 2920, "OffsetEndMs": 3375}, {"Word": "and", "OffsetStartMs": 3375, "OffsetEndMs": 3690}, {"Word": "theta", "OffsetStartMs": 3690, "OffsetEndMs": 4110}, {"Word": "that", "OffsetStartMs": 4110, "OffsetEndMs": 4395}, {"Word": "define", "OffsetStartMs": 4395, "OffsetEndMs": 4710}, {"Word": "the", "OffsetStartMs": 4710, "OffsetEndMs": 5010}, {"Word": "weights", "OffsetStartMs": 5010, "OffsetEndMs": 5400}, {"Word": "of", "OffsetStartMs": 5400, "OffsetEndMs": 5580}, {"Word": "the", "OffsetStartMs": 5580, "OffsetEndMs": 5745}, {"Word": "encoder", "OffsetStartMs": 5745, "OffsetEndMs": 6465}, {"Word": "and", "OffsetStartMs": 6465, "OffsetEndMs": 6860}, {"Word": "the", "OffsetStartMs": 6940, "OffsetEndMs": 7200}, {"Word": "decoder", "OffsetStartMs": 7200, "OffsetEndMs": 7790}], "SpeechSpeed": 14.5}, {"FinalSentence": "We consider these two terms. First, the reconstruction loss, again, the reconstruction loss is very, very similar, same as before, you can think of it as the error or the likelihood that effectively captures the difference between your input and your outputs. And again, we can trade this in an unsupervised way, not requiring any labels to force the latent space and the network to learn how to effectively reconstruct the input data.", "SliceSentence": "We consider these two terms . Firstthe reconstruction loss again the reconstruction loss is very very similar same as before you can think of it as the error or the likelihood that effectively captures the difference between your input and your outputs . Andagain we can trade this in an unsupervised way not requiring any labels to force the latent space and the network to learn how to effectively reconstruct the input data", "StartMs": 1191140, "EndMs": 1220680, "WordsNum": 73, "Words": [{"Word": "We", "OffsetStartMs": 160, "OffsetEndMs": 560}, {"Word": "consider", "OffsetStartMs": 580, "OffsetEndMs": 915}, {"Word": "these", "OffsetStartMs": 915, "OffsetEndMs": 1185}, {"Word": "two", "OffsetStartMs": 1185, "OffsetEndMs": 1425}, {"Word": "terms", "OffsetStartMs": 1425, "OffsetEndMs": 1730}, {"Word": ".", "OffsetStartMs": 2410, "OffsetEndMs": 2810}, {"Word": "Firstthe", "OffsetStartMs": 2920, "OffsetEndMs": 3180}, {"Word": "reconstruction", "OffsetStartMs": 3180, "OffsetEndMs": 3780}, {"Word": "loss", "OffsetStartMs": 3780, "OffsetEndMs": 4160}, {"Word": "again", "OffsetStartMs": 5020, "OffsetEndMs": 5420}, {"Word": "the", "OffsetStartMs": 5470, "OffsetEndMs": 5730}, {"Word": "reconstruction", "OffsetStartMs": 5730, "OffsetEndMs": 6330}, {"Word": "loss", "OffsetStartMs": 6330, "OffsetEndMs": 6660}, {"Word": "is", "OffsetStartMs": 6660, "OffsetEndMs": 7010}, {"Word": "very", "OffsetStartMs": 7150, "OffsetEndMs": 7500}, {"Word": "very", "OffsetStartMs": 7500, "OffsetEndMs": 7800}, {"Word": "similar", "OffsetStartMs": 7800, "OffsetEndMs": 8150}, {"Word": "same", "OffsetStartMs": 8290, "OffsetEndMs": 8580}, {"Word": "as", "OffsetStartMs": 8580, "OffsetEndMs": 8760}, {"Word": "before", "OffsetStartMs": 8760, "OffsetEndMs": 9050}, {"Word": "you", "OffsetStartMs": 9670, "OffsetEndMs": 9930}, {"Word": "can", "OffsetStartMs": 9930, "OffsetEndMs": 10080}, {"Word": "think", "OffsetStartMs": 10080, "OffsetEndMs": 10260}, {"Word": "of", "OffsetStartMs": 10260, "OffsetEndMs": 10410}, {"Word": "it", "OffsetStartMs": 10410, "OffsetEndMs": 10560}, {"Word": "as", "OffsetStartMs": 10560, "OffsetEndMs": 10845}, {"Word": "the", "OffsetStartMs": 10845, "OffsetEndMs": 11115}, {"Word": "error", "OffsetStartMs": 11115, "OffsetEndMs": 11390}, {"Word": "or", "OffsetStartMs": 11440, "OffsetEndMs": 11730}, {"Word": "the", "OffsetStartMs": 11730, "OffsetEndMs": 11895}, {"Word": "likelihood", "OffsetStartMs": 11895, "OffsetEndMs": 12590}, {"Word": "that", "OffsetStartMs": 12760, "OffsetEndMs": 13140}, {"Word": "effectively", "OffsetStartMs": 13140, "OffsetEndMs": 13520}, {"Word": "captures", "OffsetStartMs": 13750, "OffsetEndMs": 14400}, {"Word": "the", "OffsetStartMs": 14400, "OffsetEndMs": 14610}, {"Word": "difference", "OffsetStartMs": 14610, "OffsetEndMs": 14900}, {"Word": "between", "OffsetStartMs": 15190, "OffsetEndMs": 15540}, {"Word": "your", "OffsetStartMs": 15540, "OffsetEndMs": 15890}, {"Word": "input", "OffsetStartMs": 15910, "OffsetEndMs": 16310}, {"Word": "and", "OffsetStartMs": 16510, "OffsetEndMs": 16860}, {"Word": "your", "OffsetStartMs": 16860, "OffsetEndMs": 17210}, {"Word": "outputs", "OffsetStartMs": 17260, "OffsetEndMs": 17780}, {"Word": ".", "OffsetStartMs": 18100, "OffsetEndMs": 18420}, {"Word": "Andagain", "OffsetStartMs": 18420, "OffsetEndMs": 18645}, {"Word": "we", "OffsetStartMs": 18645, "OffsetEndMs": 18825}, {"Word": "can", "OffsetStartMs": 18825, "OffsetEndMs": 19020}, {"Word": "trade", "OffsetStartMs": 19020, "OffsetEndMs": 19275}, {"Word": "this", "OffsetStartMs": 19275, "OffsetEndMs": 19575}, {"Word": "in", "OffsetStartMs": 19575, "OffsetEndMs": 19815}, {"Word": "an", "OffsetStartMs": 19815, "OffsetEndMs": 19965}, {"Word": "unsupervised", "OffsetStartMs": 19965, "OffsetEndMs": 20730}, {"Word": "way", "OffsetStartMs": 20730, "OffsetEndMs": 21080}, {"Word": "not", "OffsetStartMs": 21280, "OffsetEndMs": 21675}, {"Word": "requiring", "OffsetStartMs": 21675, "OffsetEndMs": 22080}, {"Word": "any", "OffsetStartMs": 22080, "OffsetEndMs": 22410}, {"Word": "labels", "OffsetStartMs": 22410, "OffsetEndMs": 22970}, {"Word": "to", "OffsetStartMs": 23260, "OffsetEndMs": 23550}, {"Word": "force", "OffsetStartMs": 23550, "OffsetEndMs": 23805}, {"Word": "the", "OffsetStartMs": 23805, "OffsetEndMs": 24045}, {"Word": "latent", "OffsetStartMs": 24045, "OffsetEndMs": 24390}, {"Word": "space", "OffsetStartMs": 24390, "OffsetEndMs": 24710}, {"Word": "and", "OffsetStartMs": 25180, "OffsetEndMs": 25470}, {"Word": "the", "OffsetStartMs": 25470, "OffsetEndMs": 25605}, {"Word": "network", "OffsetStartMs": 25605, "OffsetEndMs": 25850}, {"Word": "to", "OffsetStartMs": 25930, "OffsetEndMs": 26205}, {"Word": "learn", "OffsetStartMs": 26205, "OffsetEndMs": 26445}, {"Word": "how", "OffsetStartMs": 26445, "OffsetEndMs": 26700}, {"Word": "to", "OffsetStartMs": 26700, "OffsetEndMs": 26925}, {"Word": "effectively", "OffsetStartMs": 26925, "OffsetEndMs": 27260}, {"Word": "reconstruct", "OffsetStartMs": 27430, "OffsetEndMs": 28190}, {"Word": "the", "OffsetStartMs": 28210, "OffsetEndMs": 28560}, {"Word": "input", "OffsetStartMs": 28560, "OffsetEndMs": 28785}, {"Word": "data", "OffsetStartMs": 28785, "OffsetEndMs": 29060}], "SpeechSpeed": 14.4}, {"FinalSentence": "The second term, the regularization term, is now where things get a bit more interesting. So let's go on into this in a little bit more detail.", "SliceSentence": "The second term the regularization term is now where things get a bit more interesting . Solet's go on into this in a little bit more detail", "StartMs": 1221780, "EndMs": 1230560, "WordsNum": 27, "Words": [{"Word": "The", "OffsetStartMs": 100, "OffsetEndMs": 375}, {"Word": "second", "OffsetStartMs": 375, "OffsetEndMs": 630}, {"Word": "term", "OffsetStartMs": 630, "OffsetEndMs": 930}, {"Word": "the", "OffsetStartMs": 930, "OffsetEndMs": 1110}, {"Word": "regularization", "OffsetStartMs": 1110, "OffsetEndMs": 1800}, {"Word": "term", "OffsetStartMs": 1800, "OffsetEndMs": 2055}, {"Word": "is", "OffsetStartMs": 2055, "OffsetEndMs": 2235}, {"Word": "now", "OffsetStartMs": 2235, "OffsetEndMs": 2475}, {"Word": "where", "OffsetStartMs": 2475, "OffsetEndMs": 2715}, {"Word": "things", "OffsetStartMs": 2715, "OffsetEndMs": 2970}, {"Word": "get", "OffsetStartMs": 2970, "OffsetEndMs": 3240}, {"Word": "a", "OffsetStartMs": 3240, "OffsetEndMs": 3435}, {"Word": "bit", "OffsetStartMs": 3435, "OffsetEndMs": 3600}, {"Word": "more", "OffsetStartMs": 3600, "OffsetEndMs": 3890}, {"Word": "interesting", "OffsetStartMs": 4000, "OffsetEndMs": 4365}, {"Word": ".", "OffsetStartMs": 4365, "OffsetEndMs": 4665}, {"Word": "Solet's", "OffsetStartMs": 4665, "OffsetEndMs": 5190}, {"Word": "go", "OffsetStartMs": 5190, "OffsetEndMs": 5310}, {"Word": "on", "OffsetStartMs": 5310, "OffsetEndMs": 5570}, {"Word": "into", "OffsetStartMs": 5950, "OffsetEndMs": 6300}, {"Word": "this", "OffsetStartMs": 6300, "OffsetEndMs": 6585}, {"Word": "in", "OffsetStartMs": 6585, "OffsetEndMs": 6780}, {"Word": "a", "OffsetStartMs": 6780, "OffsetEndMs": 6900}, {"Word": "little", "OffsetStartMs": 6900, "OffsetEndMs": 7035}, {"Word": "bit", "OffsetStartMs": 7035, "OffsetEndMs": 7185}, {"Word": "more", "OffsetStartMs": 7185, "OffsetEndMs": 7455}, {"Word": "detail", "OffsetStartMs": 7455, "OffsetEndMs": 7850}], "SpeechSpeed": 15.8}, {"FinalSentence": "Because we have this probability distribution and we're trying to compute this encoding and then decode back up.", "SliceSentence": "Because we have this probability distribution and we're trying to compute this encoding and then decode back up", "StartMs": 1230660, "EndMs": 1240280, "WordsNum": 18, "Words": [{"Word": "Because", "OffsetStartMs": 340, "OffsetEndMs": 645}, {"Word": "we", "OffsetStartMs": 645, "OffsetEndMs": 840}, {"Word": "have", "OffsetStartMs": 840, "OffsetEndMs": 1035}, {"Word": "this", "OffsetStartMs": 1035, "OffsetEndMs": 1260}, {"Word": "probability", "OffsetStartMs": 1260, "OffsetEndMs": 1820}, {"Word": "distribution", "OffsetStartMs": 1990, "OffsetEndMs": 2390}, {"Word": "and", "OffsetStartMs": 3730, "OffsetEndMs": 4110}, {"Word": "we're", "OffsetStartMs": 4110, "OffsetEndMs": 4455}, {"Word": "trying", "OffsetStartMs": 4455, "OffsetEndMs": 4695}, {"Word": "to", "OffsetStartMs": 4695, "OffsetEndMs": 4935}, {"Word": "compute", "OffsetStartMs": 4935, "OffsetEndMs": 5450}, {"Word": "this", "OffsetStartMs": 6460, "OffsetEndMs": 6765}, {"Word": "encoding", "OffsetStartMs": 6765, "OffsetEndMs": 7350}, {"Word": "and", "OffsetStartMs": 7350, "OffsetEndMs": 7515}, {"Word": "then", "OffsetStartMs": 7515, "OffsetEndMs": 7725}, {"Word": "decode", "OffsetStartMs": 7725, "OffsetEndMs": 8235}, {"Word": "back", "OffsetStartMs": 8235, "OffsetEndMs": 8415}, {"Word": "up", "OffsetStartMs": 8415, "OffsetEndMs": 8720}], "SpeechSpeed": 11.5}, {"FinalSentence": "As part of regularizing, we want to take that inference over the latent distribution and constrain it to behave nicely, if you will. The way we do that is we place what we call a prior on the latent distribution. And what this is is some initial hypothesis or guess about what that latent variable space may look like.", "SliceSentence": "As part of regularizing we want to take that inference over the latent distribution and constrain it to behave nicely if you will . Theway we do that is we place what we call a prior on the latent distribution . Andwhat this is is some initial hypothesis or guess about what that latent variable space may look like", "StartMs": 1240280, "EndMs": 1264320, "WordsNum": 59, "Words": [{"Word": "As", "OffsetStartMs": 40, "OffsetEndMs": 405}, {"Word": "part", "OffsetStartMs": 405, "OffsetEndMs": 660}, {"Word": "of", "OffsetStartMs": 660, "OffsetEndMs": 950}, {"Word": "regularizing", "OffsetStartMs": 1690, "OffsetEndMs": 2450}, {"Word": "we", "OffsetStartMs": 3190, "OffsetEndMs": 3480}, {"Word": "want", "OffsetStartMs": 3480, "OffsetEndMs": 3690}, {"Word": "to", "OffsetStartMs": 3690, "OffsetEndMs": 3945}, {"Word": "take", "OffsetStartMs": 3945, "OffsetEndMs": 4245}, {"Word": "that", "OffsetStartMs": 4245, "OffsetEndMs": 4530}, {"Word": "inference", "OffsetStartMs": 4530, "OffsetEndMs": 5115}, {"Word": "over", "OffsetStartMs": 5115, "OffsetEndMs": 5510}, {"Word": "the", "OffsetStartMs": 5770, "OffsetEndMs": 6045}, {"Word": "latent", "OffsetStartMs": 6045, "OffsetEndMs": 6560}, {"Word": "distribution", "OffsetStartMs": 7000, "OffsetEndMs": 7400}, {"Word": "and", "OffsetStartMs": 8080, "OffsetEndMs": 8385}, {"Word": "constrain", "OffsetStartMs": 8385, "OffsetEndMs": 8895}, {"Word": "it", "OffsetStartMs": 8895, "OffsetEndMs": 9090}, {"Word": "to", "OffsetStartMs": 9090, "OffsetEndMs": 9255}, {"Word": "behave", "OffsetStartMs": 9255, "OffsetEndMs": 9630}, {"Word": "nicely", "OffsetStartMs": 9630, "OffsetEndMs": 9980}, {"Word": "if", "OffsetStartMs": 10060, "OffsetEndMs": 10335}, {"Word": "you", "OffsetStartMs": 10335, "OffsetEndMs": 10470}, {"Word": "will", "OffsetStartMs": 10470, "OffsetEndMs": 10730}, {"Word": ".", "OffsetStartMs": 11380, "OffsetEndMs": 11640}, {"Word": "Theway", "OffsetStartMs": 11640, "OffsetEndMs": 11805}, {"Word": "we", "OffsetStartMs": 11805, "OffsetEndMs": 12000}, {"Word": "do", "OffsetStartMs": 12000, "OffsetEndMs": 12290}, {"Word": "that", "OffsetStartMs": 12400, "OffsetEndMs": 12795}, {"Word": "is", "OffsetStartMs": 12795, "OffsetEndMs": 13110}, {"Word": "we", "OffsetStartMs": 13110, "OffsetEndMs": 13380}, {"Word": "place", "OffsetStartMs": 13380, "OffsetEndMs": 13665}, {"Word": "what", "OffsetStartMs": 13665, "OffsetEndMs": 13875}, {"Word": "we", "OffsetStartMs": 13875, "OffsetEndMs": 14040}, {"Word": "call", "OffsetStartMs": 14040, "OffsetEndMs": 14235}, {"Word": "a", "OffsetStartMs": 14235, "OffsetEndMs": 14475}, {"Word": "prior", "OffsetStartMs": 14475, "OffsetEndMs": 14810}, {"Word": "on", "OffsetStartMs": 14860, "OffsetEndMs": 15150}, {"Word": "the", "OffsetStartMs": 15150, "OffsetEndMs": 15300}, {"Word": "latent", "OffsetStartMs": 15300, "OffsetEndMs": 15690}, {"Word": "distribution", "OffsetStartMs": 15690, "OffsetEndMs": 16040}, {"Word": ".", "OffsetStartMs": 16810, "OffsetEndMs": 17115}, {"Word": "Andwhat", "OffsetStartMs": 17115, "OffsetEndMs": 17310}, {"Word": "this", "OffsetStartMs": 17310, "OffsetEndMs": 17475}, {"Word": "is", "OffsetStartMs": 17475, "OffsetEndMs": 17685}, {"Word": "is", "OffsetStartMs": 17685, "OffsetEndMs": 17970}, {"Word": "some", "OffsetStartMs": 17970, "OffsetEndMs": 18320}, {"Word": "initial", "OffsetStartMs": 18400, "OffsetEndMs": 18780}, {"Word": "hypothesis", "OffsetStartMs": 18780, "OffsetEndMs": 19710}, {"Word": "or", "OffsetStartMs": 19710, "OffsetEndMs": 19995}, {"Word": "guess", "OffsetStartMs": 19995, "OffsetEndMs": 20330}, {"Word": "about", "OffsetStartMs": 20800, "OffsetEndMs": 21150}, {"Word": "what", "OffsetStartMs": 21150, "OffsetEndMs": 21420}, {"Word": "that", "OffsetStartMs": 21420, "OffsetEndMs": 21645}, {"Word": "latent", "OffsetStartMs": 21645, "OffsetEndMs": 22005}, {"Word": "variable", "OffsetStartMs": 22005, "OffsetEndMs": 22280}, {"Word": "space", "OffsetStartMs": 22390, "OffsetEndMs": 22785}, {"Word": "may", "OffsetStartMs": 22785, "OffsetEndMs": 23070}, {"Word": "look", "OffsetStartMs": 23070, "OffsetEndMs": 23280}, {"Word": "like", "OffsetStartMs": 23280, "OffsetEndMs": 23600}], "SpeechSpeed": 13.0}, {"FinalSentence": "This helps us and helps the network to enforce a latent space that roughly tries to follow this prior distribution.", "SliceSentence": "This helps us and helps the network to enforce a latent space that roughly tries to follow this prior distribution", "StartMs": 1264460, "EndMs": 1272600, "WordsNum": 20, "Words": [{"Word": "This", "OffsetStartMs": 70, "OffsetEndMs": 405}, {"Word": "helps", "OffsetStartMs": 405, "OffsetEndMs": 720}, {"Word": "us", "OffsetStartMs": 720, "OffsetEndMs": 1100}, {"Word": "and", "OffsetStartMs": 1180, "OffsetEndMs": 1485}, {"Word": "helps", "OffsetStartMs": 1485, "OffsetEndMs": 1710}, {"Word": "the", "OffsetStartMs": 1710, "OffsetEndMs": 1890}, {"Word": "network", "OffsetStartMs": 1890, "OffsetEndMs": 2150}, {"Word": "to", "OffsetStartMs": 2560, "OffsetEndMs": 2960}, {"Word": "enforce", "OffsetStartMs": 2980, "OffsetEndMs": 3380}, {"Word": "a", "OffsetStartMs": 3670, "OffsetEndMs": 3945}, {"Word": "latent", "OffsetStartMs": 3945, "OffsetEndMs": 4275}, {"Word": "space", "OffsetStartMs": 4275, "OffsetEndMs": 4500}, {"Word": "that", "OffsetStartMs": 4500, "OffsetEndMs": 4755}, {"Word": "roughly", "OffsetStartMs": 4755, "OffsetEndMs": 5090}, {"Word": "tries", "OffsetStartMs": 5200, "OffsetEndMs": 5535}, {"Word": "to", "OffsetStartMs": 5535, "OffsetEndMs": 5775}, {"Word": "follow", "OffsetStartMs": 5775, "OffsetEndMs": 6075}, {"Word": "this", "OffsetStartMs": 6075, "OffsetEndMs": 6420}, {"Word": "prior", "OffsetStartMs": 6420, "OffsetEndMs": 6770}, {"Word": "distribution", "OffsetStartMs": 6820, "OffsetEndMs": 7220}], "SpeechSpeed": 14.0}, {"FinalSentence": "And this prior is denoted as p of z, right.", "SliceSentence": "And this prior is denoted as p of z right", "StartMs": 1272740, "EndMs": 1277120, "WordsNum": 10, "Words": [{"Word": "And", "OffsetStartMs": 310, "OffsetEndMs": 600}, {"Word": "this", "OffsetStartMs": 600, "OffsetEndMs": 810}, {"Word": "prior", "OffsetStartMs": 810, "OffsetEndMs": 1095}, {"Word": "is", "OffsetStartMs": 1095, "OffsetEndMs": 1365}, {"Word": "denoted", "OffsetStartMs": 1365, "OffsetEndMs": 1770}, {"Word": "as", "OffsetStartMs": 1770, "OffsetEndMs": 2150}, {"Word": "p", "OffsetStartMs": 2230, "OffsetEndMs": 2580}, {"Word": "of", "OffsetStartMs": 2580, "OffsetEndMs": 2835}, {"Word": "z", "OffsetStartMs": 2835, "OffsetEndMs": 3140}, {"Word": "right", "OffsetStartMs": 3280, "OffsetEndMs": 3680}], "SpeechSpeed": 9.4}, {"FinalSentence": "That term d, that's effectively the regularization term. It's capturing a distance between our encoding of the latent variables and our prior hypothesis about what the structure of that latent space should look like.", "SliceSentence": "That term d that's effectively the regularization term .It's capturing a distance between our encoding of the latent variables and our prior hypothesis about what the structure of that latent space should look like", "StartMs": 1277400, "EndMs": 1292640, "WordsNum": 34, "Words": [{"Word": "That", "OffsetStartMs": 70, "OffsetEndMs": 435}, {"Word": "term", "OffsetStartMs": 435, "OffsetEndMs": 800}, {"Word": "d", "OffsetStartMs": 880, "OffsetEndMs": 1280}, {"Word": "that's", "OffsetStartMs": 1780, "OffsetEndMs": 2340}, {"Word": "effectively", "OffsetStartMs": 2340, "OffsetEndMs": 2690}, {"Word": "the", "OffsetStartMs": 2800, "OffsetEndMs": 3060}, {"Word": "regularization", "OffsetStartMs": 3060, "OffsetEndMs": 3770}, {"Word": "term", "OffsetStartMs": 3790, "OffsetEndMs": 4190}, {"Word": ".It's", "OffsetStartMs": 4690, "OffsetEndMs": 5100}, {"Word": "capturing", "OffsetStartMs": 5100, "OffsetEndMs": 5565}, {"Word": "a", "OffsetStartMs": 5565, "OffsetEndMs": 5730}, {"Word": "distance", "OffsetStartMs": 5730, "OffsetEndMs": 6020}, {"Word": "between", "OffsetStartMs": 6340, "OffsetEndMs": 6690}, {"Word": "our", "OffsetStartMs": 6690, "OffsetEndMs": 6960}, {"Word": "encoding", "OffsetStartMs": 6960, "OffsetEndMs": 7650}, {"Word": "of", "OffsetStartMs": 7650, "OffsetEndMs": 7845}, {"Word": "the", "OffsetStartMs": 7845, "OffsetEndMs": 7980}, {"Word": "latent", "OffsetStartMs": 7980, "OffsetEndMs": 8295}, {"Word": "variables", "OffsetStartMs": 8295, "OffsetEndMs": 8870}, {"Word": "and", "OffsetStartMs": 9130, "OffsetEndMs": 9530}, {"Word": "our", "OffsetStartMs": 9550, "OffsetEndMs": 9950}, {"Word": "prior", "OffsetStartMs": 10030, "OffsetEndMs": 10410}, {"Word": "hypothesis", "OffsetStartMs": 10410, "OffsetEndMs": 11310}, {"Word": "about", "OffsetStartMs": 11310, "OffsetEndMs": 11640}, {"Word": "what", "OffsetStartMs": 11640, "OffsetEndMs": 11990}, {"Word": "the", "OffsetStartMs": 12370, "OffsetEndMs": 12675}, {"Word": "structure", "OffsetStartMs": 12675, "OffsetEndMs": 12975}, {"Word": "of", "OffsetStartMs": 12975, "OffsetEndMs": 13245}, {"Word": "that", "OffsetStartMs": 13245, "OffsetEndMs": 13410}, {"Word": "latent", "OffsetStartMs": 13410, "OffsetEndMs": 13785}, {"Word": "space", "OffsetStartMs": 13785, "OffsetEndMs": 14025}, {"Word": "should", "OffsetStartMs": 14025, "OffsetEndMs": 14220}, {"Word": "look", "OffsetStartMs": 14220, "OffsetEndMs": 14385}, {"Word": "like", "OffsetStartMs": 14385, "OffsetEndMs": 14690}], "SpeechSpeed": 14.0}, {"FinalSentence": "So over the course of training, we're trying to enforce that. Each of those latent variables adapts a prob, adapts a probability distribution that's similar to that prior.", "SliceSentence": "So over the course of training we're trying to enforce that . Eachof those latent variables adapts a prob adapts a probability distribution that's similar to that prior", "StartMs": 1292640, "EndMs": 1304980, "WordsNum": 28, "Words": [{"Word": "So", "OffsetStartMs": 190, "OffsetEndMs": 480}, {"Word": "over", "OffsetStartMs": 480, "OffsetEndMs": 720}, {"Word": "the", "OffsetStartMs": 720, "OffsetEndMs": 945}, {"Word": "course", "OffsetStartMs": 945, "OffsetEndMs": 1125}, {"Word": "of", "OffsetStartMs": 1125, "OffsetEndMs": 1335}, {"Word": "training", "OffsetStartMs": 1335, "OffsetEndMs": 1635}, {"Word": "we're", "OffsetStartMs": 1635, "OffsetEndMs": 1995}, {"Word": "trying", "OffsetStartMs": 1995, "OffsetEndMs": 2175}, {"Word": "to", "OffsetStartMs": 2175, "OffsetEndMs": 2480}, {"Word": "enforce", "OffsetStartMs": 2500, "OffsetEndMs": 2900}, {"Word": "that", "OffsetStartMs": 3310, "OffsetEndMs": 3630}, {"Word": ".", "OffsetStartMs": 3630, "OffsetEndMs": 3840}, {"Word": "Eachof", "OffsetStartMs": 3840, "OffsetEndMs": 4005}, {"Word": "those", "OffsetStartMs": 4005, "OffsetEndMs": 4185}, {"Word": "latent", "OffsetStartMs": 4185, "OffsetEndMs": 4545}, {"Word": "variables", "OffsetStartMs": 4545, "OffsetEndMs": 5150}, {"Word": "adapts", "OffsetStartMs": 5320, "OffsetEndMs": 5985}, {"Word": "a", "OffsetStartMs": 5985, "OffsetEndMs": 6150}, {"Word": "prob", "OffsetStartMs": 6150, "OffsetEndMs": 6440}, {"Word": "adapts", "OffsetStartMs": 6670, "OffsetEndMs": 7260}, {"Word": "a", "OffsetStartMs": 7260, "OffsetEndMs": 7410}, {"Word": "probability", "OffsetStartMs": 7410, "OffsetEndMs": 8000}, {"Word": "distribution", "OffsetStartMs": 8170, "OffsetEndMs": 8570}, {"Word": "that's", "OffsetStartMs": 9010, "OffsetEndMs": 9590}, {"Word": "similar", "OffsetStartMs": 9700, "OffsetEndMs": 10100}, {"Word": "to", "OffsetStartMs": 10660, "OffsetEndMs": 10980}, {"Word": "that", "OffsetStartMs": 10980, "OffsetEndMs": 11250}, {"Word": "prior", "OffsetStartMs": 11250, "OffsetEndMs": 11600}], "SpeechSpeed": 13.5}, {"FinalSentence": "A common choice when training vas and developing these models is to enforce the latent variables to be roughly standard normal gouging distributions, meaning that they are centered around mean zero and they have a standard deviation of one.", "SliceSentence": "A common choice when training vas and developing these models is to enforce the latent variables to be roughly standard normal gouging distributions meaning that they are centered around mean zero and they have a standard deviation of one", "StartMs": 1306780, "EndMs": 1324700, "WordsNum": 39, "Words": [{"Word": "A", "OffsetStartMs": 10, "OffsetEndMs": 330}, {"Word": "common", "OffsetStartMs": 330, "OffsetEndMs": 650}, {"Word": "choice", "OffsetStartMs": 670, "OffsetEndMs": 1050}, {"Word": "when", "OffsetStartMs": 1050, "OffsetEndMs": 1430}, {"Word": "training", "OffsetStartMs": 2170, "OffsetEndMs": 2550}, {"Word": "vas", "OffsetStartMs": 2550, "OffsetEndMs": 3000}, {"Word": "and", "OffsetStartMs": 3000, "OffsetEndMs": 3315}, {"Word": "developing", "OffsetStartMs": 3315, "OffsetEndMs": 3650}, {"Word": "these", "OffsetStartMs": 3700, "OffsetEndMs": 4005}, {"Word": "models", "OffsetStartMs": 4005, "OffsetEndMs": 4310}, {"Word": "is", "OffsetStartMs": 4420, "OffsetEndMs": 4820}, {"Word": "to", "OffsetStartMs": 5140, "OffsetEndMs": 5540}, {"Word": "enforce", "OffsetStartMs": 5860, "OffsetEndMs": 6255}, {"Word": "the", "OffsetStartMs": 6255, "OffsetEndMs": 6525}, {"Word": "latent", "OffsetStartMs": 6525, "OffsetEndMs": 6810}, {"Word": "variables", "OffsetStartMs": 6810, "OffsetEndMs": 7335}, {"Word": "to", "OffsetStartMs": 7335, "OffsetEndMs": 7545}, {"Word": "be", "OffsetStartMs": 7545, "OffsetEndMs": 7820}, {"Word": "roughly", "OffsetStartMs": 7840, "OffsetEndMs": 8240}, {"Word": "standard", "OffsetStartMs": 8800, "OffsetEndMs": 9200}, {"Word": "normal", "OffsetStartMs": 9370, "OffsetEndMs": 9770}, {"Word": "gouging", "OffsetStartMs": 9880, "OffsetEndMs": 10515}, {"Word": "distributions", "OffsetStartMs": 10515, "OffsetEndMs": 11000}, {"Word": "meaning", "OffsetStartMs": 11890, "OffsetEndMs": 12240}, {"Word": "that", "OffsetStartMs": 12240, "OffsetEndMs": 12590}, {"Word": "they", "OffsetStartMs": 12940, "OffsetEndMs": 13200}, {"Word": "are", "OffsetStartMs": 13200, "OffsetEndMs": 13395}, {"Word": "centered", "OffsetStartMs": 13395, "OffsetEndMs": 13970}, {"Word": "around", "OffsetStartMs": 14050, "OffsetEndMs": 14450}, {"Word": "mean", "OffsetStartMs": 14500, "OffsetEndMs": 14895}, {"Word": "zero", "OffsetStartMs": 14895, "OffsetEndMs": 15290}, {"Word": "and", "OffsetStartMs": 15400, "OffsetEndMs": 15675}, {"Word": "they", "OffsetStartMs": 15675, "OffsetEndMs": 15840}, {"Word": "have", "OffsetStartMs": 15840, "OffsetEndMs": 15990}, {"Word": "a", "OffsetStartMs": 15990, "OffsetEndMs": 16140}, {"Word": "standard", "OffsetStartMs": 16140, "OffsetEndMs": 16395}, {"Word": "deviation", "OffsetStartMs": 16395, "OffsetEndMs": 16860}, {"Word": "of", "OffsetStartMs": 16860, "OffsetEndMs": 17085}, {"Word": "one", "OffsetStartMs": 17085, "OffsetEndMs": 17390}], "SpeechSpeed": 13.3}, {"FinalSentence": "What this allows us to do is to encourage the encoder to put the latent variables roughly around a centered space, distributing the encoding smoothly so that we don't get too much divergence away from that smooth space.", "SliceSentence": "What this allows us to do is to encourage the encoder to put the latent variables roughly around a centered space distributing the encoding smoothly so that we don't get too much divergence away from that smooth space", "StartMs": 1325200, "EndMs": 1343040, "WordsNum": 38, "Words": [{"Word": "What", "OffsetStartMs": 100, "OffsetEndMs": 405}, {"Word": "this", "OffsetStartMs": 405, "OffsetEndMs": 630}, {"Word": "allows", "OffsetStartMs": 630, "OffsetEndMs": 870}, {"Word": "us", "OffsetStartMs": 870, "OffsetEndMs": 1095}, {"Word": "to", "OffsetStartMs": 1095, "OffsetEndMs": 1260}, {"Word": "do", "OffsetStartMs": 1260, "OffsetEndMs": 1455}, {"Word": "is", "OffsetStartMs": 1455, "OffsetEndMs": 1695}, {"Word": "to", "OffsetStartMs": 1695, "OffsetEndMs": 2000}, {"Word": "encourage", "OffsetStartMs": 2440, "OffsetEndMs": 2840}, {"Word": "the", "OffsetStartMs": 2980, "OffsetEndMs": 3380}, {"Word": "encoder", "OffsetStartMs": 3520, "OffsetEndMs": 4230}, {"Word": "to", "OffsetStartMs": 4230, "OffsetEndMs": 4425}, {"Word": "put", "OffsetStartMs": 4425, "OffsetEndMs": 4620}, {"Word": "the", "OffsetStartMs": 4620, "OffsetEndMs": 4785}, {"Word": "latent", "OffsetStartMs": 4785, "OffsetEndMs": 5130}, {"Word": "variables", "OffsetStartMs": 5130, "OffsetEndMs": 5720}, {"Word": "roughly", "OffsetStartMs": 6040, "OffsetEndMs": 6440}, {"Word": "around", "OffsetStartMs": 6610, "OffsetEndMs": 7010}, {"Word": "a", "OffsetStartMs": 7060, "OffsetEndMs": 7425}, {"Word": "centered", "OffsetStartMs": 7425, "OffsetEndMs": 8030}, {"Word": "space", "OffsetStartMs": 8170, "OffsetEndMs": 8570}, {"Word": "distributing", "OffsetStartMs": 9340, "OffsetEndMs": 9840}, {"Word": "the", "OffsetStartMs": 9840, "OffsetEndMs": 10035}, {"Word": "encoding", "OffsetStartMs": 10035, "OffsetEndMs": 10665}, {"Word": "smoothly", "OffsetStartMs": 10665, "OffsetEndMs": 11300}, {"Word": "so", "OffsetStartMs": 11710, "OffsetEndMs": 12110}, {"Word": "that", "OffsetStartMs": 12370, "OffsetEndMs": 12770}, {"Word": "we", "OffsetStartMs": 13360, "OffsetEndMs": 13635}, {"Word": "don't", "OffsetStartMs": 13635, "OffsetEndMs": 13935}, {"Word": "get", "OffsetStartMs": 13935, "OffsetEndMs": 14160}, {"Word": "too", "OffsetStartMs": 14160, "OffsetEndMs": 14400}, {"Word": "much", "OffsetStartMs": 14400, "OffsetEndMs": 14655}, {"Word": "divergence", "OffsetStartMs": 14655, "OffsetEndMs": 15500}, {"Word": "away", "OffsetStartMs": 15520, "OffsetEndMs": 15870}, {"Word": "from", "OffsetStartMs": 15870, "OffsetEndMs": 16110}, {"Word": "that", "OffsetStartMs": 16110, "OffsetEndMs": 16400}, {"Word": "smooth", "OffsetStartMs": 16450, "OffsetEndMs": 16815}, {"Word": "space", "OffsetStartMs": 16815, "OffsetEndMs": 17180}], "SpeechSpeed": 12.2}, {"FinalSentence": "Which can occur if the network tries to cheat and try to simply memorize the data.", "SliceSentence": "Which can occur if the network tries to cheat and try to simply memorize the data", "StartMs": 1343140, "EndMs": 1349760, "WordsNum": 16, "Words": [{"Word": "Which", "OffsetStartMs": 100, "OffsetEndMs": 435}, {"Word": "can", "OffsetStartMs": 435, "OffsetEndMs": 770}, {"Word": "occur", "OffsetStartMs": 850, "OffsetEndMs": 1185}, {"Word": "if", "OffsetStartMs": 1185, "OffsetEndMs": 1410}, {"Word": "the", "OffsetStartMs": 1410, "OffsetEndMs": 1575}, {"Word": "network", "OffsetStartMs": 1575, "OffsetEndMs": 1850}, {"Word": "tries", "OffsetStartMs": 1870, "OffsetEndMs": 2205}, {"Word": "to", "OffsetStartMs": 2205, "OffsetEndMs": 2445}, {"Word": "cheat", "OffsetStartMs": 2445, "OffsetEndMs": 2810}, {"Word": "and", "OffsetStartMs": 2980, "OffsetEndMs": 3315}, {"Word": "try", "OffsetStartMs": 3315, "OffsetEndMs": 3555}, {"Word": "to", "OffsetStartMs": 3555, "OffsetEndMs": 3735}, {"Word": "simply", "OffsetStartMs": 3735, "OffsetEndMs": 4010}, {"Word": "memorize", "OffsetStartMs": 4390, "OffsetEndMs": 5010}, {"Word": "the", "OffsetStartMs": 5010, "OffsetEndMs": 5220}, {"Word": "data", "OffsetStartMs": 5220, "OffsetEndMs": 5480}], "SpeechSpeed": 12.2}, {"FinalSentence": "By placing the gaussian standard normal prior on the latent space, we can define a concrete mathematical term that captures the distance the divergence between our encoded latent variables and this prior.", "SliceSentence": "By placing the gaussian standard normal prior on the latent space we can define a concrete mathematical term that captures the distance the divergence between our encoded latent variables and this prior", "StartMs": 1349960, "EndMs": 1365860, "WordsNum": 32, "Words": [{"Word": "By", "OffsetStartMs": 280, "OffsetEndMs": 630}, {"Word": "placing", "OffsetStartMs": 630, "OffsetEndMs": 1065}, {"Word": "the", "OffsetStartMs": 1065, "OffsetEndMs": 1200}, {"Word": "gaussian", "OffsetStartMs": 1200, "OffsetEndMs": 1730}, {"Word": "standard", "OffsetStartMs": 1900, "OffsetEndMs": 2295}, {"Word": "normal", "OffsetStartMs": 2295, "OffsetEndMs": 2690}, {"Word": "prior", "OffsetStartMs": 2710, "OffsetEndMs": 3110}, {"Word": "on", "OffsetStartMs": 3190, "OffsetEndMs": 3525}, {"Word": "the", "OffsetStartMs": 3525, "OffsetEndMs": 3720}, {"Word": "latent", "OffsetStartMs": 3720, "OffsetEndMs": 4035}, {"Word": "space", "OffsetStartMs": 4035, "OffsetEndMs": 4340}, {"Word": "we", "OffsetStartMs": 4930, "OffsetEndMs": 5205}, {"Word": "can", "OffsetStartMs": 5205, "OffsetEndMs": 5445}, {"Word": "define", "OffsetStartMs": 5445, "OffsetEndMs": 5775}, {"Word": "a", "OffsetStartMs": 5775, "OffsetEndMs": 6140}, {"Word": "concrete", "OffsetStartMs": 6340, "OffsetEndMs": 6720}, {"Word": "mathematical", "OffsetStartMs": 6720, "OffsetEndMs": 7560}, {"Word": "term", "OffsetStartMs": 7560, "OffsetEndMs": 7880}, {"Word": "that", "OffsetStartMs": 8230, "OffsetEndMs": 8565}, {"Word": "captures", "OffsetStartMs": 8565, "OffsetEndMs": 9120}, {"Word": "the", "OffsetStartMs": 9120, "OffsetEndMs": 9440}, {"Word": "distance", "OffsetStartMs": 9970, "OffsetEndMs": 10370}, {"Word": "the", "OffsetStartMs": 10690, "OffsetEndMs": 10965}, {"Word": "divergence", "OffsetStartMs": 10965, "OffsetEndMs": 11660}, {"Word": "between", "OffsetStartMs": 12100, "OffsetEndMs": 12405}, {"Word": "our", "OffsetStartMs": 12405, "OffsetEndMs": 12705}, {"Word": "encoded", "OffsetStartMs": 12705, "OffsetEndMs": 13425}, {"Word": "latent", "OffsetStartMs": 13425, "OffsetEndMs": 13785}, {"Word": "variables", "OffsetStartMs": 13785, "OffsetEndMs": 14310}, {"Word": "and", "OffsetStartMs": 14310, "OffsetEndMs": 14610}, {"Word": "this", "OffsetStartMs": 14610, "OffsetEndMs": 14850}, {"Word": "prior", "OffsetStartMs": 14850, "OffsetEndMs": 15170}], "SpeechSpeed": 12.7}, {"FinalSentence": "And this is called the K L divergence when our prior is a standard normal. The kl divergence takes the form of the equation that I'm showing up on the screen. But what I want you to really get away come away with is that the concept of trying to smooth things out and to.", "SliceSentence": "And this is called the K L divergence when our prior is a standard normal . Thekl divergence takes the form of the equation that I'm showing up on the screen . Butwhat I want you to really get away come away with is that the concept of trying to smooth things out and to", "StartMs": 1365860, "EndMs": 1388420, "WordsNum": 55, "Words": [{"Word": "And", "OffsetStartMs": 70, "OffsetEndMs": 465}, {"Word": "this", "OffsetStartMs": 465, "OffsetEndMs": 735}, {"Word": "is", "OffsetStartMs": 735, "OffsetEndMs": 945}, {"Word": "called", "OffsetStartMs": 945, "OffsetEndMs": 1275}, {"Word": "the", "OffsetStartMs": 1275, "OffsetEndMs": 1605}, {"Word": "K", "OffsetStartMs": 1605, "OffsetEndMs": 1875}, {"Word": "L", "OffsetStartMs": 1875, "OffsetEndMs": 2210}, {"Word": "divergence", "OffsetStartMs": 2260, "OffsetEndMs": 3080}, {"Word": "when", "OffsetStartMs": 4000, "OffsetEndMs": 4400}, {"Word": "our", "OffsetStartMs": 4420, "OffsetEndMs": 4800}, {"Word": "prior", "OffsetStartMs": 4800, "OffsetEndMs": 5160}, {"Word": "is", "OffsetStartMs": 5160, "OffsetEndMs": 5415}, {"Word": "a", "OffsetStartMs": 5415, "OffsetEndMs": 5580}, {"Word": "standard", "OffsetStartMs": 5580, "OffsetEndMs": 5850}, {"Word": "normal", "OffsetStartMs": 5850, "OffsetEndMs": 6230}, {"Word": ".", "OffsetStartMs": 6820, "OffsetEndMs": 7220}, {"Word": "Thekl", "OffsetStartMs": 7600, "OffsetEndMs": 8010}, {"Word": "divergence", "OffsetStartMs": 8010, "OffsetEndMs": 8595}, {"Word": "takes", "OffsetStartMs": 8595, "OffsetEndMs": 8850}, {"Word": "the", "OffsetStartMs": 8850, "OffsetEndMs": 9045}, {"Word": "form", "OffsetStartMs": 9045, "OffsetEndMs": 9285}, {"Word": "of", "OffsetStartMs": 9285, "OffsetEndMs": 9570}, {"Word": "the", "OffsetStartMs": 9570, "OffsetEndMs": 9795}, {"Word": "equation", "OffsetStartMs": 9795, "OffsetEndMs": 10065}, {"Word": "that", "OffsetStartMs": 10065, "OffsetEndMs": 10275}, {"Word": "I'm", "OffsetStartMs": 10275, "OffsetEndMs": 10485}, {"Word": "showing", "OffsetStartMs": 10485, "OffsetEndMs": 10760}, {"Word": "up", "OffsetStartMs": 11020, "OffsetEndMs": 11295}, {"Word": "on", "OffsetStartMs": 11295, "OffsetEndMs": 11445}, {"Word": "the", "OffsetStartMs": 11445, "OffsetEndMs": 11625}, {"Word": "screen", "OffsetStartMs": 11625, "OffsetEndMs": 11930}, {"Word": ".", "OffsetStartMs": 12850, "OffsetEndMs": 13250}, {"Word": "Butwhat", "OffsetStartMs": 13600, "OffsetEndMs": 13860}, {"Word": "I", "OffsetStartMs": 13860, "OffsetEndMs": 14010}, {"Word": "want", "OffsetStartMs": 14010, "OffsetEndMs": 14235}, {"Word": "you", "OffsetStartMs": 14235, "OffsetEndMs": 14445}, {"Word": "to", "OffsetStartMs": 14445, "OffsetEndMs": 14580}, {"Word": "really", "OffsetStartMs": 14580, "OffsetEndMs": 14840}, {"Word": "get", "OffsetStartMs": 15340, "OffsetEndMs": 15645}, {"Word": "away", "OffsetStartMs": 15645, "OffsetEndMs": 15950}, {"Word": "come", "OffsetStartMs": 16240, "OffsetEndMs": 16560}, {"Word": "away", "OffsetStartMs": 16560, "OffsetEndMs": 16785}, {"Word": "with", "OffsetStartMs": 16785, "OffsetEndMs": 17040}, {"Word": "is", "OffsetStartMs": 17040, "OffsetEndMs": 17310}, {"Word": "that", "OffsetStartMs": 17310, "OffsetEndMs": 17630}, {"Word": "the", "OffsetStartMs": 17980, "OffsetEndMs": 18285}, {"Word": "concept", "OffsetStartMs": 18285, "OffsetEndMs": 18590}, {"Word": "of", "OffsetStartMs": 18790, "OffsetEndMs": 19190}, {"Word": "trying", "OffsetStartMs": 19210, "OffsetEndMs": 19590}, {"Word": "to", "OffsetStartMs": 19590, "OffsetEndMs": 19970}, {"Word": "smooth", "OffsetStartMs": 20380, "OffsetEndMs": 20715}, {"Word": "things", "OffsetStartMs": 20715, "OffsetEndMs": 20985}, {"Word": "out", "OffsetStartMs": 20985, "OffsetEndMs": 21300}, {"Word": "and", "OffsetStartMs": 21300, "OffsetEndMs": 21630}, {"Word": "to", "OffsetStartMs": 21630, "OffsetEndMs": 21980}], "SpeechSpeed": 11.9}, {"FinalSentence": "Capture this divergence, and this difference between the prior and the latent encoding, is all this kl term is trying to capture.", "SliceSentence": "Capture this divergence and this difference between the prior and the latent encoding is all this kl term is trying to capture", "StartMs": 1388780, "EndMs": 1397080, "WordsNum": 22, "Words": [{"Word": "Capture", "OffsetStartMs": 130, "OffsetEndMs": 530}, {"Word": "this", "OffsetStartMs": 550, "OffsetEndMs": 840}, {"Word": "divergence", "OffsetStartMs": 840, "OffsetEndMs": 1550}, {"Word": "and", "OffsetStartMs": 1720, "OffsetEndMs": 2010}, {"Word": "this", "OffsetStartMs": 2010, "OffsetEndMs": 2205}, {"Word": "difference", "OffsetStartMs": 2205, "OffsetEndMs": 2510}, {"Word": "between", "OffsetStartMs": 2710, "OffsetEndMs": 2985}, {"Word": "the", "OffsetStartMs": 2985, "OffsetEndMs": 3165}, {"Word": "prior", "OffsetStartMs": 3165, "OffsetEndMs": 3450}, {"Word": "and", "OffsetStartMs": 3450, "OffsetEndMs": 3705}, {"Word": "the", "OffsetStartMs": 3705, "OffsetEndMs": 3840}, {"Word": "latent", "OffsetStartMs": 3840, "OffsetEndMs": 4155}, {"Word": "encoding", "OffsetStartMs": 4155, "OffsetEndMs": 4790}, {"Word": "is", "OffsetStartMs": 4870, "OffsetEndMs": 5190}, {"Word": "all", "OffsetStartMs": 5190, "OffsetEndMs": 5430}, {"Word": "this", "OffsetStartMs": 5430, "OffsetEndMs": 5670}, {"Word": "kl", "OffsetStartMs": 5670, "OffsetEndMs": 6075}, {"Word": "term", "OffsetStartMs": 6075, "OffsetEndMs": 6375}, {"Word": "is", "OffsetStartMs": 6375, "OffsetEndMs": 6660}, {"Word": "trying", "OffsetStartMs": 6660, "OffsetEndMs": 6900}, {"Word": "to", "OffsetStartMs": 6900, "OffsetEndMs": 7095}, {"Word": "capture", "OffsetStartMs": 7095, "OffsetEndMs": 7370}], "SpeechSpeed": 15.2}, {"FinalSentence": "So it's a bit of math, and I I acknowledge that. But what I want to next go into is really what is the intuition behind this regularization operation, why do we do this? And why does the normal prior, in particular, work effectively for v.", "SliceSentence": "So it's a bit of math and I I acknowledge that . Butwhat I want to next go into is really what is the intuition behind this regularization operation why do we do this And why does the normal prior in particular work effectively for v", "StartMs": 1397520, "EndMs": 1414600, "WordsNum": 46, "Words": [{"Word": "So", "OffsetStartMs": 160, "OffsetEndMs": 495}, {"Word": "it's", "OffsetStartMs": 495, "OffsetEndMs": 750}, {"Word": "a", "OffsetStartMs": 750, "OffsetEndMs": 825}, {"Word": "bit", "OffsetStartMs": 825, "OffsetEndMs": 930}, {"Word": "of", "OffsetStartMs": 930, "OffsetEndMs": 1065}, {"Word": "math", "OffsetStartMs": 1065, "OffsetEndMs": 1335}, {"Word": "and", "OffsetStartMs": 1335, "OffsetEndMs": 1730}, {"Word": "I", "OffsetStartMs": 1840, "OffsetEndMs": 2240}, {"Word": "I", "OffsetStartMs": 2260, "OffsetEndMs": 2660}, {"Word": "acknowledge", "OffsetStartMs": 2800, "OffsetEndMs": 3180}, {"Word": "that", "OffsetStartMs": 3180, "OffsetEndMs": 3560}, {"Word": ".", "OffsetStartMs": 3790, "OffsetEndMs": 4190}, {"Word": "Butwhat", "OffsetStartMs": 4360, "OffsetEndMs": 4665}, {"Word": "I", "OffsetStartMs": 4665, "OffsetEndMs": 4845}, {"Word": "want", "OffsetStartMs": 4845, "OffsetEndMs": 5100}, {"Word": "to", "OffsetStartMs": 5100, "OffsetEndMs": 5385}, {"Word": "next", "OffsetStartMs": 5385, "OffsetEndMs": 5640}, {"Word": "go", "OffsetStartMs": 5640, "OffsetEndMs": 5850}, {"Word": "into", "OffsetStartMs": 5850, "OffsetEndMs": 6045}, {"Word": "is", "OffsetStartMs": 6045, "OffsetEndMs": 6285}, {"Word": "really", "OffsetStartMs": 6285, "OffsetEndMs": 6555}, {"Word": "what", "OffsetStartMs": 6555, "OffsetEndMs": 6840}, {"Word": "is", "OffsetStartMs": 6840, "OffsetEndMs": 7050}, {"Word": "the", "OffsetStartMs": 7050, "OffsetEndMs": 7200}, {"Word": "intuition", "OffsetStartMs": 7200, "OffsetEndMs": 7820}, {"Word": "behind", "OffsetStartMs": 8080, "OffsetEndMs": 8415}, {"Word": "this", "OffsetStartMs": 8415, "OffsetEndMs": 8670}, {"Word": "regularization", "OffsetStartMs": 8670, "OffsetEndMs": 9500}, {"Word": "operation", "OffsetStartMs": 9730, "OffsetEndMs": 10130}, {"Word": "why", "OffsetStartMs": 10900, "OffsetEndMs": 11300}, {"Word": "do", "OffsetStartMs": 11500, "OffsetEndMs": 11760}, {"Word": "we", "OffsetStartMs": 11760, "OffsetEndMs": 11895}, {"Word": "do", "OffsetStartMs": 11895, "OffsetEndMs": 12060}, {"Word": "this", "OffsetStartMs": 12060, "OffsetEndMs": 12285}, {"Word": "And", "OffsetStartMs": 12285, "OffsetEndMs": 12540}, {"Word": "why", "OffsetStartMs": 12540, "OffsetEndMs": 12795}, {"Word": "does", "OffsetStartMs": 12795, "OffsetEndMs": 13005}, {"Word": "the", "OffsetStartMs": 13005, "OffsetEndMs": 13155}, {"Word": "normal", "OffsetStartMs": 13155, "OffsetEndMs": 13430}, {"Word": "prior", "OffsetStartMs": 13480, "OffsetEndMs": 13830}, {"Word": "in", "OffsetStartMs": 13830, "OffsetEndMs": 14145}, {"Word": "particular", "OffsetStartMs": 14145, "OffsetEndMs": 14510}, {"Word": "work", "OffsetStartMs": 14830, "OffsetEndMs": 15210}, {"Word": "effectively", "OffsetStartMs": 15210, "OffsetEndMs": 15590}, {"Word": "for", "OffsetStartMs": 15760, "OffsetEndMs": 16050}, {"Word": "v", "OffsetStartMs": 16050, "OffsetEndMs": 16340}], "SpeechSpeed": 13.6}, {"FinalSentence": "So let's consider what properties we want our latent space to adopt and for this regularization to achieve.", "SliceSentence": "So let's consider what properties we want our latent space to adopt and for this regularization to achieve", "StartMs": 1414800, "EndMs": 1422480, "WordsNum": 18, "Words": [{"Word": "So", "OffsetStartMs": 160, "OffsetEndMs": 435}, {"Word": "let's", "OffsetStartMs": 435, "OffsetEndMs": 810}, {"Word": "consider", "OffsetStartMs": 810, "OffsetEndMs": 1125}, {"Word": "what", "OffsetStartMs": 1125, "OffsetEndMs": 1395}, {"Word": "properties", "OffsetStartMs": 1395, "OffsetEndMs": 1730}, {"Word": "we", "OffsetStartMs": 1930, "OffsetEndMs": 2235}, {"Word": "want", "OffsetStartMs": 2235, "OffsetEndMs": 2540}, {"Word": "our", "OffsetStartMs": 2770, "OffsetEndMs": 3120}, {"Word": "latent", "OffsetStartMs": 3120, "OffsetEndMs": 3510}, {"Word": "space", "OffsetStartMs": 3510, "OffsetEndMs": 3830}, {"Word": "to", "OffsetStartMs": 3850, "OffsetEndMs": 4250}, {"Word": "adopt", "OffsetStartMs": 4420, "OffsetEndMs": 5000}, {"Word": "and", "OffsetStartMs": 5140, "OffsetEndMs": 5490}, {"Word": "for", "OffsetStartMs": 5490, "OffsetEndMs": 5715}, {"Word": "this", "OffsetStartMs": 5715, "OffsetEndMs": 5880}, {"Word": "regularization", "OffsetStartMs": 5880, "OffsetEndMs": 6570}, {"Word": "to", "OffsetStartMs": 6570, "OffsetEndMs": 6870}, {"Word": "achieve", "OffsetStartMs": 6870, "OffsetEndMs": 7190}], "SpeechSpeed": 13.8}, {"FinalSentence": "The first is this goal of continuity. We don't. And what we mean by continuity is that if there are points in the latent space that are close together, ideally after decoding, we should recover two reconstructions that are similar in content that make sense that they're close together.", "SliceSentence": "The first is this goal of continuity . Wedon't . Andwhat we mean by continuity is that if there are points in the latent space that are close together ideally after decoding we should recover two reconstructions that are similar in content that make sense that they're close together", "StartMs": 1422940, "EndMs": 1442880, "WordsNum": 49, "Words": [{"Word": "The", "OffsetStartMs": 100, "OffsetEndMs": 375}, {"Word": "first", "OffsetStartMs": 375, "OffsetEndMs": 650}, {"Word": "is", "OffsetStartMs": 700, "OffsetEndMs": 990}, {"Word": "this", "OffsetStartMs": 990, "OffsetEndMs": 1200}, {"Word": "goal", "OffsetStartMs": 1200, "OffsetEndMs": 1470}, {"Word": "of", "OffsetStartMs": 1470, "OffsetEndMs": 1820}, {"Word": "continuity", "OffsetStartMs": 1960, "OffsetEndMs": 2660}, {"Word": ".", "OffsetStartMs": 3340, "OffsetEndMs": 3645}, {"Word": "Wedon't", "OffsetStartMs": 3645, "OffsetEndMs": 4130}, {"Word": ".", "OffsetStartMs": 4630, "OffsetEndMs": 4935}, {"Word": "Andwhat", "OffsetStartMs": 4935, "OffsetEndMs": 5145}, {"Word": "we", "OffsetStartMs": 5145, "OffsetEndMs": 5325}, {"Word": "mean", "OffsetStartMs": 5325, "OffsetEndMs": 5490}, {"Word": "by", "OffsetStartMs": 5490, "OffsetEndMs": 5780}, {"Word": "continuity", "OffsetStartMs": 5830, "OffsetEndMs": 6465}, {"Word": "is", "OffsetStartMs": 6465, "OffsetEndMs": 6660}, {"Word": "that", "OffsetStartMs": 6660, "OffsetEndMs": 6950}, {"Word": "if", "OffsetStartMs": 7180, "OffsetEndMs": 7470}, {"Word": "there", "OffsetStartMs": 7470, "OffsetEndMs": 7620}, {"Word": "are", "OffsetStartMs": 7620, "OffsetEndMs": 7815}, {"Word": "points", "OffsetStartMs": 7815, "OffsetEndMs": 8085}, {"Word": "in", "OffsetStartMs": 8085, "OffsetEndMs": 8280}, {"Word": "the", "OffsetStartMs": 8280, "OffsetEndMs": 8400}, {"Word": "latent", "OffsetStartMs": 8400, "OffsetEndMs": 8730}, {"Word": "space", "OffsetStartMs": 8730, "OffsetEndMs": 9050}, {"Word": "that", "OffsetStartMs": 9250, "OffsetEndMs": 9495}, {"Word": "are", "OffsetStartMs": 9495, "OffsetEndMs": 9675}, {"Word": "close", "OffsetStartMs": 9675, "OffsetEndMs": 10005}, {"Word": "together", "OffsetStartMs": 10005, "OffsetEndMs": 10400}, {"Word": "ideally", "OffsetStartMs": 11230, "OffsetEndMs": 12030}, {"Word": "after", "OffsetStartMs": 12030, "OffsetEndMs": 12380}, {"Word": "decoding", "OffsetStartMs": 12430, "OffsetEndMs": 13220}, {"Word": "we", "OffsetStartMs": 13420, "OffsetEndMs": 13725}, {"Word": "should", "OffsetStartMs": 13725, "OffsetEndMs": 14025}, {"Word": "recover", "OffsetStartMs": 14025, "OffsetEndMs": 14420}, {"Word": "two", "OffsetStartMs": 14440, "OffsetEndMs": 14730}, {"Word": "reconstructions", "OffsetStartMs": 14730, "OffsetEndMs": 15540}, {"Word": "that", "OffsetStartMs": 15540, "OffsetEndMs": 15795}, {"Word": "are", "OffsetStartMs": 15795, "OffsetEndMs": 16110}, {"Word": "similar", "OffsetStartMs": 16110, "OffsetEndMs": 16485}, {"Word": "in", "OffsetStartMs": 16485, "OffsetEndMs": 16800}, {"Word": "content", "OffsetStartMs": 16800, "OffsetEndMs": 17120}, {"Word": "that", "OffsetStartMs": 17500, "OffsetEndMs": 17805}, {"Word": "make", "OffsetStartMs": 17805, "OffsetEndMs": 18045}, {"Word": "sense", "OffsetStartMs": 18045, "OffsetEndMs": 18300}, {"Word": "that", "OffsetStartMs": 18300, "OffsetEndMs": 18510}, {"Word": "they're", "OffsetStartMs": 18510, "OffsetEndMs": 18750}, {"Word": "close", "OffsetStartMs": 18750, "OffsetEndMs": 18990}, {"Word": "together", "OffsetStartMs": 18990, "OffsetEndMs": 19370}], "SpeechSpeed": 14.1}, {"FinalSentence": "The second key property is this idea of completeness.", "SliceSentence": "The second key property is this idea of completeness", "StartMs": 1443180, "EndMs": 1447220, "WordsNum": 9, "Words": [{"Word": "The", "OffsetStartMs": 130, "OffsetEndMs": 420}, {"Word": "second", "OffsetStartMs": 420, "OffsetEndMs": 710}, {"Word": "key", "OffsetStartMs": 730, "OffsetEndMs": 1050}, {"Word": "property", "OffsetStartMs": 1050, "OffsetEndMs": 1370}, {"Word": "is", "OffsetStartMs": 1510, "OffsetEndMs": 1785}, {"Word": "this", "OffsetStartMs": 1785, "OffsetEndMs": 2060}, {"Word": "idea", "OffsetStartMs": 2080, "OffsetEndMs": 2385}, {"Word": "of", "OffsetStartMs": 2385, "OffsetEndMs": 2690}, {"Word": "completeness", "OffsetStartMs": 2710, "OffsetEndMs": 3320}], "SpeechSpeed": 12.9}, {"FinalSentence": "We don't want there to be gaps in the Lane space. We want to be able to decode and sample from the Lane space in a way that is smooth and a way that is connected.", "SliceSentence": "We don't want there to be gaps in the Lane space . Wewant to be able to decode and sample from the Lane space in a way that is smooth and a way that is connected", "StartMs": 1447240, "EndMs": 1457120, "WordsNum": 36, "Words": [{"Word": "We", "OffsetStartMs": 100, "OffsetEndMs": 360}, {"Word": "don't", "OffsetStartMs": 360, "OffsetEndMs": 570}, {"Word": "want", "OffsetStartMs": 570, "OffsetEndMs": 705}, {"Word": "there", "OffsetStartMs": 705, "OffsetEndMs": 900}, {"Word": "to", "OffsetStartMs": 900, "OffsetEndMs": 1050}, {"Word": "be", "OffsetStartMs": 1050, "OffsetEndMs": 1215}, {"Word": "gaps", "OffsetStartMs": 1215, "OffsetEndMs": 1515}, {"Word": "in", "OffsetStartMs": 1515, "OffsetEndMs": 1755}, {"Word": "the", "OffsetStartMs": 1755, "OffsetEndMs": 1875}, {"Word": "Lane", "OffsetStartMs": 1875, "OffsetEndMs": 2085}, {"Word": "space", "OffsetStartMs": 2085, "OffsetEndMs": 2450}, {"Word": ".", "OffsetStartMs": 2740, "OffsetEndMs": 3030}, {"Word": "Wewant", "OffsetStartMs": 3030, "OffsetEndMs": 3240}, {"Word": "to", "OffsetStartMs": 3240, "OffsetEndMs": 3405}, {"Word": "be", "OffsetStartMs": 3405, "OffsetEndMs": 3555}, {"Word": "able", "OffsetStartMs": 3555, "OffsetEndMs": 3810}, {"Word": "to", "OffsetStartMs": 3810, "OffsetEndMs": 4035}, {"Word": "decode", "OffsetStartMs": 4035, "OffsetEndMs": 4605}, {"Word": "and", "OffsetStartMs": 4605, "OffsetEndMs": 4880}, {"Word": "sample", "OffsetStartMs": 5110, "OffsetEndMs": 5490}, {"Word": "from", "OffsetStartMs": 5490, "OffsetEndMs": 5760}, {"Word": "the", "OffsetStartMs": 5760, "OffsetEndMs": 5910}, {"Word": "Lane", "OffsetStartMs": 5910, "OffsetEndMs": 6135}, {"Word": "space", "OffsetStartMs": 6135, "OffsetEndMs": 6435}, {"Word": "in", "OffsetStartMs": 6435, "OffsetEndMs": 6615}, {"Word": "a", "OffsetStartMs": 6615, "OffsetEndMs": 6720}, {"Word": "way", "OffsetStartMs": 6720, "OffsetEndMs": 6885}, {"Word": "that", "OffsetStartMs": 6885, "OffsetEndMs": 7050}, {"Word": "is", "OffsetStartMs": 7050, "OffsetEndMs": 7245}, {"Word": "smooth", "OffsetStartMs": 7245, "OffsetEndMs": 7580}, {"Word": "and", "OffsetStartMs": 7810, "OffsetEndMs": 8085}, {"Word": "a", "OffsetStartMs": 8085, "OffsetEndMs": 8220}, {"Word": "way", "OffsetStartMs": 8220, "OffsetEndMs": 8400}, {"Word": "that", "OffsetStartMs": 8400, "OffsetEndMs": 8565}, {"Word": "is", "OffsetStartMs": 8565, "OffsetEndMs": 8760}, {"Word": "connected", "OffsetStartMs": 8760, "OffsetEndMs": 9110}], "SpeechSpeed": 16.2}, {"FinalSentence": "To get more concrete, let's ask what could be the consequences of not regularizing our latent space at all? Well, if we don't regularize, we can end up with instances where there are points that are close in the latent space, but don't end up with similar decodings or similar reconstructions.", "SliceSentence": "To get more concrete let's ask what could be the consequences of not regularizing our latent space at all Well if we don't regularize we can end up with instances where there are points that are close in the latent space but don't end up with similar decodings or similar reconstructions", "StartMs": 1457840, "EndMs": 1478500, "WordsNum": 51, "Words": [{"Word": "To", "OffsetStartMs": 100, "OffsetEndMs": 360}, {"Word": "get", "OffsetStartMs": 360, "OffsetEndMs": 495}, {"Word": "more", "OffsetStartMs": 495, "OffsetEndMs": 770}, {"Word": "concrete", "OffsetStartMs": 880, "OffsetEndMs": 1280}, {"Word": "let's", "OffsetStartMs": 2920, "OffsetEndMs": 3255}, {"Word": "ask", "OffsetStartMs": 3255, "OffsetEndMs": 3480}, {"Word": "what", "OffsetStartMs": 3480, "OffsetEndMs": 3795}, {"Word": "could", "OffsetStartMs": 3795, "OffsetEndMs": 3990}, {"Word": "be", "OffsetStartMs": 3990, "OffsetEndMs": 4125}, {"Word": "the", "OffsetStartMs": 4125, "OffsetEndMs": 4305}, {"Word": "consequences", "OffsetStartMs": 4305, "OffsetEndMs": 4610}, {"Word": "of", "OffsetStartMs": 4990, "OffsetEndMs": 5310}, {"Word": "not", "OffsetStartMs": 5310, "OffsetEndMs": 5565}, {"Word": "regularizing", "OffsetStartMs": 5565, "OffsetEndMs": 6255}, {"Word": "our", "OffsetStartMs": 6255, "OffsetEndMs": 6540}, {"Word": "latent", "OffsetStartMs": 6540, "OffsetEndMs": 6885}, {"Word": "space", "OffsetStartMs": 6885, "OffsetEndMs": 7095}, {"Word": "at", "OffsetStartMs": 7095, "OffsetEndMs": 7260}, {"Word": "all", "OffsetStartMs": 7260, "OffsetEndMs": 7520}, {"Word": "Well", "OffsetStartMs": 8260, "OffsetEndMs": 8660}, {"Word": "if", "OffsetStartMs": 9280, "OffsetEndMs": 9585}, {"Word": "we", "OffsetStartMs": 9585, "OffsetEndMs": 9750}, {"Word": "don't", "OffsetStartMs": 9750, "OffsetEndMs": 9975}, {"Word": "regularize", "OffsetStartMs": 9975, "OffsetEndMs": 10550}, {"Word": "we", "OffsetStartMs": 10750, "OffsetEndMs": 11010}, {"Word": "can", "OffsetStartMs": 11010, "OffsetEndMs": 11160}, {"Word": "end", "OffsetStartMs": 11160, "OffsetEndMs": 11340}, {"Word": "up", "OffsetStartMs": 11340, "OffsetEndMs": 11520}, {"Word": "with", "OffsetStartMs": 11520, "OffsetEndMs": 11715}, {"Word": "instances", "OffsetStartMs": 11715, "OffsetEndMs": 12465}, {"Word": "where", "OffsetStartMs": 12465, "OffsetEndMs": 12830}, {"Word": "there", "OffsetStartMs": 13000, "OffsetEndMs": 13260}, {"Word": "are", "OffsetStartMs": 13260, "OffsetEndMs": 13440}, {"Word": "points", "OffsetStartMs": 13440, "OffsetEndMs": 13695}, {"Word": "that", "OffsetStartMs": 13695, "OffsetEndMs": 13890}, {"Word": "are", "OffsetStartMs": 13890, "OffsetEndMs": 14100}, {"Word": "close", "OffsetStartMs": 14100, "OffsetEndMs": 14370}, {"Word": "in", "OffsetStartMs": 14370, "OffsetEndMs": 14550}, {"Word": "the", "OffsetStartMs": 14550, "OffsetEndMs": 14655}, {"Word": "latent", "OffsetStartMs": 14655, "OffsetEndMs": 14985}, {"Word": "space", "OffsetStartMs": 14985, "OffsetEndMs": 15290}, {"Word": "but", "OffsetStartMs": 15670, "OffsetEndMs": 16070}, {"Word": "don't", "OffsetStartMs": 16450, "OffsetEndMs": 16845}, {"Word": "end", "OffsetStartMs": 16845, "OffsetEndMs": 17040}, {"Word": "up", "OffsetStartMs": 17040, "OffsetEndMs": 17340}, {"Word": "with", "OffsetStartMs": 17340, "OffsetEndMs": 17655}, {"Word": "similar", "OffsetStartMs": 17655, "OffsetEndMs": 18015}, {"Word": "decodings", "OffsetStartMs": 18015, "OffsetEndMs": 18660}, {"Word": "or", "OffsetStartMs": 18660, "OffsetEndMs": 18900}, {"Word": "similar", "OffsetStartMs": 18900, "OffsetEndMs": 19185}, {"Word": "reconstructions", "OffsetStartMs": 19185, "OffsetEndMs": 20120}], "SpeechSpeed": 13.9}, {"FinalSentence": "Similarly, we could have points that don't lead to meaningful reconstructions at all. They're somehow encoded, but we can't decode effectively.", "SliceSentence": "Similarly we could have points that don't lead to meaningful reconstructions at all .They're somehow encoded but we can't decode effectively", "StartMs": 1478600, "EndMs": 1489060, "WordsNum": 21, "Words": [{"Word": "Similarly", "OffsetStartMs": 190, "OffsetEndMs": 1290}, {"Word": "we", "OffsetStartMs": 1290, "OffsetEndMs": 1485}, {"Word": "could", "OffsetStartMs": 1485, "OffsetEndMs": 1635}, {"Word": "have", "OffsetStartMs": 1635, "OffsetEndMs": 1910}, {"Word": "points", "OffsetStartMs": 1990, "OffsetEndMs": 2370}, {"Word": "that", "OffsetStartMs": 2370, "OffsetEndMs": 2750}, {"Word": "don't", "OffsetStartMs": 2950, "OffsetEndMs": 3330}, {"Word": "lead", "OffsetStartMs": 3330, "OffsetEndMs": 3495}, {"Word": "to", "OffsetStartMs": 3495, "OffsetEndMs": 3675}, {"Word": "meaningful", "OffsetStartMs": 3675, "OffsetEndMs": 3950}, {"Word": "reconstructions", "OffsetStartMs": 4360, "OffsetEndMs": 5145}, {"Word": "at", "OffsetStartMs": 5145, "OffsetEndMs": 5280}, {"Word": "all", "OffsetStartMs": 5280, "OffsetEndMs": 5540}, {"Word": ".They're", "OffsetStartMs": 5830, "OffsetEndMs": 6180}, {"Word": "somehow", "OffsetStartMs": 6180, "OffsetEndMs": 6405}, {"Word": "encoded", "OffsetStartMs": 6405, "OffsetEndMs": 7080}, {"Word": "but", "OffsetStartMs": 7080, "OffsetEndMs": 7400}, {"Word": "we", "OffsetStartMs": 7540, "OffsetEndMs": 7830}, {"Word": "can't", "OffsetStartMs": 7830, "OffsetEndMs": 8205}, {"Word": "decode", "OffsetStartMs": 8205, "OffsetEndMs": 8820}, {"Word": "effectively", "OffsetStartMs": 8820, "OffsetEndMs": 9200}], "SpeechSpeed": 13.3}, {"FinalSentence": "Regularization allows us to realize points that end up close into latent space and also are similarly reconstructed and meaningfully reconstructed.", "SliceSentence": "Regularization allows us to realize points that end up close into latent space and also are similarly reconstructed and meaningfully reconstructed", "StartMs": 1489340, "EndMs": 1500280, "WordsNum": 21, "Words": [{"Word": "Regularization", "OffsetStartMs": 100, "OffsetEndMs": 1010}, {"Word": "allows", "OffsetStartMs": 1540, "OffsetEndMs": 1875}, {"Word": "us", "OffsetStartMs": 1875, "OffsetEndMs": 2145}, {"Word": "to", "OffsetStartMs": 2145, "OffsetEndMs": 2460}, {"Word": "realize", "OffsetStartMs": 2460, "OffsetEndMs": 2840}, {"Word": "points", "OffsetStartMs": 3220, "OffsetEndMs": 3570}, {"Word": "that", "OffsetStartMs": 3570, "OffsetEndMs": 3840}, {"Word": "end", "OffsetStartMs": 3840, "OffsetEndMs": 4035}, {"Word": "up", "OffsetStartMs": 4035, "OffsetEndMs": 4275}, {"Word": "close", "OffsetStartMs": 4275, "OffsetEndMs": 4560}, {"Word": "into", "OffsetStartMs": 4560, "OffsetEndMs": 4800}, {"Word": "latent", "OffsetStartMs": 4800, "OffsetEndMs": 5205}, {"Word": "space", "OffsetStartMs": 5205, "OffsetEndMs": 5510}, {"Word": "and", "OffsetStartMs": 5980, "OffsetEndMs": 6380}, {"Word": "also", "OffsetStartMs": 6610, "OffsetEndMs": 6960}, {"Word": "are", "OffsetStartMs": 6960, "OffsetEndMs": 7260}, {"Word": "similarly", "OffsetStartMs": 7260, "OffsetEndMs": 7860}, {"Word": "reconstructed", "OffsetStartMs": 7860, "OffsetEndMs": 8720}, {"Word": "and", "OffsetStartMs": 8770, "OffsetEndMs": 9105}, {"Word": "meaningfully", "OffsetStartMs": 9105, "OffsetEndMs": 9705}, {"Word": "reconstructed", "OffsetStartMs": 9705, "OffsetEndMs": 10580}], "SpeechSpeed": 13.3}, {"FinalSentence": "Okay, so continuing with this example, the example that I showed there and I didn't get into details, was showing these shapes, these shapes of different colors and that were trying to be encoded in some lower dimensional space.", "SliceSentence": "Okay so continuing with this example the example that I showed there and I didn't get into details was showing these shapes these shapes of different colors and that were trying to be encoded in some lower dimensional space", "StartMs": 1502060, "EndMs": 1517880, "WordsNum": 39, "Words": [{"Word": "Okay", "OffsetStartMs": 400, "OffsetEndMs": 800}, {"Word": "so", "OffsetStartMs": 1180, "OffsetEndMs": 1580}, {"Word": "continuing", "OffsetStartMs": 2590, "OffsetEndMs": 2940}, {"Word": "with", "OffsetStartMs": 2940, "OffsetEndMs": 3165}, {"Word": "this", "OffsetStartMs": 3165, "OffsetEndMs": 3405}, {"Word": "example", "OffsetStartMs": 3405, "OffsetEndMs": 3770}, {"Word": "the", "OffsetStartMs": 3910, "OffsetEndMs": 4230}, {"Word": "example", "OffsetStartMs": 4230, "OffsetEndMs": 4515}, {"Word": "that", "OffsetStartMs": 4515, "OffsetEndMs": 4770}, {"Word": "I", "OffsetStartMs": 4770, "OffsetEndMs": 4980}, {"Word": "showed", "OffsetStartMs": 4980, "OffsetEndMs": 5220}, {"Word": "there", "OffsetStartMs": 5220, "OffsetEndMs": 5490}, {"Word": "and", "OffsetStartMs": 5490, "OffsetEndMs": 5685}, {"Word": "I", "OffsetStartMs": 5685, "OffsetEndMs": 5835}, {"Word": "didn't", "OffsetStartMs": 5835, "OffsetEndMs": 6230}, {"Word": "get", "OffsetStartMs": 7480, "OffsetEndMs": 7755}, {"Word": "into", "OffsetStartMs": 7755, "OffsetEndMs": 8030}, {"Word": "details", "OffsetStartMs": 8050, "OffsetEndMs": 8385}, {"Word": "was", "OffsetStartMs": 8385, "OffsetEndMs": 8700}, {"Word": "showing", "OffsetStartMs": 8700, "OffsetEndMs": 9030}, {"Word": "these", "OffsetStartMs": 9030, "OffsetEndMs": 9345}, {"Word": "shapes", "OffsetStartMs": 9345, "OffsetEndMs": 9740}, {"Word": "these", "OffsetStartMs": 9910, "OffsetEndMs": 10230}, {"Word": "shapes", "OffsetStartMs": 10230, "OffsetEndMs": 10485}, {"Word": "of", "OffsetStartMs": 10485, "OffsetEndMs": 10665}, {"Word": "different", "OffsetStartMs": 10665, "OffsetEndMs": 10890}, {"Word": "colors", "OffsetStartMs": 10890, "OffsetEndMs": 11240}, {"Word": "and", "OffsetStartMs": 11500, "OffsetEndMs": 11775}, {"Word": "that", "OffsetStartMs": 11775, "OffsetEndMs": 11940}, {"Word": "were", "OffsetStartMs": 11940, "OffsetEndMs": 12135}, {"Word": "trying", "OffsetStartMs": 12135, "OffsetEndMs": 12375}, {"Word": "to", "OffsetStartMs": 12375, "OffsetEndMs": 12555}, {"Word": "be", "OffsetStartMs": 12555, "OffsetEndMs": 12675}, {"Word": "encoded", "OffsetStartMs": 12675, "OffsetEndMs": 13245}, {"Word": "in", "OffsetStartMs": 13245, "OffsetEndMs": 13440}, {"Word": "some", "OffsetStartMs": 13440, "OffsetEndMs": 13760}, {"Word": "lower", "OffsetStartMs": 13900, "OffsetEndMs": 14265}, {"Word": "dimensional", "OffsetStartMs": 14265, "OffsetEndMs": 14925}, {"Word": "space", "OffsetStartMs": 14925, "OffsetEndMs": 15260}], "SpeechSpeed": 14.1}, {"FinalSentence": "With regularization, we are able to achieve this by trying to minimize that regularization term. It's not sufficient to just employ the reconstruction loss alone to achieve this continuity and this completeness.", "SliceSentence": "With regularization we are able to achieve this by trying to minimize that regularization term .It's not sufficient to just employ the reconstruction loss alone to achieve this continuity and this completeness", "StartMs": 1518960, "EndMs": 1535740, "WordsNum": 32, "Words": [{"Word": "With", "OffsetStartMs": 130, "OffsetEndMs": 480}, {"Word": "regularization", "OffsetStartMs": 480, "OffsetEndMs": 1340}, {"Word": "we", "OffsetStartMs": 2650, "OffsetEndMs": 3015}, {"Word": "are", "OffsetStartMs": 3015, "OffsetEndMs": 3285}, {"Word": "able", "OffsetStartMs": 3285, "OffsetEndMs": 3585}, {"Word": "to", "OffsetStartMs": 3585, "OffsetEndMs": 3930}, {"Word": "achieve", "OffsetStartMs": 3930, "OffsetEndMs": 4200}, {"Word": "this", "OffsetStartMs": 4200, "OffsetEndMs": 4500}, {"Word": "by", "OffsetStartMs": 4500, "OffsetEndMs": 4880}, {"Word": "trying", "OffsetStartMs": 5170, "OffsetEndMs": 5505}, {"Word": "to", "OffsetStartMs": 5505, "OffsetEndMs": 5730}, {"Word": "minimize", "OffsetStartMs": 5730, "OffsetEndMs": 6225}, {"Word": "that", "OffsetStartMs": 6225, "OffsetEndMs": 6590}, {"Word": "regularization", "OffsetStartMs": 7510, "OffsetEndMs": 8385}, {"Word": "term", "OffsetStartMs": 8385, "OffsetEndMs": 8700}, {"Word": ".It's", "OffsetStartMs": 8700, "OffsetEndMs": 9000}, {"Word": "not", "OffsetStartMs": 9000, "OffsetEndMs": 9290}, {"Word": "sufficient", "OffsetStartMs": 9310, "OffsetEndMs": 9705}, {"Word": "to", "OffsetStartMs": 9705, "OffsetEndMs": 9975}, {"Word": "just", "OffsetStartMs": 9975, "OffsetEndMs": 10250}, {"Word": "employ", "OffsetStartMs": 10420, "OffsetEndMs": 10820}, {"Word": "the", "OffsetStartMs": 11020, "OffsetEndMs": 11280}, {"Word": "reconstruction", "OffsetStartMs": 11280, "OffsetEndMs": 11925}, {"Word": "loss", "OffsetStartMs": 11925, "OffsetEndMs": 12320}, {"Word": "alone", "OffsetStartMs": 12460, "OffsetEndMs": 12860}, {"Word": "to", "OffsetStartMs": 13150, "OffsetEndMs": 13500}, {"Word": "achieve", "OffsetStartMs": 13500, "OffsetEndMs": 13800}, {"Word": "this", "OffsetStartMs": 13800, "OffsetEndMs": 14150}, {"Word": "continuity", "OffsetStartMs": 14410, "OffsetEndMs": 15105}, {"Word": "and", "OffsetStartMs": 15105, "OffsetEndMs": 15405}, {"Word": "this", "OffsetStartMs": 15405, "OffsetEndMs": 15705}, {"Word": "completeness", "OffsetStartMs": 15705, "OffsetEndMs": 16280}], "SpeechSpeed": 12.4}, {"FinalSentence": "Because of the fact that without regularization, just encoding and reconstructing does not guarantee the properties of continuity and completeness.", "SliceSentence": "Because of the fact that without regularization just encoding and reconstructing does not guarantee the properties of continuity and completeness", "StartMs": 1536480, "EndMs": 1547540, "WordsNum": 20, "Words": [{"Word": "Because", "OffsetStartMs": 250, "OffsetEndMs": 570}, {"Word": "of", "OffsetStartMs": 570, "OffsetEndMs": 765}, {"Word": "the", "OffsetStartMs": 765, "OffsetEndMs": 915}, {"Word": "fact", "OffsetStartMs": 915, "OffsetEndMs": 1170}, {"Word": "that", "OffsetStartMs": 1170, "OffsetEndMs": 1550}, {"Word": "without", "OffsetStartMs": 1720, "OffsetEndMs": 2120}, {"Word": "regularization", "OffsetStartMs": 2140, "OffsetEndMs": 2990}, {"Word": "just", "OffsetStartMs": 3070, "OffsetEndMs": 3465}, {"Word": "encoding", "OffsetStartMs": 3465, "OffsetEndMs": 4230}, {"Word": "and", "OffsetStartMs": 4230, "OffsetEndMs": 4470}, {"Word": "reconstructing", "OffsetStartMs": 4470, "OffsetEndMs": 5390}, {"Word": "does", "OffsetStartMs": 5650, "OffsetEndMs": 5955}, {"Word": "not", "OffsetStartMs": 5955, "OffsetEndMs": 6210}, {"Word": "guarantee", "OffsetStartMs": 6210, "OffsetEndMs": 6560}, {"Word": "the", "OffsetStartMs": 6760, "OffsetEndMs": 7065}, {"Word": "properties", "OffsetStartMs": 7065, "OffsetEndMs": 7370}, {"Word": "of", "OffsetStartMs": 7660, "OffsetEndMs": 8060}, {"Word": "continuity", "OffsetStartMs": 8110, "OffsetEndMs": 8810}, {"Word": "and", "OffsetStartMs": 8920, "OffsetEndMs": 9320}, {"Word": "completeness", "OffsetStartMs": 9340, "OffsetEndMs": 9920}], "SpeechSpeed": 13.1}, {"FinalSentence": "We overcome this.", "SliceSentence": "We overcome this", "StartMs": 1547840, "EndMs": 1550380, "WordsNum": 3, "Words": [{"Word": "We", "OffsetStartMs": 130, "OffsetEndMs": 450}, {"Word": "overcome", "OffsetStartMs": 450, "OffsetEndMs": 770}, {"Word": "this", "OffsetStartMs": 970, "OffsetEndMs": 1370}], "SpeechSpeed": 6.3}, {"FinalSentence": "These issues of having potentially pointed distributions, having discontinuities having disparate means that could end up in the latent space without the effect of regularization.", "SliceSentence": "These issues of having potentially pointed distributions having discontinuities having disparate means that could end up in the latent space without the effect of regularization", "StartMs": 1550460, "EndMs": 1562480, "WordsNum": 25, "Words": [{"Word": "These", "OffsetStartMs": 190, "OffsetEndMs": 510}, {"Word": "issues", "OffsetStartMs": 510, "OffsetEndMs": 830}, {"Word": "of", "OffsetStartMs": 970, "OffsetEndMs": 1370}, {"Word": "having", "OffsetStartMs": 1660, "OffsetEndMs": 2060}, {"Word": "potentially", "OffsetStartMs": 2350, "OffsetEndMs": 2750}, {"Word": "pointed", "OffsetStartMs": 2860, "OffsetEndMs": 3260}, {"Word": "distributions", "OffsetStartMs": 3370, "OffsetEndMs": 3890}, {"Word": "having", "OffsetStartMs": 4450, "OffsetEndMs": 4815}, {"Word": "discontinuities", "OffsetStartMs": 4815, "OffsetEndMs": 5870}, {"Word": "having", "OffsetStartMs": 6130, "OffsetEndMs": 6530}, {"Word": "disparate", "OffsetStartMs": 6580, "OffsetEndMs": 7155}, {"Word": "means", "OffsetStartMs": 7155, "OffsetEndMs": 7410}, {"Word": "that", "OffsetStartMs": 7410, "OffsetEndMs": 7680}, {"Word": "could", "OffsetStartMs": 7680, "OffsetEndMs": 7935}, {"Word": "end", "OffsetStartMs": 7935, "OffsetEndMs": 8190}, {"Word": "up", "OffsetStartMs": 8190, "OffsetEndMs": 8415}, {"Word": "in", "OffsetStartMs": 8415, "OffsetEndMs": 8580}, {"Word": "the", "OffsetStartMs": 8580, "OffsetEndMs": 8700}, {"Word": "latent", "OffsetStartMs": 8700, "OffsetEndMs": 9015}, {"Word": "space", "OffsetStartMs": 9015, "OffsetEndMs": 9270}, {"Word": "without", "OffsetStartMs": 9270, "OffsetEndMs": 9615}, {"Word": "the", "OffsetStartMs": 9615, "OffsetEndMs": 9930}, {"Word": "effect", "OffsetStartMs": 9930, "OffsetEndMs": 10140}, {"Word": "of", "OffsetStartMs": 10140, "OffsetEndMs": 10430}, {"Word": "regularization", "OffsetStartMs": 10480, "OffsetEndMs": 11360}], "SpeechSpeed": 14.7}, {"FinalSentence": "We overcome this by now regularizing the mean and the variance of the encoded latent distributions according to that normal prior.", "SliceSentence": "We overcome this by now regularizing the mean and the variance of the encoded latent distributions according to that normal prior", "StartMs": 1562720, "EndMs": 1574240, "WordsNum": 21, "Words": [{"Word": "We", "OffsetStartMs": 160, "OffsetEndMs": 450}, {"Word": "overcome", "OffsetStartMs": 450, "OffsetEndMs": 740}, {"Word": "this", "OffsetStartMs": 880, "OffsetEndMs": 1215}, {"Word": "by", "OffsetStartMs": 1215, "OffsetEndMs": 1485}, {"Word": "now", "OffsetStartMs": 1485, "OffsetEndMs": 1820}, {"Word": "regularizing", "OffsetStartMs": 2260, "OffsetEndMs": 3050}, {"Word": "the", "OffsetStartMs": 3400, "OffsetEndMs": 3690}, {"Word": "mean", "OffsetStartMs": 3690, "OffsetEndMs": 3975}, {"Word": "and", "OffsetStartMs": 3975, "OffsetEndMs": 4275}, {"Word": "the", "OffsetStartMs": 4275, "OffsetEndMs": 4455}, {"Word": "variance", "OffsetStartMs": 4455, "OffsetEndMs": 4995}, {"Word": "of", "OffsetStartMs": 4995, "OffsetEndMs": 5360}, {"Word": "the", "OffsetStartMs": 5650, "OffsetEndMs": 6050}, {"Word": "encoded", "OffsetStartMs": 6760, "OffsetEndMs": 7485}, {"Word": "latent", "OffsetStartMs": 7485, "OffsetEndMs": 7890}, {"Word": "distributions", "OffsetStartMs": 7890, "OffsetEndMs": 8360}, {"Word": "according", "OffsetStartMs": 9010, "OffsetEndMs": 9410}, {"Word": "to", "OffsetStartMs": 9520, "OffsetEndMs": 9795}, {"Word": "that", "OffsetStartMs": 9795, "OffsetEndMs": 9990}, {"Word": "normal", "OffsetStartMs": 9990, "OffsetEndMs": 10305}, {"Word": "prior", "OffsetStartMs": 10305, "OffsetEndMs": 10700}], "SpeechSpeed": 11.2}, {"FinalSentence": "What this allows is for the learned distributions of those latent variables to effectively overlap in the latent space, because everything is regularized to have, according to this prior, of mean zero, standard deviation one, and that centers the means.", "SliceSentence": "What this allows is for the learned distributions of those latent variables to effectively overlap in the latent space because everything is regularized to have according to this prior of mean zero standard deviation one and that centers the means", "StartMs": 1574340, "EndMs": 1591940, "WordsNum": 40, "Words": [{"Word": "What", "OffsetStartMs": 100, "OffsetEndMs": 390}, {"Word": "this", "OffsetStartMs": 390, "OffsetEndMs": 615}, {"Word": "allows", "OffsetStartMs": 615, "OffsetEndMs": 950}, {"Word": "is", "OffsetStartMs": 1180, "OffsetEndMs": 1500}, {"Word": "for", "OffsetStartMs": 1500, "OffsetEndMs": 1695}, {"Word": "the", "OffsetStartMs": 1695, "OffsetEndMs": 1860}, {"Word": "learned", "OffsetStartMs": 1860, "OffsetEndMs": 2150}, {"Word": "distributions", "OffsetStartMs": 2530, "OffsetEndMs": 3050}, {"Word": "of", "OffsetStartMs": 3130, "OffsetEndMs": 3450}, {"Word": "those", "OffsetStartMs": 3450, "OffsetEndMs": 3690}, {"Word": "latent", "OffsetStartMs": 3690, "OffsetEndMs": 4050}, {"Word": "variables", "OffsetStartMs": 4050, "OffsetEndMs": 4640}, {"Word": "to", "OffsetStartMs": 4870, "OffsetEndMs": 5235}, {"Word": "effectively", "OffsetStartMs": 5235, "OffsetEndMs": 5600}, {"Word": "overlap", "OffsetStartMs": 5800, "OffsetEndMs": 6570}, {"Word": "in", "OffsetStartMs": 6570, "OffsetEndMs": 6840}, {"Word": "the", "OffsetStartMs": 6840, "OffsetEndMs": 6990}, {"Word": "latent", "OffsetStartMs": 6990, "OffsetEndMs": 7320}, {"Word": "space", "OffsetStartMs": 7320, "OffsetEndMs": 7640}, {"Word": "because", "OffsetStartMs": 8050, "OffsetEndMs": 8450}, {"Word": "everything", "OffsetStartMs": 8680, "OffsetEndMs": 8985}, {"Word": "is", "OffsetStartMs": 8985, "OffsetEndMs": 9195}, {"Word": "regularized", "OffsetStartMs": 9195, "OffsetEndMs": 9855}, {"Word": "to", "OffsetStartMs": 9855, "OffsetEndMs": 10125}, {"Word": "have", "OffsetStartMs": 10125, "OffsetEndMs": 10430}, {"Word": "according", "OffsetStartMs": 11110, "OffsetEndMs": 11490}, {"Word": "to", "OffsetStartMs": 11490, "OffsetEndMs": 11730}, {"Word": "this", "OffsetStartMs": 11730, "OffsetEndMs": 11910}, {"Word": "prior", "OffsetStartMs": 11910, "OffsetEndMs": 12210}, {"Word": "of", "OffsetStartMs": 12210, "OffsetEndMs": 12510}, {"Word": "mean", "OffsetStartMs": 12510, "OffsetEndMs": 12780}, {"Word": "zero", "OffsetStartMs": 12780, "OffsetEndMs": 13130}, {"Word": "standard", "OffsetStartMs": 13360, "OffsetEndMs": 13740}, {"Word": "deviation", "OffsetStartMs": 13740, "OffsetEndMs": 14265}, {"Word": "one", "OffsetStartMs": 14265, "OffsetEndMs": 14660}, {"Word": "and", "OffsetStartMs": 15310, "OffsetEndMs": 15600}, {"Word": "that", "OffsetStartMs": 15600, "OffsetEndMs": 15855}, {"Word": "centers", "OffsetStartMs": 15855, "OffsetEndMs": 16215}, {"Word": "the", "OffsetStartMs": 16215, "OffsetEndMs": 16470}, {"Word": "means", "OffsetStartMs": 16470, "OffsetEndMs": 16730}], "SpeechSpeed": 14.0}, {"FinalSentence": "Regularizes the variances for each of those independent latent variable distributions.", "SliceSentence": "Regularizes the variances for each of those independent latent variable distributions", "StartMs": 1591940, "EndMs": 1598480, "WordsNum": 11, "Words": [{"Word": "Regularizes", "OffsetStartMs": 0, "OffsetEndMs": 765}, {"Word": "the", "OffsetStartMs": 765, "OffsetEndMs": 1020}, {"Word": "variances", "OffsetStartMs": 1020, "OffsetEndMs": 1730}, {"Word": "for", "OffsetStartMs": 1780, "OffsetEndMs": 2100}, {"Word": "each", "OffsetStartMs": 2100, "OffsetEndMs": 2415}, {"Word": "of", "OffsetStartMs": 2415, "OffsetEndMs": 2760}, {"Word": "those", "OffsetStartMs": 2760, "OffsetEndMs": 3110}, {"Word": "independent", "OffsetStartMs": 3520, "OffsetEndMs": 3920}, {"Word": "latent", "OffsetStartMs": 4000, "OffsetEndMs": 4530}, {"Word": "variable", "OffsetStartMs": 4530, "OffsetEndMs": 4850}, {"Word": "distributions", "OffsetStartMs": 5110, "OffsetEndMs": 5630}], "SpeechSpeed": 13.0}, {"FinalSentence": "Together, the effect of this regularization in net is that we can achieve continuity and completeness in the latent space. Points and distances that are close should correspond to similar reconstructions that we get out.", "SliceSentence": "Together the effect of this regularization in net is that we can achieve continuity and completeness in the latent space . Pointsand distances that are close should correspond to similar reconstructions that we get out", "StartMs": 1598680, "EndMs": 1614360, "WordsNum": 35, "Words": [{"Word": "Together", "OffsetStartMs": 250, "OffsetEndMs": 650}, {"Word": "the", "OffsetStartMs": 850, "OffsetEndMs": 1215}, {"Word": "effect", "OffsetStartMs": 1215, "OffsetEndMs": 1580}, {"Word": "of", "OffsetStartMs": 1660, "OffsetEndMs": 1950}, {"Word": "this", "OffsetStartMs": 1950, "OffsetEndMs": 2145}, {"Word": "regularization", "OffsetStartMs": 2145, "OffsetEndMs": 2930}, {"Word": "in", "OffsetStartMs": 2950, "OffsetEndMs": 3285}, {"Word": "net", "OffsetStartMs": 3285, "OffsetEndMs": 3620}, {"Word": "is", "OffsetStartMs": 4030, "OffsetEndMs": 4305}, {"Word": "that", "OffsetStartMs": 4305, "OffsetEndMs": 4470}, {"Word": "we", "OffsetStartMs": 4470, "OffsetEndMs": 4635}, {"Word": "can", "OffsetStartMs": 4635, "OffsetEndMs": 4890}, {"Word": "achieve", "OffsetStartMs": 4890, "OffsetEndMs": 5270}, {"Word": "continuity", "OffsetStartMs": 5500, "OffsetEndMs": 6090}, {"Word": "and", "OffsetStartMs": 6090, "OffsetEndMs": 6375}, {"Word": "completeness", "OffsetStartMs": 6375, "OffsetEndMs": 6900}, {"Word": "in", "OffsetStartMs": 6900, "OffsetEndMs": 7125}, {"Word": "the", "OffsetStartMs": 7125, "OffsetEndMs": 7260}, {"Word": "latent", "OffsetStartMs": 7260, "OffsetEndMs": 7590}, {"Word": "space", "OffsetStartMs": 7590, "OffsetEndMs": 7910}, {"Word": ".", "OffsetStartMs": 8800, "OffsetEndMs": 9150}, {"Word": "Pointsand", "OffsetStartMs": 9150, "OffsetEndMs": 9390}, {"Word": "distances", "OffsetStartMs": 9390, "OffsetEndMs": 9945}, {"Word": "that", "OffsetStartMs": 9945, "OffsetEndMs": 10065}, {"Word": "are", "OffsetStartMs": 10065, "OffsetEndMs": 10230}, {"Word": "close", "OffsetStartMs": 10230, "OffsetEndMs": 10550}, {"Word": "should", "OffsetStartMs": 11170, "OffsetEndMs": 11490}, {"Word": "correspond", "OffsetStartMs": 11490, "OffsetEndMs": 11810}, {"Word": "to", "OffsetStartMs": 11950, "OffsetEndMs": 12240}, {"Word": "similar", "OffsetStartMs": 12240, "OffsetEndMs": 12525}, {"Word": "reconstructions", "OffsetStartMs": 12525, "OffsetEndMs": 13490}, {"Word": "that", "OffsetStartMs": 13690, "OffsetEndMs": 14090}, {"Word": "we", "OffsetStartMs": 14230, "OffsetEndMs": 14505}, {"Word": "get", "OffsetStartMs": 14505, "OffsetEndMs": 14730}, {"Word": "out", "OffsetStartMs": 14730, "OffsetEndMs": 15080}], "SpeechSpeed": 13.8}, {"FinalSentence": "So hopefully this gets at some of the intuition behind the idea of the ve behind the idea of the regularization and trying to enforce the structured normal prior on the latent space.", "SliceSentence": "So hopefully this gets at some of the intuition behind the idea of the ve behind the idea of the regularization and trying to enforce the structured normal prior on the latent space", "StartMs": 1614880, "EndMs": 1628160, "WordsNum": 33, "Words": [{"Word": "So", "OffsetStartMs": 160, "OffsetEndMs": 560}, {"Word": "hopefully", "OffsetStartMs": 700, "OffsetEndMs": 1100}, {"Word": "this", "OffsetStartMs": 1210, "OffsetEndMs": 1610}, {"Word": "gets", "OffsetStartMs": 1990, "OffsetEndMs": 2295}, {"Word": "at", "OffsetStartMs": 2295, "OffsetEndMs": 2520}, {"Word": "some", "OffsetStartMs": 2520, "OffsetEndMs": 2790}, {"Word": "of", "OffsetStartMs": 2790, "OffsetEndMs": 3030}, {"Word": "the", "OffsetStartMs": 3030, "OffsetEndMs": 3165}, {"Word": "intuition", "OffsetStartMs": 3165, "OffsetEndMs": 3680}, {"Word": "behind", "OffsetStartMs": 3910, "OffsetEndMs": 4275}, {"Word": "the", "OffsetStartMs": 4275, "OffsetEndMs": 4590}, {"Word": "idea", "OffsetStartMs": 4590, "OffsetEndMs": 4845}, {"Word": "of", "OffsetStartMs": 4845, "OffsetEndMs": 5010}, {"Word": "the", "OffsetStartMs": 5010, "OffsetEndMs": 5145}, {"Word": "ve", "OffsetStartMs": 5145, "OffsetEndMs": 5660}, {"Word": "behind", "OffsetStartMs": 6040, "OffsetEndMs": 6360}, {"Word": "the", "OffsetStartMs": 6360, "OffsetEndMs": 6645}, {"Word": "idea", "OffsetStartMs": 6645, "OffsetEndMs": 6900}, {"Word": "of", "OffsetStartMs": 6900, "OffsetEndMs": 7065}, {"Word": "the", "OffsetStartMs": 7065, "OffsetEndMs": 7185}, {"Word": "regularization", "OffsetStartMs": 7185, "OffsetEndMs": 7940}, {"Word": "and", "OffsetStartMs": 8260, "OffsetEndMs": 8610}, {"Word": "trying", "OffsetStartMs": 8610, "OffsetEndMs": 8910}, {"Word": "to", "OffsetStartMs": 8910, "OffsetEndMs": 9210}, {"Word": "enforce", "OffsetStartMs": 9210, "OffsetEndMs": 9560}, {"Word": "the", "OffsetStartMs": 9610, "OffsetEndMs": 9930}, {"Word": "structured", "OffsetStartMs": 9930, "OffsetEndMs": 10520}, {"Word": "normal", "OffsetStartMs": 10600, "OffsetEndMs": 11000}, {"Word": "prior", "OffsetStartMs": 11080, "OffsetEndMs": 11480}, {"Word": "on", "OffsetStartMs": 11530, "OffsetEndMs": 11820}, {"Word": "the", "OffsetStartMs": 11820, "OffsetEndMs": 11985}, {"Word": "latent", "OffsetStartMs": 11985, "OffsetEndMs": 12315}, {"Word": "space", "OffsetStartMs": 12315, "OffsetEndMs": 12620}], "SpeechSpeed": 13.6}, {"FinalSentence": "With this in hand, with the two components of our loss function reconstructing the inputs regularizing learning to try to achieve continuity and completeness, we can now think about how we define a forward pass through the network, going from an input example and being able to decode and sample from the latent variables to look at new examples.", "SliceSentence": "With this in hand with the two components of our loss function reconstructing the inputs regularizing learning to try to achieve continuity and completeness we can now think about how we define a forward pass through the network going from an input example and being able to decode and sample from the latent variables to look at new examples", "StartMs": 1629400, "EndMs": 1652480, "WordsNum": 59, "Words": [{"Word": "With", "OffsetStartMs": 100, "OffsetEndMs": 405}, {"Word": "this", "OffsetStartMs": 405, "OffsetEndMs": 600}, {"Word": "in", "OffsetStartMs": 600, "OffsetEndMs": 780}, {"Word": "hand", "OffsetStartMs": 780, "OffsetEndMs": 1070}, {"Word": "with", "OffsetStartMs": 1240, "OffsetEndMs": 1545}, {"Word": "the", "OffsetStartMs": 1545, "OffsetEndMs": 1770}, {"Word": "two", "OffsetStartMs": 1770, "OffsetEndMs": 2055}, {"Word": "components", "OffsetStartMs": 2055, "OffsetEndMs": 2385}, {"Word": "of", "OffsetStartMs": 2385, "OffsetEndMs": 2595}, {"Word": "our", "OffsetStartMs": 2595, "OffsetEndMs": 2730}, {"Word": "loss", "OffsetStartMs": 2730, "OffsetEndMs": 2970}, {"Word": "function", "OffsetStartMs": 2970, "OffsetEndMs": 3320}, {"Word": "reconstructing", "OffsetStartMs": 3970, "OffsetEndMs": 4830}, {"Word": "the", "OffsetStartMs": 4830, "OffsetEndMs": 5070}, {"Word": "inputs", "OffsetStartMs": 5070, "OffsetEndMs": 5600}, {"Word": "regularizing", "OffsetStartMs": 5830, "OffsetEndMs": 6680}, {"Word": "learning", "OffsetStartMs": 6730, "OffsetEndMs": 7130}, {"Word": "to", "OffsetStartMs": 7180, "OffsetEndMs": 7470}, {"Word": "try", "OffsetStartMs": 7470, "OffsetEndMs": 7650}, {"Word": "to", "OffsetStartMs": 7650, "OffsetEndMs": 7905}, {"Word": "achieve", "OffsetStartMs": 7905, "OffsetEndMs": 8270}, {"Word": "continuity", "OffsetStartMs": 8410, "OffsetEndMs": 9015}, {"Word": "and", "OffsetStartMs": 9015, "OffsetEndMs": 9285}, {"Word": "completeness", "OffsetStartMs": 9285, "OffsetEndMs": 9860}, {"Word": "we", "OffsetStartMs": 10360, "OffsetEndMs": 10635}, {"Word": "can", "OffsetStartMs": 10635, "OffsetEndMs": 10785}, {"Word": "now", "OffsetStartMs": 10785, "OffsetEndMs": 11060}, {"Word": "think", "OffsetStartMs": 11380, "OffsetEndMs": 11700}, {"Word": "about", "OffsetStartMs": 11700, "OffsetEndMs": 12020}, {"Word": "how", "OffsetStartMs": 12160, "OffsetEndMs": 12465}, {"Word": "we", "OffsetStartMs": 12465, "OffsetEndMs": 12735}, {"Word": "define", "OffsetStartMs": 12735, "OffsetEndMs": 13020}, {"Word": "a", "OffsetStartMs": 13020, "OffsetEndMs": 13245}, {"Word": "forward", "OffsetStartMs": 13245, "OffsetEndMs": 13545}, {"Word": "pass", "OffsetStartMs": 13545, "OffsetEndMs": 13890}, {"Word": "through", "OffsetStartMs": 13890, "OffsetEndMs": 14100}, {"Word": "the", "OffsetStartMs": 14100, "OffsetEndMs": 14220}, {"Word": "network", "OffsetStartMs": 14220, "OffsetEndMs": 14480}, {"Word": "going", "OffsetStartMs": 14950, "OffsetEndMs": 15345}, {"Word": "from", "OffsetStartMs": 15345, "OffsetEndMs": 15720}, {"Word": "an", "OffsetStartMs": 15720, "OffsetEndMs": 16100}, {"Word": "input", "OffsetStartMs": 16120, "OffsetEndMs": 16470}, {"Word": "example", "OffsetStartMs": 16470, "OffsetEndMs": 16820}, {"Word": "and", "OffsetStartMs": 17380, "OffsetEndMs": 17685}, {"Word": "being", "OffsetStartMs": 17685, "OffsetEndMs": 17910}, {"Word": "able", "OffsetStartMs": 17910, "OffsetEndMs": 18195}, {"Word": "to", "OffsetStartMs": 18195, "OffsetEndMs": 18450}, {"Word": "decode", "OffsetStartMs": 18450, "OffsetEndMs": 18975}, {"Word": "and", "OffsetStartMs": 18975, "OffsetEndMs": 19170}, {"Word": "sample", "OffsetStartMs": 19170, "OffsetEndMs": 19485}, {"Word": "from", "OffsetStartMs": 19485, "OffsetEndMs": 19770}, {"Word": "the", "OffsetStartMs": 19770, "OffsetEndMs": 19920}, {"Word": "latent", "OffsetStartMs": 19920, "OffsetEndMs": 20205}, {"Word": "variables", "OffsetStartMs": 20205, "OffsetEndMs": 20780}, {"Word": "to", "OffsetStartMs": 20950, "OffsetEndMs": 21225}, {"Word": "look", "OffsetStartMs": 21225, "OffsetEndMs": 21420}, {"Word": "at", "OffsetStartMs": 21420, "OffsetEndMs": 21675}, {"Word": "new", "OffsetStartMs": 21675, "OffsetEndMs": 21990}, {"Word": "examples", "OffsetStartMs": 21990, "OffsetEndMs": 22370}], "SpeechSpeed": 14.8}, {"FinalSentence": "Our last critical step is how the actual back propagation training algorithm is defined and how we achieve this.", "SliceSentence": "Our last critical step is how the actual back propagation training algorithm is defined and how we achieve this", "StartMs": 1652900, "EndMs": 1660420, "WordsNum": 19, "Words": [{"Word": "Our", "OffsetStartMs": 70, "OffsetEndMs": 375}, {"Word": "last", "OffsetStartMs": 375, "OffsetEndMs": 645}, {"Word": "critical", "OffsetStartMs": 645, "OffsetEndMs": 1010}, {"Word": "step", "OffsetStartMs": 1030, "OffsetEndMs": 1365}, {"Word": "is", "OffsetStartMs": 1365, "OffsetEndMs": 1605}, {"Word": "how", "OffsetStartMs": 1605, "OffsetEndMs": 1830}, {"Word": "the", "OffsetStartMs": 1830, "OffsetEndMs": 2145}, {"Word": "actual", "OffsetStartMs": 2145, "OffsetEndMs": 2460}, {"Word": "back", "OffsetStartMs": 2460, "OffsetEndMs": 2745}, {"Word": "propagation", "OffsetStartMs": 2745, "OffsetEndMs": 3380}, {"Word": "training", "OffsetStartMs": 3790, "OffsetEndMs": 4190}, {"Word": "algorithm", "OffsetStartMs": 4390, "OffsetEndMs": 4845}, {"Word": "is", "OffsetStartMs": 4845, "OffsetEndMs": 5145}, {"Word": "defined", "OffsetStartMs": 5145, "OffsetEndMs": 5510}, {"Word": "and", "OffsetStartMs": 5560, "OffsetEndMs": 5865}, {"Word": "how", "OffsetStartMs": 5865, "OffsetEndMs": 6075}, {"Word": "we", "OffsetStartMs": 6075, "OffsetEndMs": 6315}, {"Word": "achieve", "OffsetStartMs": 6315, "OffsetEndMs": 6555}, {"Word": "this", "OffsetStartMs": 6555, "OffsetEndMs": 6860}], "SpeechSpeed": 14.8}, {"FinalSentence": "The key, as I introduce with ves is this notion of randomness of sampling that we have introduced by defining these probability distributions over each of the latent variables.", "SliceSentence": "The key as I introduce with ves is this notion of randomness of sampling that we have introduced by defining these probability distributions over each of the latent variables", "StartMs": 1661020, "EndMs": 1672880, "WordsNum": 29, "Words": [{"Word": "The", "OffsetStartMs": 40, "OffsetEndMs": 360}, {"Word": "key", "OffsetStartMs": 360, "OffsetEndMs": 660}, {"Word": "as", "OffsetStartMs": 660, "OffsetEndMs": 915}, {"Word": "I", "OffsetStartMs": 915, "OffsetEndMs": 1190}, {"Word": "introduce", "OffsetStartMs": 1210, "OffsetEndMs": 1530}, {"Word": "with", "OffsetStartMs": 1530, "OffsetEndMs": 1755}, {"Word": "ves", "OffsetStartMs": 1755, "OffsetEndMs": 2205}, {"Word": "is", "OffsetStartMs": 2205, "OffsetEndMs": 2460}, {"Word": "this", "OffsetStartMs": 2460, "OffsetEndMs": 2670}, {"Word": "notion", "OffsetStartMs": 2670, "OffsetEndMs": 2990}, {"Word": "of", "OffsetStartMs": 3010, "OffsetEndMs": 3345}, {"Word": "randomness", "OffsetStartMs": 3345, "OffsetEndMs": 3975}, {"Word": "of", "OffsetStartMs": 3975, "OffsetEndMs": 4245}, {"Word": "sampling", "OffsetStartMs": 4245, "OffsetEndMs": 4850}, {"Word": "that", "OffsetStartMs": 5200, "OffsetEndMs": 5505}, {"Word": "we", "OffsetStartMs": 5505, "OffsetEndMs": 5790}, {"Word": "have", "OffsetStartMs": 5790, "OffsetEndMs": 6170}, {"Word": "introduced", "OffsetStartMs": 6250, "OffsetEndMs": 6615}, {"Word": "by", "OffsetStartMs": 6615, "OffsetEndMs": 6960}, {"Word": "defining", "OffsetStartMs": 6960, "OffsetEndMs": 7455}, {"Word": "these", "OffsetStartMs": 7455, "OffsetEndMs": 7665}, {"Word": "probability", "OffsetStartMs": 7665, "OffsetEndMs": 8240}, {"Word": "distributions", "OffsetStartMs": 8410, "OffsetEndMs": 8930}, {"Word": "over", "OffsetStartMs": 9400, "OffsetEndMs": 9800}, {"Word": "each", "OffsetStartMs": 9820, "OffsetEndMs": 10110}, {"Word": "of", "OffsetStartMs": 10110, "OffsetEndMs": 10260}, {"Word": "the", "OffsetStartMs": 10260, "OffsetEndMs": 10380}, {"Word": "latent", "OffsetStartMs": 10380, "OffsetEndMs": 10710}, {"Word": "variables", "OffsetStartMs": 10710, "OffsetEndMs": 11270}], "SpeechSpeed": 14.7}, {"FinalSentence": "The problem this gives us is that we cannot back propagate directly through anything that has an element of sampling anything that has an element of randomness.", "SliceSentence": "The problem this gives us is that we cannot back propagate directly through anything that has an element of sampling anything that has an element of randomness", "StartMs": 1673320, "EndMs": 1684240, "WordsNum": 27, "Words": [{"Word": "The", "OffsetStartMs": 70, "OffsetEndMs": 390}, {"Word": "problem", "OffsetStartMs": 390, "OffsetEndMs": 705}, {"Word": "this", "OffsetStartMs": 705, "OffsetEndMs": 1020}, {"Word": "gives", "OffsetStartMs": 1020, "OffsetEndMs": 1245}, {"Word": "us", "OffsetStartMs": 1245, "OffsetEndMs": 1550}, {"Word": "is", "OffsetStartMs": 1570, "OffsetEndMs": 1860}, {"Word": "that", "OffsetStartMs": 1860, "OffsetEndMs": 2055}, {"Word": "we", "OffsetStartMs": 2055, "OffsetEndMs": 2310}, {"Word": "cannot", "OffsetStartMs": 2310, "OffsetEndMs": 2660}, {"Word": "back", "OffsetStartMs": 3040, "OffsetEndMs": 3405}, {"Word": "propagate", "OffsetStartMs": 3405, "OffsetEndMs": 4040}, {"Word": "directly", "OffsetStartMs": 4150, "OffsetEndMs": 4550}, {"Word": "through", "OffsetStartMs": 4990, "OffsetEndMs": 5390}, {"Word": "anything", "OffsetStartMs": 5560, "OffsetEndMs": 5850}, {"Word": "that", "OffsetStartMs": 5850, "OffsetEndMs": 6030}, {"Word": "has", "OffsetStartMs": 6030, "OffsetEndMs": 6270}, {"Word": "an", "OffsetStartMs": 6270, "OffsetEndMs": 6510}, {"Word": "element", "OffsetStartMs": 6510, "OffsetEndMs": 6795}, {"Word": "of", "OffsetStartMs": 6795, "OffsetEndMs": 7095}, {"Word": "sampling", "OffsetStartMs": 7095, "OffsetEndMs": 7640}, {"Word": "anything", "OffsetStartMs": 7960, "OffsetEndMs": 8235}, {"Word": "that", "OffsetStartMs": 8235, "OffsetEndMs": 8400}, {"Word": "has", "OffsetStartMs": 8400, "OffsetEndMs": 8670}, {"Word": "an", "OffsetStartMs": 8670, "OffsetEndMs": 8925}, {"Word": "element", "OffsetStartMs": 8925, "OffsetEndMs": 9200}, {"Word": "of", "OffsetStartMs": 9370, "OffsetEndMs": 9645}, {"Word": "randomness", "OffsetStartMs": 9645, "OffsetEndMs": 10310}], "SpeechSpeed": 14.6}, {"FinalSentence": "Back propagation requires completely deterministic nodes, deterministic layers to be able to successfully apply gradient descent and the back propagation algorithm.", "SliceSentence": "Back propagation requires completely deterministic nodes deterministic layers to be able to successfully apply gradient descent and the back propagation algorithm", "StartMs": 1685000, "EndMs": 1696580, "WordsNum": 21, "Words": [{"Word": "Back", "OffsetStartMs": 220, "OffsetEndMs": 555}, {"Word": "propagation", "OffsetStartMs": 555, "OffsetEndMs": 1190}, {"Word": "requires", "OffsetStartMs": 1420, "OffsetEndMs": 1820}, {"Word": "completely", "OffsetStartMs": 2020, "OffsetEndMs": 2420}, {"Word": "deterministic", "OffsetStartMs": 2740, "OffsetEndMs": 3510}, {"Word": "nodes", "OffsetStartMs": 3510, "OffsetEndMs": 4020}, {"Word": "deterministic", "OffsetStartMs": 4020, "OffsetEndMs": 4695}, {"Word": "layers", "OffsetStartMs": 4695, "OffsetEndMs": 5180}, {"Word": "to", "OffsetStartMs": 5290, "OffsetEndMs": 5535}, {"Word": "be", "OffsetStartMs": 5535, "OffsetEndMs": 5685}, {"Word": "able", "OffsetStartMs": 5685, "OffsetEndMs": 5990}, {"Word": "to", "OffsetStartMs": 6070, "OffsetEndMs": 6470}, {"Word": "successfully", "OffsetStartMs": 6760, "OffsetEndMs": 7160}, {"Word": "apply", "OffsetStartMs": 7630, "OffsetEndMs": 8030}, {"Word": "gradient", "OffsetStartMs": 8050, "OffsetEndMs": 8550}, {"Word": "descent", "OffsetStartMs": 8550, "OffsetEndMs": 8990}, {"Word": "and", "OffsetStartMs": 9100, "OffsetEndMs": 9390}, {"Word": "the", "OffsetStartMs": 9390, "OffsetEndMs": 9540}, {"Word": "back", "OffsetStartMs": 9540, "OffsetEndMs": 9735}, {"Word": "propagation", "OffsetStartMs": 9735, "OffsetEndMs": 10340}, {"Word": "algorithm", "OffsetStartMs": 10480, "OffsetEndMs": 11030}], "SpeechSpeed": 14.0}, {"FinalSentence": "The breakthrough idea that enabled va to be trained completely end to end was this idea of re-parameterriization within that sampling layer.", "SliceSentence": "The breakthrough idea that enabled va to be trained completely end to end was this idea of re -parameterriization within that sampling layer", "StartMs": 1697700, "EndMs": 1708740, "WordsNum": 23, "Words": [{"Word": "The", "OffsetStartMs": 100, "OffsetEndMs": 390}, {"Word": "breakthrough", "OffsetStartMs": 390, "OffsetEndMs": 930}, {"Word": "idea", "OffsetStartMs": 930, "OffsetEndMs": 1245}, {"Word": "that", "OffsetStartMs": 1245, "OffsetEndMs": 1440}, {"Word": "enabled", "OffsetStartMs": 1440, "OffsetEndMs": 1880}, {"Word": "va", "OffsetStartMs": 1960, "OffsetEndMs": 2415}, {"Word": "to", "OffsetStartMs": 2415, "OffsetEndMs": 2655}, {"Word": "be", "OffsetStartMs": 2655, "OffsetEndMs": 2835}, {"Word": "trained", "OffsetStartMs": 2835, "OffsetEndMs": 3170}, {"Word": "completely", "OffsetStartMs": 3310, "OffsetEndMs": 3690}, {"Word": "end", "OffsetStartMs": 3690, "OffsetEndMs": 3975}, {"Word": "to", "OffsetStartMs": 3975, "OffsetEndMs": 4140}, {"Word": "end", "OffsetStartMs": 4140, "OffsetEndMs": 4400}, {"Word": "was", "OffsetStartMs": 4840, "OffsetEndMs": 5145}, {"Word": "this", "OffsetStartMs": 5145, "OffsetEndMs": 5445}, {"Word": "idea", "OffsetStartMs": 5445, "OffsetEndMs": 5805}, {"Word": "of", "OffsetStartMs": 5805, "OffsetEndMs": 6170}, {"Word": "re", "OffsetStartMs": 6310, "OffsetEndMs": 6710}, {"Word": "-parameterriization", "OffsetStartMs": 6730, "OffsetEndMs": 7730}, {"Word": "within", "OffsetStartMs": 8890, "OffsetEndMs": 9255}, {"Word": "that", "OffsetStartMs": 9255, "OffsetEndMs": 9540}, {"Word": "sampling", "OffsetStartMs": 9540, "OffsetEndMs": 10005}, {"Word": "layer", "OffsetStartMs": 10005, "OffsetEndMs": 10310}], "SpeechSpeed": 12.6}, {"FinalSentence": "And I'll give you the key idea about how this operation works. It's actually really quite level.", "SliceSentence": "And I'll give you the key idea about how this operation works .It's actually really quite level", "StartMs": 1708760, "EndMs": 1714400, "WordsNum": 17, "Words": [{"Word": "And", "OffsetStartMs": 100, "OffsetEndMs": 500}, {"Word": "I'll", "OffsetStartMs": 580, "OffsetEndMs": 945}, {"Word": "give", "OffsetStartMs": 945, "OffsetEndMs": 1050}, {"Word": "you", "OffsetStartMs": 1050, "OffsetEndMs": 1185}, {"Word": "the", "OffsetStartMs": 1185, "OffsetEndMs": 1365}, {"Word": "key", "OffsetStartMs": 1365, "OffsetEndMs": 1670}, {"Word": "idea", "OffsetStartMs": 1690, "OffsetEndMs": 2090}, {"Word": "about", "OffsetStartMs": 2140, "OffsetEndMs": 2475}, {"Word": "how", "OffsetStartMs": 2475, "OffsetEndMs": 2715}, {"Word": "this", "OffsetStartMs": 2715, "OffsetEndMs": 3020}, {"Word": "operation", "OffsetStartMs": 3040, "OffsetEndMs": 3390}, {"Word": "works", "OffsetStartMs": 3390, "OffsetEndMs": 3675}, {"Word": ".It's", "OffsetStartMs": 3675, "OffsetEndMs": 4035}, {"Word": "actually", "OffsetStartMs": 4035, "OffsetEndMs": 4275}, {"Word": "really", "OffsetStartMs": 4275, "OffsetEndMs": 4530}, {"Word": "quite", "OffsetStartMs": 4530, "OffsetEndMs": 4785}, {"Word": "level", "OffsetStartMs": 4785, "OffsetEndMs": 5090}], "SpeechSpeed": 16.7}, {"FinalSentence": "Quite clever.", "SliceSentence": "Quite clever", "StartMs": 1714400, "EndMs": 1715940, "WordsNum": 2, "Words": [{"Word": "Quite", "OffsetStartMs": 0, "OffsetEndMs": 315}, {"Word": "clever", "OffsetStartMs": 315, "OffsetEndMs": 680}], "SpeechSpeed": 7.8}, {"FinalSentence": "So, as I said, when we have a notion of randomness of probability, we can't sample directly through that layer.", "SliceSentence": "So as I said when we have a notion of randomness of probability we can't sample directly through that layer", "StartMs": 1716140, "EndMs": 1724880, "WordsNum": 20, "Words": [{"Word": "So", "OffsetStartMs": 130, "OffsetEndMs": 530}, {"Word": "as", "OffsetStartMs": 670, "OffsetEndMs": 960}, {"Word": "I", "OffsetStartMs": 960, "OffsetEndMs": 1140}, {"Word": "said", "OffsetStartMs": 1140, "OffsetEndMs": 1430}, {"Word": "when", "OffsetStartMs": 1540, "OffsetEndMs": 1830}, {"Word": "we", "OffsetStartMs": 1830, "OffsetEndMs": 2010}, {"Word": "have", "OffsetStartMs": 2010, "OffsetEndMs": 2295}, {"Word": "a", "OffsetStartMs": 2295, "OffsetEndMs": 2690}, {"Word": "notion", "OffsetStartMs": 2770, "OffsetEndMs": 3120}, {"Word": "of", "OffsetStartMs": 3120, "OffsetEndMs": 3345}, {"Word": "randomness", "OffsetStartMs": 3345, "OffsetEndMs": 3855}, {"Word": "of", "OffsetStartMs": 3855, "OffsetEndMs": 4050}, {"Word": "probability", "OffsetStartMs": 4050, "OffsetEndMs": 4580}, {"Word": "we", "OffsetStartMs": 5170, "OffsetEndMs": 5520}, {"Word": "can't", "OffsetStartMs": 5520, "OffsetEndMs": 5925}, {"Word": "sample", "OffsetStartMs": 5925, "OffsetEndMs": 6230}, {"Word": "directly", "OffsetStartMs": 6370, "OffsetEndMs": 6770}, {"Word": "through", "OffsetStartMs": 6940, "OffsetEndMs": 7335}, {"Word": "that", "OffsetStartMs": 7335, "OffsetEndMs": 7665}, {"Word": "layer", "OffsetStartMs": 7665, "OffsetEndMs": 8000}], "SpeechSpeed": 12.2}, {"FinalSentence": "Instead, with parameterriization, what we do is we redefine how a latent variable vector is sampled.", "SliceSentence": "Instead with parameterriization what we do is we redefine how a latent variable vector is sampled", "StartMs": 1725400, "EndMs": 1734040, "WordsNum": 16, "Words": [{"Word": "Instead", "OffsetStartMs": 400, "OffsetEndMs": 795}, {"Word": "with", "OffsetStartMs": 795, "OffsetEndMs": 1190}, {"Word": "parameterriization", "OffsetStartMs": 1270, "OffsetEndMs": 2210}, {"Word": "what", "OffsetStartMs": 2560, "OffsetEndMs": 2835}, {"Word": "we", "OffsetStartMs": 2835, "OffsetEndMs": 3015}, {"Word": "do", "OffsetStartMs": 3015, "OffsetEndMs": 3320}, {"Word": "is", "OffsetStartMs": 3700, "OffsetEndMs": 4005}, {"Word": "we", "OffsetStartMs": 4005, "OffsetEndMs": 4215}, {"Word": "redefine", "OffsetStartMs": 4215, "OffsetEndMs": 4880}, {"Word": "how", "OffsetStartMs": 5260, "OffsetEndMs": 5640}, {"Word": "a", "OffsetStartMs": 5640, "OffsetEndMs": 5895}, {"Word": "latent", "OffsetStartMs": 5895, "OffsetEndMs": 6210}, {"Word": "variable", "OffsetStartMs": 6210, "OffsetEndMs": 6500}, {"Word": "vector", "OffsetStartMs": 6610, "OffsetEndMs": 7040}, {"Word": "is", "OffsetStartMs": 7180, "OffsetEndMs": 7470}, {"Word": "sampled", "OffsetStartMs": 7470, "OffsetEndMs": 8000}], "SpeechSpeed": 11.2}, {"FinalSentence": "As a sum of a fixed deterministic mean mu a fixed vector of standard deviation sigma. And now the trick is that we divert all the randomness, all the sampling to a random constant epsilon that's drawn from a normal distribution. So mean itself is fixed, standard deviation is fixed, all the randomness and the sampling occurs according to that epsilon constant.", "SliceSentence": "As a sum of a fixed deterministic mean mu a fixed vector of standard deviation sigma . Andnow the trick is that we divert all the randomness all the sampling to a random constant epsilon that's drawn from a normal distribution . Somean itself is fixed standard deviation is fixed all the randomness and the sampling occurs according to that epsilon constant", "StartMs": 1734040, "EndMs": 1765160, "WordsNum": 62, "Words": [{"Word": "As", "OffsetStartMs": 0, "OffsetEndMs": 255}, {"Word": "a", "OffsetStartMs": 255, "OffsetEndMs": 495}, {"Word": "sum", "OffsetStartMs": 495, "OffsetEndMs": 765}, {"Word": "of", "OffsetStartMs": 765, "OffsetEndMs": 1005}, {"Word": "a", "OffsetStartMs": 1005, "OffsetEndMs": 1185}, {"Word": "fixed", "OffsetStartMs": 1185, "OffsetEndMs": 1490}, {"Word": "deterministic", "OffsetStartMs": 2080, "OffsetEndMs": 2880}, {"Word": "mean", "OffsetStartMs": 2880, "OffsetEndMs": 3165}, {"Word": "mu", "OffsetStartMs": 3165, "OffsetEndMs": 3530}, {"Word": "a", "OffsetStartMs": 4390, "OffsetEndMs": 4710}, {"Word": "fixed", "OffsetStartMs": 4710, "OffsetEndMs": 5030}, {"Word": "vector", "OffsetStartMs": 5710, "OffsetEndMs": 6165}, {"Word": "of", "OffsetStartMs": 6165, "OffsetEndMs": 6495}, {"Word": "standard", "OffsetStartMs": 6495, "OffsetEndMs": 6795}, {"Word": "deviation", "OffsetStartMs": 6795, "OffsetEndMs": 7370}, {"Word": "sigma", "OffsetStartMs": 7450, "OffsetEndMs": 8060}, {"Word": ".", "OffsetStartMs": 8530, "OffsetEndMs": 8835}, {"Word": "Andnow", "OffsetStartMs": 8835, "OffsetEndMs": 9135}, {"Word": "the", "OffsetStartMs": 9135, "OffsetEndMs": 9480}, {"Word": "trick", "OffsetStartMs": 9480, "OffsetEndMs": 9830}, {"Word": "is", "OffsetStartMs": 10090, "OffsetEndMs": 10395}, {"Word": "that", "OffsetStartMs": 10395, "OffsetEndMs": 10590}, {"Word": "we", "OffsetStartMs": 10590, "OffsetEndMs": 10880}, {"Word": "divert", "OffsetStartMs": 11320, "OffsetEndMs": 11990}, {"Word": "all", "OffsetStartMs": 12010, "OffsetEndMs": 12330}, {"Word": "the", "OffsetStartMs": 12330, "OffsetEndMs": 12510}, {"Word": "randomness", "OffsetStartMs": 12510, "OffsetEndMs": 13065}, {"Word": "all", "OffsetStartMs": 13065, "OffsetEndMs": 13320}, {"Word": "the", "OffsetStartMs": 13320, "OffsetEndMs": 13530}, {"Word": "sampling", "OffsetStartMs": 13530, "OffsetEndMs": 14090}, {"Word": "to", "OffsetStartMs": 14410, "OffsetEndMs": 14715}, {"Word": "a", "OffsetStartMs": 14715, "OffsetEndMs": 14955}, {"Word": "random", "OffsetStartMs": 14955, "OffsetEndMs": 15290}, {"Word": "constant", "OffsetStartMs": 15430, "OffsetEndMs": 15830}, {"Word": "epsilon", "OffsetStartMs": 16210, "OffsetEndMs": 16970}, {"Word": "that's", "OffsetStartMs": 17440, "OffsetEndMs": 17880}, {"Word": "drawn", "OffsetStartMs": 17880, "OffsetEndMs": 18200}, {"Word": "from", "OffsetStartMs": 18280, "OffsetEndMs": 18680}, {"Word": "a", "OffsetStartMs": 18730, "OffsetEndMs": 19130}, {"Word": "normal", "OffsetStartMs": 19180, "OffsetEndMs": 19580}, {"Word": "distribution", "OffsetStartMs": 19930, "OffsetEndMs": 20330}, {"Word": ".", "OffsetStartMs": 21430, "OffsetEndMs": 21830}, {"Word": "Somean", "OffsetStartMs": 22120, "OffsetEndMs": 22520}, {"Word": "itself", "OffsetStartMs": 22570, "OffsetEndMs": 22970}, {"Word": "is", "OffsetStartMs": 23080, "OffsetEndMs": 23385}, {"Word": "fixed", "OffsetStartMs": 23385, "OffsetEndMs": 23690}, {"Word": "standard", "OffsetStartMs": 24130, "OffsetEndMs": 24495}, {"Word": "deviation", "OffsetStartMs": 24495, "OffsetEndMs": 24975}, {"Word": "is", "OffsetStartMs": 24975, "OffsetEndMs": 25215}, {"Word": "fixed", "OffsetStartMs": 25215, "OffsetEndMs": 25520}, {"Word": "all", "OffsetStartMs": 25810, "OffsetEndMs": 26130}, {"Word": "the", "OffsetStartMs": 26130, "OffsetEndMs": 26310}, {"Word": "randomness", "OffsetStartMs": 26310, "OffsetEndMs": 26960}, {"Word": "and", "OffsetStartMs": 27010, "OffsetEndMs": 27285}, {"Word": "the", "OffsetStartMs": 27285, "OffsetEndMs": 27435}, {"Word": "sampling", "OffsetStartMs": 27435, "OffsetEndMs": 27980}, {"Word": "occurs", "OffsetStartMs": 28180, "OffsetEndMs": 28580}, {"Word": "according", "OffsetStartMs": 28720, "OffsetEndMs": 29115}, {"Word": "to", "OffsetStartMs": 29115, "OffsetEndMs": 29355}, {"Word": "that", "OffsetStartMs": 29355, "OffsetEndMs": 29535}, {"Word": "epsilon", "OffsetStartMs": 29535, "OffsetEndMs": 30135}, {"Word": "constant", "OffsetStartMs": 30135, "OffsetEndMs": 30470}], "SpeechSpeed": 11.4}, {"FinalSentence": "We can then scale the mean and standard deviation by that random constant to re-achieve the sampling operation within the latent variables themselves.", "SliceSentence": "We can then scale the mean and standard deviation by that random constant to re -achieve the sampling operation within the latent variables themselves", "StartMs": 1765200, "EndMs": 1776160, "WordsNum": 24, "Words": [{"Word": "We", "OffsetStartMs": 130, "OffsetEndMs": 405}, {"Word": "can", "OffsetStartMs": 405, "OffsetEndMs": 570}, {"Word": "then", "OffsetStartMs": 570, "OffsetEndMs": 860}, {"Word": "scale", "OffsetStartMs": 1300, "OffsetEndMs": 1700}, {"Word": "the", "OffsetStartMs": 1810, "OffsetEndMs": 2085}, {"Word": "mean", "OffsetStartMs": 2085, "OffsetEndMs": 2265}, {"Word": "and", "OffsetStartMs": 2265, "OffsetEndMs": 2490}, {"Word": "standard", "OffsetStartMs": 2490, "OffsetEndMs": 2810}, {"Word": "deviation", "OffsetStartMs": 2950, "OffsetEndMs": 3530}, {"Word": "by", "OffsetStartMs": 3550, "OffsetEndMs": 3885}, {"Word": "that", "OffsetStartMs": 3885, "OffsetEndMs": 4110}, {"Word": "random", "OffsetStartMs": 4110, "OffsetEndMs": 4395}, {"Word": "constant", "OffsetStartMs": 4395, "OffsetEndMs": 4790}, {"Word": "to", "OffsetStartMs": 5290, "OffsetEndMs": 5595}, {"Word": "re", "OffsetStartMs": 5595, "OffsetEndMs": 5900}, {"Word": "-achieve", "OffsetStartMs": 6310, "OffsetEndMs": 6710}, {"Word": "the", "OffsetStartMs": 7030, "OffsetEndMs": 7350}, {"Word": "sampling", "OffsetStartMs": 7350, "OffsetEndMs": 7910}, {"Word": "operation", "OffsetStartMs": 7990, "OffsetEndMs": 8370}, {"Word": "within", "OffsetStartMs": 8370, "OffsetEndMs": 8730}, {"Word": "the", "OffsetStartMs": 8730, "OffsetEndMs": 8970}, {"Word": "latent", "OffsetStartMs": 8970, "OffsetEndMs": 9255}, {"Word": "variables", "OffsetStartMs": 9255, "OffsetEndMs": 9800}, {"Word": "themselves", "OffsetStartMs": 9850, "OffsetEndMs": 10250}], "SpeechSpeed": 13.6}, {"FinalSentence": "What this actually looks like, and an illustration that breaks down this concept of reperatization and divergence, is as follows.", "SliceSentence": "What this actually looks like and an illustration that breaks down this concept of reperatization and divergence is as follows", "StartMs": 1777040, "EndMs": 1786540, "WordsNum": 20, "Words": [{"Word": "What", "OffsetStartMs": 10, "OffsetEndMs": 315}, {"Word": "this", "OffsetStartMs": 315, "OffsetEndMs": 600}, {"Word": "actually", "OffsetStartMs": 600, "OffsetEndMs": 885}, {"Word": "looks", "OffsetStartMs": 885, "OffsetEndMs": 1110}, {"Word": "like", "OffsetStartMs": 1110, "OffsetEndMs": 1350}, {"Word": "and", "OffsetStartMs": 1350, "OffsetEndMs": 1560}, {"Word": "an", "OffsetStartMs": 1560, "OffsetEndMs": 1755}, {"Word": "illustration", "OffsetStartMs": 1755, "OffsetEndMs": 2340}, {"Word": "that", "OffsetStartMs": 2340, "OffsetEndMs": 2720}, {"Word": "breaks", "OffsetStartMs": 3610, "OffsetEndMs": 3975}, {"Word": "down", "OffsetStartMs": 3975, "OffsetEndMs": 4275}, {"Word": "this", "OffsetStartMs": 4275, "OffsetEndMs": 4530}, {"Word": "concept", "OffsetStartMs": 4530, "OffsetEndMs": 4850}, {"Word": "of", "OffsetStartMs": 4870, "OffsetEndMs": 5175}, {"Word": "reperatization", "OffsetStartMs": 5175, "OffsetEndMs": 6200}, {"Word": "and", "OffsetStartMs": 6430, "OffsetEndMs": 6720}, {"Word": "divergence", "OffsetStartMs": 6720, "OffsetEndMs": 7400}, {"Word": "is", "OffsetStartMs": 7660, "OffsetEndMs": 8025}, {"Word": "as", "OffsetStartMs": 8025, "OffsetEndMs": 8325}, {"Word": "follows", "OffsetStartMs": 8325, "OffsetEndMs": 8660}], "SpeechSpeed": 13.3}, {"FinalSentence": "So looking, looking here, right, what I've shown is these completely deterministic steps in blue and the sampling random steps in orange originally. If our latent variables are what effectively are capturing the randomness, the sampling themselves, we have this problem in that we can't back propagate. We can't train directly through anything that has stochasticity that has randomness.", "SliceSentence": "So looking looking here right what I've shown is these completely deterministic steps in blue and the sampling random steps in orange originally . Ifour latent variables are what effectively are capturing the randomness the sampling themselves we have this problem in that we can't back propagate . Wecan't train directly through anything that has stochasticity that has randomness", "StartMs": 1786540, "EndMs": 1814060, "WordsNum": 59, "Words": [{"Word": "So", "OffsetStartMs": 10, "OffsetEndMs": 285}, {"Word": "looking", "OffsetStartMs": 285, "OffsetEndMs": 560}, {"Word": "looking", "OffsetStartMs": 580, "OffsetEndMs": 945}, {"Word": "here", "OffsetStartMs": 945, "OffsetEndMs": 1245}, {"Word": "right", "OffsetStartMs": 1245, "OffsetEndMs": 1580}, {"Word": "what", "OffsetStartMs": 1810, "OffsetEndMs": 2085}, {"Word": "I've", "OffsetStartMs": 2085, "OffsetEndMs": 2310}, {"Word": "shown", "OffsetStartMs": 2310, "OffsetEndMs": 2550}, {"Word": "is", "OffsetStartMs": 2550, "OffsetEndMs": 2880}, {"Word": "these", "OffsetStartMs": 2880, "OffsetEndMs": 3230}, {"Word": "completely", "OffsetStartMs": 3670, "OffsetEndMs": 4070}, {"Word": "deterministic", "OffsetStartMs": 4210, "OffsetEndMs": 4950}, {"Word": "steps", "OffsetStartMs": 4950, "OffsetEndMs": 5235}, {"Word": "in", "OffsetStartMs": 5235, "OffsetEndMs": 5535}, {"Word": "blue", "OffsetStartMs": 5535, "OffsetEndMs": 5870}, {"Word": "and", "OffsetStartMs": 6430, "OffsetEndMs": 6830}, {"Word": "the", "OffsetStartMs": 7180, "OffsetEndMs": 7580}, {"Word": "sampling", "OffsetStartMs": 8170, "OffsetEndMs": 8820}, {"Word": "random", "OffsetStartMs": 8820, "OffsetEndMs": 9200}, {"Word": "steps", "OffsetStartMs": 9280, "OffsetEndMs": 9660}, {"Word": "in", "OffsetStartMs": 9660, "OffsetEndMs": 9915}, {"Word": "orange", "OffsetStartMs": 9915, "OffsetEndMs": 10190}, {"Word": "originally", "OffsetStartMs": 11110, "OffsetEndMs": 11510}, {"Word": ".", "OffsetStartMs": 12040, "OffsetEndMs": 12360}, {"Word": "Ifour", "OffsetStartMs": 12360, "OffsetEndMs": 12585}, {"Word": "latent", "OffsetStartMs": 12585, "OffsetEndMs": 12915}, {"Word": "variables", "OffsetStartMs": 12915, "OffsetEndMs": 13410}, {"Word": "are", "OffsetStartMs": 13410, "OffsetEndMs": 13730}, {"Word": "what", "OffsetStartMs": 13870, "OffsetEndMs": 14270}, {"Word": "effectively", "OffsetStartMs": 14440, "OffsetEndMs": 14840}, {"Word": "are", "OffsetStartMs": 14890, "OffsetEndMs": 15225}, {"Word": "capturing", "OffsetStartMs": 15225, "OffsetEndMs": 15795}, {"Word": "the", "OffsetStartMs": 15795, "OffsetEndMs": 15960}, {"Word": "randomness", "OffsetStartMs": 15960, "OffsetEndMs": 16485}, {"Word": "the", "OffsetStartMs": 16485, "OffsetEndMs": 16695}, {"Word": "sampling", "OffsetStartMs": 16695, "OffsetEndMs": 17240}, {"Word": "themselves", "OffsetStartMs": 17530, "OffsetEndMs": 17930}, {"Word": "we", "OffsetStartMs": 18610, "OffsetEndMs": 18900}, {"Word": "have", "OffsetStartMs": 18900, "OffsetEndMs": 19095}, {"Word": "this", "OffsetStartMs": 19095, "OffsetEndMs": 19335}, {"Word": "problem", "OffsetStartMs": 19335, "OffsetEndMs": 19665}, {"Word": "in", "OffsetStartMs": 19665, "OffsetEndMs": 19950}, {"Word": "that", "OffsetStartMs": 19950, "OffsetEndMs": 20190}, {"Word": "we", "OffsetStartMs": 20190, "OffsetEndMs": 20460}, {"Word": "can't", "OffsetStartMs": 20460, "OffsetEndMs": 20820}, {"Word": "back", "OffsetStartMs": 20820, "OffsetEndMs": 21045}, {"Word": "propagate", "OffsetStartMs": 21045, "OffsetEndMs": 21540}, {"Word": ".", "OffsetStartMs": 21540, "OffsetEndMs": 21780}, {"Word": "Wecan't", "OffsetStartMs": 21780, "OffsetEndMs": 22185}, {"Word": "train", "OffsetStartMs": 22185, "OffsetEndMs": 22490}, {"Word": "directly", "OffsetStartMs": 22840, "OffsetEndMs": 23240}, {"Word": "through", "OffsetStartMs": 23320, "OffsetEndMs": 23720}, {"Word": "anything", "OffsetStartMs": 23830, "OffsetEndMs": 24135}, {"Word": "that", "OffsetStartMs": 24135, "OffsetEndMs": 24345}, {"Word": "has", "OffsetStartMs": 24345, "OffsetEndMs": 24650}, {"Word": "stochasticity", "OffsetStartMs": 24790, "OffsetEndMs": 25905}, {"Word": "that", "OffsetStartMs": 25905, "OffsetEndMs": 26190}, {"Word": "has", "OffsetStartMs": 26190, "OffsetEndMs": 26400}, {"Word": "randomness", "OffsetStartMs": 26400, "OffsetEndMs": 27080}], "SpeechSpeed": 13.8}, {"FinalSentence": "What Rep parameterriization allows us to do is it shifts this diagram where now we've completely diverted that sampling operation off to the side, to this constant epsilon, which is drawn from a normal prior. And now when we look back at our latent variable, it is deterministic with respect to that sampling operation.", "SliceSentence": "What Rep parameterriization allows us to do is it shifts this diagram where now we've completely diverted that sampling operation off to the side to this constant epsilon which is drawn from a normal prior . Andnow when we look back at our latent variable it is deterministic with respect to that sampling operation", "StartMs": 1814520, "EndMs": 1837960, "WordsNum": 54, "Words": [{"Word": "What", "OffsetStartMs": 160, "OffsetEndMs": 510}, {"Word": "Rep", "OffsetStartMs": 510, "OffsetEndMs": 780}, {"Word": "parameterriization", "OffsetStartMs": 780, "OffsetEndMs": 1700}, {"Word": "allows", "OffsetStartMs": 2020, "OffsetEndMs": 2355}, {"Word": "us", "OffsetStartMs": 2355, "OffsetEndMs": 2580}, {"Word": "to", "OffsetStartMs": 2580, "OffsetEndMs": 2745}, {"Word": "do", "OffsetStartMs": 2745, "OffsetEndMs": 3020}, {"Word": "is", "OffsetStartMs": 3370, "OffsetEndMs": 3720}, {"Word": "it", "OffsetStartMs": 3720, "OffsetEndMs": 4070}, {"Word": "shifts", "OffsetStartMs": 4090, "OffsetEndMs": 4500}, {"Word": "this", "OffsetStartMs": 4500, "OffsetEndMs": 4695}, {"Word": "diagram", "OffsetStartMs": 4695, "OffsetEndMs": 5300}, {"Word": "where", "OffsetStartMs": 5650, "OffsetEndMs": 5970}, {"Word": "now", "OffsetStartMs": 5970, "OffsetEndMs": 6240}, {"Word": "we've", "OffsetStartMs": 6240, "OffsetEndMs": 6690}, {"Word": "completely", "OffsetStartMs": 6690, "OffsetEndMs": 7065}, {"Word": "diverted", "OffsetStartMs": 7065, "OffsetEndMs": 7785}, {"Word": "that", "OffsetStartMs": 7785, "OffsetEndMs": 7995}, {"Word": "sampling", "OffsetStartMs": 7995, "OffsetEndMs": 8595}, {"Word": "operation", "OffsetStartMs": 8595, "OffsetEndMs": 8990}, {"Word": "off", "OffsetStartMs": 9520, "OffsetEndMs": 9870}, {"Word": "to", "OffsetStartMs": 9870, "OffsetEndMs": 10065}, {"Word": "the", "OffsetStartMs": 10065, "OffsetEndMs": 10185}, {"Word": "side", "OffsetStartMs": 10185, "OffsetEndMs": 10460}, {"Word": "to", "OffsetStartMs": 10990, "OffsetEndMs": 11280}, {"Word": "this", "OffsetStartMs": 11280, "OffsetEndMs": 11505}, {"Word": "constant", "OffsetStartMs": 11505, "OffsetEndMs": 11840}, {"Word": "epsilon", "OffsetStartMs": 11980, "OffsetEndMs": 12740}, {"Word": "which", "OffsetStartMs": 13150, "OffsetEndMs": 13425}, {"Word": "is", "OffsetStartMs": 13425, "OffsetEndMs": 13620}, {"Word": "drawn", "OffsetStartMs": 13620, "OffsetEndMs": 13920}, {"Word": "from", "OffsetStartMs": 13920, "OffsetEndMs": 14160}, {"Word": "a", "OffsetStartMs": 14160, "OffsetEndMs": 14295}, {"Word": "normal", "OffsetStartMs": 14295, "OffsetEndMs": 14570}, {"Word": "prior", "OffsetStartMs": 14590, "OffsetEndMs": 14990}, {"Word": ".", "OffsetStartMs": 15700, "OffsetEndMs": 16020}, {"Word": "Andnow", "OffsetStartMs": 16020, "OffsetEndMs": 16340}, {"Word": "when", "OffsetStartMs": 16720, "OffsetEndMs": 17010}, {"Word": "we", "OffsetStartMs": 17010, "OffsetEndMs": 17190}, {"Word": "look", "OffsetStartMs": 17190, "OffsetEndMs": 17400}, {"Word": "back", "OffsetStartMs": 17400, "OffsetEndMs": 17625}, {"Word": "at", "OffsetStartMs": 17625, "OffsetEndMs": 17790}, {"Word": "our", "OffsetStartMs": 17790, "OffsetEndMs": 17925}, {"Word": "latent", "OffsetStartMs": 17925, "OffsetEndMs": 18240}, {"Word": "variable", "OffsetStartMs": 18240, "OffsetEndMs": 18530}, {"Word": "it", "OffsetStartMs": 18850, "OffsetEndMs": 19125}, {"Word": "is", "OffsetStartMs": 19125, "OffsetEndMs": 19400}, {"Word": "deterministic", "OffsetStartMs": 19420, "OffsetEndMs": 20300}, {"Word": "with", "OffsetStartMs": 20380, "OffsetEndMs": 20780}, {"Word": "respect", "OffsetStartMs": 20830, "OffsetEndMs": 21230}, {"Word": "to", "OffsetStartMs": 21310, "OffsetEndMs": 21570}, {"Word": "that", "OffsetStartMs": 21570, "OffsetEndMs": 21765}, {"Word": "sampling", "OffsetStartMs": 21765, "OffsetEndMs": 22370}, {"Word": "operation", "OffsetStartMs": 22450, "OffsetEndMs": 22850}], "SpeechSpeed": 13.4}, {"FinalSentence": "What this means is that we can back propagate to update our network weights completely end to end, without having to worry about direct randomness, direct stochasticity within those latent variables c.", "SliceSentence": "What this means is that we can back propagate to update our network weights completely end to end without having to worry about direct randomness direct stochasticity within those latent variables c", "StartMs": 1838360, "EndMs": 1852220, "WordsNum": 32, "Words": [{"Word": "What", "OffsetStartMs": 220, "OffsetEndMs": 510}, {"Word": "this", "OffsetStartMs": 510, "OffsetEndMs": 705}, {"Word": "means", "OffsetStartMs": 705, "OffsetEndMs": 945}, {"Word": "is", "OffsetStartMs": 945, "OffsetEndMs": 1155}, {"Word": "that", "OffsetStartMs": 1155, "OffsetEndMs": 1335}, {"Word": "we", "OffsetStartMs": 1335, "OffsetEndMs": 1500}, {"Word": "can", "OffsetStartMs": 1500, "OffsetEndMs": 1680}, {"Word": "back", "OffsetStartMs": 1680, "OffsetEndMs": 1950}, {"Word": "propagate", "OffsetStartMs": 1950, "OffsetEndMs": 2550}, {"Word": "to", "OffsetStartMs": 2550, "OffsetEndMs": 2930}, {"Word": "update", "OffsetStartMs": 2980, "OffsetEndMs": 3270}, {"Word": "our", "OffsetStartMs": 3270, "OffsetEndMs": 3450}, {"Word": "network", "OffsetStartMs": 3450, "OffsetEndMs": 3735}, {"Word": "weights", "OffsetStartMs": 3735, "OffsetEndMs": 4310}, {"Word": "completely", "OffsetStartMs": 4780, "OffsetEndMs": 5160}, {"Word": "end", "OffsetStartMs": 5160, "OffsetEndMs": 5445}, {"Word": "to", "OffsetStartMs": 5445, "OffsetEndMs": 5610}, {"Word": "end", "OffsetStartMs": 5610, "OffsetEndMs": 5870}, {"Word": "without", "OffsetStartMs": 6850, "OffsetEndMs": 7250}, {"Word": "having", "OffsetStartMs": 7360, "OffsetEndMs": 7740}, {"Word": "to", "OffsetStartMs": 7740, "OffsetEndMs": 7995}, {"Word": "worry", "OffsetStartMs": 7995, "OffsetEndMs": 8270}, {"Word": "about", "OffsetStartMs": 8410, "OffsetEndMs": 8810}, {"Word": "direct", "OffsetStartMs": 9040, "OffsetEndMs": 9440}, {"Word": "randomness", "OffsetStartMs": 9520, "OffsetEndMs": 10245}, {"Word": "direct", "OffsetStartMs": 10245, "OffsetEndMs": 10530}, {"Word": "stochasticity", "OffsetStartMs": 10530, "OffsetEndMs": 11490}, {"Word": "within", "OffsetStartMs": 11490, "OffsetEndMs": 11780}, {"Word": "those", "OffsetStartMs": 12010, "OffsetEndMs": 12300}, {"Word": "latent", "OffsetStartMs": 12300, "OffsetEndMs": 12645}, {"Word": "variables", "OffsetStartMs": 12645, "OffsetEndMs": 13095}, {"Word": "c", "OffsetStartMs": 13095, "OffsetEndMs": 13400}], "SpeechSpeed": 14.3}, {"FinalSentence": "This trick is really, really powerful because it enabled the ability to train these vas completely end to end in through back propagation algorithm.", "SliceSentence": "This trick is really really powerful because it enabled the ability to train these vas completely end to end in through back propagation algorithm", "StartMs": 1852860, "EndMs": 1864280, "WordsNum": 24, "Words": [{"Word": "This", "OffsetStartMs": 100, "OffsetEndMs": 435}, {"Word": "trick", "OffsetStartMs": 435, "OffsetEndMs": 705}, {"Word": "is", "OffsetStartMs": 705, "OffsetEndMs": 1005}, {"Word": "really", "OffsetStartMs": 1005, "OffsetEndMs": 1305}, {"Word": "really", "OffsetStartMs": 1305, "OffsetEndMs": 1575}, {"Word": "powerful", "OffsetStartMs": 1575, "OffsetEndMs": 1910}, {"Word": "because", "OffsetStartMs": 2050, "OffsetEndMs": 2310}, {"Word": "it", "OffsetStartMs": 2310, "OffsetEndMs": 2430}, {"Word": "enabled", "OffsetStartMs": 2430, "OffsetEndMs": 2870}, {"Word": "the", "OffsetStartMs": 3250, "OffsetEndMs": 3570}, {"Word": "ability", "OffsetStartMs": 3570, "OffsetEndMs": 3890}, {"Word": "to", "OffsetStartMs": 3970, "OffsetEndMs": 4275}, {"Word": "train", "OffsetStartMs": 4275, "OffsetEndMs": 4500}, {"Word": "these", "OffsetStartMs": 4500, "OffsetEndMs": 4755}, {"Word": "vas", "OffsetStartMs": 4755, "OffsetEndMs": 5180}, {"Word": "completely", "OffsetStartMs": 5710, "OffsetEndMs": 6090}, {"Word": "end", "OffsetStartMs": 6090, "OffsetEndMs": 6375}, {"Word": "to", "OffsetStartMs": 6375, "OffsetEndMs": 6540}, {"Word": "end", "OffsetStartMs": 6540, "OffsetEndMs": 6800}, {"Word": "in", "OffsetStartMs": 6910, "OffsetEndMs": 7310}, {"Word": "through", "OffsetStartMs": 8440, "OffsetEndMs": 8730}, {"Word": "back", "OffsetStartMs": 8730, "OffsetEndMs": 8955}, {"Word": "propagation", "OffsetStartMs": 8955, "OffsetEndMs": 9530}, {"Word": "algorithm", "OffsetStartMs": 9670, "OffsetEndMs": 10190}], "SpeechSpeed": 12.8}, {"FinalSentence": "All right. So at this point, we've gone through the core architecture of vas. We've introduced these two terms of the loss. We've seen how we can train it end to end.", "SliceSentence": "All right . Soat this point we've gone through the core architecture of vas .We've introduced these two terms of the loss .We've seen how we can train it end to end", "StartMs": 1865000, "EndMs": 1875480, "WordsNum": 32, "Words": [{"Word": "All", "OffsetStartMs": 70, "OffsetEndMs": 330}, {"Word": "right", "OffsetStartMs": 330, "OffsetEndMs": 590}, {"Word": ".", "OffsetStartMs": 1150, "OffsetEndMs": 1550}, {"Word": "Soat", "OffsetStartMs": 1870, "OffsetEndMs": 2160}, {"Word": "this", "OffsetStartMs": 2160, "OffsetEndMs": 2355}, {"Word": "point", "OffsetStartMs": 2355, "OffsetEndMs": 2655}, {"Word": "we've", "OffsetStartMs": 2655, "OffsetEndMs": 3015}, {"Word": "gone", "OffsetStartMs": 3015, "OffsetEndMs": 3225}, {"Word": "through", "OffsetStartMs": 3225, "OffsetEndMs": 3465}, {"Word": "the", "OffsetStartMs": 3465, "OffsetEndMs": 3660}, {"Word": "core", "OffsetStartMs": 3660, "OffsetEndMs": 3885}, {"Word": "architecture", "OffsetStartMs": 3885, "OffsetEndMs": 4190}, {"Word": "of", "OffsetStartMs": 4360, "OffsetEndMs": 4650}, {"Word": "vas", "OffsetStartMs": 4650, "OffsetEndMs": 5030}, {"Word": ".We've", "OffsetStartMs": 5530, "OffsetEndMs": 6050}, {"Word": "introduced", "OffsetStartMs": 6070, "OffsetEndMs": 6375}, {"Word": "these", "OffsetStartMs": 6375, "OffsetEndMs": 6615}, {"Word": "two", "OffsetStartMs": 6615, "OffsetEndMs": 6870}, {"Word": "terms", "OffsetStartMs": 6870, "OffsetEndMs": 7110}, {"Word": "of", "OffsetStartMs": 7110, "OffsetEndMs": 7305}, {"Word": "the", "OffsetStartMs": 7305, "OffsetEndMs": 7455}, {"Word": "loss", "OffsetStartMs": 7455, "OffsetEndMs": 7730}, {"Word": ".We've", "OffsetStartMs": 7780, "OffsetEndMs": 8160}, {"Word": "seen", "OffsetStartMs": 8160, "OffsetEndMs": 8385}, {"Word": "how", "OffsetStartMs": 8385, "OffsetEndMs": 8595}, {"Word": "we", "OffsetStartMs": 8595, "OffsetEndMs": 8745}, {"Word": "can", "OffsetStartMs": 8745, "OffsetEndMs": 8925}, {"Word": "train", "OffsetStartMs": 8925, "OffsetEndMs": 9105}, {"Word": "it", "OffsetStartMs": 9105, "OffsetEndMs": 9255}, {"Word": "end", "OffsetStartMs": 9255, "OffsetEndMs": 9435}, {"Word": "to", "OffsetStartMs": 9435, "OffsetEndMs": 9600}, {"Word": "end", "OffsetStartMs": 9600, "OffsetEndMs": 9860}], "SpeechSpeed": 15.4}, {"FinalSentence": "Now let's consider what these latent variables are actually capturing and what they represent.", "SliceSentence": "Now let 's consider what these latent variables are actually capturing and what they represent", "StartMs": 1875480, "EndMs": 1881460, "WordsNum": 15, "Words": [{"Word": "Now", "OffsetStartMs": 160, "OffsetEndMs": 495}, {"Word": "let", "OffsetStartMs": 495, "OffsetEndMs": 660}, {"Word": "'s", "OffsetStartMs": 660, "OffsetEndMs": 855}, {"Word": "consider", "OffsetStartMs": 855, "OffsetEndMs": 1185}, {"Word": "what", "OffsetStartMs": 1185, "OffsetEndMs": 1470}, {"Word": "these", "OffsetStartMs": 1470, "OffsetEndMs": 1740}, {"Word": "latent", "OffsetStartMs": 1740, "OffsetEndMs": 2115}, {"Word": "variables", "OffsetStartMs": 2115, "OffsetEndMs": 2580}, {"Word": "are", "OffsetStartMs": 2580, "OffsetEndMs": 2870}, {"Word": "actually", "OffsetStartMs": 3010, "OffsetEndMs": 3315}, {"Word": "capturing", "OffsetStartMs": 3315, "OffsetEndMs": 3765}, {"Word": "and", "OffsetStartMs": 3765, "OffsetEndMs": 3930}, {"Word": "what", "OffsetStartMs": 3930, "OffsetEndMs": 4110}, {"Word": "they", "OffsetStartMs": 4110, "OffsetEndMs": 4290}, {"Word": "represent", "OffsetStartMs": 4290, "OffsetEndMs": 4580}], "SpeechSpeed": 15.6}, {"FinalSentence": "When we impose this distributional prior, what it allows us to do is to sample effectively from the latent space and actually slowly perturb the value of single latent variables, keeping the other ones fixed. And what you can observe, and what you can see here is that by doing that perturbation that tuning of the value of the latent variables.", "SliceSentence": "When we impose this distributional prior what it allows us to do is to sample effectively from the latent space and actually slowly perturb the value of single latent variables keeping the other ones fixed . Andwhat you can observe and what you can see here is that by doing that perturbation that tuning of the value of the latent variables", "StartMs": 1882320, "EndMs": 1907180, "WordsNum": 61, "Words": [{"Word": "When", "OffsetStartMs": 190, "OffsetEndMs": 510}, {"Word": "we", "OffsetStartMs": 510, "OffsetEndMs": 830}, {"Word": "impose", "OffsetStartMs": 880, "OffsetEndMs": 1550}, {"Word": "this", "OffsetStartMs": 1600, "OffsetEndMs": 2000}, {"Word": "distributional", "OffsetStartMs": 2110, "OffsetEndMs": 2820}, {"Word": "prior", "OffsetStartMs": 2820, "OffsetEndMs": 3170}, {"Word": "what", "OffsetStartMs": 3970, "OffsetEndMs": 4275}, {"Word": "it", "OffsetStartMs": 4275, "OffsetEndMs": 4530}, {"Word": "allows", "OffsetStartMs": 4530, "OffsetEndMs": 4785}, {"Word": "us", "OffsetStartMs": 4785, "OffsetEndMs": 4995}, {"Word": "to", "OffsetStartMs": 4995, "OffsetEndMs": 5145}, {"Word": "do", "OffsetStartMs": 5145, "OffsetEndMs": 5295}, {"Word": "is", "OffsetStartMs": 5295, "OffsetEndMs": 5490}, {"Word": "to", "OffsetStartMs": 5490, "OffsetEndMs": 5685}, {"Word": "sample", "OffsetStartMs": 5685, "OffsetEndMs": 5990}, {"Word": "effectively", "OffsetStartMs": 6190, "OffsetEndMs": 6590}, {"Word": "from", "OffsetStartMs": 6760, "OffsetEndMs": 7080}, {"Word": "the", "OffsetStartMs": 7080, "OffsetEndMs": 7260}, {"Word": "latent", "OffsetStartMs": 7260, "OffsetEndMs": 7605}, {"Word": "space", "OffsetStartMs": 7605, "OffsetEndMs": 7910}, {"Word": "and", "OffsetStartMs": 8500, "OffsetEndMs": 8900}, {"Word": "actually", "OffsetStartMs": 9190, "OffsetEndMs": 9590}, {"Word": "slowly", "OffsetStartMs": 9670, "OffsetEndMs": 10070}, {"Word": "perturb", "OffsetStartMs": 10150, "OffsetEndMs": 10935}, {"Word": "the", "OffsetStartMs": 10935, "OffsetEndMs": 11130}, {"Word": "value", "OffsetStartMs": 11130, "OffsetEndMs": 11420}, {"Word": "of", "OffsetStartMs": 11800, "OffsetEndMs": 12150}, {"Word": "single", "OffsetStartMs": 12150, "OffsetEndMs": 12480}, {"Word": "latent", "OffsetStartMs": 12480, "OffsetEndMs": 12930}, {"Word": "variables", "OffsetStartMs": 12930, "OffsetEndMs": 13550}, {"Word": "keeping", "OffsetStartMs": 14140, "OffsetEndMs": 14490}, {"Word": "the", "OffsetStartMs": 14490, "OffsetEndMs": 14685}, {"Word": "other", "OffsetStartMs": 14685, "OffsetEndMs": 14850}, {"Word": "ones", "OffsetStartMs": 14850, "OffsetEndMs": 15105}, {"Word": "fixed", "OffsetStartMs": 15105, "OffsetEndMs": 15440}, {"Word": ".", "OffsetStartMs": 16330, "OffsetEndMs": 16730}, {"Word": "Andwhat", "OffsetStartMs": 17110, "OffsetEndMs": 17385}, {"Word": "you", "OffsetStartMs": 17385, "OffsetEndMs": 17520}, {"Word": "can", "OffsetStartMs": 17520, "OffsetEndMs": 17745}, {"Word": "observe", "OffsetStartMs": 17745, "OffsetEndMs": 18015}, {"Word": "and", "OffsetStartMs": 18015, "OffsetEndMs": 18210}, {"Word": "what", "OffsetStartMs": 18210, "OffsetEndMs": 18375}, {"Word": "you", "OffsetStartMs": 18375, "OffsetEndMs": 18510}, {"Word": "can", "OffsetStartMs": 18510, "OffsetEndMs": 18690}, {"Word": "see", "OffsetStartMs": 18690, "OffsetEndMs": 18945}, {"Word": "here", "OffsetStartMs": 18945, "OffsetEndMs": 19280}, {"Word": "is", "OffsetStartMs": 19480, "OffsetEndMs": 19770}, {"Word": "that", "OffsetStartMs": 19770, "OffsetEndMs": 19965}, {"Word": "by", "OffsetStartMs": 19965, "OffsetEndMs": 20205}, {"Word": "doing", "OffsetStartMs": 20205, "OffsetEndMs": 20475}, {"Word": "that", "OffsetStartMs": 20475, "OffsetEndMs": 20730}, {"Word": "perturbation", "OffsetStartMs": 20730, "OffsetEndMs": 21270}, {"Word": "that", "OffsetStartMs": 21270, "OffsetEndMs": 21645}, {"Word": "tuning", "OffsetStartMs": 21645, "OffsetEndMs": 22095}, {"Word": "of", "OffsetStartMs": 22095, "OffsetEndMs": 22245}, {"Word": "the", "OffsetStartMs": 22245, "OffsetEndMs": 22395}, {"Word": "value", "OffsetStartMs": 22395, "OffsetEndMs": 22635}, {"Word": "of", "OffsetStartMs": 22635, "OffsetEndMs": 22860}, {"Word": "the", "OffsetStartMs": 22860, "OffsetEndMs": 22995}, {"Word": "latent", "OffsetStartMs": 22995, "OffsetEndMs": 23295}, {"Word": "variables", "OffsetStartMs": 23295, "OffsetEndMs": 23900}], "SpeechSpeed": 13.7}, {"FinalSentence": "We can run the decoder of the va every time, reconstruct the output every time we do that tuning. And what you'll see hopefully with this example with the face is that an individual latent variable is capturing something semantically informative, something meaningful. And we see that by this perturbation, by this tuning.", "SliceSentence": "We can run the decoder of the va every time reconstruct the output every time we do that tuning . Andwhat you'll see hopefully with this example with the face is that an individual latent variable is capturing something semantically informative something meaningful . Andwe see that by this perturbation by this tuning", "StartMs": 1907180, "EndMs": 1929940, "WordsNum": 53, "Words": [{"Word": "We", "OffsetStartMs": 100, "OffsetEndMs": 375}, {"Word": "can", "OffsetStartMs": 375, "OffsetEndMs": 555}, {"Word": "run", "OffsetStartMs": 555, "OffsetEndMs": 795}, {"Word": "the", "OffsetStartMs": 795, "OffsetEndMs": 1005}, {"Word": "decoder", "OffsetStartMs": 1005, "OffsetEndMs": 1665}, {"Word": "of", "OffsetStartMs": 1665, "OffsetEndMs": 1965}, {"Word": "the", "OffsetStartMs": 1965, "OffsetEndMs": 2145}, {"Word": "va", "OffsetStartMs": 2145, "OffsetEndMs": 2505}, {"Word": "every", "OffsetStartMs": 2505, "OffsetEndMs": 2865}, {"Word": "time", "OffsetStartMs": 2865, "OffsetEndMs": 3260}, {"Word": "reconstruct", "OffsetStartMs": 3550, "OffsetEndMs": 4290}, {"Word": "the", "OffsetStartMs": 4290, "OffsetEndMs": 4575}, {"Word": "output", "OffsetStartMs": 4575, "OffsetEndMs": 4830}, {"Word": "every", "OffsetStartMs": 4830, "OffsetEndMs": 5100}, {"Word": "time", "OffsetStartMs": 5100, "OffsetEndMs": 5415}, {"Word": "we", "OffsetStartMs": 5415, "OffsetEndMs": 5640}, {"Word": "do", "OffsetStartMs": 5640, "OffsetEndMs": 5805}, {"Word": "that", "OffsetStartMs": 5805, "OffsetEndMs": 6030}, {"Word": "tuning", "OffsetStartMs": 6030, "OffsetEndMs": 6530}, {"Word": ".", "OffsetStartMs": 7120, "OffsetEndMs": 7520}, {"Word": "Andwhat", "OffsetStartMs": 7840, "OffsetEndMs": 8115}, {"Word": "you'll", "OffsetStartMs": 8115, "OffsetEndMs": 8355}, {"Word": "see", "OffsetStartMs": 8355, "OffsetEndMs": 8630}, {"Word": "hopefully", "OffsetStartMs": 8950, "OffsetEndMs": 9350}, {"Word": "with", "OffsetStartMs": 9430, "OffsetEndMs": 9690}, {"Word": "this", "OffsetStartMs": 9690, "OffsetEndMs": 9950}, {"Word": "example", "OffsetStartMs": 10390, "OffsetEndMs": 10770}, {"Word": "with", "OffsetStartMs": 10770, "OffsetEndMs": 11025}, {"Word": "the", "OffsetStartMs": 11025, "OffsetEndMs": 11175}, {"Word": "face", "OffsetStartMs": 11175, "OffsetEndMs": 11450}, {"Word": "is", "OffsetStartMs": 11470, "OffsetEndMs": 11745}, {"Word": "that", "OffsetStartMs": 11745, "OffsetEndMs": 11880}, {"Word": "an", "OffsetStartMs": 11880, "OffsetEndMs": 12140}, {"Word": "individual", "OffsetStartMs": 12310, "OffsetEndMs": 12690}, {"Word": "latent", "OffsetStartMs": 12690, "OffsetEndMs": 13140}, {"Word": "variable", "OffsetStartMs": 13140, "OffsetEndMs": 13430}, {"Word": "is", "OffsetStartMs": 13900, "OffsetEndMs": 14265}, {"Word": "capturing", "OffsetStartMs": 14265, "OffsetEndMs": 14925}, {"Word": "something", "OffsetStartMs": 14925, "OffsetEndMs": 15260}, {"Word": "semantically", "OffsetStartMs": 15850, "OffsetEndMs": 16820}, {"Word": "informative", "OffsetStartMs": 17110, "OffsetEndMs": 17745}, {"Word": "something", "OffsetStartMs": 17745, "OffsetEndMs": 18105}, {"Word": "meaningful", "OffsetStartMs": 18105, "OffsetEndMs": 18500}, {"Word": ".", "OffsetStartMs": 19300, "OffsetEndMs": 19560}, {"Word": "Andwe", "OffsetStartMs": 19560, "OffsetEndMs": 19740}, {"Word": "see", "OffsetStartMs": 19740, "OffsetEndMs": 19950}, {"Word": "that", "OffsetStartMs": 19950, "OffsetEndMs": 20160}, {"Word": "by", "OffsetStartMs": 20160, "OffsetEndMs": 20370}, {"Word": "this", "OffsetStartMs": 20370, "OffsetEndMs": 20580}, {"Word": "perturbation", "OffsetStartMs": 20580, "OffsetEndMs": 21140}, {"Word": "by", "OffsetStartMs": 21160, "OffsetEndMs": 21495}, {"Word": "this", "OffsetStartMs": 21495, "OffsetEndMs": 21780}, {"Word": "tuning", "OffsetStartMs": 21780, "OffsetEndMs": 22250}], "SpeechSpeed": 13.9}, {"FinalSentence": "In this example, the face, as you hopefully can appreciate, is shifting. The pose is shifting, and all this is driven by is the perturbation of a single latent variable.", "SliceSentence": "In this example the face as you hopefully can appreciate is shifting . Thepose is shifting and all this is driven by is the perturbation of a single latent variable", "StartMs": 1930040, "EndMs": 1941060, "WordsNum": 30, "Words": [{"Word": "In", "OffsetStartMs": 70, "OffsetEndMs": 345}, {"Word": "this", "OffsetStartMs": 345, "OffsetEndMs": 585}, {"Word": "example", "OffsetStartMs": 585, "OffsetEndMs": 950}, {"Word": "the", "OffsetStartMs": 1210, "OffsetEndMs": 1500}, {"Word": "face", "OffsetStartMs": 1500, "OffsetEndMs": 1790}, {"Word": "as", "OffsetStartMs": 1810, "OffsetEndMs": 2100}, {"Word": "you", "OffsetStartMs": 2100, "OffsetEndMs": 2280}, {"Word": "hopefully", "OffsetStartMs": 2280, "OffsetEndMs": 2550}, {"Word": "can", "OffsetStartMs": 2550, "OffsetEndMs": 2865}, {"Word": "appreciate", "OffsetStartMs": 2865, "OffsetEndMs": 3200}, {"Word": "is", "OffsetStartMs": 3580, "OffsetEndMs": 3930}, {"Word": "shifting", "OffsetStartMs": 3930, "OffsetEndMs": 4410}, {"Word": ".", "OffsetStartMs": 4410, "OffsetEndMs": 4605}, {"Word": "Thepose", "OffsetStartMs": 4605, "OffsetEndMs": 4890}, {"Word": "is", "OffsetStartMs": 4890, "OffsetEndMs": 5145}, {"Word": "shifting", "OffsetStartMs": 5145, "OffsetEndMs": 5660}, {"Word": "and", "OffsetStartMs": 5890, "OffsetEndMs": 6210}, {"Word": "all", "OffsetStartMs": 6210, "OffsetEndMs": 6465}, {"Word": "this", "OffsetStartMs": 6465, "OffsetEndMs": 6705}, {"Word": "is", "OffsetStartMs": 6705, "OffsetEndMs": 6945}, {"Word": "driven", "OffsetStartMs": 6945, "OffsetEndMs": 7245}, {"Word": "by", "OffsetStartMs": 7245, "OffsetEndMs": 7545}, {"Word": "is", "OffsetStartMs": 7545, "OffsetEndMs": 7770}, {"Word": "the", "OffsetStartMs": 7770, "OffsetEndMs": 7965}, {"Word": "perturbation", "OffsetStartMs": 7965, "OffsetEndMs": 8570}, {"Word": "of", "OffsetStartMs": 8590, "OffsetEndMs": 8850}, {"Word": "a", "OffsetStartMs": 8850, "OffsetEndMs": 9015}, {"Word": "single", "OffsetStartMs": 9015, "OffsetEndMs": 9320}, {"Word": "latent", "OffsetStartMs": 9520, "OffsetEndMs": 10005}, {"Word": "variable", "OffsetStartMs": 10005, "OffsetEndMs": 10310}], "SpeechSpeed": 14.8}, {"FinalSentence": "Tuning the value of that latent variable and seeing how that affects the decoded reconstruction.", "SliceSentence": "Tuning the value of that latent variable and seeing how that affects the decoded reconstruction", "StartMs": 1941120, "EndMs": 1947520, "WordsNum": 15, "Words": [{"Word": "Tuning", "OffsetStartMs": 160, "OffsetEndMs": 660}, {"Word": "the", "OffsetStartMs": 660, "OffsetEndMs": 840}, {"Word": "value", "OffsetStartMs": 840, "OffsetEndMs": 1080}, {"Word": "of", "OffsetStartMs": 1080, "OffsetEndMs": 1320}, {"Word": "that", "OffsetStartMs": 1320, "OffsetEndMs": 1485}, {"Word": "latent", "OffsetStartMs": 1485, "OffsetEndMs": 1830}, {"Word": "variable", "OffsetStartMs": 1830, "OffsetEndMs": 2120}, {"Word": "and", "OffsetStartMs": 2380, "OffsetEndMs": 2730}, {"Word": "seeing", "OffsetStartMs": 2730, "OffsetEndMs": 3060}, {"Word": "how", "OffsetStartMs": 3060, "OffsetEndMs": 3345}, {"Word": "that", "OffsetStartMs": 3345, "OffsetEndMs": 3615}, {"Word": "affects", "OffsetStartMs": 3615, "OffsetEndMs": 4130}, {"Word": "the", "OffsetStartMs": 4150, "OffsetEndMs": 4425}, {"Word": "decoded", "OffsetStartMs": 4425, "OffsetEndMs": 5025}, {"Word": "reconstruction", "OffsetStartMs": 5025, "OffsetEndMs": 5750}], "SpeechSpeed": 14.8}, {"FinalSentence": "The network is actually able to learn these different encoded features, these different latent variables, such that by perturbing the values of them individually, we can interpret and make sense of what those latent variables mean and what they represent.", "SliceSentence": "The network is actually able to learn these different encoded features these different latent variables such that by perturbing the values of them individually we can interpret and make sense of what those latent variables mean and what they represent", "StartMs": 1948060, "EndMs": 1966400, "WordsNum": 40, "Words": [{"Word": "The", "OffsetStartMs": 100, "OffsetEndMs": 390}, {"Word": "network", "OffsetStartMs": 390, "OffsetEndMs": 680}, {"Word": "is", "OffsetStartMs": 820, "OffsetEndMs": 1220}, {"Word": "actually", "OffsetStartMs": 1390, "OffsetEndMs": 1790}, {"Word": "able", "OffsetStartMs": 2050, "OffsetEndMs": 2450}, {"Word": "to", "OffsetStartMs": 2470, "OffsetEndMs": 2760}, {"Word": "learn", "OffsetStartMs": 2760, "OffsetEndMs": 3000}, {"Word": "these", "OffsetStartMs": 3000, "OffsetEndMs": 3285}, {"Word": "different", "OffsetStartMs": 3285, "OffsetEndMs": 3620}, {"Word": "encoded", "OffsetStartMs": 3790, "OffsetEndMs": 4485}, {"Word": "features", "OffsetStartMs": 4485, "OffsetEndMs": 4790}, {"Word": "these", "OffsetStartMs": 4840, "OffsetEndMs": 5190}, {"Word": "different", "OffsetStartMs": 5190, "OffsetEndMs": 5520}, {"Word": "latent", "OffsetStartMs": 5520, "OffsetEndMs": 5940}, {"Word": "variables", "OffsetStartMs": 5940, "OffsetEndMs": 6560}, {"Word": "such", "OffsetStartMs": 7150, "OffsetEndMs": 7485}, {"Word": "that", "OffsetStartMs": 7485, "OffsetEndMs": 7785}, {"Word": "by", "OffsetStartMs": 7785, "OffsetEndMs": 8100}, {"Word": "perturbing", "OffsetStartMs": 8100, "OffsetEndMs": 8900}, {"Word": "the", "OffsetStartMs": 9040, "OffsetEndMs": 9315}, {"Word": "values", "OffsetStartMs": 9315, "OffsetEndMs": 9590}, {"Word": "of", "OffsetStartMs": 9640, "OffsetEndMs": 9915}, {"Word": "them", "OffsetStartMs": 9915, "OffsetEndMs": 10190}, {"Word": "individually", "OffsetStartMs": 10270, "OffsetEndMs": 10850}, {"Word": "we", "OffsetStartMs": 11440, "OffsetEndMs": 11715}, {"Word": "can", "OffsetStartMs": 11715, "OffsetEndMs": 11990}, {"Word": "interpret", "OffsetStartMs": 12070, "OffsetEndMs": 12470}, {"Word": "and", "OffsetStartMs": 12910, "OffsetEndMs": 13200}, {"Word": "make", "OffsetStartMs": 13200, "OffsetEndMs": 13440}, {"Word": "sense", "OffsetStartMs": 13440, "OffsetEndMs": 13785}, {"Word": "of", "OffsetStartMs": 13785, "OffsetEndMs": 14115}, {"Word": "what", "OffsetStartMs": 14115, "OffsetEndMs": 14370}, {"Word": "those", "OffsetStartMs": 14370, "OffsetEndMs": 14595}, {"Word": "latent", "OffsetStartMs": 14595, "OffsetEndMs": 14955}, {"Word": "variables", "OffsetStartMs": 14955, "OffsetEndMs": 15465}, {"Word": "mean", "OffsetStartMs": 15465, "OffsetEndMs": 15800}, {"Word": "and", "OffsetStartMs": 16000, "OffsetEndMs": 16305}, {"Word": "what", "OffsetStartMs": 16305, "OffsetEndMs": 16515}, {"Word": "they", "OffsetStartMs": 16515, "OffsetEndMs": 16695}, {"Word": "represent", "OffsetStartMs": 16695, "OffsetEndMs": 16970}], "SpeechSpeed": 13.7}, {"FinalSentence": "To make this more concrete, we can consider even multiple latent variables simultaneously, compare one against the other, and ideally, we want those latent features to be as independent as possible in order to get at the most compact and richest representation and compact encoding.", "SliceSentence": "To make this more concrete we can consider even multiple latent variables simultaneously compare one against the other and ideally we want those latent features to be as independent as possible in order to get at the most compact and richest representation and compact encoding", "StartMs": 1966620, "EndMs": 1988320, "WordsNum": 45, "Words": [{"Word": "To", "OffsetStartMs": 130, "OffsetEndMs": 390}, {"Word": "make", "OffsetStartMs": 390, "OffsetEndMs": 555}, {"Word": "this", "OffsetStartMs": 555, "OffsetEndMs": 860}, {"Word": "more", "OffsetStartMs": 1180, "OffsetEndMs": 1580}, {"Word": "concrete", "OffsetStartMs": 1600, "OffsetEndMs": 2000}, {"Word": "we", "OffsetStartMs": 3100, "OffsetEndMs": 3375}, {"Word": "can", "OffsetStartMs": 3375, "OffsetEndMs": 3630}, {"Word": "consider", "OffsetStartMs": 3630, "OffsetEndMs": 3930}, {"Word": "even", "OffsetStartMs": 3930, "OffsetEndMs": 4230}, {"Word": "multiple", "OffsetStartMs": 4230, "OffsetEndMs": 4610}, {"Word": "latent", "OffsetStartMs": 5080, "OffsetEndMs": 5535}, {"Word": "variables", "OffsetStartMs": 5535, "OffsetEndMs": 6110}, {"Word": "simultaneously", "OffsetStartMs": 6160, "OffsetEndMs": 7275}, {"Word": "compare", "OffsetStartMs": 7275, "OffsetEndMs": 7620}, {"Word": "one", "OffsetStartMs": 7620, "OffsetEndMs": 7970}, {"Word": "against", "OffsetStartMs": 7990, "OffsetEndMs": 8325}, {"Word": "the", "OffsetStartMs": 8325, "OffsetEndMs": 8505}, {"Word": "other", "OffsetStartMs": 8505, "OffsetEndMs": 8750}, {"Word": "and", "OffsetStartMs": 9310, "OffsetEndMs": 9615}, {"Word": "ideally", "OffsetStartMs": 9615, "OffsetEndMs": 10290}, {"Word": "we", "OffsetStartMs": 10290, "OffsetEndMs": 10485}, {"Word": "want", "OffsetStartMs": 10485, "OffsetEndMs": 10725}, {"Word": "those", "OffsetStartMs": 10725, "OffsetEndMs": 10980}, {"Word": "latent", "OffsetStartMs": 10980, "OffsetEndMs": 11415}, {"Word": "features", "OffsetStartMs": 11415, "OffsetEndMs": 11780}, {"Word": "to", "OffsetStartMs": 11890, "OffsetEndMs": 12150}, {"Word": "be", "OffsetStartMs": 12150, "OffsetEndMs": 12345}, {"Word": "as", "OffsetStartMs": 12345, "OffsetEndMs": 12680}, {"Word": "independent", "OffsetStartMs": 13060, "OffsetEndMs": 13460}, {"Word": "as", "OffsetStartMs": 13480, "OffsetEndMs": 13800}, {"Word": "possible", "OffsetStartMs": 13800, "OffsetEndMs": 14120}, {"Word": "in", "OffsetStartMs": 14650, "OffsetEndMs": 14970}, {"Word": "order", "OffsetStartMs": 14970, "OffsetEndMs": 15290}, {"Word": "to", "OffsetStartMs": 15340, "OffsetEndMs": 15690}, {"Word": "get", "OffsetStartMs": 15690, "OffsetEndMs": 15930}, {"Word": "at", "OffsetStartMs": 15930, "OffsetEndMs": 16110}, {"Word": "the", "OffsetStartMs": 16110, "OffsetEndMs": 16275}, {"Word": "most", "OffsetStartMs": 16275, "OffsetEndMs": 16550}, {"Word": "compact", "OffsetStartMs": 16990, "OffsetEndMs": 17625}, {"Word": "and", "OffsetStartMs": 17625, "OffsetEndMs": 17895}, {"Word": "richest", "OffsetStartMs": 17895, "OffsetEndMs": 18375}, {"Word": "representation", "OffsetStartMs": 18375, "OffsetEndMs": 19250}, {"Word": "and", "OffsetStartMs": 19570, "OffsetEndMs": 19965}, {"Word": "compact", "OffsetStartMs": 19965, "OffsetEndMs": 20460}, {"Word": "encoding", "OffsetStartMs": 20460, "OffsetEndMs": 21140}], "SpeechSpeed": 12.8}, {"FinalSentence": "So here again, in this example of faces, we're walking along two axes.", "SliceSentence": "So here again in this example of faces we 're walking along two axes", "StartMs": 1988320, "EndMs": 1993940, "WordsNum": 14, "Words": [{"Word": "So", "OffsetStartMs": 0, "OffsetEndMs": 285}, {"Word": "here", "OffsetStartMs": 285, "OffsetEndMs": 590}, {"Word": "again", "OffsetStartMs": 730, "OffsetEndMs": 1035}, {"Word": "in", "OffsetStartMs": 1035, "OffsetEndMs": 1215}, {"Word": "this", "OffsetStartMs": 1215, "OffsetEndMs": 1455}, {"Word": "example", "OffsetStartMs": 1455, "OffsetEndMs": 1770}, {"Word": "of", "OffsetStartMs": 1770, "OffsetEndMs": 1995}, {"Word": "faces", "OffsetStartMs": 1995, "OffsetEndMs": 2270}, {"Word": "we", "OffsetStartMs": 2710, "OffsetEndMs": 2940}, {"Word": "'re", "OffsetStartMs": 2940, "OffsetEndMs": 3030}, {"Word": "walking", "OffsetStartMs": 3030, "OffsetEndMs": 3290}, {"Word": "along", "OffsetStartMs": 3400, "OffsetEndMs": 3800}, {"Word": "two", "OffsetStartMs": 3820, "OffsetEndMs": 4125}, {"Word": "axes", "OffsetStartMs": 4125, "OffsetEndMs": 4700}], "SpeechSpeed": 11.9}, {"FinalSentence": "Head pose on the X axis and what appears to be kind of a notion of a smile on the y axis.", "SliceSentence": "Head pose on the X axis and what appears to be kind of a notion of a smile on the y axis", "StartMs": 1993940, "EndMs": 2001640, "WordsNum": 22, "Words": [{"Word": "Head", "OffsetStartMs": 0, "OffsetEndMs": 270}, {"Word": "pose", "OffsetStartMs": 270, "OffsetEndMs": 615}, {"Word": "on", "OffsetStartMs": 615, "OffsetEndMs": 930}, {"Word": "the", "OffsetStartMs": 930, "OffsetEndMs": 1125}, {"Word": "X", "OffsetStartMs": 1125, "OffsetEndMs": 1335}, {"Word": "axis", "OffsetStartMs": 1335, "OffsetEndMs": 1940}, {"Word": "and", "OffsetStartMs": 2320, "OffsetEndMs": 2685}, {"Word": "what", "OffsetStartMs": 2685, "OffsetEndMs": 3050}, {"Word": "appears", "OffsetStartMs": 3100, "OffsetEndMs": 3465}, {"Word": "to", "OffsetStartMs": 3465, "OffsetEndMs": 3690}, {"Word": "be", "OffsetStartMs": 3690, "OffsetEndMs": 3950}, {"Word": "kind", "OffsetStartMs": 4360, "OffsetEndMs": 4635}, {"Word": "of", "OffsetStartMs": 4635, "OffsetEndMs": 4755}, {"Word": "a", "OffsetStartMs": 4755, "OffsetEndMs": 4935}, {"Word": "notion", "OffsetStartMs": 4935, "OffsetEndMs": 5220}, {"Word": "of", "OffsetStartMs": 5220, "OffsetEndMs": 5415}, {"Word": "a", "OffsetStartMs": 5415, "OffsetEndMs": 5595}, {"Word": "smile", "OffsetStartMs": 5595, "OffsetEndMs": 5910}, {"Word": "on", "OffsetStartMs": 5910, "OffsetEndMs": 6180}, {"Word": "the", "OffsetStartMs": 6180, "OffsetEndMs": 6330}, {"Word": "y", "OffsetStartMs": 6330, "OffsetEndMs": 6525}, {"Word": "axis", "OffsetStartMs": 6525, "OffsetEndMs": 7130}], "SpeechSpeed": 11.4}, {"FinalSentence": "And you can see that with these reconstructions, we can actually perturb these features to be able to perturb the end effect in the reconstructed space.", "SliceSentence": "And you can see that with these reconstructions we can actually perturb these features to be able to perturb the end effect in the reconstructed space", "StartMs": 2001640, "EndMs": 2014020, "WordsNum": 26, "Words": [{"Word": "And", "OffsetStartMs": 10, "OffsetEndMs": 285}, {"Word": "you", "OffsetStartMs": 285, "OffsetEndMs": 420}, {"Word": "can", "OffsetStartMs": 420, "OffsetEndMs": 585}, {"Word": "see", "OffsetStartMs": 585, "OffsetEndMs": 795}, {"Word": "that", "OffsetStartMs": 795, "OffsetEndMs": 1100}, {"Word": "with", "OffsetStartMs": 1270, "OffsetEndMs": 1575}, {"Word": "these", "OffsetStartMs": 1575, "OffsetEndMs": 1785}, {"Word": "reconstructions", "OffsetStartMs": 1785, "OffsetEndMs": 2720}, {"Word": "we", "OffsetStartMs": 3040, "OffsetEndMs": 3330}, {"Word": "can", "OffsetStartMs": 3330, "OffsetEndMs": 3620}, {"Word": "actually", "OffsetStartMs": 3670, "OffsetEndMs": 3975}, {"Word": "perturb", "OffsetStartMs": 3975, "OffsetEndMs": 4470}, {"Word": "these", "OffsetStartMs": 4470, "OffsetEndMs": 4680}, {"Word": "features", "OffsetStartMs": 4680, "OffsetEndMs": 5030}, {"Word": "to", "OffsetStartMs": 5440, "OffsetEndMs": 5685}, {"Word": "be", "OffsetStartMs": 5685, "OffsetEndMs": 5835}, {"Word": "able", "OffsetStartMs": 5835, "OffsetEndMs": 6140}, {"Word": "to", "OffsetStartMs": 6340, "OffsetEndMs": 6645}, {"Word": "perturb", "OffsetStartMs": 6645, "OffsetEndMs": 7370}, {"Word": "the", "OffsetStartMs": 7420, "OffsetEndMs": 7695}, {"Word": "end", "OffsetStartMs": 7695, "OffsetEndMs": 7965}, {"Word": "effect", "OffsetStartMs": 7965, "OffsetEndMs": 8360}, {"Word": "in", "OffsetStartMs": 8590, "OffsetEndMs": 8925}, {"Word": "the", "OffsetStartMs": 8925, "OffsetEndMs": 9260}, {"Word": "reconstructed", "OffsetStartMs": 9850, "OffsetEndMs": 10785}, {"Word": "space", "OffsetStartMs": 10785, "OffsetEndMs": 11120}], "SpeechSpeed": 12.1}, {"FinalSentence": "And so ultimately, with with AV, our goal is to try to enforce as much information to be captured in that encoding as possible. We want these latent features to be independent and ideally disentangled.", "SliceSentence": "And so ultimately with with AV our goal is to try to enforce as much information to be captured in that encoding as possible . Wewant these latent features to be independent and ideally disentangled", "StartMs": 2014320, "EndMs": 2029400, "WordsNum": 35, "Words": [{"Word": "And", "OffsetStartMs": 130, "OffsetEndMs": 435}, {"Word": "so", "OffsetStartMs": 435, "OffsetEndMs": 740}, {"Word": "ultimately", "OffsetStartMs": 1000, "OffsetEndMs": 1400}, {"Word": "with", "OffsetStartMs": 1480, "OffsetEndMs": 1880}, {"Word": "with", "OffsetStartMs": 2050, "OffsetEndMs": 2340}, {"Word": "AV", "OffsetStartMs": 2490, "OffsetEndMs": 2750}, {"Word": "our", "OffsetStartMs": 2890, "OffsetEndMs": 3225}, {"Word": "goal", "OffsetStartMs": 3225, "OffsetEndMs": 3555}, {"Word": "is", "OffsetStartMs": 3555, "OffsetEndMs": 3855}, {"Word": "to", "OffsetStartMs": 3855, "OffsetEndMs": 4065}, {"Word": "try", "OffsetStartMs": 4065, "OffsetEndMs": 4305}, {"Word": "to", "OffsetStartMs": 4305, "OffsetEndMs": 4605}, {"Word": "enforce", "OffsetStartMs": 4605, "OffsetEndMs": 4970}, {"Word": "as", "OffsetStartMs": 5260, "OffsetEndMs": 5610}, {"Word": "much", "OffsetStartMs": 5610, "OffsetEndMs": 5960}, {"Word": "information", "OffsetStartMs": 6070, "OffsetEndMs": 6470}, {"Word": "to", "OffsetStartMs": 6550, "OffsetEndMs": 6795}, {"Word": "be", "OffsetStartMs": 6795, "OffsetEndMs": 6960}, {"Word": "captured", "OffsetStartMs": 6960, "OffsetEndMs": 7280}, {"Word": "in", "OffsetStartMs": 7330, "OffsetEndMs": 7605}, {"Word": "that", "OffsetStartMs": 7605, "OffsetEndMs": 7755}, {"Word": "encoding", "OffsetStartMs": 7755, "OffsetEndMs": 8280}, {"Word": "as", "OffsetStartMs": 8280, "OffsetEndMs": 8430}, {"Word": "possible", "OffsetStartMs": 8430, "OffsetEndMs": 8720}, {"Word": ".", "OffsetStartMs": 9430, "OffsetEndMs": 9735}, {"Word": "Wewant", "OffsetStartMs": 9735, "OffsetEndMs": 9990}, {"Word": "these", "OffsetStartMs": 9990, "OffsetEndMs": 10275}, {"Word": "latent", "OffsetStartMs": 10275, "OffsetEndMs": 10680}, {"Word": "features", "OffsetStartMs": 10680, "OffsetEndMs": 10970}, {"Word": "to", "OffsetStartMs": 11020, "OffsetEndMs": 11295}, {"Word": "be", "OffsetStartMs": 11295, "OffsetEndMs": 11570}, {"Word": "independent", "OffsetStartMs": 11770, "OffsetEndMs": 12170}, {"Word": "and", "OffsetStartMs": 12490, "OffsetEndMs": 12795}, {"Word": "ideally", "OffsetStartMs": 12795, "OffsetEndMs": 13520}, {"Word": "disentangled", "OffsetStartMs": 13570, "OffsetEndMs": 14600}], "SpeechSpeed": 13.1}, {"FinalSentence": "It turns out that there is a very clever and simple way to try to encourage this independence and this disentanglement.", "SliceSentence": "It turns out that there is a very clever and simple way to try to encourage this independence and this disentanglement", "StartMs": 2030020, "EndMs": 2039600, "WordsNum": 21, "Words": [{"Word": "It", "OffsetStartMs": 100, "OffsetEndMs": 390}, {"Word": "turns", "OffsetStartMs": 390, "OffsetEndMs": 600}, {"Word": "out", "OffsetStartMs": 600, "OffsetEndMs": 840}, {"Word": "that", "OffsetStartMs": 840, "OffsetEndMs": 1065}, {"Word": "there", "OffsetStartMs": 1065, "OffsetEndMs": 1245}, {"Word": "is", "OffsetStartMs": 1245, "OffsetEndMs": 1395}, {"Word": "a", "OffsetStartMs": 1395, "OffsetEndMs": 1560}, {"Word": "very", "OffsetStartMs": 1560, "OffsetEndMs": 1850}, {"Word": "clever", "OffsetStartMs": 2860, "OffsetEndMs": 3180}, {"Word": "and", "OffsetStartMs": 3180, "OffsetEndMs": 3420}, {"Word": "simple", "OffsetStartMs": 3420, "OffsetEndMs": 3720}, {"Word": "way", "OffsetStartMs": 3720, "OffsetEndMs": 4065}, {"Word": "to", "OffsetStartMs": 4065, "OffsetEndMs": 4395}, {"Word": "try", "OffsetStartMs": 4395, "OffsetEndMs": 4760}, {"Word": "to", "OffsetStartMs": 4780, "OffsetEndMs": 5180}, {"Word": "encourage", "OffsetStartMs": 5830, "OffsetEndMs": 6230}, {"Word": "this", "OffsetStartMs": 6520, "OffsetEndMs": 6920}, {"Word": "independence", "OffsetStartMs": 7000, "OffsetEndMs": 7400}, {"Word": "and", "OffsetStartMs": 7450, "OffsetEndMs": 7755}, {"Word": "this", "OffsetStartMs": 7755, "OffsetEndMs": 7965}, {"Word": "disentanglement", "OffsetStartMs": 7965, "OffsetEndMs": 8900}], "SpeechSpeed": 12.3}, {"FinalSentence": "While this may look a little complicated with the math and a bit scary, I will break this down with the idea of how a very simple concept enforces this independent latent encoding and this disentanglement.", "SliceSentence": "While this may look a little complicated with the math and a bit scary I will break this down with the idea of how a very simple concept enforces this independent latent encoding and this disentanglement", "StartMs": 2039880, "EndMs": 2055680, "WordsNum": 36, "Words": [{"Word": "While", "OffsetStartMs": 100, "OffsetEndMs": 405}, {"Word": "this", "OffsetStartMs": 405, "OffsetEndMs": 600}, {"Word": "may", "OffsetStartMs": 600, "OffsetEndMs": 795}, {"Word": "look", "OffsetStartMs": 795, "OffsetEndMs": 975}, {"Word": "a", "OffsetStartMs": 975, "OffsetEndMs": 1110}, {"Word": "little", "OffsetStartMs": 1110, "OffsetEndMs": 1320}, {"Word": "complicated", "OffsetStartMs": 1320, "OffsetEndMs": 1670}, {"Word": "with", "OffsetStartMs": 1900, "OffsetEndMs": 2300}, {"Word": "the", "OffsetStartMs": 2440, "OffsetEndMs": 2700}, {"Word": "math", "OffsetStartMs": 2700, "OffsetEndMs": 2940}, {"Word": "and", "OffsetStartMs": 2940, "OffsetEndMs": 3320}, {"Word": "a", "OffsetStartMs": 3340, "OffsetEndMs": 3600}, {"Word": "bit", "OffsetStartMs": 3600, "OffsetEndMs": 3810}, {"Word": "scary", "OffsetStartMs": 3810, "OffsetEndMs": 4160}, {"Word": "I", "OffsetStartMs": 4690, "OffsetEndMs": 5070}, {"Word": "will", "OffsetStartMs": 5070, "OffsetEndMs": 5450}, {"Word": "break", "OffsetStartMs": 5890, "OffsetEndMs": 6195}, {"Word": "this", "OffsetStartMs": 6195, "OffsetEndMs": 6405}, {"Word": "down", "OffsetStartMs": 6405, "OffsetEndMs": 6710}, {"Word": "with", "OffsetStartMs": 6820, "OffsetEndMs": 7155}, {"Word": "the", "OffsetStartMs": 7155, "OffsetEndMs": 7470}, {"Word": "idea", "OffsetStartMs": 7470, "OffsetEndMs": 7830}, {"Word": "of", "OffsetStartMs": 7830, "OffsetEndMs": 8210}, {"Word": "how", "OffsetStartMs": 8410, "OffsetEndMs": 8810}, {"Word": "a", "OffsetStartMs": 8980, "OffsetEndMs": 9285}, {"Word": "very", "OffsetStartMs": 9285, "OffsetEndMs": 9540}, {"Word": "simple", "OffsetStartMs": 9540, "OffsetEndMs": 9840}, {"Word": "concept", "OffsetStartMs": 9840, "OffsetEndMs": 10190}, {"Word": "enforces", "OffsetStartMs": 10870, "OffsetEndMs": 11700}, {"Word": "this", "OffsetStartMs": 11700, "OffsetEndMs": 12020}, {"Word": "independent", "OffsetStartMs": 12280, "OffsetEndMs": 12680}, {"Word": "latent", "OffsetStartMs": 13030, "OffsetEndMs": 13470}, {"Word": "encoding", "OffsetStartMs": 13470, "OffsetEndMs": 13965}, {"Word": "and", "OffsetStartMs": 13965, "OffsetEndMs": 14130}, {"Word": "this", "OffsetStartMs": 14130, "OffsetEndMs": 14400}, {"Word": "disentanglement", "OffsetStartMs": 14400, "OffsetEndMs": 15380}], "SpeechSpeed": 12.8}, {"FinalSentence": "All this term is showing is those two components of the loss, the reconstruction term, the regularization term. That's what I want you to focus on.", "SliceSentence": "All this term is showing is those two components of the loss the reconstruction term the regularization term .That's what I want you to focus on", "StartMs": 2056100, "EndMs": 2065100, "WordsNum": 26, "Words": [{"Word": "All", "OffsetStartMs": 100, "OffsetEndMs": 405}, {"Word": "this", "OffsetStartMs": 405, "OffsetEndMs": 615}, {"Word": "term", "OffsetStartMs": 615, "OffsetEndMs": 795}, {"Word": "is", "OffsetStartMs": 795, "OffsetEndMs": 975}, {"Word": "showing", "OffsetStartMs": 975, "OffsetEndMs": 1280}, {"Word": "is", "OffsetStartMs": 1330, "OffsetEndMs": 1680}, {"Word": "those", "OffsetStartMs": 1680, "OffsetEndMs": 1980}, {"Word": "two", "OffsetStartMs": 1980, "OffsetEndMs": 2310}, {"Word": "components", "OffsetStartMs": 2310, "OffsetEndMs": 2685}, {"Word": "of", "OffsetStartMs": 2685, "OffsetEndMs": 2955}, {"Word": "the", "OffsetStartMs": 2955, "OffsetEndMs": 3090}, {"Word": "loss", "OffsetStartMs": 3090, "OffsetEndMs": 3350}, {"Word": "the", "OffsetStartMs": 3820, "OffsetEndMs": 4080}, {"Word": "reconstruction", "OffsetStartMs": 4080, "OffsetEndMs": 4695}, {"Word": "term", "OffsetStartMs": 4695, "OffsetEndMs": 5090}, {"Word": "the", "OffsetStartMs": 5290, "OffsetEndMs": 5550}, {"Word": "regularization", "OffsetStartMs": 5550, "OffsetEndMs": 6255}, {"Word": "term", "OffsetStartMs": 6255, "OffsetEndMs": 6650}, {"Word": ".That's", "OffsetStartMs": 6880, "OffsetEndMs": 7275}, {"Word": "what", "OffsetStartMs": 7275, "OffsetEndMs": 7365}, {"Word": "I", "OffsetStartMs": 7365, "OffsetEndMs": 7485}, {"Word": "want", "OffsetStartMs": 7485, "OffsetEndMs": 7620}, {"Word": "you", "OffsetStartMs": 7620, "OffsetEndMs": 7755}, {"Word": "to", "OffsetStartMs": 7755, "OffsetEndMs": 7890}, {"Word": "focus", "OffsetStartMs": 7890, "OffsetEndMs": 8085}, {"Word": "on", "OffsetStartMs": 8085, "OffsetEndMs": 8420}], "SpeechSpeed": 15.9}, {"FinalSentence": "The idea of latent space disentanglement really arose with this concept of Beta Beta ves.", "SliceSentence": "The idea of latent space disentanglement really arose with this concept of Beta Beta ves", "StartMs": 2065600, "EndMs": 2074300, "WordsNum": 15, "Words": [{"Word": "The", "OffsetStartMs": 100, "OffsetEndMs": 480}, {"Word": "idea", "OffsetStartMs": 480, "OffsetEndMs": 860}, {"Word": "of", "OffsetStartMs": 880, "OffsetEndMs": 1280}, {"Word": "latent", "OffsetStartMs": 1720, "OffsetEndMs": 2220}, {"Word": "space", "OffsetStartMs": 2220, "OffsetEndMs": 2520}, {"Word": "disentanglement", "OffsetStartMs": 2520, "OffsetEndMs": 3480}, {"Word": "really", "OffsetStartMs": 3480, "OffsetEndMs": 3780}, {"Word": "arose", "OffsetStartMs": 3780, "OffsetEndMs": 4320}, {"Word": "with", "OffsetStartMs": 4320, "OffsetEndMs": 4485}, {"Word": "this", "OffsetStartMs": 4485, "OffsetEndMs": 4680}, {"Word": "concept", "OffsetStartMs": 4680, "OffsetEndMs": 5000}, {"Word": "of", "OffsetStartMs": 5320, "OffsetEndMs": 5715}, {"Word": "Beta", "OffsetStartMs": 5715, "OffsetEndMs": 6320}, {"Word": "Beta", "OffsetStartMs": 6700, "OffsetEndMs": 7245}, {"Word": "ves", "OffsetStartMs": 7245, "OffsetEndMs": 7940}], "SpeechSpeed": 10.1}, {"FinalSentence": "What Beta vas do is they introduce this parameter Beta and what it is it's awaiting constant, the awaiting constant controls, how powerful that regularization term is in the overall loss of the v.", "SliceSentence": "What Beta vas do is they introduce this parameter Beta and what it is it's awaiting constant the awaiting constant controls how powerful that regularization term is in the overall loss of the v", "StartMs": 2074300, "EndMs": 2090560, "WordsNum": 34, "Words": [{"Word": "What", "OffsetStartMs": 10, "OffsetEndMs": 300}, {"Word": "Beta", "OffsetStartMs": 300, "OffsetEndMs": 645}, {"Word": "vas", "OffsetStartMs": 645, "OffsetEndMs": 980}, {"Word": "do", "OffsetStartMs": 1030, "OffsetEndMs": 1430}, {"Word": "is", "OffsetStartMs": 1720, "OffsetEndMs": 2025}, {"Word": "they", "OffsetStartMs": 2025, "OffsetEndMs": 2330}, {"Word": "introduce", "OffsetStartMs": 2440, "OffsetEndMs": 2775}, {"Word": "this", "OffsetStartMs": 2775, "OffsetEndMs": 3045}, {"Word": "parameter", "OffsetStartMs": 3045, "OffsetEndMs": 3615}, {"Word": "Beta", "OffsetStartMs": 3615, "OffsetEndMs": 4160}, {"Word": "and", "OffsetStartMs": 4660, "OffsetEndMs": 5010}, {"Word": "what", "OffsetStartMs": 5010, "OffsetEndMs": 5220}, {"Word": "it", "OffsetStartMs": 5220, "OffsetEndMs": 5340}, {"Word": "is", "OffsetStartMs": 5340, "OffsetEndMs": 5565}, {"Word": "it's", "OffsetStartMs": 5565, "OffsetEndMs": 6080}, {"Word": "awaiting", "OffsetStartMs": 6190, "OffsetEndMs": 6675}, {"Word": "constant", "OffsetStartMs": 6675, "OffsetEndMs": 6980}, {"Word": "the", "OffsetStartMs": 7690, "OffsetEndMs": 7980}, {"Word": "awaiting", "OffsetStartMs": 7980, "OffsetEndMs": 8340}, {"Word": "constant", "OffsetStartMs": 8340, "OffsetEndMs": 8630}, {"Word": "controls", "OffsetStartMs": 9640, "OffsetEndMs": 10040}, {"Word": "how", "OffsetStartMs": 10210, "OffsetEndMs": 10590}, {"Word": "powerful", "OffsetStartMs": 10590, "OffsetEndMs": 10970}, {"Word": "that", "OffsetStartMs": 11170, "OffsetEndMs": 11460}, {"Word": "regularization", "OffsetStartMs": 11460, "OffsetEndMs": 12230}, {"Word": "term", "OffsetStartMs": 12250, "OffsetEndMs": 12650}, {"Word": "is", "OffsetStartMs": 12850, "OffsetEndMs": 13245}, {"Word": "in", "OffsetStartMs": 13245, "OffsetEndMs": 13515}, {"Word": "the", "OffsetStartMs": 13515, "OffsetEndMs": 13665}, {"Word": "overall", "OffsetStartMs": 13665, "OffsetEndMs": 13940}, {"Word": "loss", "OffsetStartMs": 14110, "OffsetEndMs": 14490}, {"Word": "of", "OffsetStartMs": 14490, "OffsetEndMs": 14745}, {"Word": "the", "OffsetStartMs": 14745, "OffsetEndMs": 14895}, {"Word": "v", "OffsetStartMs": 14895, "OffsetEndMs": 15170}], "SpeechSpeed": 11.9}, {"FinalSentence": "And it turns out that by increasing the value of Beta, you can try to encourage greater disentanglement, more efficient encoding to enforce these latent variables to be uncorrelated with each other.", "SliceSentence": "And it turns out that by increasing the value of Beta you can try to encourage greater disentanglement more efficient encoding to enforce these latent variables to be uncorrelated with each other", "StartMs": 2090560, "EndMs": 2105160, "WordsNum": 32, "Words": [{"Word": "And", "OffsetStartMs": 0, "OffsetEndMs": 180}, {"Word": "it", "OffsetStartMs": 180, "OffsetEndMs": 360}, {"Word": "turns", "OffsetStartMs": 360, "OffsetEndMs": 615}, {"Word": "out", "OffsetStartMs": 615, "OffsetEndMs": 915}, {"Word": "that", "OffsetStartMs": 915, "OffsetEndMs": 1185}, {"Word": "by", "OffsetStartMs": 1185, "OffsetEndMs": 1490}, {"Word": "increasing", "OffsetStartMs": 1660, "OffsetEndMs": 2055}, {"Word": "the", "OffsetStartMs": 2055, "OffsetEndMs": 2310}, {"Word": "value", "OffsetStartMs": 2310, "OffsetEndMs": 2550}, {"Word": "of", "OffsetStartMs": 2550, "OffsetEndMs": 2820}, {"Word": "Beta", "OffsetStartMs": 2820, "OffsetEndMs": 3320}, {"Word": "you", "OffsetStartMs": 3730, "OffsetEndMs": 4005}, {"Word": "can", "OffsetStartMs": 4005, "OffsetEndMs": 4230}, {"Word": "try", "OffsetStartMs": 4230, "OffsetEndMs": 4560}, {"Word": "to", "OffsetStartMs": 4560, "OffsetEndMs": 4940}, {"Word": "encourage", "OffsetStartMs": 5110, "OffsetEndMs": 5510}, {"Word": "greater", "OffsetStartMs": 6100, "OffsetEndMs": 6480}, {"Word": "disentanglement", "OffsetStartMs": 6480, "OffsetEndMs": 7550}, {"Word": "more", "OffsetStartMs": 7960, "OffsetEndMs": 8355}, {"Word": "efficient", "OffsetStartMs": 8355, "OffsetEndMs": 8670}, {"Word": "encoding", "OffsetStartMs": 8670, "OffsetEndMs": 9270}, {"Word": "to", "OffsetStartMs": 9270, "OffsetEndMs": 9590}, {"Word": "enforce", "OffsetStartMs": 9940, "OffsetEndMs": 10340}, {"Word": "these", "OffsetStartMs": 10360, "OffsetEndMs": 10680}, {"Word": "latent", "OffsetStartMs": 10680, "OffsetEndMs": 11040}, {"Word": "variables", "OffsetStartMs": 11040, "OffsetEndMs": 11565}, {"Word": "to", "OffsetStartMs": 11565, "OffsetEndMs": 11760}, {"Word": "be", "OffsetStartMs": 11760, "OffsetEndMs": 12020}, {"Word": "uncorrelated", "OffsetStartMs": 12340, "OffsetEndMs": 13170}, {"Word": "with", "OffsetStartMs": 13170, "OffsetEndMs": 13410}, {"Word": "each", "OffsetStartMs": 13410, "OffsetEndMs": 13590}, {"Word": "other", "OffsetStartMs": 13590, "OffsetEndMs": 13880}], "SpeechSpeed": 13.4}, {"FinalSentence": "Now, if you're interested in mathematically why Beta v enforce this disentanglement there are many papers in the literature and proofs and discussions as to why this occurs, and we can point you in those directions, but to get a sense of what this actually affects downstream when we look at face reconstruction as a task of interest with a standard v no Beta term, or rather a Beta of one.", "SliceSentence": "Now if you're interested in mathematically why Beta v enforce this disentanglement there are many papers in the literature and proofs and discussions as to why this occurs and we can point you in those directions but to get a sense of what this actually affects downstream when we look at face reconstruction as a task of interest with a standard v no Beta term or rather a Beta of one", "StartMs": 2105400, "EndMs": 2134420, "WordsNum": 71, "Words": [{"Word": "Now", "OffsetStartMs": 130, "OffsetEndMs": 530}, {"Word": "if", "OffsetStartMs": 880, "OffsetEndMs": 1185}, {"Word": "you're", "OffsetStartMs": 1185, "OffsetEndMs": 1580}, {"Word": "interested", "OffsetStartMs": 1660, "OffsetEndMs": 1995}, {"Word": "in", "OffsetStartMs": 1995, "OffsetEndMs": 2330}, {"Word": "mathematically", "OffsetStartMs": 2680, "OffsetEndMs": 3350}, {"Word": "why", "OffsetStartMs": 3490, "OffsetEndMs": 3890}, {"Word": "Beta", "OffsetStartMs": 4750, "OffsetEndMs": 5175}, {"Word": "v", "OffsetStartMs": 5175, "OffsetEndMs": 5450}, {"Word": "enforce", "OffsetStartMs": 5770, "OffsetEndMs": 6120}, {"Word": "this", "OffsetStartMs": 6120, "OffsetEndMs": 6450}, {"Word": "disentanglement", "OffsetStartMs": 6450, "OffsetEndMs": 7365}, {"Word": "there", "OffsetStartMs": 7365, "OffsetEndMs": 7500}, {"Word": "are", "OffsetStartMs": 7500, "OffsetEndMs": 7620}, {"Word": "many", "OffsetStartMs": 7620, "OffsetEndMs": 7910}, {"Word": "papers", "OffsetStartMs": 8110, "OffsetEndMs": 8505}, {"Word": "in", "OffsetStartMs": 8505, "OffsetEndMs": 8760}, {"Word": "the", "OffsetStartMs": 8760, "OffsetEndMs": 8880}, {"Word": "literature", "OffsetStartMs": 8880, "OffsetEndMs": 9140}, {"Word": "and", "OffsetStartMs": 9250, "OffsetEndMs": 9650}, {"Word": "proofs", "OffsetStartMs": 9820, "OffsetEndMs": 10290}, {"Word": "and", "OffsetStartMs": 10290, "OffsetEndMs": 10545}, {"Word": "discussions", "OffsetStartMs": 10545, "OffsetEndMs": 10890}, {"Word": "as", "OffsetStartMs": 10890, "OffsetEndMs": 11175}, {"Word": "to", "OffsetStartMs": 11175, "OffsetEndMs": 11340}, {"Word": "why", "OffsetStartMs": 11340, "OffsetEndMs": 11505}, {"Word": "this", "OffsetStartMs": 11505, "OffsetEndMs": 11760}, {"Word": "occurs", "OffsetStartMs": 11760, "OffsetEndMs": 12110}, {"Word": "and", "OffsetStartMs": 12340, "OffsetEndMs": 12630}, {"Word": "we", "OffsetStartMs": 12630, "OffsetEndMs": 12765}, {"Word": "can", "OffsetStartMs": 12765, "OffsetEndMs": 12900}, {"Word": "point", "OffsetStartMs": 12900, "OffsetEndMs": 13095}, {"Word": "you", "OffsetStartMs": 13095, "OffsetEndMs": 13400}, {"Word": "in", "OffsetStartMs": 13570, "OffsetEndMs": 13845}, {"Word": "those", "OffsetStartMs": 13845, "OffsetEndMs": 14055}, {"Word": "directions", "OffsetStartMs": 14055, "OffsetEndMs": 14390}, {"Word": "but", "OffsetStartMs": 15100, "OffsetEndMs": 15500}, {"Word": "to", "OffsetStartMs": 15670, "OffsetEndMs": 15945}, {"Word": "get", "OffsetStartMs": 15945, "OffsetEndMs": 16080}, {"Word": "a", "OffsetStartMs": 16080, "OffsetEndMs": 16200}, {"Word": "sense", "OffsetStartMs": 16200, "OffsetEndMs": 16380}, {"Word": "of", "OffsetStartMs": 16380, "OffsetEndMs": 16575}, {"Word": "what", "OffsetStartMs": 16575, "OffsetEndMs": 16770}, {"Word": "this", "OffsetStartMs": 16770, "OffsetEndMs": 17085}, {"Word": "actually", "OffsetStartMs": 17085, "OffsetEndMs": 17445}, {"Word": "affects", "OffsetStartMs": 17445, "OffsetEndMs": 17865}, {"Word": "downstream", "OffsetStartMs": 17865, "OffsetEndMs": 18530}, {"Word": "when", "OffsetStartMs": 19030, "OffsetEndMs": 19320}, {"Word": "we", "OffsetStartMs": 19320, "OffsetEndMs": 19515}, {"Word": "look", "OffsetStartMs": 19515, "OffsetEndMs": 19755}, {"Word": "at", "OffsetStartMs": 19755, "OffsetEndMs": 20090}, {"Word": "face", "OffsetStartMs": 20470, "OffsetEndMs": 20820}, {"Word": "reconstruction", "OffsetStartMs": 20820, "OffsetEndMs": 21480}, {"Word": "as", "OffsetStartMs": 21480, "OffsetEndMs": 21860}, {"Word": "a", "OffsetStartMs": 21880, "OffsetEndMs": 22170}, {"Word": "task", "OffsetStartMs": 22170, "OffsetEndMs": 22395}, {"Word": "of", "OffsetStartMs": 22395, "OffsetEndMs": 22710}, {"Word": "interest", "OffsetStartMs": 22710, "OffsetEndMs": 23090}, {"Word": "with", "OffsetStartMs": 23620, "OffsetEndMs": 23895}, {"Word": "a", "OffsetStartMs": 23895, "OffsetEndMs": 24075}, {"Word": "standard", "OffsetStartMs": 24075, "OffsetEndMs": 24380}, {"Word": "v", "OffsetStartMs": 24430, "OffsetEndMs": 24830}, {"Word": "no", "OffsetStartMs": 25240, "OffsetEndMs": 25590}, {"Word": "Beta", "OffsetStartMs": 25590, "OffsetEndMs": 26010}, {"Word": "term", "OffsetStartMs": 26010, "OffsetEndMs": 26300}, {"Word": "or", "OffsetStartMs": 26500, "OffsetEndMs": 26865}, {"Word": "rather", "OffsetStartMs": 26865, "OffsetEndMs": 27150}, {"Word": "a", "OffsetStartMs": 27150, "OffsetEndMs": 27345}, {"Word": "Beta", "OffsetStartMs": 27345, "OffsetEndMs": 27615}, {"Word": "of", "OffsetStartMs": 27615, "OffsetEndMs": 27765}, {"Word": "one", "OffsetStartMs": 27765, "OffsetEndMs": 28070}], "SpeechSpeed": 13.3}, {"FinalSentence": "You can hopefully appreciate that the features of the rotation of the head, the pose and the rotation of the head is also actually ends up being correlated with smile and the facial, the mouth expression in the mouth position. In that as the head pose is changing, the apparent smile or the position of the mouth is also changing.", "SliceSentence": "You can hopefully appreciate that the features of the rotation of the head the pose and the rotation of the head is also actually ends up being correlated with smile and the facial the mouth expression in the mouth position . Inthat as the head pose is changing the apparent smile or the position of the mouth is also changing", "StartMs": 2134660, "EndMs": 2158080, "WordsNum": 60, "Words": [{"Word": "You", "OffsetStartMs": 70, "OffsetEndMs": 345}, {"Word": "can", "OffsetStartMs": 345, "OffsetEndMs": 495}, {"Word": "hopefully", "OffsetStartMs": 495, "OffsetEndMs": 770}, {"Word": "appreciate", "OffsetStartMs": 910, "OffsetEndMs": 1310}, {"Word": "that", "OffsetStartMs": 1390, "OffsetEndMs": 1790}, {"Word": "the", "OffsetStartMs": 2410, "OffsetEndMs": 2810}, {"Word": "features", "OffsetStartMs": 2890, "OffsetEndMs": 3290}, {"Word": "of", "OffsetStartMs": 3430, "OffsetEndMs": 3830}, {"Word": "the", "OffsetStartMs": 3970, "OffsetEndMs": 4245}, {"Word": "rotation", "OffsetStartMs": 4245, "OffsetEndMs": 4695}, {"Word": "of", "OffsetStartMs": 4695, "OffsetEndMs": 4935}, {"Word": "the", "OffsetStartMs": 4935, "OffsetEndMs": 5085}, {"Word": "head", "OffsetStartMs": 5085, "OffsetEndMs": 5360}, {"Word": "the", "OffsetStartMs": 5530, "OffsetEndMs": 5790}, {"Word": "pose", "OffsetStartMs": 5790, "OffsetEndMs": 6060}, {"Word": "and", "OffsetStartMs": 6060, "OffsetEndMs": 6285}, {"Word": "the", "OffsetStartMs": 6285, "OffsetEndMs": 6560}, {"Word": "rotation", "OffsetStartMs": 6820, "OffsetEndMs": 7320}, {"Word": "of", "OffsetStartMs": 7320, "OffsetEndMs": 7515}, {"Word": "the", "OffsetStartMs": 7515, "OffsetEndMs": 7665}, {"Word": "head", "OffsetStartMs": 7665, "OffsetEndMs": 7940}, {"Word": "is", "OffsetStartMs": 8110, "OffsetEndMs": 8510}, {"Word": "also", "OffsetStartMs": 8650, "OffsetEndMs": 9050}, {"Word": "actually", "OffsetStartMs": 9130, "OffsetEndMs": 9420}, {"Word": "ends", "OffsetStartMs": 9420, "OffsetEndMs": 9630}, {"Word": "up", "OffsetStartMs": 9630, "OffsetEndMs": 9870}, {"Word": "being", "OffsetStartMs": 9870, "OffsetEndMs": 10190}, {"Word": "correlated", "OffsetStartMs": 10390, "OffsetEndMs": 11000}, {"Word": "with", "OffsetStartMs": 11260, "OffsetEndMs": 11660}, {"Word": "smile", "OffsetStartMs": 11770, "OffsetEndMs": 12135}, {"Word": "and", "OffsetStartMs": 12135, "OffsetEndMs": 12375}, {"Word": "the", "OffsetStartMs": 12375, "OffsetEndMs": 12525}, {"Word": "facial", "OffsetStartMs": 12525, "OffsetEndMs": 13010}, {"Word": "the", "OffsetStartMs": 13570, "OffsetEndMs": 13830}, {"Word": "mouth", "OffsetStartMs": 13830, "OffsetEndMs": 14090}, {"Word": "expression", "OffsetStartMs": 14380, "OffsetEndMs": 14745}, {"Word": "in", "OffsetStartMs": 14745, "OffsetEndMs": 14985}, {"Word": "the", "OffsetStartMs": 14985, "OffsetEndMs": 15105}, {"Word": "mouth", "OffsetStartMs": 15105, "OffsetEndMs": 15350}, {"Word": "position", "OffsetStartMs": 15400, "OffsetEndMs": 15800}, {"Word": ".", "OffsetStartMs": 16450, "OffsetEndMs": 16740}, {"Word": "Inthat", "OffsetStartMs": 16740, "OffsetEndMs": 17030}, {"Word": "as", "OffsetStartMs": 17290, "OffsetEndMs": 17625}, {"Word": "the", "OffsetStartMs": 17625, "OffsetEndMs": 17835}, {"Word": "head", "OffsetStartMs": 17835, "OffsetEndMs": 18000}, {"Word": "pose", "OffsetStartMs": 18000, "OffsetEndMs": 18210}, {"Word": "is", "OffsetStartMs": 18210, "OffsetEndMs": 18405}, {"Word": "changing", "OffsetStartMs": 18405, "OffsetEndMs": 18710}, {"Word": "the", "OffsetStartMs": 19090, "OffsetEndMs": 19425}, {"Word": "apparent", "OffsetStartMs": 19425, "OffsetEndMs": 19760}, {"Word": "smile", "OffsetStartMs": 19840, "OffsetEndMs": 20240}, {"Word": "or", "OffsetStartMs": 20470, "OffsetEndMs": 20760}, {"Word": "the", "OffsetStartMs": 20760, "OffsetEndMs": 20970}, {"Word": "position", "OffsetStartMs": 20970, "OffsetEndMs": 21210}, {"Word": "of", "OffsetStartMs": 21210, "OffsetEndMs": 21390}, {"Word": "the", "OffsetStartMs": 21390, "OffsetEndMs": 21510}, {"Word": "mouth", "OffsetStartMs": 21510, "OffsetEndMs": 21735}, {"Word": "is", "OffsetStartMs": 21735, "OffsetEndMs": 22095}, {"Word": "also", "OffsetStartMs": 22095, "OffsetEndMs": 22380}, {"Word": "changing", "OffsetStartMs": 22380, "OffsetEndMs": 22670}], "SpeechSpeed": 13.9}, {"FinalSentence": "But with Beta ves empirically we can observe that with imposing these Beta values much, much, much greater than one, we can try to enforce greater disentanglement, where now we can consider only a single latent variable head pose and the smile, the position of the mouth in these images is more constant compared to the standard v.", "SliceSentence": "But with Beta ves empirically we can observe that with imposing these Beta values much much much greater than one we can try to enforce greater disentanglement where now we can consider only a single latent variable head pose and the smile the position of the mouth in these images is more constant compared to the standard v", "StartMs": 2158500, "EndMs": 2184600, "WordsNum": 58, "Words": [{"Word": "But", "OffsetStartMs": 70, "OffsetEndMs": 470}, {"Word": "with", "OffsetStartMs": 790, "OffsetEndMs": 1170}, {"Word": "Beta", "OffsetStartMs": 1170, "OffsetEndMs": 1635}, {"Word": "ves", "OffsetStartMs": 1635, "OffsetEndMs": 2150}, {"Word": "empirically", "OffsetStartMs": 2830, "OffsetEndMs": 3645}, {"Word": "we", "OffsetStartMs": 3645, "OffsetEndMs": 3795}, {"Word": "can", "OffsetStartMs": 3795, "OffsetEndMs": 4050}, {"Word": "observe", "OffsetStartMs": 4050, "OffsetEndMs": 4425}, {"Word": "that", "OffsetStartMs": 4425, "OffsetEndMs": 4820}, {"Word": "with", "OffsetStartMs": 5380, "OffsetEndMs": 5715}, {"Word": "imposing", "OffsetStartMs": 5715, "OffsetEndMs": 6480}, {"Word": "these", "OffsetStartMs": 6480, "OffsetEndMs": 6690}, {"Word": "Beta", "OffsetStartMs": 6690, "OffsetEndMs": 7050}, {"Word": "values", "OffsetStartMs": 7050, "OffsetEndMs": 7310}, {"Word": "much", "OffsetStartMs": 7360, "OffsetEndMs": 7680}, {"Word": "much", "OffsetStartMs": 7680, "OffsetEndMs": 7935}, {"Word": "much", "OffsetStartMs": 7935, "OffsetEndMs": 8220}, {"Word": "greater", "OffsetStartMs": 8220, "OffsetEndMs": 8535}, {"Word": "than", "OffsetStartMs": 8535, "OffsetEndMs": 8805}, {"Word": "one", "OffsetStartMs": 8805, "OffsetEndMs": 9110}, {"Word": "we", "OffsetStartMs": 9520, "OffsetEndMs": 9795}, {"Word": "can", "OffsetStartMs": 9795, "OffsetEndMs": 10005}, {"Word": "try", "OffsetStartMs": 10005, "OffsetEndMs": 10290}, {"Word": "to", "OffsetStartMs": 10290, "OffsetEndMs": 10605}, {"Word": "enforce", "OffsetStartMs": 10605, "OffsetEndMs": 10970}, {"Word": "greater", "OffsetStartMs": 11200, "OffsetEndMs": 11580}, {"Word": "disentanglement", "OffsetStartMs": 11580, "OffsetEndMs": 12590}, {"Word": "where", "OffsetStartMs": 12910, "OffsetEndMs": 13230}, {"Word": "now", "OffsetStartMs": 13230, "OffsetEndMs": 13500}, {"Word": "we", "OffsetStartMs": 13500, "OffsetEndMs": 13725}, {"Word": "can", "OffsetStartMs": 13725, "OffsetEndMs": 13995}, {"Word": "consider", "OffsetStartMs": 13995, "OffsetEndMs": 14325}, {"Word": "only", "OffsetStartMs": 14325, "OffsetEndMs": 14595}, {"Word": "a", "OffsetStartMs": 14595, "OffsetEndMs": 14850}, {"Word": "single", "OffsetStartMs": 14850, "OffsetEndMs": 15120}, {"Word": "latent", "OffsetStartMs": 15120, "OffsetEndMs": 15525}, {"Word": "variable", "OffsetStartMs": 15525, "OffsetEndMs": 15800}, {"Word": "head", "OffsetStartMs": 16300, "OffsetEndMs": 16590}, {"Word": "pose", "OffsetStartMs": 16590, "OffsetEndMs": 16940}, {"Word": "and", "OffsetStartMs": 17350, "OffsetEndMs": 17750}, {"Word": "the", "OffsetStartMs": 18340, "OffsetEndMs": 18690}, {"Word": "smile", "OffsetStartMs": 18690, "OffsetEndMs": 19040}, {"Word": "the", "OffsetStartMs": 19210, "OffsetEndMs": 19560}, {"Word": "position", "OffsetStartMs": 19560, "OffsetEndMs": 19830}, {"Word": "of", "OffsetStartMs": 19830, "OffsetEndMs": 20010}, {"Word": "the", "OffsetStartMs": 20010, "OffsetEndMs": 20130}, {"Word": "mouth", "OffsetStartMs": 20130, "OffsetEndMs": 20355}, {"Word": "in", "OffsetStartMs": 20355, "OffsetEndMs": 20625}, {"Word": "these", "OffsetStartMs": 20625, "OffsetEndMs": 20850}, {"Word": "images", "OffsetStartMs": 20850, "OffsetEndMs": 21170}, {"Word": "is", "OffsetStartMs": 21520, "OffsetEndMs": 21855}, {"Word": "more", "OffsetStartMs": 21855, "OffsetEndMs": 22155}, {"Word": "constant", "OffsetStartMs": 22155, "OffsetEndMs": 22520}, {"Word": "compared", "OffsetStartMs": 23200, "OffsetEndMs": 23600}, {"Word": "to", "OffsetStartMs": 23860, "OffsetEndMs": 24120}, {"Word": "the", "OffsetStartMs": 24120, "OffsetEndMs": 24380}, {"Word": "standard", "OffsetStartMs": 24430, "OffsetEndMs": 24830}, {"Word": "v", "OffsetStartMs": 25030, "OffsetEndMs": 25430}], "SpeechSpeed": 12.5}, {"FinalSentence": "All right, so this is really all the core math, the core operations, the core architecture of the a that we're going to cover in today's lecture and in this class in general to close this section. And as a final note, I want to remind you back to the motivating example that I introduced at the beginning of this lecture, facial detection.", "SliceSentence": "All right so this is really all the core math the core operations the core architecture of the a that we're going to cover in today's lecture and in this class in general to close this section . Andas a final note I want to remind you back to the motivating example that I introduced at the beginning of this lecture facial detection", "StartMs": 2186140, "EndMs": 2209440, "WordsNum": 63, "Words": [{"Word": "All", "OffsetStartMs": 70, "OffsetEndMs": 330}, {"Word": "right", "OffsetStartMs": 330, "OffsetEndMs": 590}, {"Word": "so", "OffsetStartMs": 940, "OffsetEndMs": 1245}, {"Word": "this", "OffsetStartMs": 1245, "OffsetEndMs": 1440}, {"Word": "is", "OffsetStartMs": 1440, "OffsetEndMs": 1620}, {"Word": "really", "OffsetStartMs": 1620, "OffsetEndMs": 1905}, {"Word": "all", "OffsetStartMs": 1905, "OffsetEndMs": 2220}, {"Word": "the", "OffsetStartMs": 2220, "OffsetEndMs": 2460}, {"Word": "core", "OffsetStartMs": 2460, "OffsetEndMs": 2780}, {"Word": "math", "OffsetStartMs": 3070, "OffsetEndMs": 3470}, {"Word": "the", "OffsetStartMs": 3580, "OffsetEndMs": 3885}, {"Word": "core", "OffsetStartMs": 3885, "OffsetEndMs": 4190}, {"Word": "operations", "OffsetStartMs": 4870, "OffsetEndMs": 5270}, {"Word": "the", "OffsetStartMs": 5380, "OffsetEndMs": 5670}, {"Word": "core", "OffsetStartMs": 5670, "OffsetEndMs": 5865}, {"Word": "architecture", "OffsetStartMs": 5865, "OffsetEndMs": 6170}, {"Word": "of", "OffsetStartMs": 6460, "OffsetEndMs": 6860}, {"Word": "the", "OffsetStartMs": 6880, "OffsetEndMs": 7125}, {"Word": "a", "OffsetStartMs": 7125, "OffsetEndMs": 7380}, {"Word": "that", "OffsetStartMs": 7380, "OffsetEndMs": 7695}, {"Word": "we're", "OffsetStartMs": 7695, "OffsetEndMs": 8025}, {"Word": "going", "OffsetStartMs": 8025, "OffsetEndMs": 8175}, {"Word": "to", "OffsetStartMs": 8175, "OffsetEndMs": 8340}, {"Word": "cover", "OffsetStartMs": 8340, "OffsetEndMs": 8600}, {"Word": "in", "OffsetStartMs": 8800, "OffsetEndMs": 9120}, {"Word": "today's", "OffsetStartMs": 9120, "OffsetEndMs": 9510}, {"Word": "lecture", "OffsetStartMs": 9510, "OffsetEndMs": 9735}, {"Word": "and", "OffsetStartMs": 9735, "OffsetEndMs": 10005}, {"Word": "in", "OffsetStartMs": 10005, "OffsetEndMs": 10185}, {"Word": "this", "OffsetStartMs": 10185, "OffsetEndMs": 10395}, {"Word": "class", "OffsetStartMs": 10395, "OffsetEndMs": 10730}, {"Word": "in", "OffsetStartMs": 10780, "OffsetEndMs": 11070}, {"Word": "general", "OffsetStartMs": 11070, "OffsetEndMs": 11360}, {"Word": "to", "OffsetStartMs": 12610, "OffsetEndMs": 12960}, {"Word": "close", "OffsetStartMs": 12960, "OffsetEndMs": 13230}, {"Word": "this", "OffsetStartMs": 13230, "OffsetEndMs": 13455}, {"Word": "section", "OffsetStartMs": 13455, "OffsetEndMs": 13760}, {"Word": ".", "OffsetStartMs": 13990, "OffsetEndMs": 14390}, {"Word": "Andas", "OffsetStartMs": 15070, "OffsetEndMs": 15360}, {"Word": "a", "OffsetStartMs": 15360, "OffsetEndMs": 15540}, {"Word": "final", "OffsetStartMs": 15540, "OffsetEndMs": 15795}, {"Word": "note", "OffsetStartMs": 15795, "OffsetEndMs": 16095}, {"Word": "I", "OffsetStartMs": 16095, "OffsetEndMs": 16320}, {"Word": "want", "OffsetStartMs": 16320, "OffsetEndMs": 16500}, {"Word": "to", "OffsetStartMs": 16500, "OffsetEndMs": 16710}, {"Word": "remind", "OffsetStartMs": 16710, "OffsetEndMs": 16965}, {"Word": "you", "OffsetStartMs": 16965, "OffsetEndMs": 17175}, {"Word": "back", "OffsetStartMs": 17175, "OffsetEndMs": 17445}, {"Word": "to", "OffsetStartMs": 17445, "OffsetEndMs": 17715}, {"Word": "the", "OffsetStartMs": 17715, "OffsetEndMs": 17865}, {"Word": "motivating", "OffsetStartMs": 17865, "OffsetEndMs": 18410}, {"Word": "example", "OffsetStartMs": 18460, "OffsetEndMs": 18860}, {"Word": "that", "OffsetStartMs": 19300, "OffsetEndMs": 19650}, {"Word": "I", "OffsetStartMs": 19650, "OffsetEndMs": 20000}, {"Word": "introduced", "OffsetStartMs": 20020, "OffsetEndMs": 20310}, {"Word": "at", "OffsetStartMs": 20310, "OffsetEndMs": 20460}, {"Word": "the", "OffsetStartMs": 20460, "OffsetEndMs": 20640}, {"Word": "beginning", "OffsetStartMs": 20640, "OffsetEndMs": 20865}, {"Word": "of", "OffsetStartMs": 20865, "OffsetEndMs": 21045}, {"Word": "this", "OffsetStartMs": 21045, "OffsetEndMs": 21210}, {"Word": "lecture", "OffsetStartMs": 21210, "OffsetEndMs": 21500}, {"Word": "facial", "OffsetStartMs": 21880, "OffsetEndMs": 22380}, {"Word": "detection", "OffsetStartMs": 22380, "OffsetEndMs": 22910}], "SpeechSpeed": 14.3}, {"FinalSentence": "Where now hopefully you've understood this concept of latent variable learning and encoding, and how this may be useful for a task like facial detection, where we may want to learn those distributions of the underlying features in the data, and indeed, you're going to get hands on practice in the software labs to build variational auto encoders that can automatically uncover.", "SliceSentence": "Where now hopefully you've understood this concept of latent variable learning and encoding and how this may be useful for a task like facial detection where we may want to learn those distributions of the underlying features in the data and indeed you're going to get hands on practice in the software labs to build variational auto encoders that can automatically uncover", "StartMs": 2209440, "EndMs": 2235780, "WordsNum": 62, "Words": [{"Word": "Where", "OffsetStartMs": 310, "OffsetEndMs": 615}, {"Word": "now", "OffsetStartMs": 615, "OffsetEndMs": 920}, {"Word": "hopefully", "OffsetStartMs": 970, "OffsetEndMs": 1370}, {"Word": "you've", "OffsetStartMs": 1420, "OffsetEndMs": 1940}, {"Word": "understood", "OffsetStartMs": 2020, "OffsetEndMs": 2420}, {"Word": "this", "OffsetStartMs": 2530, "OffsetEndMs": 2865}, {"Word": "concept", "OffsetStartMs": 2865, "OffsetEndMs": 3200}, {"Word": "of", "OffsetStartMs": 3340, "OffsetEndMs": 3645}, {"Word": "latent", "OffsetStartMs": 3645, "OffsetEndMs": 3975}, {"Word": "variable", "OffsetStartMs": 3975, "OffsetEndMs": 4250}, {"Word": "learning", "OffsetStartMs": 4330, "OffsetEndMs": 4730}, {"Word": "and", "OffsetStartMs": 4780, "OffsetEndMs": 5040}, {"Word": "encoding", "OffsetStartMs": 5040, "OffsetEndMs": 5720}, {"Word": "and", "OffsetStartMs": 5860, "OffsetEndMs": 6180}, {"Word": "how", "OffsetStartMs": 6180, "OffsetEndMs": 6420}, {"Word": "this", "OffsetStartMs": 6420, "OffsetEndMs": 6660}, {"Word": "may", "OffsetStartMs": 6660, "OffsetEndMs": 6855}, {"Word": "be", "OffsetStartMs": 6855, "OffsetEndMs": 7005}, {"Word": "useful", "OffsetStartMs": 7005, "OffsetEndMs": 7280}, {"Word": "for", "OffsetStartMs": 7420, "OffsetEndMs": 7740}, {"Word": "a", "OffsetStartMs": 7740, "OffsetEndMs": 7965}, {"Word": "task", "OffsetStartMs": 7965, "OffsetEndMs": 8265}, {"Word": "like", "OffsetStartMs": 8265, "OffsetEndMs": 8595}, {"Word": "facial", "OffsetStartMs": 8595, "OffsetEndMs": 9045}, {"Word": "detection", "OffsetStartMs": 9045, "OffsetEndMs": 9620}, {"Word": "where", "OffsetStartMs": 9940, "OffsetEndMs": 10230}, {"Word": "we", "OffsetStartMs": 10230, "OffsetEndMs": 10425}, {"Word": "may", "OffsetStartMs": 10425, "OffsetEndMs": 10680}, {"Word": "want", "OffsetStartMs": 10680, "OffsetEndMs": 10965}, {"Word": "to", "OffsetStartMs": 10965, "OffsetEndMs": 11220}, {"Word": "learn", "OffsetStartMs": 11220, "OffsetEndMs": 11540}, {"Word": "those", "OffsetStartMs": 11860, "OffsetEndMs": 12260}, {"Word": "distributions", "OffsetStartMs": 12280, "OffsetEndMs": 12830}, {"Word": "of", "OffsetStartMs": 13030, "OffsetEndMs": 13320}, {"Word": "the", "OffsetStartMs": 13320, "OffsetEndMs": 13485}, {"Word": "underlying", "OffsetStartMs": 13485, "OffsetEndMs": 13760}, {"Word": "features", "OffsetStartMs": 14110, "OffsetEndMs": 14505}, {"Word": "in", "OffsetStartMs": 14505, "OffsetEndMs": 14775}, {"Word": "the", "OffsetStartMs": 14775, "OffsetEndMs": 14910}, {"Word": "data", "OffsetStartMs": 14910, "OffsetEndMs": 15170}, {"Word": "and", "OffsetStartMs": 15880, "OffsetEndMs": 16245}, {"Word": "indeed", "OffsetStartMs": 16245, "OffsetEndMs": 16515}, {"Word": "you're", "OffsetStartMs": 16515, "OffsetEndMs": 16755}, {"Word": "going", "OffsetStartMs": 16755, "OffsetEndMs": 16905}, {"Word": "to", "OffsetStartMs": 16905, "OffsetEndMs": 17055}, {"Word": "get", "OffsetStartMs": 17055, "OffsetEndMs": 17220}, {"Word": "hands", "OffsetStartMs": 17220, "OffsetEndMs": 17475}, {"Word": "on", "OffsetStartMs": 17475, "OffsetEndMs": 17745}, {"Word": "practice", "OffsetStartMs": 17745, "OffsetEndMs": 18080}, {"Word": "in", "OffsetStartMs": 18550, "OffsetEndMs": 18930}, {"Word": "the", "OffsetStartMs": 18930, "OffsetEndMs": 19310}, {"Word": "software", "OffsetStartMs": 19330, "OffsetEndMs": 19725}, {"Word": "labs", "OffsetStartMs": 19725, "OffsetEndMs": 20360}, {"Word": "to", "OffsetStartMs": 21190, "OffsetEndMs": 21555}, {"Word": "build", "OffsetStartMs": 21555, "OffsetEndMs": 21920}, {"Word": "variational", "OffsetStartMs": 22330, "OffsetEndMs": 22965}, {"Word": "auto", "OffsetStartMs": 22965, "OffsetEndMs": 23280}, {"Word": "encoders", "OffsetStartMs": 23280, "OffsetEndMs": 23805}, {"Word": "that", "OffsetStartMs": 23805, "OffsetEndMs": 24015}, {"Word": "can", "OffsetStartMs": 24015, "OffsetEndMs": 24320}, {"Word": "automatically", "OffsetStartMs": 24430, "OffsetEndMs": 24830}, {"Word": "uncover", "OffsetStartMs": 25000, "OffsetEndMs": 25820}], "SpeechSpeed": 14.2}, {"FinalSentence": "Features underlying facial detection data sets and use this to actually understand underlying and hidden biases that may exist with those data and with those models.", "SliceSentence": "Features underlying facial detection data sets and use this to actually understand underlying and hidden biases that may exist with those data and with those models", "StartMs": 2235980, "EndMs": 2247640, "WordsNum": 26, "Words": [{"Word": "Features", "OffsetStartMs": 190, "OffsetEndMs": 590}, {"Word": "underlying", "OffsetStartMs": 670, "OffsetEndMs": 1070}, {"Word": "facial", "OffsetStartMs": 1330, "OffsetEndMs": 1860}, {"Word": "detection", "OffsetStartMs": 1860, "OffsetEndMs": 2265}, {"Word": "data", "OffsetStartMs": 2265, "OffsetEndMs": 2490}, {"Word": "sets", "OffsetStartMs": 2490, "OffsetEndMs": 2840}, {"Word": "and", "OffsetStartMs": 3190, "OffsetEndMs": 3540}, {"Word": "use", "OffsetStartMs": 3540, "OffsetEndMs": 3840}, {"Word": "this", "OffsetStartMs": 3840, "OffsetEndMs": 4095}, {"Word": "to", "OffsetStartMs": 4095, "OffsetEndMs": 4400}, {"Word": "actually", "OffsetStartMs": 4480, "OffsetEndMs": 4880}, {"Word": "understand", "OffsetStartMs": 5320, "OffsetEndMs": 5720}, {"Word": "underlying", "OffsetStartMs": 5920, "OffsetEndMs": 6320}, {"Word": "and", "OffsetStartMs": 6610, "OffsetEndMs": 6930}, {"Word": "hidden", "OffsetStartMs": 6930, "OffsetEndMs": 7230}, {"Word": "biases", "OffsetStartMs": 7230, "OffsetEndMs": 8000}, {"Word": "that", "OffsetStartMs": 8140, "OffsetEndMs": 8445}, {"Word": "may", "OffsetStartMs": 8445, "OffsetEndMs": 8750}, {"Word": "exist", "OffsetStartMs": 8800, "OffsetEndMs": 9135}, {"Word": "with", "OffsetStartMs": 9135, "OffsetEndMs": 9345}, {"Word": "those", "OffsetStartMs": 9345, "OffsetEndMs": 9540}, {"Word": "data", "OffsetStartMs": 9540, "OffsetEndMs": 9860}, {"Word": "and", "OffsetStartMs": 10030, "OffsetEndMs": 10305}, {"Word": "with", "OffsetStartMs": 10305, "OffsetEndMs": 10455}, {"Word": "those", "OffsetStartMs": 10455, "OffsetEndMs": 10635}, {"Word": "models", "OffsetStartMs": 10635, "OffsetEndMs": 10940}], "SpeechSpeed": 14.1}, {"FinalSentence": "And it doesn't just stop there. Tomorrow we'll have a very, very exciting guest lecture on robust and trustworthy deep learning, which will take this concept a step further to realize how we can use this idea of generative models and latent variable learning to not only uncover and diagnose biases, but actually solve and mitigate some of those harmful effects of those biases in.", "SliceSentence": "And it doesn't just stop there . Tomorrowwe'll have a very very exciting guest lecture on robust and trustworthy deep learning which will take this concept a step further to realize how we can use this idea of generative models and latent variable learning to not only uncover and diagnose biases but actually solve and mitigate some of those harmful effects of those biases in", "StartMs": 2247820, "EndMs": 2273380, "WordsNum": 65, "Words": [{"Word": "And", "OffsetStartMs": 70, "OffsetEndMs": 315}, {"Word": "it", "OffsetStartMs": 315, "OffsetEndMs": 420}, {"Word": "doesn't", "OffsetStartMs": 420, "OffsetEndMs": 705}, {"Word": "just", "OffsetStartMs": 705, "OffsetEndMs": 885}, {"Word": "stop", "OffsetStartMs": 885, "OffsetEndMs": 1125}, {"Word": "there", "OffsetStartMs": 1125, "OffsetEndMs": 1460}, {"Word": ".", "OffsetStartMs": 1690, "OffsetEndMs": 2085}, {"Word": "Tomorrowwe'll", "OffsetStartMs": 2085, "OffsetEndMs": 2400}, {"Word": "have", "OffsetStartMs": 2400, "OffsetEndMs": 2610}, {"Word": "a", "OffsetStartMs": 2610, "OffsetEndMs": 2835}, {"Word": "very", "OffsetStartMs": 2835, "OffsetEndMs": 3060}, {"Word": "very", "OffsetStartMs": 3060, "OffsetEndMs": 3390}, {"Word": "exciting", "OffsetStartMs": 3390, "OffsetEndMs": 3770}, {"Word": "guest", "OffsetStartMs": 4000, "OffsetEndMs": 4335}, {"Word": "lecture", "OffsetStartMs": 4335, "OffsetEndMs": 4670}, {"Word": "on", "OffsetStartMs": 5350, "OffsetEndMs": 5750}, {"Word": "robust", "OffsetStartMs": 5800, "OffsetEndMs": 6180}, {"Word": "and", "OffsetStartMs": 6180, "OffsetEndMs": 6525}, {"Word": "trustworthy", "OffsetStartMs": 6525, "OffsetEndMs": 7200}, {"Word": "deep", "OffsetStartMs": 7200, "OffsetEndMs": 7395}, {"Word": "learning", "OffsetStartMs": 7395, "OffsetEndMs": 7700}, {"Word": "which", "OffsetStartMs": 8050, "OffsetEndMs": 8355}, {"Word": "will", "OffsetStartMs": 8355, "OffsetEndMs": 8565}, {"Word": "take", "OffsetStartMs": 8565, "OffsetEndMs": 8790}, {"Word": "this", "OffsetStartMs": 8790, "OffsetEndMs": 9030}, {"Word": "concept", "OffsetStartMs": 9030, "OffsetEndMs": 9350}, {"Word": "a", "OffsetStartMs": 9370, "OffsetEndMs": 9660}, {"Word": "step", "OffsetStartMs": 9660, "OffsetEndMs": 9885}, {"Word": "further", "OffsetStartMs": 9885, "OffsetEndMs": 10220}, {"Word": "to", "OffsetStartMs": 10720, "OffsetEndMs": 11100}, {"Word": "realize", "OffsetStartMs": 11100, "OffsetEndMs": 11480}, {"Word": "how", "OffsetStartMs": 11650, "OffsetEndMs": 11970}, {"Word": "we", "OffsetStartMs": 11970, "OffsetEndMs": 12150}, {"Word": "can", "OffsetStartMs": 12150, "OffsetEndMs": 12315}, {"Word": "use", "OffsetStartMs": 12315, "OffsetEndMs": 12570}, {"Word": "this", "OffsetStartMs": 12570, "OffsetEndMs": 12900}, {"Word": "idea", "OffsetStartMs": 12900, "OffsetEndMs": 13125}, {"Word": "of", "OffsetStartMs": 13125, "OffsetEndMs": 13260}, {"Word": "generative", "OffsetStartMs": 13260, "OffsetEndMs": 13725}, {"Word": "models", "OffsetStartMs": 13725, "OffsetEndMs": 14030}, {"Word": "and", "OffsetStartMs": 14320, "OffsetEndMs": 14625}, {"Word": "latent", "OffsetStartMs": 14625, "OffsetEndMs": 15000}, {"Word": "variable", "OffsetStartMs": 15000, "OffsetEndMs": 15290}, {"Word": "learning", "OffsetStartMs": 15310, "OffsetEndMs": 15710}, {"Word": "to", "OffsetStartMs": 16090, "OffsetEndMs": 16350}, {"Word": "not", "OffsetStartMs": 16350, "OffsetEndMs": 16500}, {"Word": "only", "OffsetStartMs": 16500, "OffsetEndMs": 16790}, {"Word": "uncover", "OffsetStartMs": 17050, "OffsetEndMs": 17775}, {"Word": "and", "OffsetStartMs": 17775, "OffsetEndMs": 17985}, {"Word": "diagnose", "OffsetStartMs": 17985, "OffsetEndMs": 18555}, {"Word": "biases", "OffsetStartMs": 18555, "OffsetEndMs": 19280}, {"Word": "but", "OffsetStartMs": 19600, "OffsetEndMs": 20000}, {"Word": "actually", "OffsetStartMs": 20170, "OffsetEndMs": 20570}, {"Word": "solve", "OffsetStartMs": 20800, "OffsetEndMs": 21200}, {"Word": "and", "OffsetStartMs": 21220, "OffsetEndMs": 21540}, {"Word": "mitigate", "OffsetStartMs": 21540, "OffsetEndMs": 22080}, {"Word": "some", "OffsetStartMs": 22080, "OffsetEndMs": 22320}, {"Word": "of", "OffsetStartMs": 22320, "OffsetEndMs": 22470}, {"Word": "those", "OffsetStartMs": 22470, "OffsetEndMs": 22695}, {"Word": "harmful", "OffsetStartMs": 22695, "OffsetEndMs": 23235}, {"Word": "effects", "OffsetStartMs": 23235, "OffsetEndMs": 23505}, {"Word": "of", "OffsetStartMs": 23505, "OffsetEndMs": 23715}, {"Word": "those", "OffsetStartMs": 23715, "OffsetEndMs": 23895}, {"Word": "biases", "OffsetStartMs": 23895, "OffsetEndMs": 24530}, {"Word": "in", "OffsetStartMs": 24700, "OffsetEndMs": 25100}], "SpeechSpeed": 14.7}, {"FinalSentence": "Neural networks for facial detection and other applications.", "SliceSentence": "Neural networks for facial detection and other applications", "StartMs": 2273380, "EndMs": 2277520, "WordsNum": 8, "Words": [{"Word": "Neural", "OffsetStartMs": 0, "OffsetEndMs": 270}, {"Word": "networks", "OffsetStartMs": 270, "OffsetEndMs": 530}, {"Word": "for", "OffsetStartMs": 610, "OffsetEndMs": 885}, {"Word": "facial", "OffsetStartMs": 885, "OffsetEndMs": 1275}, {"Word": "detection", "OffsetStartMs": 1275, "OffsetEndMs": 1815}, {"Word": "and", "OffsetStartMs": 1815, "OffsetEndMs": 2085}, {"Word": "other", "OffsetStartMs": 2085, "OffsetEndMs": 2360}, {"Word": "applications", "OffsetStartMs": 2530, "OffsetEndMs": 2930}], "SpeechSpeed": 14.3}, {"FinalSentence": "All right, so to summarize quickly the key points of vas we've gone through how they're able to compress data into this compact encoded representation. From this representation, we can generate reconstructions of the input in a completely unsupervised fashion.", "SliceSentence": "All right so to summarize quickly the key points of vas we've gone through how they're able to compress data into this compact encoded representation . Fromthis representation we can generate reconstructions of the input in a completely unsupervised fashion", "StartMs": 2277760, "EndMs": 2296120, "WordsNum": 40, "Words": [{"Word": "All", "OffsetStartMs": 70, "OffsetEndMs": 345}, {"Word": "right", "OffsetStartMs": 345, "OffsetEndMs": 620}, {"Word": "so", "OffsetStartMs": 1000, "OffsetEndMs": 1395}, {"Word": "to", "OffsetStartMs": 1395, "OffsetEndMs": 1680}, {"Word": "summarize", "OffsetStartMs": 1680, "OffsetEndMs": 2115}, {"Word": "quickly", "OffsetStartMs": 2115, "OffsetEndMs": 2415}, {"Word": "the", "OffsetStartMs": 2415, "OffsetEndMs": 2685}, {"Word": "key", "OffsetStartMs": 2685, "OffsetEndMs": 2910}, {"Word": "points", "OffsetStartMs": 2910, "OffsetEndMs": 3230}, {"Word": "of", "OffsetStartMs": 3250, "OffsetEndMs": 3540}, {"Word": "vas", "OffsetStartMs": 3540, "OffsetEndMs": 3920}, {"Word": "we've", "OffsetStartMs": 4480, "OffsetEndMs": 4860}, {"Word": "gone", "OffsetStartMs": 4860, "OffsetEndMs": 5100}, {"Word": "through", "OffsetStartMs": 5100, "OffsetEndMs": 5460}, {"Word": "how", "OffsetStartMs": 5460, "OffsetEndMs": 5775}, {"Word": "they're", "OffsetStartMs": 5775, "OffsetEndMs": 6135}, {"Word": "able", "OffsetStartMs": 6135, "OffsetEndMs": 6410}, {"Word": "to", "OffsetStartMs": 6520, "OffsetEndMs": 6920}, {"Word": "compress", "OffsetStartMs": 7000, "OffsetEndMs": 7560}, {"Word": "data", "OffsetStartMs": 7560, "OffsetEndMs": 7905}, {"Word": "into", "OffsetStartMs": 7905, "OffsetEndMs": 8295}, {"Word": "this", "OffsetStartMs": 8295, "OffsetEndMs": 8610}, {"Word": "compact", "OffsetStartMs": 8610, "OffsetEndMs": 9170}, {"Word": "encoded", "OffsetStartMs": 9310, "OffsetEndMs": 9900}, {"Word": "representation", "OffsetStartMs": 9900, "OffsetEndMs": 10640}, {"Word": ".", "OffsetStartMs": 11380, "OffsetEndMs": 11700}, {"Word": "Fromthis", "OffsetStartMs": 11700, "OffsetEndMs": 11910}, {"Word": "representation", "OffsetStartMs": 11910, "OffsetEndMs": 12675}, {"Word": "we", "OffsetStartMs": 12675, "OffsetEndMs": 12915}, {"Word": "can", "OffsetStartMs": 12915, "OffsetEndMs": 13095}, {"Word": "generate", "OffsetStartMs": 13095, "OffsetEndMs": 13400}, {"Word": "reconstructions", "OffsetStartMs": 13450, "OffsetEndMs": 14325}, {"Word": "of", "OffsetStartMs": 14325, "OffsetEndMs": 14490}, {"Word": "the", "OffsetStartMs": 14490, "OffsetEndMs": 14715}, {"Word": "input", "OffsetStartMs": 14715, "OffsetEndMs": 15080}, {"Word": "in", "OffsetStartMs": 15580, "OffsetEndMs": 15840}, {"Word": "a", "OffsetStartMs": 15840, "OffsetEndMs": 16065}, {"Word": "completely", "OffsetStartMs": 16065, "OffsetEndMs": 16380}, {"Word": "unsupervised", "OffsetStartMs": 16380, "OffsetEndMs": 17130}, {"Word": "fashion", "OffsetStartMs": 17130, "OffsetEndMs": 17480}], "SpeechSpeed": 13.9}, {"FinalSentence": "We can train them end to end using the parameterurization trick. We can understand the semantic interpretation of individual latent variables by perturbing their values. And finally, we can sample from the latent space to generate new examples by passing back up through the decoder.", "SliceSentence": "We can train them end to end using the parameterurization trick . Wecan understand the semantic interpretation of individual latent variables by perturbing their values . Andfinally we can sample from the latent space to generate new examples by passing back up through the decoder", "StartMs": 2296940, "EndMs": 2319120, "WordsNum": 45, "Words": [{"Word": "We", "OffsetStartMs": 220, "OffsetEndMs": 510}, {"Word": "can", "OffsetStartMs": 510, "OffsetEndMs": 800}, {"Word": "train", "OffsetStartMs": 1630, "OffsetEndMs": 1950}, {"Word": "them", "OffsetStartMs": 1950, "OffsetEndMs": 2175}, {"Word": "end", "OffsetStartMs": 2175, "OffsetEndMs": 2385}, {"Word": "to", "OffsetStartMs": 2385, "OffsetEndMs": 2550}, {"Word": "end", "OffsetStartMs": 2550, "OffsetEndMs": 2805}, {"Word": "using", "OffsetStartMs": 2805, "OffsetEndMs": 3180}, {"Word": "the", "OffsetStartMs": 3180, "OffsetEndMs": 3525}, {"Word": "parameterurization", "OffsetStartMs": 3525, "OffsetEndMs": 4460}, {"Word": "trick", "OffsetStartMs": 4510, "OffsetEndMs": 4910}, {"Word": ".", "OffsetStartMs": 5740, "OffsetEndMs": 6000}, {"Word": "Wecan", "OffsetStartMs": 6000, "OffsetEndMs": 6260}, {"Word": "understand", "OffsetStartMs": 6460, "OffsetEndMs": 6810}, {"Word": "the", "OffsetStartMs": 6810, "OffsetEndMs": 7035}, {"Word": "semantic", "OffsetStartMs": 7035, "OffsetEndMs": 7670}, {"Word": "interpretation", "OffsetStartMs": 8500, "OffsetEndMs": 9200}, {"Word": "of", "OffsetStartMs": 9250, "OffsetEndMs": 9650}, {"Word": "individual", "OffsetStartMs": 9760, "OffsetEndMs": 10140}, {"Word": "latent", "OffsetStartMs": 10140, "OffsetEndMs": 10560}, {"Word": "variables", "OffsetStartMs": 10560, "OffsetEndMs": 11070}, {"Word": "by", "OffsetStartMs": 11070, "OffsetEndMs": 11390}, {"Word": "perturbing", "OffsetStartMs": 11560, "OffsetEndMs": 12300}, {"Word": "their", "OffsetStartMs": 12300, "OffsetEndMs": 12510}, {"Word": "values", "OffsetStartMs": 12510, "OffsetEndMs": 12800}, {"Word": ".", "OffsetStartMs": 13690, "OffsetEndMs": 13995}, {"Word": "Andfinally", "OffsetStartMs": 13995, "OffsetEndMs": 14300}, {"Word": "we", "OffsetStartMs": 14350, "OffsetEndMs": 14625}, {"Word": "can", "OffsetStartMs": 14625, "OffsetEndMs": 14820}, {"Word": "sample", "OffsetStartMs": 14820, "OffsetEndMs": 15140}, {"Word": "from", "OffsetStartMs": 15310, "OffsetEndMs": 15710}, {"Word": "the", "OffsetStartMs": 15940, "OffsetEndMs": 16340}, {"Word": "latent", "OffsetStartMs": 16450, "OffsetEndMs": 16950}, {"Word": "space", "OffsetStartMs": 16950, "OffsetEndMs": 17270}, {"Word": "to", "OffsetStartMs": 17290, "OffsetEndMs": 17580}, {"Word": "generate", "OffsetStartMs": 17580, "OffsetEndMs": 17870}, {"Word": "new", "OffsetStartMs": 18190, "OffsetEndMs": 18570}, {"Word": "examples", "OffsetStartMs": 18570, "OffsetEndMs": 18950}, {"Word": "by", "OffsetStartMs": 19030, "OffsetEndMs": 19365}, {"Word": "passing", "OffsetStartMs": 19365, "OffsetEndMs": 19700}, {"Word": "back", "OffsetStartMs": 19720, "OffsetEndMs": 20070}, {"Word": "up", "OffsetStartMs": 20070, "OffsetEndMs": 20420}, {"Word": "through", "OffsetStartMs": 20650, "OffsetEndMs": 20955}, {"Word": "the", "OffsetStartMs": 20955, "OffsetEndMs": 21135}, {"Word": "decoder", "OffsetStartMs": 21135, "OffsetEndMs": 21740}], "SpeechSpeed": 12.6}, {"FinalSentence": "So v are looking at this idea of latent variable encoding and density estimation as their core problem. What if now we only focus on the quality of the generated samples, and that's the task that we care more about.", "SliceSentence": "So v are looking at this idea of latent variable encoding and density estimation as their core problem . Whatif now we only focus on the quality of the generated samples and that's the task that we care more about", "StartMs": 2319860, "EndMs": 2335000, "WordsNum": 40, "Words": [{"Word": "So", "OffsetStartMs": 190, "OffsetEndMs": 590}, {"Word": "v", "OffsetStartMs": 790, "OffsetEndMs": 1190}, {"Word": "are", "OffsetStartMs": 1330, "OffsetEndMs": 1650}, {"Word": "looking", "OffsetStartMs": 1650, "OffsetEndMs": 1905}, {"Word": "at", "OffsetStartMs": 1905, "OffsetEndMs": 2130}, {"Word": "this", "OffsetStartMs": 2130, "OffsetEndMs": 2415}, {"Word": "idea", "OffsetStartMs": 2415, "OffsetEndMs": 2730}, {"Word": "of", "OffsetStartMs": 2730, "OffsetEndMs": 2970}, {"Word": "latent", "OffsetStartMs": 2970, "OffsetEndMs": 3345}, {"Word": "variable", "OffsetStartMs": 3345, "OffsetEndMs": 3585}, {"Word": "encoding", "OffsetStartMs": 3585, "OffsetEndMs": 4245}, {"Word": "and", "OffsetStartMs": 4245, "OffsetEndMs": 4440}, {"Word": "density", "OffsetStartMs": 4440, "OffsetEndMs": 5040}, {"Word": "estimation", "OffsetStartMs": 5040, "OffsetEndMs": 5480}, {"Word": "as", "OffsetStartMs": 5560, "OffsetEndMs": 5880}, {"Word": "their", "OffsetStartMs": 5880, "OffsetEndMs": 6120}, {"Word": "core", "OffsetStartMs": 6120, "OffsetEndMs": 6375}, {"Word": "problem", "OffsetStartMs": 6375, "OffsetEndMs": 6710}, {"Word": ".", "OffsetStartMs": 7690, "OffsetEndMs": 7965}, {"Word": "Whatif", "OffsetStartMs": 7965, "OffsetEndMs": 8145}, {"Word": "now", "OffsetStartMs": 8145, "OffsetEndMs": 8370}, {"Word": "we", "OffsetStartMs": 8370, "OffsetEndMs": 8595}, {"Word": "only", "OffsetStartMs": 8595, "OffsetEndMs": 8895}, {"Word": "focus", "OffsetStartMs": 8895, "OffsetEndMs": 9285}, {"Word": "on", "OffsetStartMs": 9285, "OffsetEndMs": 9585}, {"Word": "the", "OffsetStartMs": 9585, "OffsetEndMs": 9825}, {"Word": "quality", "OffsetStartMs": 9825, "OffsetEndMs": 10160}, {"Word": "of", "OffsetStartMs": 10300, "OffsetEndMs": 10620}, {"Word": "the", "OffsetStartMs": 10620, "OffsetEndMs": 10830}, {"Word": "generated", "OffsetStartMs": 10830, "OffsetEndMs": 11120}, {"Word": "samples", "OffsetStartMs": 11260, "OffsetEndMs": 11805}, {"Word": "and", "OffsetStartMs": 11805, "OffsetEndMs": 12015}, {"Word": "that's", "OffsetStartMs": 12015, "OffsetEndMs": 12525}, {"Word": "the", "OffsetStartMs": 12525, "OffsetEndMs": 12795}, {"Word": "task", "OffsetStartMs": 12795, "OffsetEndMs": 13020}, {"Word": "that", "OffsetStartMs": 13020, "OffsetEndMs": 13245}, {"Word": "we", "OffsetStartMs": 13245, "OffsetEndMs": 13410}, {"Word": "care", "OffsetStartMs": 13410, "OffsetEndMs": 13700}, {"Word": "more", "OffsetStartMs": 13900, "OffsetEndMs": 14300}, {"Word": "about", "OffsetStartMs": 14380, "OffsetEndMs": 14780}], "SpeechSpeed": 14.0}, {"FinalSentence": "For that, we're going to transition to a new type of generative model called a generative adversarial network, or gam.", "SliceSentence": "For that we're going to transition to a new type of generative model called a generative adversarial network or gam", "StartMs": 2335560, "EndMs": 2343400, "WordsNum": 20, "Words": [{"Word": "For", "OffsetStartMs": 130, "OffsetEndMs": 420}, {"Word": "that", "OffsetStartMs": 420, "OffsetEndMs": 645}, {"Word": "we're", "OffsetStartMs": 645, "OffsetEndMs": 900}, {"Word": "going", "OffsetStartMs": 900, "OffsetEndMs": 1035}, {"Word": "to", "OffsetStartMs": 1035, "OffsetEndMs": 1230}, {"Word": "transition", "OffsetStartMs": 1230, "OffsetEndMs": 1520}, {"Word": "to", "OffsetStartMs": 1690, "OffsetEndMs": 1920}, {"Word": "a", "OffsetStartMs": 1920, "OffsetEndMs": 2055}, {"Word": "new", "OffsetStartMs": 2055, "OffsetEndMs": 2280}, {"Word": "type", "OffsetStartMs": 2280, "OffsetEndMs": 2490}, {"Word": "of", "OffsetStartMs": 2490, "OffsetEndMs": 2655}, {"Word": "generative", "OffsetStartMs": 2655, "OffsetEndMs": 3075}, {"Word": "model", "OffsetStartMs": 3075, "OffsetEndMs": 3350}, {"Word": "called", "OffsetStartMs": 3910, "OffsetEndMs": 4260}, {"Word": "a", "OffsetStartMs": 4260, "OffsetEndMs": 4500}, {"Word": "generative", "OffsetStartMs": 4500, "OffsetEndMs": 5040}, {"Word": "adversarial", "OffsetStartMs": 5040, "OffsetEndMs": 5820}, {"Word": "network", "OffsetStartMs": 5820, "OffsetEndMs": 6110}, {"Word": "or", "OffsetStartMs": 6250, "OffsetEndMs": 6650}, {"Word": "gam", "OffsetStartMs": 6700, "OffsetEndMs": 7130}], "SpeechSpeed": 14.7}, {"FinalSentence": "Where with gans, our goal is really that we care more about how well we generate new instances that are similar to the existing data, meaning that we want to try to sample from a potentially very complex distribution that the model is trying to approximate.", "SliceSentence": "Where with gans our goal is really that we care more about how well we generate new instances that are similar to the existing data meaning that we want to try to sample from a potentially very complex distribution that the model is trying to approximate", "StartMs": 2343940, "EndMs": 2362600, "WordsNum": 46, "Words": [{"Word": "Where", "OffsetStartMs": 100, "OffsetEndMs": 405}, {"Word": "with", "OffsetStartMs": 405, "OffsetEndMs": 630}, {"Word": "gans", "OffsetStartMs": 630, "OffsetEndMs": 980}, {"Word": "our", "OffsetStartMs": 1030, "OffsetEndMs": 1365}, {"Word": "goal", "OffsetStartMs": 1365, "OffsetEndMs": 1680}, {"Word": "is", "OffsetStartMs": 1680, "OffsetEndMs": 2010}, {"Word": "really", "OffsetStartMs": 2010, "OffsetEndMs": 2310}, {"Word": "that", "OffsetStartMs": 2310, "OffsetEndMs": 2535}, {"Word": "we", "OffsetStartMs": 2535, "OffsetEndMs": 2760}, {"Word": "care", "OffsetStartMs": 2760, "OffsetEndMs": 3075}, {"Word": "more", "OffsetStartMs": 3075, "OffsetEndMs": 3440}, {"Word": "about", "OffsetStartMs": 3760, "OffsetEndMs": 4125}, {"Word": "how", "OffsetStartMs": 4125, "OffsetEndMs": 4440}, {"Word": "well", "OffsetStartMs": 4440, "OffsetEndMs": 4710}, {"Word": "we", "OffsetStartMs": 4710, "OffsetEndMs": 4935}, {"Word": "generate", "OffsetStartMs": 4935, "OffsetEndMs": 5240}, {"Word": "new", "OffsetStartMs": 5440, "OffsetEndMs": 5760}, {"Word": "instances", "OffsetStartMs": 5760, "OffsetEndMs": 6530}, {"Word": "that", "OffsetStartMs": 6820, "OffsetEndMs": 7095}, {"Word": "are", "OffsetStartMs": 7095, "OffsetEndMs": 7305}, {"Word": "similar", "OffsetStartMs": 7305, "OffsetEndMs": 7640}, {"Word": "to", "OffsetStartMs": 7750, "OffsetEndMs": 8025}, {"Word": "the", "OffsetStartMs": 8025, "OffsetEndMs": 8250}, {"Word": "existing", "OffsetStartMs": 8250, "OffsetEndMs": 8580}, {"Word": "data", "OffsetStartMs": 8580, "OffsetEndMs": 8960}, {"Word": "meaning", "OffsetStartMs": 9670, "OffsetEndMs": 10035}, {"Word": "that", "OffsetStartMs": 10035, "OffsetEndMs": 10365}, {"Word": "we", "OffsetStartMs": 10365, "OffsetEndMs": 10650}, {"Word": "want", "OffsetStartMs": 10650, "OffsetEndMs": 10950}, {"Word": "to", "OffsetStartMs": 10950, "OffsetEndMs": 11250}, {"Word": "try", "OffsetStartMs": 11250, "OffsetEndMs": 11505}, {"Word": "to", "OffsetStartMs": 11505, "OffsetEndMs": 11805}, {"Word": "sample", "OffsetStartMs": 11805, "OffsetEndMs": 12170}, {"Word": "from", "OffsetStartMs": 12310, "OffsetEndMs": 12710}, {"Word": "a", "OffsetStartMs": 12880, "OffsetEndMs": 13230}, {"Word": "potentially", "OffsetStartMs": 13230, "OffsetEndMs": 13580}, {"Word": "very", "OffsetStartMs": 13660, "OffsetEndMs": 14060}, {"Word": "complex", "OffsetStartMs": 14170, "OffsetEndMs": 14570}, {"Word": "distribution", "OffsetStartMs": 14590, "OffsetEndMs": 14990}, {"Word": "that", "OffsetStartMs": 15670, "OffsetEndMs": 16020}, {"Word": "the", "OffsetStartMs": 16020, "OffsetEndMs": 16230}, {"Word": "model", "OffsetStartMs": 16230, "OffsetEndMs": 16485}, {"Word": "is", "OffsetStartMs": 16485, "OffsetEndMs": 16815}, {"Word": "trying", "OffsetStartMs": 16815, "OffsetEndMs": 17130}, {"Word": "to", "OffsetStartMs": 17130, "OffsetEndMs": 17505}, {"Word": "approximate", "OffsetStartMs": 17505, "OffsetEndMs": 18200}], "SpeechSpeed": 13.6}, {"FinalSentence": "It can be extremely, extremely difficult to learn that distribution directly because it's complex, it's high dimensional and we want to be able to get around that complexity.", "SliceSentence": "It can be extremely extremely difficult to learn that distribution directly because it's complex it's high dimensional and we want to be able to get around that complexity", "StartMs": 2363180, "EndMs": 2374440, "WordsNum": 28, "Words": [{"Word": "It", "OffsetStartMs": 190, "OffsetEndMs": 450}, {"Word": "can", "OffsetStartMs": 450, "OffsetEndMs": 555}, {"Word": "be", "OffsetStartMs": 555, "OffsetEndMs": 800}, {"Word": "extremely", "OffsetStartMs": 970, "OffsetEndMs": 1370}, {"Word": "extremely", "OffsetStartMs": 1480, "OffsetEndMs": 1880}, {"Word": "difficult", "OffsetStartMs": 2050, "OffsetEndMs": 2355}, {"Word": "to", "OffsetStartMs": 2355, "OffsetEndMs": 2565}, {"Word": "learn", "OffsetStartMs": 2565, "OffsetEndMs": 2870}, {"Word": "that", "OffsetStartMs": 3040, "OffsetEndMs": 3440}, {"Word": "distribution", "OffsetStartMs": 3580, "OffsetEndMs": 3980}, {"Word": "directly", "OffsetStartMs": 4090, "OffsetEndMs": 4490}, {"Word": "because", "OffsetStartMs": 4660, "OffsetEndMs": 5025}, {"Word": "it's", "OffsetStartMs": 5025, "OffsetEndMs": 5475}, {"Word": "complex", "OffsetStartMs": 5475, "OffsetEndMs": 5850}, {"Word": "it's", "OffsetStartMs": 5850, "OffsetEndMs": 6195}, {"Word": "high", "OffsetStartMs": 6195, "OffsetEndMs": 6375}, {"Word": "dimensional", "OffsetStartMs": 6375, "OffsetEndMs": 7070}, {"Word": "and", "OffsetStartMs": 7270, "OffsetEndMs": 7545}, {"Word": "we", "OffsetStartMs": 7545, "OffsetEndMs": 7710}, {"Word": "want", "OffsetStartMs": 7710, "OffsetEndMs": 7980}, {"Word": "to", "OffsetStartMs": 7980, "OffsetEndMs": 8360}, {"Word": "be", "OffsetStartMs": 8620, "OffsetEndMs": 8880}, {"Word": "able", "OffsetStartMs": 8880, "OffsetEndMs": 9060}, {"Word": "to", "OffsetStartMs": 9060, "OffsetEndMs": 9240}, {"Word": "get", "OffsetStartMs": 9240, "OffsetEndMs": 9420}, {"Word": "around", "OffsetStartMs": 9420, "OffsetEndMs": 9645}, {"Word": "that", "OffsetStartMs": 9645, "OffsetEndMs": 9915}, {"Word": "complexity", "OffsetStartMs": 9915, "OffsetEndMs": 10610}], "SpeechSpeed": 15.2}, {"FinalSentence": "What ganss do is they say, okay, what if we start from something super, super simple? As simple as it can get completely random noise? Could we build a neural network architecture that can learn to generate synthetic examples from complete random noise?", "SliceSentence": "What ganss do is they say okay what if we start from something super super simple As simple as it can get completely random noise Could we build a neural network architecture that can learn to generate synthetic examples from complete random noise", "StartMs": 2374440, "EndMs": 2393360, "WordsNum": 43, "Words": [{"Word": "What", "OffsetStartMs": 70, "OffsetEndMs": 375}, {"Word": "ganss", "OffsetStartMs": 375, "OffsetEndMs": 795}, {"Word": "do", "OffsetStartMs": 795, "OffsetEndMs": 1095}, {"Word": "is", "OffsetStartMs": 1095, "OffsetEndMs": 1380}, {"Word": "they", "OffsetStartMs": 1380, "OffsetEndMs": 1575}, {"Word": "say", "OffsetStartMs": 1575, "OffsetEndMs": 1880}, {"Word": "okay", "OffsetStartMs": 1900, "OffsetEndMs": 2300}, {"Word": "what", "OffsetStartMs": 2680, "OffsetEndMs": 2955}, {"Word": "if", "OffsetStartMs": 2955, "OffsetEndMs": 3105}, {"Word": "we", "OffsetStartMs": 3105, "OffsetEndMs": 3300}, {"Word": "start", "OffsetStartMs": 3300, "OffsetEndMs": 3525}, {"Word": "from", "OffsetStartMs": 3525, "OffsetEndMs": 3735}, {"Word": "something", "OffsetStartMs": 3735, "OffsetEndMs": 4040}, {"Word": "super", "OffsetStartMs": 4180, "OffsetEndMs": 4560}, {"Word": "super", "OffsetStartMs": 4560, "OffsetEndMs": 4890}, {"Word": "simple", "OffsetStartMs": 4890, "OffsetEndMs": 5235}, {"Word": "As", "OffsetStartMs": 5235, "OffsetEndMs": 5625}, {"Word": "simple", "OffsetStartMs": 5625, "OffsetEndMs": 5970}, {"Word": "as", "OffsetStartMs": 5970, "OffsetEndMs": 6210}, {"Word": "it", "OffsetStartMs": 6210, "OffsetEndMs": 6360}, {"Word": "can", "OffsetStartMs": 6360, "OffsetEndMs": 6510}, {"Word": "get", "OffsetStartMs": 6510, "OffsetEndMs": 6800}, {"Word": "completely", "OffsetStartMs": 7510, "OffsetEndMs": 7910}, {"Word": "random", "OffsetStartMs": 7930, "OffsetEndMs": 8330}, {"Word": "noise", "OffsetStartMs": 8350, "OffsetEndMs": 8750}, {"Word": "Could", "OffsetStartMs": 9460, "OffsetEndMs": 9750}, {"Word": "we", "OffsetStartMs": 9750, "OffsetEndMs": 9930}, {"Word": "build", "OffsetStartMs": 9930, "OffsetEndMs": 10155}, {"Word": "a", "OffsetStartMs": 10155, "OffsetEndMs": 10380}, {"Word": "neural", "OffsetStartMs": 10380, "OffsetEndMs": 10710}, {"Word": "network", "OffsetStartMs": 10710, "OffsetEndMs": 11000}, {"Word": "architecture", "OffsetStartMs": 11320, "OffsetEndMs": 11720}, {"Word": "that", "OffsetStartMs": 12490, "OffsetEndMs": 12765}, {"Word": "can", "OffsetStartMs": 12765, "OffsetEndMs": 12960}, {"Word": "learn", "OffsetStartMs": 12960, "OffsetEndMs": 13280}, {"Word": "to", "OffsetStartMs": 13630, "OffsetEndMs": 13935}, {"Word": "generate", "OffsetStartMs": 13935, "OffsetEndMs": 14240}, {"Word": "synthetic", "OffsetStartMs": 14590, "OffsetEndMs": 15230}, {"Word": "examples", "OffsetStartMs": 15310, "OffsetEndMs": 15710}, {"Word": "from", "OffsetStartMs": 15940, "OffsetEndMs": 16340}, {"Word": "complete", "OffsetStartMs": 16420, "OffsetEndMs": 16820}, {"Word": "random", "OffsetStartMs": 17290, "OffsetEndMs": 17690}, {"Word": "noise", "OffsetStartMs": 17950, "OffsetEndMs": 18350}], "SpeechSpeed": 13.1}, {"FinalSentence": "And this is the underlying concept of gans, where the goal is to train this generator network that learns a transformation from noise to the training data distribution.", "SliceSentence": "And this is the underlying concept of gans where the goal is to train this generator network that learns a transformation from noise to the training data distribution", "StartMs": 2394020, "EndMs": 2407840, "WordsNum": 28, "Words": [{"Word": "And", "OffsetStartMs": 190, "OffsetEndMs": 480}, {"Word": "this", "OffsetStartMs": 480, "OffsetEndMs": 720}, {"Word": "is", "OffsetStartMs": 720, "OffsetEndMs": 990}, {"Word": "the", "OffsetStartMs": 990, "OffsetEndMs": 1155}, {"Word": "underlying", "OffsetStartMs": 1155, "OffsetEndMs": 1400}, {"Word": "concept", "OffsetStartMs": 1660, "OffsetEndMs": 2060}, {"Word": "of", "OffsetStartMs": 2230, "OffsetEndMs": 2625}, {"Word": "gans", "OffsetStartMs": 2625, "OffsetEndMs": 3050}, {"Word": "where", "OffsetStartMs": 3790, "OffsetEndMs": 4190}, {"Word": "the", "OffsetStartMs": 4630, "OffsetEndMs": 4905}, {"Word": "goal", "OffsetStartMs": 4905, "OffsetEndMs": 5130}, {"Word": "is", "OffsetStartMs": 5130, "OffsetEndMs": 5370}, {"Word": "to", "OffsetStartMs": 5370, "OffsetEndMs": 5595}, {"Word": "train", "OffsetStartMs": 5595, "OffsetEndMs": 5850}, {"Word": "this", "OffsetStartMs": 5850, "OffsetEndMs": 6075}, {"Word": "generator", "OffsetStartMs": 6075, "OffsetEndMs": 6620}, {"Word": "network", "OffsetStartMs": 6640, "OffsetEndMs": 7040}, {"Word": "that", "OffsetStartMs": 7480, "OffsetEndMs": 7815}, {"Word": "learns", "OffsetStartMs": 7815, "OffsetEndMs": 8325}, {"Word": "a", "OffsetStartMs": 8325, "OffsetEndMs": 8690}, {"Word": "transformation", "OffsetStartMs": 8710, "OffsetEndMs": 9110}, {"Word": "from", "OffsetStartMs": 9760, "OffsetEndMs": 10065}, {"Word": "noise", "OffsetStartMs": 10065, "OffsetEndMs": 10370}, {"Word": "to", "OffsetStartMs": 11020, "OffsetEndMs": 11420}, {"Word": "the", "OffsetStartMs": 11470, "OffsetEndMs": 11775}, {"Word": "training", "OffsetStartMs": 11775, "OffsetEndMs": 12060}, {"Word": "data", "OffsetStartMs": 12060, "OffsetEndMs": 12440}, {"Word": "distribution", "OffsetStartMs": 12550, "OffsetEndMs": 12950}], "SpeechSpeed": 12.0}, {"FinalSentence": "With the goal of making the generated examples as close to the real deo as possible.", "SliceSentence": "With the goal of making the generated examples as close to the real deo as possible", "StartMs": 2407840, "EndMs": 2414640, "WordsNum": 16, "Words": [{"Word": "With", "OffsetStartMs": 0, "OffsetEndMs": 270}, {"Word": "the", "OffsetStartMs": 270, "OffsetEndMs": 420}, {"Word": "goal", "OffsetStartMs": 420, "OffsetEndMs": 630}, {"Word": "of", "OffsetStartMs": 630, "OffsetEndMs": 960}, {"Word": "making", "OffsetStartMs": 960, "OffsetEndMs": 1305}, {"Word": "the", "OffsetStartMs": 1305, "OffsetEndMs": 1545}, {"Word": "generated", "OffsetStartMs": 1545, "OffsetEndMs": 1820}, {"Word": "examples", "OffsetStartMs": 2050, "OffsetEndMs": 2450}, {"Word": "as", "OffsetStartMs": 2890, "OffsetEndMs": 3270}, {"Word": "close", "OffsetStartMs": 3270, "OffsetEndMs": 3585}, {"Word": "to", "OffsetStartMs": 3585, "OffsetEndMs": 3765}, {"Word": "the", "OffsetStartMs": 3765, "OffsetEndMs": 3870}, {"Word": "real", "OffsetStartMs": 3870, "OffsetEndMs": 4065}, {"Word": "deo", "OffsetStartMs": 4065, "OffsetEndMs": 4550}, {"Word": "as", "OffsetStartMs": 4750, "OffsetEndMs": 5100}, {"Word": "possible", "OffsetStartMs": 5100, "OffsetEndMs": 5450}], "SpeechSpeed": 12.2}, {"FinalSentence": "With gans, the breakthrough idea here was to interface these two neural networks together, one being a generator and one being a discriminator.", "SliceSentence": "With gans the breakthrough idea here was to interface these two neural networks together one being a generator and one being a discriminator", "StartMs": 2414780, "EndMs": 2428440, "WordsNum": 23, "Words": [{"Word": "With", "OffsetStartMs": 130, "OffsetEndMs": 465}, {"Word": "gans", "OffsetStartMs": 465, "OffsetEndMs": 830}, {"Word": "the", "OffsetStartMs": 1690, "OffsetEndMs": 2010}, {"Word": "breakthrough", "OffsetStartMs": 2010, "OffsetEndMs": 2610}, {"Word": "idea", "OffsetStartMs": 2610, "OffsetEndMs": 2940}, {"Word": "here", "OffsetStartMs": 2940, "OffsetEndMs": 3240}, {"Word": "was", "OffsetStartMs": 3240, "OffsetEndMs": 3590}, {"Word": "to", "OffsetStartMs": 3850, "OffsetEndMs": 4250}, {"Word": "interface", "OffsetStartMs": 5800, "OffsetEndMs": 6540}, {"Word": "these", "OffsetStartMs": 6540, "OffsetEndMs": 6915}, {"Word": "two", "OffsetStartMs": 6915, "OffsetEndMs": 7245}, {"Word": "neural", "OffsetStartMs": 7245, "OffsetEndMs": 7590}, {"Word": "networks", "OffsetStartMs": 7590, "OffsetEndMs": 7880}, {"Word": "together", "OffsetStartMs": 8080, "OffsetEndMs": 8480}, {"Word": "one", "OffsetStartMs": 9280, "OffsetEndMs": 9675}, {"Word": "being", "OffsetStartMs": 9675, "OffsetEndMs": 9990}, {"Word": "a", "OffsetStartMs": 9990, "OffsetEndMs": 10185}, {"Word": "generator", "OffsetStartMs": 10185, "OffsetEndMs": 10700}, {"Word": "and", "OffsetStartMs": 11080, "OffsetEndMs": 11400}, {"Word": "one", "OffsetStartMs": 11400, "OffsetEndMs": 11685}, {"Word": "being", "OffsetStartMs": 11685, "OffsetEndMs": 12050}, {"Word": "a", "OffsetStartMs": 12070, "OffsetEndMs": 12345}, {"Word": "discriminator", "OffsetStartMs": 12345, "OffsetEndMs": 13070}], "SpeechSpeed": 10.2}, {"FinalSentence": "And these two components, the generator and discriminator, are at war, at competition with each other.", "SliceSentence": "And these two components the generator and discriminator are at war at competition with each other", "StartMs": 2428440, "EndMs": 2435460, "WordsNum": 16, "Words": [{"Word": "And", "OffsetStartMs": 40, "OffsetEndMs": 345}, {"Word": "these", "OffsetStartMs": 345, "OffsetEndMs": 600}, {"Word": "two", "OffsetStartMs": 600, "OffsetEndMs": 900}, {"Word": "components", "OffsetStartMs": 900, "OffsetEndMs": 1250}, {"Word": "the", "OffsetStartMs": 1300, "OffsetEndMs": 1590}, {"Word": "generator", "OffsetStartMs": 1590, "OffsetEndMs": 2100}, {"Word": "and", "OffsetStartMs": 2100, "OffsetEndMs": 2480}, {"Word": "discriminator", "OffsetStartMs": 2590, "OffsetEndMs": 3410}, {"Word": "are", "OffsetStartMs": 3700, "OffsetEndMs": 3975}, {"Word": "at", "OffsetStartMs": 3975, "OffsetEndMs": 4185}, {"Word": "war", "OffsetStartMs": 4185, "OffsetEndMs": 4520}, {"Word": "at", "OffsetStartMs": 4720, "OffsetEndMs": 5120}, {"Word": "competition", "OffsetStartMs": 5290, "OffsetEndMs": 5625}, {"Word": "with", "OffsetStartMs": 5625, "OffsetEndMs": 5835}, {"Word": "each", "OffsetStartMs": 5835, "OffsetEndMs": 6000}, {"Word": "other", "OffsetStartMs": 6000, "OffsetEndMs": 6290}], "SpeechSpeed": 14.0}, {"FinalSentence": "Specifically, the goal of the generator network is to look at random noise and try to produce an imitation of the data that's as close to real as possible.", "SliceSentence": "Specifically the goal of the generator network is to look at random noise and try to produce an imitation of the data that's as close to real as possible", "StartMs": 2435460, "EndMs": 2446760, "WordsNum": 29, "Words": [{"Word": "Specifically", "OffsetStartMs": 190, "OffsetEndMs": 590}, {"Word": "the", "OffsetStartMs": 1120, "OffsetEndMs": 1410}, {"Word": "goal", "OffsetStartMs": 1410, "OffsetEndMs": 1620}, {"Word": "of", "OffsetStartMs": 1620, "OffsetEndMs": 1815}, {"Word": "the", "OffsetStartMs": 1815, "OffsetEndMs": 1965}, {"Word": "generator", "OffsetStartMs": 1965, "OffsetEndMs": 2415}, {"Word": "network", "OffsetStartMs": 2415, "OffsetEndMs": 2780}, {"Word": "is", "OffsetStartMs": 3340, "OffsetEndMs": 3735}, {"Word": "to", "OffsetStartMs": 3735, "OffsetEndMs": 4125}, {"Word": "look", "OffsetStartMs": 4125, "OffsetEndMs": 4395}, {"Word": "at", "OffsetStartMs": 4395, "OffsetEndMs": 4560}, {"Word": "random", "OffsetStartMs": 4560, "OffsetEndMs": 4845}, {"Word": "noise", "OffsetStartMs": 4845, "OffsetEndMs": 5240}, {"Word": "and", "OffsetStartMs": 5710, "OffsetEndMs": 6060}, {"Word": "try", "OffsetStartMs": 6060, "OffsetEndMs": 6330}, {"Word": "to", "OffsetStartMs": 6330, "OffsetEndMs": 6615}, {"Word": "produce", "OffsetStartMs": 6615, "OffsetEndMs": 6930}, {"Word": "an", "OffsetStartMs": 6930, "OffsetEndMs": 7170}, {"Word": "imitation", "OffsetStartMs": 7170, "OffsetEndMs": 7695}, {"Word": "of", "OffsetStartMs": 7695, "OffsetEndMs": 7905}, {"Word": "the", "OffsetStartMs": 7905, "OffsetEndMs": 8040}, {"Word": "data", "OffsetStartMs": 8040, "OffsetEndMs": 8300}, {"Word": "that's", "OffsetStartMs": 8560, "OffsetEndMs": 9015}, {"Word": "as", "OffsetStartMs": 9015, "OffsetEndMs": 9255}, {"Word": "close", "OffsetStartMs": 9255, "OffsetEndMs": 9555}, {"Word": "to", "OffsetStartMs": 9555, "OffsetEndMs": 9750}, {"Word": "real", "OffsetStartMs": 9750, "OffsetEndMs": 9900}, {"Word": "as", "OffsetStartMs": 9900, "OffsetEndMs": 10125}, {"Word": "possible", "OffsetStartMs": 10125, "OffsetEndMs": 10460}], "SpeechSpeed": 13.5}, {"FinalSentence": "The discriminator then takes the output of the generator as well as some real data examples, and tries to learn a classification decision.", "SliceSentence": "The discriminator then takes the output of the generator as well as some real data examples and tries to learn a classification decision", "StartMs": 2446940, "EndMs": 2458340, "WordsNum": 23, "Words": [{"Word": "The", "OffsetStartMs": 160, "OffsetEndMs": 450}, {"Word": "discriminator", "OffsetStartMs": 450, "OffsetEndMs": 1160}, {"Word": "then", "OffsetStartMs": 1540, "OffsetEndMs": 1905}, {"Word": "takes", "OffsetStartMs": 1905, "OffsetEndMs": 2190}, {"Word": "the", "OffsetStartMs": 2190, "OffsetEndMs": 2510}, {"Word": "output", "OffsetStartMs": 2590, "OffsetEndMs": 2990}, {"Word": "of", "OffsetStartMs": 3220, "OffsetEndMs": 3555}, {"Word": "the", "OffsetStartMs": 3555, "OffsetEndMs": 3780}, {"Word": "generator", "OffsetStartMs": 3780, "OffsetEndMs": 4310}, {"Word": "as", "OffsetStartMs": 4690, "OffsetEndMs": 5040}, {"Word": "well", "OffsetStartMs": 5040, "OffsetEndMs": 5280}, {"Word": "as", "OffsetStartMs": 5280, "OffsetEndMs": 5475}, {"Word": "some", "OffsetStartMs": 5475, "OffsetEndMs": 5685}, {"Word": "real", "OffsetStartMs": 5685, "OffsetEndMs": 5910}, {"Word": "data", "OffsetStartMs": 5910, "OffsetEndMs": 6210}, {"Word": "examples", "OffsetStartMs": 6210, "OffsetEndMs": 6590}, {"Word": "and", "OffsetStartMs": 7150, "OffsetEndMs": 7500}, {"Word": "tries", "OffsetStartMs": 7500, "OffsetEndMs": 7800}, {"Word": "to", "OffsetStartMs": 7800, "OffsetEndMs": 8025}, {"Word": "learn", "OffsetStartMs": 8025, "OffsetEndMs": 8250}, {"Word": "a", "OffsetStartMs": 8250, "OffsetEndMs": 8520}, {"Word": "classification", "OffsetStartMs": 8520, "OffsetEndMs": 10070}, {"Word": "decision", "OffsetStartMs": 10330, "OffsetEndMs": 10730}], "SpeechSpeed": 11.9}, {"FinalSentence": "Distinguishing real from fake.", "SliceSentence": "Distinguishing real from fake", "StartMs": 2458440, "EndMs": 2461480, "WordsNum": 4, "Words": [{"Word": "Distinguishing", "OffsetStartMs": 310, "OffsetEndMs": 1070}, {"Word": "real", "OffsetStartMs": 1180, "OffsetEndMs": 1580}, {"Word": "from", "OffsetStartMs": 1690, "OffsetEndMs": 1995}, {"Word": "fake", "OffsetStartMs": 1995, "OffsetEndMs": 2300}], "SpeechSpeed": 9.5}, {"FinalSentence": "And effectively in the g, these two components are going back and forth, competing each other, trying to force the discriminator to better learn this distinction between real and fake, while the generator is trying to fool and outperform the ability of the discriminator to make that classification.", "SliceSentence": "And effectively in the g these two components are going back and forth competing each other trying to force the discriminator to better learn this distinction between real and fake while the generator is trying to fool and outperform the ability of the discriminator to make that classification", "StartMs": 2461480, "EndMs": 2481740, "WordsNum": 48, "Words": [{"Word": "And", "OffsetStartMs": 0, "OffsetEndMs": 345}, {"Word": "effectively", "OffsetStartMs": 345, "OffsetEndMs": 710}, {"Word": "in", "OffsetStartMs": 820, "OffsetEndMs": 1110}, {"Word": "the", "OffsetStartMs": 1110, "OffsetEndMs": 1275}, {"Word": "g", "OffsetStartMs": 1275, "OffsetEndMs": 1485}, {"Word": "these", "OffsetStartMs": 1485, "OffsetEndMs": 1800}, {"Word": "two", "OffsetStartMs": 1800, "OffsetEndMs": 2180}, {"Word": "components", "OffsetStartMs": 2350, "OffsetEndMs": 2750}, {"Word": "are", "OffsetStartMs": 3070, "OffsetEndMs": 3375}, {"Word": "going", "OffsetStartMs": 3375, "OffsetEndMs": 3630}, {"Word": "back", "OffsetStartMs": 3630, "OffsetEndMs": 3885}, {"Word": "and", "OffsetStartMs": 3885, "OffsetEndMs": 4080}, {"Word": "forth", "OffsetStartMs": 4080, "OffsetEndMs": 4370}, {"Word": "competing", "OffsetStartMs": 4510, "OffsetEndMs": 4875}, {"Word": "each", "OffsetStartMs": 4875, "OffsetEndMs": 5040}, {"Word": "other", "OffsetStartMs": 5040, "OffsetEndMs": 5330}, {"Word": "trying", "OffsetStartMs": 6040, "OffsetEndMs": 6375}, {"Word": "to", "OffsetStartMs": 6375, "OffsetEndMs": 6585}, {"Word": "force", "OffsetStartMs": 6585, "OffsetEndMs": 6825}, {"Word": "the", "OffsetStartMs": 6825, "OffsetEndMs": 7185}, {"Word": "discriminator", "OffsetStartMs": 7185, "OffsetEndMs": 7995}, {"Word": "to", "OffsetStartMs": 7995, "OffsetEndMs": 8265}, {"Word": "better", "OffsetStartMs": 8265, "OffsetEndMs": 8550}, {"Word": "learn", "OffsetStartMs": 8550, "OffsetEndMs": 8850}, {"Word": "this", "OffsetStartMs": 8850, "OffsetEndMs": 9075}, {"Word": "distinction", "OffsetStartMs": 9075, "OffsetEndMs": 9560}, {"Word": "between", "OffsetStartMs": 10060, "OffsetEndMs": 10380}, {"Word": "real", "OffsetStartMs": 10380, "OffsetEndMs": 10605}, {"Word": "and", "OffsetStartMs": 10605, "OffsetEndMs": 10815}, {"Word": "fake", "OffsetStartMs": 10815, "OffsetEndMs": 11120}, {"Word": "while", "OffsetStartMs": 11770, "OffsetEndMs": 12170}, {"Word": "the", "OffsetStartMs": 12520, "OffsetEndMs": 12825}, {"Word": "generator", "OffsetStartMs": 12825, "OffsetEndMs": 13290}, {"Word": "is", "OffsetStartMs": 13290, "OffsetEndMs": 13575}, {"Word": "trying", "OffsetStartMs": 13575, "OffsetEndMs": 13845}, {"Word": "to", "OffsetStartMs": 13845, "OffsetEndMs": 14180}, {"Word": "fool", "OffsetStartMs": 14260, "OffsetEndMs": 14660}, {"Word": "and", "OffsetStartMs": 14770, "OffsetEndMs": 15075}, {"Word": "outperform", "OffsetStartMs": 15075, "OffsetEndMs": 15860}, {"Word": "the", "OffsetStartMs": 16060, "OffsetEndMs": 16440}, {"Word": "ability", "OffsetStartMs": 16440, "OffsetEndMs": 16820}, {"Word": "of", "OffsetStartMs": 16870, "OffsetEndMs": 17145}, {"Word": "the", "OffsetStartMs": 17145, "OffsetEndMs": 17280}, {"Word": "discriminator", "OffsetStartMs": 17280, "OffsetEndMs": 17960}, {"Word": "to", "OffsetStartMs": 17980, "OffsetEndMs": 18255}, {"Word": "make", "OffsetStartMs": 18255, "OffsetEndMs": 18480}, {"Word": "that", "OffsetStartMs": 18480, "OffsetEndMs": 18830}, {"Word": "classification", "OffsetStartMs": 18910, "OffsetEndMs": 19580}], "SpeechSpeed": 14.5}, {"FinalSentence": "So that's the overlying concept. But what I'm really excited about is the next example, which is one of my absolute favorite illustrations and walkthroughs in this class. And it gets at the intuition behind gans, how they work and the underlying concept.", "SliceSentence": "So that's the overlying concept . Butwhat I'm really excited about is the next example which is one of my absolute favorite illustrations and walkthroughs in this class . Andit gets at the intuition behind gans how they work and the underlying concept", "StartMs": 2482620, "EndMs": 2502760, "WordsNum": 43, "Words": [{"Word": "So", "OffsetStartMs": 160, "OffsetEndMs": 560}, {"Word": "that's", "OffsetStartMs": 1330, "OffsetEndMs": 1770}, {"Word": "the", "OffsetStartMs": 1770, "OffsetEndMs": 1875}, {"Word": "overlying", "OffsetStartMs": 1875, "OffsetEndMs": 2390}, {"Word": "concept", "OffsetStartMs": 2470, "OffsetEndMs": 2870}, {"Word": ".", "OffsetStartMs": 3460, "OffsetEndMs": 3860}, {"Word": "Butwhat", "OffsetStartMs": 3880, "OffsetEndMs": 4155}, {"Word": "I'm", "OffsetStartMs": 4155, "OffsetEndMs": 4520}, {"Word": "really", "OffsetStartMs": 4600, "OffsetEndMs": 4965}, {"Word": "excited", "OffsetStartMs": 4965, "OffsetEndMs": 5295}, {"Word": "about", "OffsetStartMs": 5295, "OffsetEndMs": 5595}, {"Word": "is", "OffsetStartMs": 5595, "OffsetEndMs": 5930}, {"Word": "the", "OffsetStartMs": 6310, "OffsetEndMs": 6585}, {"Word": "next", "OffsetStartMs": 6585, "OffsetEndMs": 6860}, {"Word": "example", "OffsetStartMs": 6880, "OffsetEndMs": 7280}, {"Word": "which", "OffsetStartMs": 7300, "OffsetEndMs": 7575}, {"Word": "is", "OffsetStartMs": 7575, "OffsetEndMs": 7755}, {"Word": "one", "OffsetStartMs": 7755, "OffsetEndMs": 7935}, {"Word": "of", "OffsetStartMs": 7935, "OffsetEndMs": 8085}, {"Word": "my", "OffsetStartMs": 8085, "OffsetEndMs": 8360}, {"Word": "absolute", "OffsetStartMs": 8500, "OffsetEndMs": 8895}, {"Word": "favorite", "OffsetStartMs": 8895, "OffsetEndMs": 9290}, {"Word": "illustrations", "OffsetStartMs": 9460, "OffsetEndMs": 10190}, {"Word": "and", "OffsetStartMs": 10360, "OffsetEndMs": 10760}, {"Word": "walkthroughs", "OffsetStartMs": 10960, "OffsetEndMs": 11610}, {"Word": "in", "OffsetStartMs": 11610, "OffsetEndMs": 11745}, {"Word": "this", "OffsetStartMs": 11745, "OffsetEndMs": 11925}, {"Word": "class", "OffsetStartMs": 11925, "OffsetEndMs": 12230}, {"Word": ".", "OffsetStartMs": 12610, "OffsetEndMs": 12870}, {"Word": "Andit", "OffsetStartMs": 12870, "OffsetEndMs": 13020}, {"Word": "gets", "OffsetStartMs": 13020, "OffsetEndMs": 13275}, {"Word": "at", "OffsetStartMs": 13275, "OffsetEndMs": 13545}, {"Word": "the", "OffsetStartMs": 13545, "OffsetEndMs": 13725}, {"Word": "intuition", "OffsetStartMs": 13725, "OffsetEndMs": 14300}, {"Word": "behind", "OffsetStartMs": 14560, "OffsetEndMs": 14910}, {"Word": "gans", "OffsetStartMs": 14910, "OffsetEndMs": 15290}, {"Word": "how", "OffsetStartMs": 15610, "OffsetEndMs": 15900}, {"Word": "they", "OffsetStartMs": 15900, "OffsetEndMs": 16080}, {"Word": "work", "OffsetStartMs": 16080, "OffsetEndMs": 16370}, {"Word": "and", "OffsetStartMs": 16450, "OffsetEndMs": 16725}, {"Word": "the", "OffsetStartMs": 16725, "OffsetEndMs": 16845}, {"Word": "underlying", "OffsetStartMs": 16845, "OffsetEndMs": 17090}, {"Word": "concept", "OffsetStartMs": 17260, "OffsetEndMs": 17660}], "SpeechSpeed": 12.4}, {"FinalSentence": "We're going to look at a one d example, points on a line, right? That's the data that we're working with.", "SliceSentence": "We're going to look at a one d example points on a line right That's the data that we're working with", "StartMs": 2502760, "EndMs": 2508720, "WordsNum": 21, "Words": [{"Word": "We're", "OffsetStartMs": 40, "OffsetEndMs": 360}, {"Word": "going", "OffsetStartMs": 360, "OffsetEndMs": 480}, {"Word": "to", "OffsetStartMs": 480, "OffsetEndMs": 645}, {"Word": "look", "OffsetStartMs": 645, "OffsetEndMs": 795}, {"Word": "at", "OffsetStartMs": 795, "OffsetEndMs": 975}, {"Word": "a", "OffsetStartMs": 975, "OffsetEndMs": 1170}, {"Word": "one", "OffsetStartMs": 1170, "OffsetEndMs": 1395}, {"Word": "d", "OffsetStartMs": 1395, "OffsetEndMs": 1665}, {"Word": "example", "OffsetStartMs": 1665, "OffsetEndMs": 2000}, {"Word": "points", "OffsetStartMs": 2200, "OffsetEndMs": 2520}, {"Word": "on", "OffsetStartMs": 2520, "OffsetEndMs": 2700}, {"Word": "a", "OffsetStartMs": 2700, "OffsetEndMs": 2820}, {"Word": "line", "OffsetStartMs": 2820, "OffsetEndMs": 3080}, {"Word": "right", "OffsetStartMs": 3100, "OffsetEndMs": 3480}, {"Word": "That's", "OffsetStartMs": 3480, "OffsetEndMs": 3975}, {"Word": "the", "OffsetStartMs": 3975, "OffsetEndMs": 4185}, {"Word": "data", "OffsetStartMs": 4185, "OffsetEndMs": 4395}, {"Word": "that", "OffsetStartMs": 4395, "OffsetEndMs": 4605}, {"Word": "we're", "OffsetStartMs": 4605, "OffsetEndMs": 4815}, {"Word": "working", "OffsetStartMs": 4815, "OffsetEndMs": 5040}, {"Word": "with", "OffsetStartMs": 5040, "OffsetEndMs": 5420}], "SpeechSpeed": 16.9}, {"FinalSentence": "And again, the generator starts from random noise, produces some fake data. They're going to fall somewhere on this one dimensional line.", "SliceSentence": "And again the generator starts from random noise produces some fake data .They're going to fall somewhere on this one dimensional line", "StartMs": 2508720, "EndMs": 2517460, "WordsNum": 22, "Words": [{"Word": "And", "OffsetStartMs": 40, "OffsetEndMs": 375}, {"Word": "again", "OffsetStartMs": 375, "OffsetEndMs": 710}, {"Word": "the", "OffsetStartMs": 880, "OffsetEndMs": 1170}, {"Word": "generator", "OffsetStartMs": 1170, "OffsetEndMs": 1730}, {"Word": "starts", "OffsetStartMs": 1750, "OffsetEndMs": 2150}, {"Word": "from", "OffsetStartMs": 2170, "OffsetEndMs": 2570}, {"Word": "random", "OffsetStartMs": 2620, "OffsetEndMs": 2985}, {"Word": "noise", "OffsetStartMs": 2985, "OffsetEndMs": 3350}, {"Word": "produces", "OffsetStartMs": 3670, "OffsetEndMs": 4155}, {"Word": "some", "OffsetStartMs": 4155, "OffsetEndMs": 4455}, {"Word": "fake", "OffsetStartMs": 4455, "OffsetEndMs": 4710}, {"Word": "data", "OffsetStartMs": 4710, "OffsetEndMs": 4995}, {"Word": ".They're", "OffsetStartMs": 4995, "OffsetEndMs": 5295}, {"Word": "going", "OffsetStartMs": 5295, "OffsetEndMs": 5445}, {"Word": "to", "OffsetStartMs": 5445, "OffsetEndMs": 5655}, {"Word": "fall", "OffsetStartMs": 5655, "OffsetEndMs": 5925}, {"Word": "somewhere", "OffsetStartMs": 5925, "OffsetEndMs": 6285}, {"Word": "on", "OffsetStartMs": 6285, "OffsetEndMs": 6555}, {"Word": "this", "OffsetStartMs": 6555, "OffsetEndMs": 6720}, {"Word": "one", "OffsetStartMs": 6720, "OffsetEndMs": 6900}, {"Word": "dimensional", "OffsetStartMs": 6900, "OffsetEndMs": 7580}, {"Word": "line", "OffsetStartMs": 7630, "OffsetEndMs": 8030}], "SpeechSpeed": 15.2}, {"FinalSentence": "Now the next step is the discriminator then sees these points.", "SliceSentence": "Now the next step is the discriminator then sees these points", "StartMs": 2517740, "EndMs": 2522720, "WordsNum": 11, "Words": [{"Word": "Now", "OffsetStartMs": 130, "OffsetEndMs": 530}, {"Word": "the", "OffsetStartMs": 760, "OffsetEndMs": 1035}, {"Word": "next", "OffsetStartMs": 1035, "OffsetEndMs": 1260}, {"Word": "step", "OffsetStartMs": 1260, "OffsetEndMs": 1610}, {"Word": "is", "OffsetStartMs": 1870, "OffsetEndMs": 2220}, {"Word": "the", "OffsetStartMs": 2220, "OffsetEndMs": 2445}, {"Word": "discriminator", "OffsetStartMs": 2445, "OffsetEndMs": 3105}, {"Word": "then", "OffsetStartMs": 3105, "OffsetEndMs": 3405}, {"Word": "sees", "OffsetStartMs": 3405, "OffsetEndMs": 3645}, {"Word": "these", "OffsetStartMs": 3645, "OffsetEndMs": 3870}, {"Word": "points", "OffsetStartMs": 3870, "OffsetEndMs": 4190}], "SpeechSpeed": 12.2}, {"FinalSentence": "And it also sees some real data.", "SliceSentence": "And it also sees some real data", "StartMs": 2522820, "EndMs": 2526160, "WordsNum": 7, "Words": [{"Word": "And", "OffsetStartMs": 100, "OffsetEndMs": 500}, {"Word": "it", "OffsetStartMs": 550, "OffsetEndMs": 950}, {"Word": "also", "OffsetStartMs": 970, "OffsetEndMs": 1275}, {"Word": "sees", "OffsetStartMs": 1275, "OffsetEndMs": 1560}, {"Word": "some", "OffsetStartMs": 1560, "OffsetEndMs": 1940}, {"Word": "real", "OffsetStartMs": 1990, "OffsetEndMs": 2295}, {"Word": "data", "OffsetStartMs": 2295, "OffsetEndMs": 2600}], "SpeechSpeed": 9.3}, {"FinalSentence": "The goal of the discriminator is to be trained to output a probability that an instance it sees is real or fake.", "SliceSentence": "The goal of the discriminator is to be trained to output a probability that an instance it sees is real or fake", "StartMs": 2526360, "EndMs": 2536560, "WordsNum": 22, "Words": [{"Word": "The", "OffsetStartMs": 100, "OffsetEndMs": 375}, {"Word": "goal", "OffsetStartMs": 375, "OffsetEndMs": 555}, {"Word": "of", "OffsetStartMs": 555, "OffsetEndMs": 735}, {"Word": "the", "OffsetStartMs": 735, "OffsetEndMs": 870}, {"Word": "discriminator", "OffsetStartMs": 870, "OffsetEndMs": 1520}, {"Word": "is", "OffsetStartMs": 1690, "OffsetEndMs": 2090}, {"Word": "to", "OffsetStartMs": 2410, "OffsetEndMs": 2685}, {"Word": "be", "OffsetStartMs": 2685, "OffsetEndMs": 2880}, {"Word": "trained", "OffsetStartMs": 2880, "OffsetEndMs": 3200}, {"Word": "to", "OffsetStartMs": 3610, "OffsetEndMs": 4010}, {"Word": "output", "OffsetStartMs": 4090, "OffsetEndMs": 4350}, {"Word": "a", "OffsetStartMs": 4350, "OffsetEndMs": 4515}, {"Word": "probability", "OffsetStartMs": 4515, "OffsetEndMs": 5090}, {"Word": "that", "OffsetStartMs": 5410, "OffsetEndMs": 5790}, {"Word": "an", "OffsetStartMs": 5790, "OffsetEndMs": 6170}, {"Word": "instance", "OffsetStartMs": 6400, "OffsetEndMs": 6690}, {"Word": "it", "OffsetStartMs": 6690, "OffsetEndMs": 6900}, {"Word": "sees", "OffsetStartMs": 6900, "OffsetEndMs": 7220}, {"Word": "is", "OffsetStartMs": 7690, "OffsetEndMs": 8025}, {"Word": "real", "OffsetStartMs": 8025, "OffsetEndMs": 8360}, {"Word": "or", "OffsetStartMs": 8890, "OffsetEndMs": 9210}, {"Word": "fake", "OffsetStartMs": 9210, "OffsetEndMs": 9530}], "SpeechSpeed": 10.9}, {"FinalSentence": "And initially in the beginning before training, it's not trained right. So its predictions may not be very good. But over the course of training, you're going to train it and it hopefully will start increasing the probability for those examples that are real and decreasing the probability for those examples that are fake.", "SliceSentence": "And initially in the beginning before training it's not trained right . Soits predictions may not be very good . Butover the course of training you're going to train it and it hopefully will start increasing the probability for those examples that are real and decreasing the probability for those examples that are fake", "StartMs": 2537060, "EndMs": 2558560, "WordsNum": 54, "Words": [{"Word": "And", "OffsetStartMs": 70, "OffsetEndMs": 435}, {"Word": "initially", "OffsetStartMs": 435, "OffsetEndMs": 800}, {"Word": "in", "OffsetStartMs": 910, "OffsetEndMs": 1200}, {"Word": "the", "OffsetStartMs": 1200, "OffsetEndMs": 1410}, {"Word": "beginning", "OffsetStartMs": 1410, "OffsetEndMs": 1710}, {"Word": "before", "OffsetStartMs": 1710, "OffsetEndMs": 2090}, {"Word": "training", "OffsetStartMs": 2170, "OffsetEndMs": 2570}, {"Word": "it's", "OffsetStartMs": 3010, "OffsetEndMs": 3405}, {"Word": "not", "OffsetStartMs": 3405, "OffsetEndMs": 3615}, {"Word": "trained", "OffsetStartMs": 3615, "OffsetEndMs": 3915}, {"Word": "right", "OffsetStartMs": 3915, "OffsetEndMs": 4280}, {"Word": ".", "OffsetStartMs": 4540, "OffsetEndMs": 4800}, {"Word": "Soits", "OffsetStartMs": 4800, "OffsetEndMs": 4965}, {"Word": "predictions", "OffsetStartMs": 4965, "OffsetEndMs": 5490}, {"Word": "may", "OffsetStartMs": 5490, "OffsetEndMs": 5685}, {"Word": "not", "OffsetStartMs": 5685, "OffsetEndMs": 5850}, {"Word": "be", "OffsetStartMs": 5850, "OffsetEndMs": 6015}, {"Word": "very", "OffsetStartMs": 6015, "OffsetEndMs": 6240}, {"Word": "good", "OffsetStartMs": 6240, "OffsetEndMs": 6590}, {"Word": ".", "OffsetStartMs": 7180, "OffsetEndMs": 7580}, {"Word": "Butover", "OffsetStartMs": 7690, "OffsetEndMs": 8025}, {"Word": "the", "OffsetStartMs": 8025, "OffsetEndMs": 8235}, {"Word": "course", "OffsetStartMs": 8235, "OffsetEndMs": 8400}, {"Word": "of", "OffsetStartMs": 8400, "OffsetEndMs": 8595}, {"Word": "training", "OffsetStartMs": 8595, "OffsetEndMs": 8895}, {"Word": "you're", "OffsetStartMs": 8895, "OffsetEndMs": 9225}, {"Word": "going", "OffsetStartMs": 9225, "OffsetEndMs": 9375}, {"Word": "to", "OffsetStartMs": 9375, "OffsetEndMs": 9570}, {"Word": "train", "OffsetStartMs": 9570, "OffsetEndMs": 9750}, {"Word": "it", "OffsetStartMs": 9750, "OffsetEndMs": 10040}, {"Word": "and", "OffsetStartMs": 10420, "OffsetEndMs": 10710}, {"Word": "it", "OffsetStartMs": 10710, "OffsetEndMs": 11000}, {"Word": "hopefully", "OffsetStartMs": 11050, "OffsetEndMs": 11445}, {"Word": "will", "OffsetStartMs": 11445, "OffsetEndMs": 11790}, {"Word": "start", "OffsetStartMs": 11790, "OffsetEndMs": 12140}, {"Word": "increasing", "OffsetStartMs": 12370, "OffsetEndMs": 12750}, {"Word": "the", "OffsetStartMs": 12750, "OffsetEndMs": 13005}, {"Word": "probability", "OffsetStartMs": 13005, "OffsetEndMs": 13550}, {"Word": "for", "OffsetStartMs": 14410, "OffsetEndMs": 14730}, {"Word": "those", "OffsetStartMs": 14730, "OffsetEndMs": 15030}, {"Word": "examples", "OffsetStartMs": 15030, "OffsetEndMs": 15410}, {"Word": "that", "OffsetStartMs": 15550, "OffsetEndMs": 15810}, {"Word": "are", "OffsetStartMs": 15810, "OffsetEndMs": 15990}, {"Word": "real", "OffsetStartMs": 15990, "OffsetEndMs": 16310}, {"Word": "and", "OffsetStartMs": 16810, "OffsetEndMs": 17210}, {"Word": "decreasing", "OffsetStartMs": 17410, "OffsetEndMs": 17850}, {"Word": "the", "OffsetStartMs": 17850, "OffsetEndMs": 17985}, {"Word": "probability", "OffsetStartMs": 17985, "OffsetEndMs": 18530}, {"Word": "for", "OffsetStartMs": 18880, "OffsetEndMs": 19170}, {"Word": "those", "OffsetStartMs": 19170, "OffsetEndMs": 19460}, {"Word": "examples", "OffsetStartMs": 19480, "OffsetEndMs": 19880}, {"Word": "that", "OffsetStartMs": 20200, "OffsetEndMs": 20460}, {"Word": "are", "OffsetStartMs": 20460, "OffsetEndMs": 20625}, {"Word": "fake", "OffsetStartMs": 20625, "OffsetEndMs": 20930}], "SpeechSpeed": 14.8}, {"FinalSentence": "Overall goal is to predict what is real.", "SliceSentence": "Overall goal is to predict what is real", "StartMs": 2558680, "EndMs": 2562260, "WordsNum": 8, "Words": [{"Word": "Overall", "OffsetStartMs": 70, "OffsetEndMs": 470}, {"Word": "goal", "OffsetStartMs": 550, "OffsetEndMs": 950}, {"Word": "is", "OffsetStartMs": 1240, "OffsetEndMs": 1620}, {"Word": "to", "OffsetStartMs": 1620, "OffsetEndMs": 1890}, {"Word": "predict", "OffsetStartMs": 1890, "OffsetEndMs": 2180}, {"Word": "what", "OffsetStartMs": 2200, "OffsetEndMs": 2460}, {"Word": "is", "OffsetStartMs": 2460, "OffsetEndMs": 2625}, {"Word": "real", "OffsetStartMs": 2625, "OffsetEndMs": 2930}], "SpeechSpeed": 10.9}, {"FinalSentence": "Until eventually the discriminator reaches this point where it has a perfect separation, perfect classification of real versus fake.", "SliceSentence": "Until eventually the discriminator reaches this point where it has a perfect separation perfect classification of real versus fake", "StartMs": 2562260, "EndMs": 2572480, "WordsNum": 19, "Words": [{"Word": "Until", "OffsetStartMs": 340, "OffsetEndMs": 740}, {"Word": "eventually", "OffsetStartMs": 1480, "OffsetEndMs": 1880}, {"Word": "the", "OffsetStartMs": 1930, "OffsetEndMs": 2190}, {"Word": "discriminator", "OffsetStartMs": 2190, "OffsetEndMs": 2865}, {"Word": "reaches", "OffsetStartMs": 2865, "OffsetEndMs": 3300}, {"Word": "this", "OffsetStartMs": 3300, "OffsetEndMs": 3495}, {"Word": "point", "OffsetStartMs": 3495, "OffsetEndMs": 3765}, {"Word": "where", "OffsetStartMs": 3765, "OffsetEndMs": 4065}, {"Word": "it", "OffsetStartMs": 4065, "OffsetEndMs": 4275}, {"Word": "has", "OffsetStartMs": 4275, "OffsetEndMs": 4425}, {"Word": "a", "OffsetStartMs": 4425, "OffsetEndMs": 4605}, {"Word": "perfect", "OffsetStartMs": 4605, "OffsetEndMs": 4875}, {"Word": "separation", "OffsetStartMs": 4875, "OffsetEndMs": 5510}, {"Word": "perfect", "OffsetStartMs": 5890, "OffsetEndMs": 6255}, {"Word": "classification", "OffsetStartMs": 6255, "OffsetEndMs": 6920}, {"Word": "of", "OffsetStartMs": 7600, "OffsetEndMs": 8000}, {"Word": "real", "OffsetStartMs": 8170, "OffsetEndMs": 8570}, {"Word": "versus", "OffsetStartMs": 8860, "OffsetEndMs": 9240}, {"Word": "fake", "OffsetStartMs": 9240, "OffsetEndMs": 9620}], "SpeechSpeed": 12.7}, {"FinalSentence": "Okay, so at this point, the discriminator thinks, okay, I've done my job, now we go back to the generator and it sees the examples of where the real data lie.", "SliceSentence": "Okay so at this point the discriminator thinks okay I've done my job now we go back to the generator and it sees the examples of where the real data lie", "StartMs": 2572820, "EndMs": 2584140, "WordsNum": 31, "Words": [{"Word": "Okay", "OffsetStartMs": 220, "OffsetEndMs": 620}, {"Word": "so", "OffsetStartMs": 820, "OffsetEndMs": 1065}, {"Word": "at", "OffsetStartMs": 1065, "OffsetEndMs": 1200}, {"Word": "this", "OffsetStartMs": 1200, "OffsetEndMs": 1380}, {"Word": "point", "OffsetStartMs": 1380, "OffsetEndMs": 1575}, {"Word": "the", "OffsetStartMs": 1575, "OffsetEndMs": 1740}, {"Word": "discriminator", "OffsetStartMs": 1740, "OffsetEndMs": 2400}, {"Word": "thinks", "OffsetStartMs": 2400, "OffsetEndMs": 2780}, {"Word": "okay", "OffsetStartMs": 2860, "OffsetEndMs": 3120}, {"Word": "I've", "OffsetStartMs": 3120, "OffsetEndMs": 3375}, {"Word": "done", "OffsetStartMs": 3375, "OffsetEndMs": 3525}, {"Word": "my", "OffsetStartMs": 3525, "OffsetEndMs": 3720}, {"Word": "job", "OffsetStartMs": 3720, "OffsetEndMs": 4010}, {"Word": "now", "OffsetStartMs": 4510, "OffsetEndMs": 4910}, {"Word": "we", "OffsetStartMs": 5290, "OffsetEndMs": 5565}, {"Word": "go", "OffsetStartMs": 5565, "OffsetEndMs": 5730}, {"Word": "back", "OffsetStartMs": 5730, "OffsetEndMs": 5955}, {"Word": "to", "OffsetStartMs": 5955, "OffsetEndMs": 6135}, {"Word": "the", "OffsetStartMs": 6135, "OffsetEndMs": 6255}, {"Word": "generator", "OffsetStartMs": 6255, "OffsetEndMs": 6740}, {"Word": "and", "OffsetStartMs": 7360, "OffsetEndMs": 7620}, {"Word": "it", "OffsetStartMs": 7620, "OffsetEndMs": 7815}, {"Word": "sees", "OffsetStartMs": 7815, "OffsetEndMs": 8085}, {"Word": "the", "OffsetStartMs": 8085, "OffsetEndMs": 8370}, {"Word": "examples", "OffsetStartMs": 8370, "OffsetEndMs": 8720}, {"Word": "of", "OffsetStartMs": 8740, "OffsetEndMs": 9030}, {"Word": "where", "OffsetStartMs": 9030, "OffsetEndMs": 9225}, {"Word": "the", "OffsetStartMs": 9225, "OffsetEndMs": 9405}, {"Word": "real", "OffsetStartMs": 9405, "OffsetEndMs": 9600}, {"Word": "data", "OffsetStartMs": 9600, "OffsetEndMs": 9885}, {"Word": "lie", "OffsetStartMs": 9885, "OffsetEndMs": 10250}], "SpeechSpeed": 13.4}, {"FinalSentence": "And it can be forced to start moving its generated fake data closer and closer, increasingly closer to the real data.", "SliceSentence": "And it can be forced to start moving its generated fake data closer and closer increasingly closer to the real data", "StartMs": 2584140, "EndMs": 2593640, "WordsNum": 21, "Words": [{"Word": "And", "OffsetStartMs": 0, "OffsetEndMs": 320}, {"Word": "it", "OffsetStartMs": 730, "OffsetEndMs": 1005}, {"Word": "can", "OffsetStartMs": 1005, "OffsetEndMs": 1260}, {"Word": "be", "OffsetStartMs": 1260, "OffsetEndMs": 1575}, {"Word": "forced", "OffsetStartMs": 1575, "OffsetEndMs": 1875}, {"Word": "to", "OffsetStartMs": 1875, "OffsetEndMs": 2145}, {"Word": "start", "OffsetStartMs": 2145, "OffsetEndMs": 2400}, {"Word": "moving", "OffsetStartMs": 2400, "OffsetEndMs": 2750}, {"Word": "its", "OffsetStartMs": 2830, "OffsetEndMs": 3180}, {"Word": "generated", "OffsetStartMs": 3180, "OffsetEndMs": 3530}, {"Word": "fake", "OffsetStartMs": 3730, "OffsetEndMs": 4050}, {"Word": "data", "OffsetStartMs": 4050, "OffsetEndMs": 4370}, {"Word": "closer", "OffsetStartMs": 4960, "OffsetEndMs": 5360}, {"Word": "and", "OffsetStartMs": 5620, "OffsetEndMs": 6000}, {"Word": "closer", "OffsetStartMs": 6000, "OffsetEndMs": 6380}, {"Word": "increasingly", "OffsetStartMs": 6760, "OffsetEndMs": 7160}, {"Word": "closer", "OffsetStartMs": 7300, "OffsetEndMs": 7700}, {"Word": "to", "OffsetStartMs": 7960, "OffsetEndMs": 8205}, {"Word": "the", "OffsetStartMs": 8205, "OffsetEndMs": 8325}, {"Word": "real", "OffsetStartMs": 8325, "OffsetEndMs": 8520}, {"Word": "data", "OffsetStartMs": 8520, "OffsetEndMs": 8840}], "SpeechSpeed": 12.1}, {"FinalSentence": "We can then go back to the discriminator, which receives these newly synthesized examples from the generator, and repeats that same process of estimating the probability that any given point is real.", "SliceSentence": "We can then go back to the discriminator which receives these newly synthesized examples from the generator and repeats that same process of estimating the probability that any given point is real", "StartMs": 2594180, "EndMs": 2607680, "WordsNum": 32, "Words": [{"Word": "We", "OffsetStartMs": 130, "OffsetEndMs": 390}, {"Word": "can", "OffsetStartMs": 390, "OffsetEndMs": 525}, {"Word": "then", "OffsetStartMs": 525, "OffsetEndMs": 720}, {"Word": "go", "OffsetStartMs": 720, "OffsetEndMs": 930}, {"Word": "back", "OffsetStartMs": 930, "OffsetEndMs": 1170}, {"Word": "to", "OffsetStartMs": 1170, "OffsetEndMs": 1380}, {"Word": "the", "OffsetStartMs": 1380, "OffsetEndMs": 1500}, {"Word": "discriminator", "OffsetStartMs": 1500, "OffsetEndMs": 2115}, {"Word": "which", "OffsetStartMs": 2115, "OffsetEndMs": 2400}, {"Word": "receives", "OffsetStartMs": 2400, "OffsetEndMs": 2820}, {"Word": "these", "OffsetStartMs": 2820, "OffsetEndMs": 3105}, {"Word": "newly", "OffsetStartMs": 3105, "OffsetEndMs": 3615}, {"Word": "synthesized", "OffsetStartMs": 3615, "OffsetEndMs": 4250}, {"Word": "examples", "OffsetStartMs": 4450, "OffsetEndMs": 4850}, {"Word": "from", "OffsetStartMs": 4960, "OffsetEndMs": 5265}, {"Word": "the", "OffsetStartMs": 5265, "OffsetEndMs": 5445}, {"Word": "generator", "OffsetStartMs": 5445, "OffsetEndMs": 5930}, {"Word": "and", "OffsetStartMs": 6490, "OffsetEndMs": 6890}, {"Word": "repeats", "OffsetStartMs": 6910, "OffsetEndMs": 7275}, {"Word": "that", "OffsetStartMs": 7275, "OffsetEndMs": 7470}, {"Word": "same", "OffsetStartMs": 7470, "OffsetEndMs": 7725}, {"Word": "process", "OffsetStartMs": 7725, "OffsetEndMs": 8060}, {"Word": "of", "OffsetStartMs": 8710, "OffsetEndMs": 9110}, {"Word": "estimating", "OffsetStartMs": 9250, "OffsetEndMs": 9720}, {"Word": "the", "OffsetStartMs": 9720, "OffsetEndMs": 9960}, {"Word": "probability", "OffsetStartMs": 9960, "OffsetEndMs": 10520}, {"Word": "that", "OffsetStartMs": 10780, "OffsetEndMs": 11100}, {"Word": "any", "OffsetStartMs": 11100, "OffsetEndMs": 11355}, {"Word": "given", "OffsetStartMs": 11355, "OffsetEndMs": 11640}, {"Word": "point", "OffsetStartMs": 11640, "OffsetEndMs": 11990}, {"Word": "is", "OffsetStartMs": 12190, "OffsetEndMs": 12495}, {"Word": "real", "OffsetStartMs": 12495, "OffsetEndMs": 12800}], "SpeechSpeed": 14.5}, {"FinalSentence": "And learning to increase the probability of the true real examples decrease the probability of the fake points.", "SliceSentence": "And learning to increase the probability of the true real examples decrease the probability of the fake points", "StartMs": 2608060, "EndMs": 2616080, "WordsNum": 18, "Words": [{"Word": "And", "OffsetStartMs": 160, "OffsetEndMs": 560}, {"Word": "learning", "OffsetStartMs": 820, "OffsetEndMs": 1200}, {"Word": "to", "OffsetStartMs": 1200, "OffsetEndMs": 1580}, {"Word": "increase", "OffsetStartMs": 1630, "OffsetEndMs": 1935}, {"Word": "the", "OffsetStartMs": 1935, "OffsetEndMs": 2115}, {"Word": "probability", "OffsetStartMs": 2115, "OffsetEndMs": 2655}, {"Word": "of", "OffsetStartMs": 2655, "OffsetEndMs": 3015}, {"Word": "the", "OffsetStartMs": 3015, "OffsetEndMs": 3315}, {"Word": "true", "OffsetStartMs": 3315, "OffsetEndMs": 3540}, {"Word": "real", "OffsetStartMs": 3540, "OffsetEndMs": 3825}, {"Word": "examples", "OffsetStartMs": 3825, "OffsetEndMs": 4190}, {"Word": "decrease", "OffsetStartMs": 4930, "OffsetEndMs": 5235}, {"Word": "the", "OffsetStartMs": 5235, "OffsetEndMs": 5415}, {"Word": "probability", "OffsetStartMs": 5415, "OffsetEndMs": 5960}, {"Word": "of", "OffsetStartMs": 6010, "OffsetEndMs": 6390}, {"Word": "the", "OffsetStartMs": 6390, "OffsetEndMs": 6645}, {"Word": "fake", "OffsetStartMs": 6645, "OffsetEndMs": 6855}, {"Word": "points", "OffsetStartMs": 6855, "OffsetEndMs": 7190}], "SpeechSpeed": 13.7}, {"FinalSentence": "Adjusting, adjusting over the course of its training.", "SliceSentence": "Adjusting adjusting over the course of its training", "StartMs": 2616300, "EndMs": 2620020, "WordsNum": 8, "Words": [{"Word": "Adjusting", "OffsetStartMs": 280, "OffsetEndMs": 915}, {"Word": "adjusting", "OffsetStartMs": 915, "OffsetEndMs": 1520}, {"Word": "over", "OffsetStartMs": 1540, "OffsetEndMs": 1875}, {"Word": "the", "OffsetStartMs": 1875, "OffsetEndMs": 2100}, {"Word": "course", "OffsetStartMs": 2100, "OffsetEndMs": 2280}, {"Word": "of", "OffsetStartMs": 2280, "OffsetEndMs": 2430}, {"Word": "its", "OffsetStartMs": 2430, "OffsetEndMs": 2610}, {"Word": "training", "OffsetStartMs": 2610, "OffsetEndMs": 2930}], "SpeechSpeed": 13.7}, {"FinalSentence": "And finally, we can go back and repeat to the generator again one last time. The generator starts moving those fake points closer.", "SliceSentence": "And finally we can go back and repeat to the generator again one last time . Thegenerator starts moving those fake points closer", "StartMs": 2620460, "EndMs": 2629480, "WordsNum": 23, "Words": [{"Word": "And", "OffsetStartMs": 70, "OffsetEndMs": 360}, {"Word": "finally", "OffsetStartMs": 360, "OffsetEndMs": 645}, {"Word": "we", "OffsetStartMs": 645, "OffsetEndMs": 900}, {"Word": "can", "OffsetStartMs": 900, "OffsetEndMs": 1035}, {"Word": "go", "OffsetStartMs": 1035, "OffsetEndMs": 1200}, {"Word": "back", "OffsetStartMs": 1200, "OffsetEndMs": 1440}, {"Word": "and", "OffsetStartMs": 1440, "OffsetEndMs": 1790}, {"Word": "repeat", "OffsetStartMs": 1840, "OffsetEndMs": 2220}, {"Word": "to", "OffsetStartMs": 2220, "OffsetEndMs": 2445}, {"Word": "the", "OffsetStartMs": 2445, "OffsetEndMs": 2550}, {"Word": "generator", "OffsetStartMs": 2550, "OffsetEndMs": 3030}, {"Word": "again", "OffsetStartMs": 3030, "OffsetEndMs": 3410}, {"Word": "one", "OffsetStartMs": 3730, "OffsetEndMs": 4035}, {"Word": "last", "OffsetStartMs": 4035, "OffsetEndMs": 4305}, {"Word": "time", "OffsetStartMs": 4305, "OffsetEndMs": 4670}, {"Word": ".", "OffsetStartMs": 4930, "OffsetEndMs": 5220}, {"Word": "Thegenerator", "OffsetStartMs": 5220, "OffsetEndMs": 5700}, {"Word": "starts", "OffsetStartMs": 5700, "OffsetEndMs": 6045}, {"Word": "moving", "OffsetStartMs": 6045, "OffsetEndMs": 6375}, {"Word": "those", "OffsetStartMs": 6375, "OffsetEndMs": 6690}, {"Word": "fake", "OffsetStartMs": 6690, "OffsetEndMs": 6975}, {"Word": "points", "OffsetStartMs": 6975, "OffsetEndMs": 7310}, {"Word": "closer", "OffsetStartMs": 7600, "OffsetEndMs": 8000}], "SpeechSpeed": 14.1}, {"FinalSentence": "Closer and closer to the real data, such that the fake data is almost following the distribution of the real data.", "SliceSentence": "Closer and closer to the real data such that the fake data is almost following the distribution of the real data", "StartMs": 2629480, "EndMs": 2637660, "WordsNum": 21, "Words": [{"Word": "Closer", "OffsetStartMs": 10, "OffsetEndMs": 410}, {"Word": "and", "OffsetStartMs": 520, "OffsetEndMs": 855}, {"Word": "closer", "OffsetStartMs": 855, "OffsetEndMs": 1185}, {"Word": "to", "OffsetStartMs": 1185, "OffsetEndMs": 1425}, {"Word": "the", "OffsetStartMs": 1425, "OffsetEndMs": 1530}, {"Word": "real", "OffsetStartMs": 1530, "OffsetEndMs": 1725}, {"Word": "data", "OffsetStartMs": 1725, "OffsetEndMs": 2060}, {"Word": "such", "OffsetStartMs": 2590, "OffsetEndMs": 2925}, {"Word": "that", "OffsetStartMs": 2925, "OffsetEndMs": 3150}, {"Word": "the", "OffsetStartMs": 3150, "OffsetEndMs": 3300}, {"Word": "fake", "OffsetStartMs": 3300, "OffsetEndMs": 3495}, {"Word": "data", "OffsetStartMs": 3495, "OffsetEndMs": 3825}, {"Word": "is", "OffsetStartMs": 3825, "OffsetEndMs": 4220}, {"Word": "almost", "OffsetStartMs": 4360, "OffsetEndMs": 4710}, {"Word": "following", "OffsetStartMs": 4710, "OffsetEndMs": 5060}, {"Word": "the", "OffsetStartMs": 5110, "OffsetEndMs": 5460}, {"Word": "distribution", "OffsetStartMs": 5460, "OffsetEndMs": 5810}, {"Word": "of", "OffsetStartMs": 6040, "OffsetEndMs": 6330}, {"Word": "the", "OffsetStartMs": 6330, "OffsetEndMs": 6480}, {"Word": "real", "OffsetStartMs": 6480, "OffsetEndMs": 6660}, {"Word": "data", "OffsetStartMs": 6660, "OffsetEndMs": 6980}], "SpeechSpeed": 13.7}, {"FinalSentence": "At this point, it becomes very, very hard for the discriminator to distinguish between what is real and what is fake.", "SliceSentence": "At this point it becomes very very hard for the discriminator to distinguish between what is real and what is fake", "StartMs": 2638020, "EndMs": 2646800, "WordsNum": 21, "Words": [{"Word": "At", "OffsetStartMs": 160, "OffsetEndMs": 465}, {"Word": "this", "OffsetStartMs": 465, "OffsetEndMs": 705}, {"Word": "point", "OffsetStartMs": 705, "OffsetEndMs": 1020}, {"Word": "it", "OffsetStartMs": 1020, "OffsetEndMs": 1400}, {"Word": "becomes", "OffsetStartMs": 1540, "OffsetEndMs": 1920}, {"Word": "very", "OffsetStartMs": 1920, "OffsetEndMs": 2265}, {"Word": "very", "OffsetStartMs": 2265, "OffsetEndMs": 2580}, {"Word": "hard", "OffsetStartMs": 2580, "OffsetEndMs": 2930}, {"Word": "for", "OffsetStartMs": 3280, "OffsetEndMs": 3600}, {"Word": "the", "OffsetStartMs": 3600, "OffsetEndMs": 3780}, {"Word": "discriminator", "OffsetStartMs": 3780, "OffsetEndMs": 4490}, {"Word": "to", "OffsetStartMs": 4780, "OffsetEndMs": 5175}, {"Word": "distinguish", "OffsetStartMs": 5175, "OffsetEndMs": 5745}, {"Word": "between", "OffsetStartMs": 5745, "OffsetEndMs": 6140}, {"Word": "what", "OffsetStartMs": 6190, "OffsetEndMs": 6450}, {"Word": "is", "OffsetStartMs": 6450, "OffsetEndMs": 6615}, {"Word": "real", "OffsetStartMs": 6615, "OffsetEndMs": 6920}, {"Word": "and", "OffsetStartMs": 7120, "OffsetEndMs": 7425}, {"Word": "what", "OffsetStartMs": 7425, "OffsetEndMs": 7590}, {"Word": "is", "OffsetStartMs": 7590, "OffsetEndMs": 7755}, {"Word": "fake", "OffsetStartMs": 7755, "OffsetEndMs": 8060}], "SpeechSpeed": 13.0}, {"FinalSentence": "While the generator will continue to try to create fake data points to fool the discriminator.", "SliceSentence": "While the generator will continue to try to create fake data points to fool the discriminator", "StartMs": 2646800, "EndMs": 2653400, "WordsNum": 16, "Words": [{"Word": "While", "OffsetStartMs": 0, "OffsetEndMs": 225}, {"Word": "the", "OffsetStartMs": 225, "OffsetEndMs": 450}, {"Word": "generator", "OffsetStartMs": 450, "OffsetEndMs": 915}, {"Word": "will", "OffsetStartMs": 915, "OffsetEndMs": 1245}, {"Word": "continue", "OffsetStartMs": 1245, "OffsetEndMs": 1605}, {"Word": "to", "OffsetStartMs": 1605, "OffsetEndMs": 1905}, {"Word": "try", "OffsetStartMs": 1905, "OffsetEndMs": 2205}, {"Word": "to", "OffsetStartMs": 2205, "OffsetEndMs": 2570}, {"Word": "create", "OffsetStartMs": 2650, "OffsetEndMs": 3030}, {"Word": "fake", "OffsetStartMs": 3030, "OffsetEndMs": 3345}, {"Word": "data", "OffsetStartMs": 3345, "OffsetEndMs": 3630}, {"Word": "points", "OffsetStartMs": 3630, "OffsetEndMs": 3980}, {"Word": "to", "OffsetStartMs": 4330, "OffsetEndMs": 4665}, {"Word": "fool", "OffsetStartMs": 4665, "OffsetEndMs": 4950}, {"Word": "the", "OffsetStartMs": 4950, "OffsetEndMs": 5175}, {"Word": "discriminator", "OffsetStartMs": 5175, "OffsetEndMs": 5870}], "SpeechSpeed": 14.1}, {"FinalSentence": "This is really the key concept, the underlying intuition behind how the components of the Gan are essentially competing with each other, going back and forth between the generator and the discriminator.", "SliceSentence": "This is really the key concept the underlying intuition behind how the components of the Gan are essentially competing with each other going back and forth between the generator and the discriminator", "StartMs": 2653900, "EndMs": 2667320, "WordsNum": 32, "Words": [{"Word": "This", "OffsetStartMs": 100, "OffsetEndMs": 390}, {"Word": "is", "OffsetStartMs": 390, "OffsetEndMs": 600}, {"Word": "really", "OffsetStartMs": 600, "OffsetEndMs": 855}, {"Word": "the", "OffsetStartMs": 855, "OffsetEndMs": 1125}, {"Word": "key", "OffsetStartMs": 1125, "OffsetEndMs": 1455}, {"Word": "concept", "OffsetStartMs": 1455, "OffsetEndMs": 1850}, {"Word": "the", "OffsetStartMs": 1900, "OffsetEndMs": 2160}, {"Word": "underlying", "OffsetStartMs": 2160, "OffsetEndMs": 2420}, {"Word": "intuition", "OffsetStartMs": 2650, "OffsetEndMs": 3320}, {"Word": "behind", "OffsetStartMs": 3520, "OffsetEndMs": 3915}, {"Word": "how", "OffsetStartMs": 3915, "OffsetEndMs": 4200}, {"Word": "the", "OffsetStartMs": 4200, "OffsetEndMs": 4455}, {"Word": "components", "OffsetStartMs": 4455, "OffsetEndMs": 4820}, {"Word": "of", "OffsetStartMs": 5140, "OffsetEndMs": 5445}, {"Word": "the", "OffsetStartMs": 5445, "OffsetEndMs": 5610}, {"Word": "Gan", "OffsetStartMs": 5610, "OffsetEndMs": 5900}, {"Word": "are", "OffsetStartMs": 6070, "OffsetEndMs": 6435}, {"Word": "essentially", "OffsetStartMs": 6435, "OffsetEndMs": 6800}, {"Word": "competing", "OffsetStartMs": 7000, "OffsetEndMs": 7395}, {"Word": "with", "OffsetStartMs": 7395, "OffsetEndMs": 7530}, {"Word": "each", "OffsetStartMs": 7530, "OffsetEndMs": 7680}, {"Word": "other", "OffsetStartMs": 7680, "OffsetEndMs": 7970}, {"Word": "going", "OffsetStartMs": 8320, "OffsetEndMs": 8670}, {"Word": "back", "OffsetStartMs": 8670, "OffsetEndMs": 8925}, {"Word": "and", "OffsetStartMs": 8925, "OffsetEndMs": 9120}, {"Word": "forth", "OffsetStartMs": 9120, "OffsetEndMs": 9410}, {"Word": "between", "OffsetStartMs": 9700, "OffsetEndMs": 10100}, {"Word": "the", "OffsetStartMs": 10240, "OffsetEndMs": 10530}, {"Word": "generator", "OffsetStartMs": 10530, "OffsetEndMs": 11090}, {"Word": "and", "OffsetStartMs": 11140, "OffsetEndMs": 11540}, {"Word": "the", "OffsetStartMs": 11770, "OffsetEndMs": 12030}, {"Word": "discriminator", "OffsetStartMs": 12030, "OffsetEndMs": 12710}], "SpeechSpeed": 14.8}, {"FinalSentence": "And in fact, this is this intuitive concept is how the Gan is trained in practice, where the generator first tries to synthesize new examples, synthetic examples to fool the discriminator. And the goal of the discriminator is to take both the fake examples and the real data to try to identify the synthesized instances.", "SliceSentence": "And in fact this is this intuitive concept is how the Gan is trained in practice where the generator first tries to synthesize new examples synthetic examples to fool the discriminator . Andthe goal of the discriminator is to take both the fake examples and the real data to try to identify the synthesized instances", "StartMs": 2667560, "EndMs": 2690960, "WordsNum": 55, "Words": [{"Word": "And", "OffsetStartMs": 130, "OffsetEndMs": 390}, {"Word": "in", "OffsetStartMs": 390, "OffsetEndMs": 540}, {"Word": "fact", "OffsetStartMs": 540, "OffsetEndMs": 795}, {"Word": "this", "OffsetStartMs": 795, "OffsetEndMs": 1050}, {"Word": "is", "OffsetStartMs": 1050, "OffsetEndMs": 1340}, {"Word": "this", "OffsetStartMs": 1660, "OffsetEndMs": 1995}, {"Word": "intuitive", "OffsetStartMs": 1995, "OffsetEndMs": 2595}, {"Word": "concept", "OffsetStartMs": 2595, "OffsetEndMs": 2900}, {"Word": "is", "OffsetStartMs": 2980, "OffsetEndMs": 3300}, {"Word": "how", "OffsetStartMs": 3300, "OffsetEndMs": 3555}, {"Word": "the", "OffsetStartMs": 3555, "OffsetEndMs": 3750}, {"Word": "Gan", "OffsetStartMs": 3750, "OffsetEndMs": 4020}, {"Word": "is", "OffsetStartMs": 4020, "OffsetEndMs": 4350}, {"Word": "trained", "OffsetStartMs": 4350, "OffsetEndMs": 4700}, {"Word": "in", "OffsetStartMs": 4870, "OffsetEndMs": 5175}, {"Word": "practice", "OffsetStartMs": 5175, "OffsetEndMs": 5480}, {"Word": "where", "OffsetStartMs": 6310, "OffsetEndMs": 6600}, {"Word": "the", "OffsetStartMs": 6600, "OffsetEndMs": 6765}, {"Word": "generator", "OffsetStartMs": 6765, "OffsetEndMs": 7280}, {"Word": "first", "OffsetStartMs": 7510, "OffsetEndMs": 7875}, {"Word": "tries", "OffsetStartMs": 7875, "OffsetEndMs": 8220}, {"Word": "to", "OffsetStartMs": 8220, "OffsetEndMs": 8490}, {"Word": "synthesize", "OffsetStartMs": 8490, "OffsetEndMs": 9110}, {"Word": "new", "OffsetStartMs": 9520, "OffsetEndMs": 9920}, {"Word": "examples", "OffsetStartMs": 10120, "OffsetEndMs": 10520}, {"Word": "synthetic", "OffsetStartMs": 10810, "OffsetEndMs": 11390}, {"Word": "examples", "OffsetStartMs": 11440, "OffsetEndMs": 11840}, {"Word": "to", "OffsetStartMs": 12280, "OffsetEndMs": 12570}, {"Word": "fool", "OffsetStartMs": 12570, "OffsetEndMs": 12780}, {"Word": "the", "OffsetStartMs": 12780, "OffsetEndMs": 12960}, {"Word": "discriminator", "OffsetStartMs": 12960, "OffsetEndMs": 13640}, {"Word": ".", "OffsetStartMs": 14170, "OffsetEndMs": 14460}, {"Word": "Andthe", "OffsetStartMs": 14460, "OffsetEndMs": 14640}, {"Word": "goal", "OffsetStartMs": 14640, "OffsetEndMs": 14850}, {"Word": "of", "OffsetStartMs": 14850, "OffsetEndMs": 15045}, {"Word": "the", "OffsetStartMs": 15045, "OffsetEndMs": 15180}, {"Word": "discriminator", "OffsetStartMs": 15180, "OffsetEndMs": 15870}, {"Word": "is", "OffsetStartMs": 15870, "OffsetEndMs": 16155}, {"Word": "to", "OffsetStartMs": 16155, "OffsetEndMs": 16350}, {"Word": "take", "OffsetStartMs": 16350, "OffsetEndMs": 16575}, {"Word": "both", "OffsetStartMs": 16575, "OffsetEndMs": 16910}, {"Word": "the", "OffsetStartMs": 17260, "OffsetEndMs": 17550}, {"Word": "fake", "OffsetStartMs": 17550, "OffsetEndMs": 17835}, {"Word": "examples", "OffsetStartMs": 17835, "OffsetEndMs": 18230}, {"Word": "and", "OffsetStartMs": 18610, "OffsetEndMs": 18930}, {"Word": "the", "OffsetStartMs": 18930, "OffsetEndMs": 19110}, {"Word": "real", "OffsetStartMs": 19110, "OffsetEndMs": 19275}, {"Word": "data", "OffsetStartMs": 19275, "OffsetEndMs": 19580}, {"Word": "to", "OffsetStartMs": 19780, "OffsetEndMs": 20100}, {"Word": "try", "OffsetStartMs": 20100, "OffsetEndMs": 20340}, {"Word": "to", "OffsetStartMs": 20340, "OffsetEndMs": 20660}, {"Word": "identify", "OffsetStartMs": 20920, "OffsetEndMs": 21285}, {"Word": "the", "OffsetStartMs": 21285, "OffsetEndMs": 21540}, {"Word": "synthesized", "OffsetStartMs": 21540, "OffsetEndMs": 22125}, {"Word": "instances", "OffsetStartMs": 22125, "OffsetEndMs": 22880}], "SpeechSpeed": 13.5}, {"FinalSentence": "In training, what this means is that the objective.", "SliceSentence": "In training what this means is that the objective", "StartMs": 2691880, "EndMs": 2696240, "WordsNum": 9, "Words": [{"Word": "In", "OffsetStartMs": 100, "OffsetEndMs": 450}, {"Word": "training", "OffsetStartMs": 450, "OffsetEndMs": 800}, {"Word": "what", "OffsetStartMs": 1150, "OffsetEndMs": 1470}, {"Word": "this", "OffsetStartMs": 1470, "OffsetEndMs": 1695}, {"Word": "means", "OffsetStartMs": 1695, "OffsetEndMs": 1995}, {"Word": "is", "OffsetStartMs": 1995, "OffsetEndMs": 2280}, {"Word": "that", "OffsetStartMs": 2280, "OffsetEndMs": 2570}, {"Word": "the", "OffsetStartMs": 2620, "OffsetEndMs": 3000}, {"Word": "objective", "OffsetStartMs": 3000, "OffsetEndMs": 3380}], "SpeechSpeed": 11.2}, {"FinalSentence": "The loss for the generator and discriminator have to be at odds with each other. They're adversarial, and that is what gives rise to the component of adversarial in generative adversarial network.", "SliceSentence": "The loss for the generator and discriminator have to be at odds with each other .They're adversarial and that is what gives rise to the component of adversarial in generative adversarial network", "StartMs": 2696240, "EndMs": 2709340, "WordsNum": 32, "Words": [{"Word": "The", "OffsetStartMs": 0, "OffsetEndMs": 195}, {"Word": "loss", "OffsetStartMs": 195, "OffsetEndMs": 470}, {"Word": "for", "OffsetStartMs": 580, "OffsetEndMs": 900}, {"Word": "the", "OffsetStartMs": 900, "OffsetEndMs": 1095}, {"Word": "generator", "OffsetStartMs": 1095, "OffsetEndMs": 1590}, {"Word": "and", "OffsetStartMs": 1590, "OffsetEndMs": 1875}, {"Word": "discriminator", "OffsetStartMs": 1875, "OffsetEndMs": 2600}, {"Word": "have", "OffsetStartMs": 2740, "OffsetEndMs": 3060}, {"Word": "to", "OffsetStartMs": 3060, "OffsetEndMs": 3240}, {"Word": "be", "OffsetStartMs": 3240, "OffsetEndMs": 3420}, {"Word": "at", "OffsetStartMs": 3420, "OffsetEndMs": 3690}, {"Word": "odds", "OffsetStartMs": 3690, "OffsetEndMs": 4170}, {"Word": "with", "OffsetStartMs": 4170, "OffsetEndMs": 4320}, {"Word": "each", "OffsetStartMs": 4320, "OffsetEndMs": 4470}, {"Word": "other", "OffsetStartMs": 4470, "OffsetEndMs": 4760}, {"Word": ".They're", "OffsetStartMs": 5020, "OffsetEndMs": 5355}, {"Word": "adversarial", "OffsetStartMs": 5355, "OffsetEndMs": 6260}, {"Word": "and", "OffsetStartMs": 6310, "OffsetEndMs": 6600}, {"Word": "that", "OffsetStartMs": 6600, "OffsetEndMs": 6825}, {"Word": "is", "OffsetStartMs": 6825, "OffsetEndMs": 7050}, {"Word": "what", "OffsetStartMs": 7050, "OffsetEndMs": 7230}, {"Word": "gives", "OffsetStartMs": 7230, "OffsetEndMs": 7455}, {"Word": "rise", "OffsetStartMs": 7455, "OffsetEndMs": 7790}, {"Word": "to", "OffsetStartMs": 7840, "OffsetEndMs": 8190}, {"Word": "the", "OffsetStartMs": 8190, "OffsetEndMs": 8490}, {"Word": "component", "OffsetStartMs": 8490, "OffsetEndMs": 8835}, {"Word": "of", "OffsetStartMs": 8835, "OffsetEndMs": 9230}, {"Word": "adversarial", "OffsetStartMs": 9580, "OffsetEndMs": 10530}, {"Word": "in", "OffsetStartMs": 10530, "OffsetEndMs": 10800}, {"Word": "generative", "OffsetStartMs": 10800, "OffsetEndMs": 11280}, {"Word": "adversarial", "OffsetStartMs": 11280, "OffsetEndMs": 12030}, {"Word": "network", "OffsetStartMs": 12030, "OffsetEndMs": 12380}], "SpeechSpeed": 14.7}, {"FinalSentence": "These adversarial objectives are then put together to then define what it means to arrive at a stable global optimum, where the generator is capable of producing the true data distribution that would completely fool the discriminator.", "SliceSentence": "These adversarial objectives are then put together to then define what it means to arrive at a stable global optimum where the generator is capable of producing the true data distribution that would completely fool the discriminator", "StartMs": 2709860, "EndMs": 2728300, "WordsNum": 37, "Words": [{"Word": "These", "OffsetStartMs": 100, "OffsetEndMs": 480}, {"Word": "adversarial", "OffsetStartMs": 480, "OffsetEndMs": 1650}, {"Word": "objectives", "OffsetStartMs": 1650, "OffsetEndMs": 2030}, {"Word": "are", "OffsetStartMs": 2740, "OffsetEndMs": 3140}, {"Word": "then", "OffsetStartMs": 3850, "OffsetEndMs": 4250}, {"Word": "put", "OffsetStartMs": 4300, "OffsetEndMs": 4650}, {"Word": "together", "OffsetStartMs": 4650, "OffsetEndMs": 5000}, {"Word": "to", "OffsetStartMs": 5110, "OffsetEndMs": 5415}, {"Word": "then", "OffsetStartMs": 5415, "OffsetEndMs": 5720}, {"Word": "define", "OffsetStartMs": 5740, "OffsetEndMs": 6105}, {"Word": "what", "OffsetStartMs": 6105, "OffsetEndMs": 6330}, {"Word": "it", "OffsetStartMs": 6330, "OffsetEndMs": 6465}, {"Word": "means", "OffsetStartMs": 6465, "OffsetEndMs": 6705}, {"Word": "to", "OffsetStartMs": 6705, "OffsetEndMs": 7035}, {"Word": "arrive", "OffsetStartMs": 7035, "OffsetEndMs": 7380}, {"Word": "at", "OffsetStartMs": 7380, "OffsetEndMs": 7605}, {"Word": "a", "OffsetStartMs": 7605, "OffsetEndMs": 7770}, {"Word": "stable", "OffsetStartMs": 7770, "OffsetEndMs": 8090}, {"Word": "global", "OffsetStartMs": 8230, "OffsetEndMs": 8630}, {"Word": "optimum", "OffsetStartMs": 8830, "OffsetEndMs": 9350}, {"Word": "where", "OffsetStartMs": 9820, "OffsetEndMs": 10220}, {"Word": "the", "OffsetStartMs": 10810, "OffsetEndMs": 11085}, {"Word": "generator", "OffsetStartMs": 11085, "OffsetEndMs": 11535}, {"Word": "is", "OffsetStartMs": 11535, "OffsetEndMs": 11805}, {"Word": "capable", "OffsetStartMs": 11805, "OffsetEndMs": 12140}, {"Word": "of", "OffsetStartMs": 12220, "OffsetEndMs": 12620}, {"Word": "producing", "OffsetStartMs": 12640, "OffsetEndMs": 13040}, {"Word": "the", "OffsetStartMs": 13300, "OffsetEndMs": 13650}, {"Word": "true", "OffsetStartMs": 13650, "OffsetEndMs": 14000}, {"Word": "data", "OffsetStartMs": 14020, "OffsetEndMs": 14420}, {"Word": "distribution", "OffsetStartMs": 14470, "OffsetEndMs": 14870}, {"Word": "that", "OffsetStartMs": 15340, "OffsetEndMs": 15675}, {"Word": "would", "OffsetStartMs": 15675, "OffsetEndMs": 16010}, {"Word": "completely", "OffsetStartMs": 16030, "OffsetEndMs": 16430}, {"Word": "fool", "OffsetStartMs": 16480, "OffsetEndMs": 16880}, {"Word": "the", "OffsetStartMs": 16930, "OffsetEndMs": 17205}, {"Word": "discriminator", "OffsetStartMs": 17205, "OffsetEndMs": 17870}], "SpeechSpeed": 12.6}, {"FinalSentence": "Concretely, this can be defined mathematically in terms of a loss objective and again.", "SliceSentence": "Concretely this can be defined mathematically in terms of a loss objective and again", "StartMs": 2730100, "EndMs": 2737040, "WordsNum": 14, "Words": [{"Word": "Concretely", "OffsetStartMs": 340, "OffsetEndMs": 825}, {"Word": "this", "OffsetStartMs": 825, "OffsetEndMs": 1035}, {"Word": "can", "OffsetStartMs": 1035, "OffsetEndMs": 1200}, {"Word": "be", "OffsetStartMs": 1200, "OffsetEndMs": 1410}, {"Word": "defined", "OffsetStartMs": 1410, "OffsetEndMs": 1710}, {"Word": "mathematically", "OffsetStartMs": 1710, "OffsetEndMs": 2360}, {"Word": "in", "OffsetStartMs": 2560, "OffsetEndMs": 2880}, {"Word": "terms", "OffsetStartMs": 2880, "OffsetEndMs": 3180}, {"Word": "of", "OffsetStartMs": 3180, "OffsetEndMs": 3525}, {"Word": "a", "OffsetStartMs": 3525, "OffsetEndMs": 3780}, {"Word": "loss", "OffsetStartMs": 3780, "OffsetEndMs": 4070}, {"Word": "objective", "OffsetStartMs": 4240, "OffsetEndMs": 4640}, {"Word": "and", "OffsetStartMs": 5410, "OffsetEndMs": 5730}, {"Word": "again", "OffsetStartMs": 5730, "OffsetEndMs": 6050}], "SpeechSpeed": 12.1}, {"FinalSentence": "Though I'm, I'm showing math, I can, we can distill this down and go through what each of these terms reflect in terms of that core intuitive idea and conceptual idea that hopefully that one d example conveyed.", "SliceSentence": "Though I'm I'm showing math I can we can distill this down and go through what each of these terms reflect in terms of that core intuitive idea and conceptual idea that hopefully that one d example conveyed", "StartMs": 2737180, "EndMs": 2752520, "WordsNum": 38, "Words": [{"Word": "Though", "OffsetStartMs": 190, "OffsetEndMs": 480}, {"Word": "I'm", "OffsetStartMs": 480, "OffsetEndMs": 825}, {"Word": "I'm", "OffsetStartMs": 825, "OffsetEndMs": 1110}, {"Word": "showing", "OffsetStartMs": 1110, "OffsetEndMs": 1335}, {"Word": "math", "OffsetStartMs": 1335, "OffsetEndMs": 1670}, {"Word": "I", "OffsetStartMs": 1930, "OffsetEndMs": 2205}, {"Word": "can", "OffsetStartMs": 2205, "OffsetEndMs": 2480}, {"Word": "we", "OffsetStartMs": 2500, "OffsetEndMs": 2760}, {"Word": "can", "OffsetStartMs": 2760, "OffsetEndMs": 2895}, {"Word": "distill", "OffsetStartMs": 2895, "OffsetEndMs": 3300}, {"Word": "this", "OffsetStartMs": 3300, "OffsetEndMs": 3540}, {"Word": "down", "OffsetStartMs": 3540, "OffsetEndMs": 3810}, {"Word": "and", "OffsetStartMs": 3810, "OffsetEndMs": 4065}, {"Word": "go", "OffsetStartMs": 4065, "OffsetEndMs": 4335}, {"Word": "through", "OffsetStartMs": 4335, "OffsetEndMs": 4700}, {"Word": "what", "OffsetStartMs": 4810, "OffsetEndMs": 5115}, {"Word": "each", "OffsetStartMs": 5115, "OffsetEndMs": 5310}, {"Word": "of", "OffsetStartMs": 5310, "OffsetEndMs": 5475}, {"Word": "these", "OffsetStartMs": 5475, "OffsetEndMs": 5685}, {"Word": "terms", "OffsetStartMs": 5685, "OffsetEndMs": 6020}, {"Word": "reflect", "OffsetStartMs": 6490, "OffsetEndMs": 6870}, {"Word": "in", "OffsetStartMs": 6870, "OffsetEndMs": 7170}, {"Word": "terms", "OffsetStartMs": 7170, "OffsetEndMs": 7410}, {"Word": "of", "OffsetStartMs": 7410, "OffsetEndMs": 7605}, {"Word": "that", "OffsetStartMs": 7605, "OffsetEndMs": 7875}, {"Word": "core", "OffsetStartMs": 7875, "OffsetEndMs": 8190}, {"Word": "intuitive", "OffsetStartMs": 8190, "OffsetEndMs": 8865}, {"Word": "idea", "OffsetStartMs": 8865, "OffsetEndMs": 9260}, {"Word": "and", "OffsetStartMs": 9370, "OffsetEndMs": 9675}, {"Word": "conceptual", "OffsetStartMs": 9675, "OffsetEndMs": 10350}, {"Word": "idea", "OffsetStartMs": 10350, "OffsetEndMs": 10730}, {"Word": "that", "OffsetStartMs": 10930, "OffsetEndMs": 11330}, {"Word": "hopefully", "OffsetStartMs": 11380, "OffsetEndMs": 11780}, {"Word": "that", "OffsetStartMs": 11860, "OffsetEndMs": 12260}, {"Word": "one", "OffsetStartMs": 13060, "OffsetEndMs": 13380}, {"Word": "d", "OffsetStartMs": 13380, "OffsetEndMs": 13680}, {"Word": "example", "OffsetStartMs": 13680, "OffsetEndMs": 14060}, {"Word": "conveyed", "OffsetStartMs": 14080, "OffsetEndMs": 14780}], "SpeechSpeed": 13.4}, {"FinalSentence": "So we'll first consider the perspective of the discriminator d its goal is to maximize probability that its decisions in its decisions that real data are classified real fake data classified as fake.", "SliceSentence": "So we'll first consider the perspective of the discriminator d its goal is to maximize probability that its decisions in its decisions that real data are classified real fake data classified as fake", "StartMs": 2752920, "EndMs": 2769060, "WordsNum": 33, "Words": [{"Word": "So", "OffsetStartMs": 220, "OffsetEndMs": 495}, {"Word": "we'll", "OffsetStartMs": 495, "OffsetEndMs": 735}, {"Word": "first", "OffsetStartMs": 735, "OffsetEndMs": 1010}, {"Word": "consider", "OffsetStartMs": 1090, "OffsetEndMs": 1490}, {"Word": "the", "OffsetStartMs": 2140, "OffsetEndMs": 2535}, {"Word": "perspective", "OffsetStartMs": 2535, "OffsetEndMs": 2895}, {"Word": "of", "OffsetStartMs": 2895, "OffsetEndMs": 3135}, {"Word": "the", "OffsetStartMs": 3135, "OffsetEndMs": 3285}, {"Word": "discriminator", "OffsetStartMs": 3285, "OffsetEndMs": 3950}, {"Word": "d", "OffsetStartMs": 4120, "OffsetEndMs": 4520}, {"Word": "its", "OffsetStartMs": 5290, "OffsetEndMs": 5640}, {"Word": "goal", "OffsetStartMs": 5640, "OffsetEndMs": 5985}, {"Word": "is", "OffsetStartMs": 5985, "OffsetEndMs": 6285}, {"Word": "to", "OffsetStartMs": 6285, "OffsetEndMs": 6495}, {"Word": "maximize", "OffsetStartMs": 6495, "OffsetEndMs": 7185}, {"Word": "probability", "OffsetStartMs": 7185, "OffsetEndMs": 7830}, {"Word": "that", "OffsetStartMs": 7830, "OffsetEndMs": 8100}, {"Word": "its", "OffsetStartMs": 8100, "OffsetEndMs": 8385}, {"Word": "decisions", "OffsetStartMs": 8385, "OffsetEndMs": 8780}, {"Word": "in", "OffsetStartMs": 10000, "OffsetEndMs": 10260}, {"Word": "its", "OffsetStartMs": 10260, "OffsetEndMs": 10515}, {"Word": "decisions", "OffsetStartMs": 10515, "OffsetEndMs": 10875}, {"Word": "that", "OffsetStartMs": 10875, "OffsetEndMs": 11190}, {"Word": "real", "OffsetStartMs": 11190, "OffsetEndMs": 11475}, {"Word": "data", "OffsetStartMs": 11475, "OffsetEndMs": 11810}, {"Word": "are", "OffsetStartMs": 11980, "OffsetEndMs": 12285}, {"Word": "classified", "OffsetStartMs": 12285, "OffsetEndMs": 12795}, {"Word": "real", "OffsetStartMs": 12795, "OffsetEndMs": 13130}, {"Word": "fake", "OffsetStartMs": 13630, "OffsetEndMs": 13965}, {"Word": "data", "OffsetStartMs": 13965, "OffsetEndMs": 14300}, {"Word": "classified", "OffsetStartMs": 14410, "OffsetEndMs": 15030}, {"Word": "as", "OffsetStartMs": 15030, "OffsetEndMs": 15270}, {"Word": "fake", "OffsetStartMs": 15270, "OffsetEndMs": 15590}], "SpeechSpeed": 12.3}, {"FinalSentence": "So here the first term g of z is the generator's output, and d of g of z is the discriminator's estimate of that generated output as being fake.", "SliceSentence": "So here the first term g of z is the generator's output and d of g of z is the discriminator's estimate of that generated output as being fake", "StartMs": 2769140, "EndMs": 2783760, "WordsNum": 29, "Words": [{"Word": "So", "OffsetStartMs": 190, "OffsetEndMs": 510}, {"Word": "here", "OffsetStartMs": 510, "OffsetEndMs": 830}, {"Word": "the", "OffsetStartMs": 1360, "OffsetEndMs": 1650}, {"Word": "first", "OffsetStartMs": 1650, "OffsetEndMs": 1905}, {"Word": "term", "OffsetStartMs": 1905, "OffsetEndMs": 2270}, {"Word": "g", "OffsetStartMs": 3220, "OffsetEndMs": 3480}, {"Word": "of", "OffsetStartMs": 3480, "OffsetEndMs": 3675}, {"Word": "z", "OffsetStartMs": 3675, "OffsetEndMs": 3945}, {"Word": "is", "OffsetStartMs": 3945, "OffsetEndMs": 4185}, {"Word": "the", "OffsetStartMs": 4185, "OffsetEndMs": 4395}, {"Word": "generator's", "OffsetStartMs": 4395, "OffsetEndMs": 5300}, {"Word": "output", "OffsetStartMs": 5410, "OffsetEndMs": 5810}, {"Word": "and", "OffsetStartMs": 6280, "OffsetEndMs": 6680}, {"Word": "d", "OffsetStartMs": 6850, "OffsetEndMs": 7230}, {"Word": "of", "OffsetStartMs": 7230, "OffsetEndMs": 7575}, {"Word": "g", "OffsetStartMs": 7575, "OffsetEndMs": 7845}, {"Word": "of", "OffsetStartMs": 7845, "OffsetEndMs": 8085}, {"Word": "z", "OffsetStartMs": 8085, "OffsetEndMs": 8420}, {"Word": "is", "OffsetStartMs": 8680, "OffsetEndMs": 8985}, {"Word": "the", "OffsetStartMs": 8985, "OffsetEndMs": 9165}, {"Word": "discriminator's", "OffsetStartMs": 9165, "OffsetEndMs": 10100}, {"Word": "estimate", "OffsetStartMs": 10300, "OffsetEndMs": 10700}, {"Word": "of", "OffsetStartMs": 11140, "OffsetEndMs": 11540}, {"Word": "that", "OffsetStartMs": 11680, "OffsetEndMs": 12030}, {"Word": "generated", "OffsetStartMs": 12030, "OffsetEndMs": 12380}, {"Word": "output", "OffsetStartMs": 12790, "OffsetEndMs": 13095}, {"Word": "as", "OffsetStartMs": 13095, "OffsetEndMs": 13320}, {"Word": "being", "OffsetStartMs": 13320, "OffsetEndMs": 13605}, {"Word": "fake", "OffsetStartMs": 13605, "OffsetEndMs": 13970}], "SpeechSpeed": 9.7}, {"FinalSentence": "D of X X is the real data, and so d of X is the estimate of the probability that a real instance is fake.", "SliceSentence": "D of X X is the real data and so d of X is the estimate of the probability that a real instance is fake", "StartMs": 2785100, "EndMs": 2793780, "WordsNum": 25, "Words": [{"Word": "D", "OffsetStartMs": 100, "OffsetEndMs": 345}, {"Word": "of", "OffsetStartMs": 345, "OffsetEndMs": 480}, {"Word": "X", "OffsetStartMs": 480, "OffsetEndMs": 770}, {"Word": "X", "OffsetStartMs": 1210, "OffsetEndMs": 1545}, {"Word": "is", "OffsetStartMs": 1545, "OffsetEndMs": 1770}, {"Word": "the", "OffsetStartMs": 1770, "OffsetEndMs": 1935}, {"Word": "real", "OffsetStartMs": 1935, "OffsetEndMs": 2130}, {"Word": "data", "OffsetStartMs": 2130, "OffsetEndMs": 2450}, {"Word": "and", "OffsetStartMs": 2710, "OffsetEndMs": 3000}, {"Word": "so", "OffsetStartMs": 3000, "OffsetEndMs": 3210}, {"Word": "d", "OffsetStartMs": 3210, "OffsetEndMs": 3375}, {"Word": "of", "OffsetStartMs": 3375, "OffsetEndMs": 3525}, {"Word": "X", "OffsetStartMs": 3525, "OffsetEndMs": 3795}, {"Word": "is", "OffsetStartMs": 3795, "OffsetEndMs": 4050}, {"Word": "the", "OffsetStartMs": 4050, "OffsetEndMs": 4340}, {"Word": "estimate", "OffsetStartMs": 4390, "OffsetEndMs": 4665}, {"Word": "of", "OffsetStartMs": 4665, "OffsetEndMs": 4830}, {"Word": "the", "OffsetStartMs": 4830, "OffsetEndMs": 5010}, {"Word": "probability", "OffsetStartMs": 5010, "OffsetEndMs": 5570}, {"Word": "that", "OffsetStartMs": 5830, "OffsetEndMs": 6090}, {"Word": "a", "OffsetStartMs": 6090, "OffsetEndMs": 6255}, {"Word": "real", "OffsetStartMs": 6255, "OffsetEndMs": 6560}, {"Word": "instance", "OffsetStartMs": 7030, "OffsetEndMs": 7380}, {"Word": "is", "OffsetStartMs": 7380, "OffsetEndMs": 7635}, {"Word": "fake", "OffsetStartMs": 7635, "OffsetEndMs": 7940}], "SpeechSpeed": 11.9}, {"FinalSentence": "One minus d of X is the estimate that that real instance is real.", "SliceSentence": "One minus d of X is the estimate that that real instance is real", "StartMs": 2793780, "EndMs": 2799280, "WordsNum": 14, "Words": [{"Word": "One", "OffsetStartMs": 0, "OffsetEndMs": 300}, {"Word": "minus", "OffsetStartMs": 300, "OffsetEndMs": 645}, {"Word": "d", "OffsetStartMs": 645, "OffsetEndMs": 885}, {"Word": "of", "OffsetStartMs": 885, "OffsetEndMs": 1035}, {"Word": "X", "OffsetStartMs": 1035, "OffsetEndMs": 1340}, {"Word": "is", "OffsetStartMs": 1900, "OffsetEndMs": 2190}, {"Word": "the", "OffsetStartMs": 2190, "OffsetEndMs": 2480}, {"Word": "estimate", "OffsetStartMs": 2530, "OffsetEndMs": 2820}, {"Word": "that", "OffsetStartMs": 2820, "OffsetEndMs": 3000}, {"Word": "that", "OffsetStartMs": 3000, "OffsetEndMs": 3225}, {"Word": "real", "OffsetStartMs": 3225, "OffsetEndMs": 3560}, {"Word": "instance", "OffsetStartMs": 3790, "OffsetEndMs": 4170}, {"Word": "is", "OffsetStartMs": 4170, "OffsetEndMs": 4470}, {"Word": "real", "OffsetStartMs": 4470, "OffsetEndMs": 4790}], "SpeechSpeed": 11.6}, {"FinalSentence": "So here in both these cases, the discriminator is producing a decision about fake data, real data. And together it wants to try to maximize the probability that it's getting answers correct, right?", "SliceSentence": "So here in both these cases the discriminator is producing a decision about fake data real data . Andtogether it wants to try to maximize the probability that it's getting answers correct right", "StartMs": 2799360, "EndMs": 2814320, "WordsNum": 33, "Words": [{"Word": "So", "OffsetStartMs": 220, "OffsetEndMs": 620}, {"Word": "here", "OffsetStartMs": 880, "OffsetEndMs": 1280}, {"Word": "in", "OffsetStartMs": 1540, "OffsetEndMs": 1845}, {"Word": "both", "OffsetStartMs": 1845, "OffsetEndMs": 2070}, {"Word": "these", "OffsetStartMs": 2070, "OffsetEndMs": 2295}, {"Word": "cases", "OffsetStartMs": 2295, "OffsetEndMs": 2595}, {"Word": "the", "OffsetStartMs": 2595, "OffsetEndMs": 2865}, {"Word": "discriminator", "OffsetStartMs": 2865, "OffsetEndMs": 3495}, {"Word": "is", "OffsetStartMs": 3495, "OffsetEndMs": 3830}, {"Word": "producing", "OffsetStartMs": 3850, "OffsetEndMs": 4200}, {"Word": "a", "OffsetStartMs": 4200, "OffsetEndMs": 4485}, {"Word": "decision", "OffsetStartMs": 4485, "OffsetEndMs": 4820}, {"Word": "about", "OffsetStartMs": 5260, "OffsetEndMs": 5660}, {"Word": "fake", "OffsetStartMs": 5740, "OffsetEndMs": 6060}, {"Word": "data", "OffsetStartMs": 6060, "OffsetEndMs": 6380}, {"Word": "real", "OffsetStartMs": 6880, "OffsetEndMs": 7215}, {"Word": "data", "OffsetStartMs": 7215, "OffsetEndMs": 7550}, {"Word": ".", "OffsetStartMs": 7840, "OffsetEndMs": 8205}, {"Word": "Andtogether", "OffsetStartMs": 8205, "OffsetEndMs": 8570}, {"Word": "it", "OffsetStartMs": 8890, "OffsetEndMs": 9180}, {"Word": "wants", "OffsetStartMs": 9180, "OffsetEndMs": 9420}, {"Word": "to", "OffsetStartMs": 9420, "OffsetEndMs": 9645}, {"Word": "try", "OffsetStartMs": 9645, "OffsetEndMs": 9870}, {"Word": "to", "OffsetStartMs": 9870, "OffsetEndMs": 10170}, {"Word": "maximize", "OffsetStartMs": 10170, "OffsetEndMs": 10830}, {"Word": "the", "OffsetStartMs": 10830, "OffsetEndMs": 11070}, {"Word": "probability", "OffsetStartMs": 11070, "OffsetEndMs": 11625}, {"Word": "that", "OffsetStartMs": 11625, "OffsetEndMs": 11925}, {"Word": "it's", "OffsetStartMs": 11925, "OffsetEndMs": 12350}, {"Word": "getting", "OffsetStartMs": 12430, "OffsetEndMs": 12780}, {"Word": "answers", "OffsetStartMs": 12780, "OffsetEndMs": 13130}, {"Word": "correct", "OffsetStartMs": 13480, "OffsetEndMs": 13880}, {"Word": "right", "OffsetStartMs": 14050, "OffsetEndMs": 14450}], "SpeechSpeed": 12.8}, {"FinalSentence": "Now with the generator, we have those same exact terms, but keep in mind the generator is never.", "SliceSentence": "Now with the generator we have those same exact terms but keep in mind the generator is never", "StartMs": 2816080, "EndMs": 2823540, "WordsNum": 18, "Words": [{"Word": "Now", "OffsetStartMs": 280, "OffsetEndMs": 680}, {"Word": "with", "OffsetStartMs": 1060, "OffsetEndMs": 1350}, {"Word": "the", "OffsetStartMs": 1350, "OffsetEndMs": 1515}, {"Word": "generator", "OffsetStartMs": 1515, "OffsetEndMs": 1980}, {"Word": "we", "OffsetStartMs": 1980, "OffsetEndMs": 2235}, {"Word": "have", "OffsetStartMs": 2235, "OffsetEndMs": 2430}, {"Word": "those", "OffsetStartMs": 2430, "OffsetEndMs": 2655}, {"Word": "same", "OffsetStartMs": 2655, "OffsetEndMs": 2970}, {"Word": "exact", "OffsetStartMs": 2970, "OffsetEndMs": 3300}, {"Word": "terms", "OffsetStartMs": 3300, "OffsetEndMs": 3650}, {"Word": "but", "OffsetStartMs": 4240, "OffsetEndMs": 4545}, {"Word": "keep", "OffsetStartMs": 4545, "OffsetEndMs": 4725}, {"Word": "in", "OffsetStartMs": 4725, "OffsetEndMs": 4875}, {"Word": "mind", "OffsetStartMs": 4875, "OffsetEndMs": 5115}, {"Word": "the", "OffsetStartMs": 5115, "OffsetEndMs": 5355}, {"Word": "generator", "OffsetStartMs": 5355, "OffsetEndMs": 5790}, {"Word": "is", "OffsetStartMs": 5790, "OffsetEndMs": 6045}, {"Word": "never", "OffsetStartMs": 6045, "OffsetEndMs": 6380}], "SpeechSpeed": 12.5}, {"FinalSentence": "Able to affect anything that the discriminator decision is actually doing, besides generating new data examples.", "SliceSentence": "Able to affect anything that the discriminator decision is actually doing besides generating new data examples", "StartMs": 2823540, "EndMs": 2832900, "WordsNum": 16, "Words": [{"Word": "Able", "OffsetStartMs": 0, "OffsetEndMs": 345}, {"Word": "to", "OffsetStartMs": 345, "OffsetEndMs": 690}, {"Word": "affect", "OffsetStartMs": 690, "OffsetEndMs": 1040}, {"Word": "anything", "OffsetStartMs": 1180, "OffsetEndMs": 1485}, {"Word": "that", "OffsetStartMs": 1485, "OffsetEndMs": 1770}, {"Word": "the", "OffsetStartMs": 1770, "OffsetEndMs": 2150}, {"Word": "discriminator", "OffsetStartMs": 2290, "OffsetEndMs": 3270}, {"Word": "decision", "OffsetStartMs": 3270, "OffsetEndMs": 3620}, {"Word": "is", "OffsetStartMs": 3820, "OffsetEndMs": 4220}, {"Word": "actually", "OffsetStartMs": 4450, "OffsetEndMs": 4755}, {"Word": "doing", "OffsetStartMs": 4755, "OffsetEndMs": 5060}, {"Word": "besides", "OffsetStartMs": 5620, "OffsetEndMs": 6020}, {"Word": "generating", "OffsetStartMs": 6460, "OffsetEndMs": 7065}, {"Word": "new", "OffsetStartMs": 7065, "OffsetEndMs": 7460}, {"Word": "data", "OffsetStartMs": 7480, "OffsetEndMs": 7880}, {"Word": "examples", "OffsetStartMs": 7900, "OffsetEndMs": 8300}], "SpeechSpeed": 11.9}, {"FinalSentence": "So for the generator, its objective is simply to minimize the probability that the generated data is identified as fake.", "SliceSentence": "So for the generator its objective is simply to minimize the probability that the generated data is identified as fake", "StartMs": 2832900, "EndMs": 2843640, "WordsNum": 20, "Words": [{"Word": "So", "OffsetStartMs": 0, "OffsetEndMs": 255}, {"Word": "for", "OffsetStartMs": 255, "OffsetEndMs": 375}, {"Word": "the", "OffsetStartMs": 375, "OffsetEndMs": 495}, {"Word": "generator", "OffsetStartMs": 495, "OffsetEndMs": 1040}, {"Word": "its", "OffsetStartMs": 1270, "OffsetEndMs": 1670}, {"Word": "objective", "OffsetStartMs": 1690, "OffsetEndMs": 2090}, {"Word": "is", "OffsetStartMs": 2230, "OffsetEndMs": 2580}, {"Word": "simply", "OffsetStartMs": 2580, "OffsetEndMs": 2930}, {"Word": "to", "OffsetStartMs": 3670, "OffsetEndMs": 4070}, {"Word": "minimize", "OffsetStartMs": 4360, "OffsetEndMs": 5030}, {"Word": "the", "OffsetStartMs": 5080, "OffsetEndMs": 5400}, {"Word": "probability", "OffsetStartMs": 5400, "OffsetEndMs": 5990}, {"Word": "that", "OffsetStartMs": 6340, "OffsetEndMs": 6630}, {"Word": "the", "OffsetStartMs": 6630, "OffsetEndMs": 6825}, {"Word": "generated", "OffsetStartMs": 6825, "OffsetEndMs": 7130}, {"Word": "data", "OffsetStartMs": 7300, "OffsetEndMs": 7700}, {"Word": "is", "OffsetStartMs": 7870, "OffsetEndMs": 8270}, {"Word": "identified", "OffsetStartMs": 8560, "OffsetEndMs": 8925}, {"Word": "as", "OffsetStartMs": 8925, "OffsetEndMs": 9225}, {"Word": "fake", "OffsetStartMs": 9225, "OffsetEndMs": 9560}], "SpeechSpeed": 11.0}, {"FinalSentence": "Together, we want to then put this together to define what it means for the generator to synthesize fake images that hopefully fool the discriminator.", "SliceSentence": "Together we want to then put this together to define what it means for the generator to synthesize fake images that hopefully fool the discriminator", "StartMs": 2844580, "EndMs": 2856220, "WordsNum": 25, "Words": [{"Word": "Together", "OffsetStartMs": 220, "OffsetEndMs": 620}, {"Word": "we", "OffsetStartMs": 850, "OffsetEndMs": 1155}, {"Word": "want", "OffsetStartMs": 1155, "OffsetEndMs": 1440}, {"Word": "to", "OffsetStartMs": 1440, "OffsetEndMs": 1800}, {"Word": "then", "OffsetStartMs": 1800, "OffsetEndMs": 2180}, {"Word": "put", "OffsetStartMs": 2770, "OffsetEndMs": 3045}, {"Word": "this", "OffsetStartMs": 3045, "OffsetEndMs": 3270}, {"Word": "together", "OffsetStartMs": 3270, "OffsetEndMs": 3620}, {"Word": "to", "OffsetStartMs": 3640, "OffsetEndMs": 4040}, {"Word": "define", "OffsetStartMs": 4270, "OffsetEndMs": 4665}, {"Word": "what", "OffsetStartMs": 4665, "OffsetEndMs": 4920}, {"Word": "it", "OffsetStartMs": 4920, "OffsetEndMs": 5055}, {"Word": "means", "OffsetStartMs": 5055, "OffsetEndMs": 5330}, {"Word": "for", "OffsetStartMs": 5650, "OffsetEndMs": 5940}, {"Word": "the", "OffsetStartMs": 5940, "OffsetEndMs": 6105}, {"Word": "generator", "OffsetStartMs": 6105, "OffsetEndMs": 6620}, {"Word": "to", "OffsetStartMs": 6700, "OffsetEndMs": 7100}, {"Word": "synthesize", "OffsetStartMs": 7120, "OffsetEndMs": 7800}, {"Word": "fake", "OffsetStartMs": 7800, "OffsetEndMs": 8070}, {"Word": "images", "OffsetStartMs": 8070, "OffsetEndMs": 8390}, {"Word": "that", "OffsetStartMs": 8740, "OffsetEndMs": 9060}, {"Word": "hopefully", "OffsetStartMs": 9060, "OffsetEndMs": 9380}, {"Word": "fool", "OffsetStartMs": 9670, "OffsetEndMs": 10070}, {"Word": "the", "OffsetStartMs": 10090, "OffsetEndMs": 10350}, {"Word": "discriminator", "OffsetStartMs": 10350, "OffsetEndMs": 11000}], "SpeechSpeed": 12.7}, {"FinalSentence": "All in all, right, this term, besides the math, besides the particularities of this definition, what I want you to get away from this, from this section on gans, is that we have this dual competing objective where the generator is trying to synthesize these synthetic examples that ideally fool the best discriminator possible.", "SliceSentence": "All in all right this term besides the math besides the particularities of this definition what I want you to get away from this from this section on gans is that we have this dual competing objective where the generator is trying to synthesize these synthetic examples that ideally fool the best discriminator possible", "StartMs": 2856960, "EndMs": 2882940, "WordsNum": 54, "Words": [{"Word": "All", "OffsetStartMs": 70, "OffsetEndMs": 360}, {"Word": "in", "OffsetStartMs": 360, "OffsetEndMs": 510}, {"Word": "all", "OffsetStartMs": 510, "OffsetEndMs": 770}, {"Word": "right", "OffsetStartMs": 940, "OffsetEndMs": 1340}, {"Word": "this", "OffsetStartMs": 1390, "OffsetEndMs": 1790}, {"Word": "term", "OffsetStartMs": 1900, "OffsetEndMs": 2300}, {"Word": "besides", "OffsetStartMs": 3070, "OffsetEndMs": 3405}, {"Word": "the", "OffsetStartMs": 3405, "OffsetEndMs": 3600}, {"Word": "math", "OffsetStartMs": 3600, "OffsetEndMs": 3860}, {"Word": "besides", "OffsetStartMs": 4000, "OffsetEndMs": 4380}, {"Word": "the", "OffsetStartMs": 4380, "OffsetEndMs": 4760}, {"Word": "particularities", "OffsetStartMs": 4960, "OffsetEndMs": 5775}, {"Word": "of", "OffsetStartMs": 5775, "OffsetEndMs": 5955}, {"Word": "this", "OffsetStartMs": 5955, "OffsetEndMs": 6120}, {"Word": "definition", "OffsetStartMs": 6120, "OffsetEndMs": 6410}, {"Word": "what", "OffsetStartMs": 7180, "OffsetEndMs": 7455}, {"Word": "I", "OffsetStartMs": 7455, "OffsetEndMs": 7605}, {"Word": "want", "OffsetStartMs": 7605, "OffsetEndMs": 7815}, {"Word": "you", "OffsetStartMs": 7815, "OffsetEndMs": 8025}, {"Word": "to", "OffsetStartMs": 8025, "OffsetEndMs": 8145}, {"Word": "get", "OffsetStartMs": 8145, "OffsetEndMs": 8310}, {"Word": "away", "OffsetStartMs": 8310, "OffsetEndMs": 8630}, {"Word": "from", "OffsetStartMs": 8860, "OffsetEndMs": 9180}, {"Word": "this", "OffsetStartMs": 9180, "OffsetEndMs": 9500}, {"Word": "from", "OffsetStartMs": 9850, "OffsetEndMs": 10125}, {"Word": "this", "OffsetStartMs": 10125, "OffsetEndMs": 10290}, {"Word": "section", "OffsetStartMs": 10290, "OffsetEndMs": 10530}, {"Word": "on", "OffsetStartMs": 10530, "OffsetEndMs": 10800}, {"Word": "gans", "OffsetStartMs": 10800, "OffsetEndMs": 11150}, {"Word": "is", "OffsetStartMs": 11830, "OffsetEndMs": 12120}, {"Word": "that", "OffsetStartMs": 12120, "OffsetEndMs": 12315}, {"Word": "we", "OffsetStartMs": 12315, "OffsetEndMs": 12540}, {"Word": "have", "OffsetStartMs": 12540, "OffsetEndMs": 12825}, {"Word": "this", "OffsetStartMs": 12825, "OffsetEndMs": 13190}, {"Word": "dual", "OffsetStartMs": 13570, "OffsetEndMs": 14120}, {"Word": "competing", "OffsetStartMs": 14230, "OffsetEndMs": 14750}, {"Word": "objective", "OffsetStartMs": 14980, "OffsetEndMs": 15380}, {"Word": "where", "OffsetStartMs": 16030, "OffsetEndMs": 16430}, {"Word": "the", "OffsetStartMs": 16540, "OffsetEndMs": 16830}, {"Word": "generator", "OffsetStartMs": 16830, "OffsetEndMs": 17295}, {"Word": "is", "OffsetStartMs": 17295, "OffsetEndMs": 17550}, {"Word": "trying", "OffsetStartMs": 17550, "OffsetEndMs": 17805}, {"Word": "to", "OffsetStartMs": 17805, "OffsetEndMs": 18015}, {"Word": "synthesize", "OffsetStartMs": 18015, "OffsetEndMs": 18570}, {"Word": "these", "OffsetStartMs": 18570, "OffsetEndMs": 18920}, {"Word": "synthetic", "OffsetStartMs": 19810, "OffsetEndMs": 20360}, {"Word": "examples", "OffsetStartMs": 20410, "OffsetEndMs": 20810}, {"Word": "that", "OffsetStartMs": 21310, "OffsetEndMs": 21710}, {"Word": "ideally", "OffsetStartMs": 21940, "OffsetEndMs": 22760}, {"Word": "fool", "OffsetStartMs": 22780, "OffsetEndMs": 23180}, {"Word": "the", "OffsetStartMs": 23500, "OffsetEndMs": 23850}, {"Word": "best", "OffsetStartMs": 23850, "OffsetEndMs": 24180}, {"Word": "discriminator", "OffsetStartMs": 24180, "OffsetEndMs": 24975}, {"Word": "possible", "OffsetStartMs": 24975, "OffsetEndMs": 25370}], "SpeechSpeed": 12.3}, {"FinalSentence": "And in doing so, the goal is to build up a network.", "SliceSentence": "And in doing so the goal is to build up a network", "StartMs": 2882940, "EndMs": 2887680, "WordsNum": 12, "Words": [{"Word": "And", "OffsetStartMs": 160, "OffsetEndMs": 435}, {"Word": "in", "OffsetStartMs": 435, "OffsetEndMs": 615}, {"Word": "doing", "OffsetStartMs": 615, "OffsetEndMs": 885}, {"Word": "so", "OffsetStartMs": 885, "OffsetEndMs": 1250}, {"Word": "the", "OffsetStartMs": 1480, "OffsetEndMs": 1770}, {"Word": "goal", "OffsetStartMs": 1770, "OffsetEndMs": 2040}, {"Word": "is", "OffsetStartMs": 2040, "OffsetEndMs": 2355}, {"Word": "to", "OffsetStartMs": 2355, "OffsetEndMs": 2690}, {"Word": "build", "OffsetStartMs": 2710, "OffsetEndMs": 3030}, {"Word": "up", "OffsetStartMs": 3030, "OffsetEndMs": 3225}, {"Word": "a", "OffsetStartMs": 3225, "OffsetEndMs": 3360}, {"Word": "network", "OffsetStartMs": 3360, "OffsetEndMs": 3620}], "SpeechSpeed": 10.3}, {"FinalSentence": "VIA this adversarial training, this adversarial competition to use the generator to create new data that best mimics the true data distribution and its completely synthetic new instances.", "SliceSentence": "VIA this adversarial training this adversarial competition to use the generator to create new data that best mimics the true data distribution and its completely synthetic new instances", "StartMs": 2887680, "EndMs": 2901420, "WordsNum": 28, "Words": [{"Word": "VIA", "OffsetStartMs": 130, "OffsetEndMs": 510}, {"Word": "this", "OffsetStartMs": 510, "OffsetEndMs": 780}, {"Word": "adversarial", "OffsetStartMs": 780, "OffsetEndMs": 1590}, {"Word": "training", "OffsetStartMs": 1590, "OffsetEndMs": 1890}, {"Word": "this", "OffsetStartMs": 1890, "OffsetEndMs": 2175}, {"Word": "adversarial", "OffsetStartMs": 2175, "OffsetEndMs": 3050}, {"Word": "competition", "OffsetStartMs": 3160, "OffsetEndMs": 3560}, {"Word": "to", "OffsetStartMs": 4060, "OffsetEndMs": 4335}, {"Word": "use", "OffsetStartMs": 4335, "OffsetEndMs": 4560}, {"Word": "the", "OffsetStartMs": 4560, "OffsetEndMs": 4785}, {"Word": "generator", "OffsetStartMs": 4785, "OffsetEndMs": 5300}, {"Word": "to", "OffsetStartMs": 5680, "OffsetEndMs": 6015}, {"Word": "create", "OffsetStartMs": 6015, "OffsetEndMs": 6330}, {"Word": "new", "OffsetStartMs": 6330, "OffsetEndMs": 6630}, {"Word": "data", "OffsetStartMs": 6630, "OffsetEndMs": 6950}, {"Word": "that", "OffsetStartMs": 7060, "OffsetEndMs": 7395}, {"Word": "best", "OffsetStartMs": 7395, "OffsetEndMs": 7730}, {"Word": "mimics", "OffsetStartMs": 7750, "OffsetEndMs": 8270}, {"Word": "the", "OffsetStartMs": 8680, "OffsetEndMs": 8985}, {"Word": "true", "OffsetStartMs": 8985, "OffsetEndMs": 9195}, {"Word": "data", "OffsetStartMs": 9195, "OffsetEndMs": 9500}, {"Word": "distribution", "OffsetStartMs": 9520, "OffsetEndMs": 9920}, {"Word": "and", "OffsetStartMs": 10210, "OffsetEndMs": 10485}, {"Word": "its", "OffsetStartMs": 10485, "OffsetEndMs": 10755}, {"Word": "completely", "OffsetStartMs": 10755, "OffsetEndMs": 11145}, {"Word": "synthetic", "OffsetStartMs": 11145, "OffsetEndMs": 11690}, {"Word": "new", "OffsetStartMs": 12010, "OffsetEndMs": 12345}, {"Word": "instances", "OffsetStartMs": 12345, "OffsetEndMs": 13130}], "SpeechSpeed": 13.5}, {"FinalSentence": "What this amounts to in practice is that after the training process, you can look exclusively at the generator component and use it to then create new data instances.", "SliceSentence": "What this amounts to in practice is that after the training process you can look exclusively at the generator component and use it to then create new data instances", "StartMs": 2902900, "EndMs": 2915740, "WordsNum": 29, "Words": [{"Word": "What", "OffsetStartMs": 220, "OffsetEndMs": 620}, {"Word": "this", "OffsetStartMs": 910, "OffsetEndMs": 1230}, {"Word": "amounts", "OffsetStartMs": 1230, "OffsetEndMs": 1515}, {"Word": "to", "OffsetStartMs": 1515, "OffsetEndMs": 1755}, {"Word": "in", "OffsetStartMs": 1755, "OffsetEndMs": 1950}, {"Word": "practice", "OffsetStartMs": 1950, "OffsetEndMs": 2270}, {"Word": "is", "OffsetStartMs": 2410, "OffsetEndMs": 2685}, {"Word": "that", "OffsetStartMs": 2685, "OffsetEndMs": 2880}, {"Word": "after", "OffsetStartMs": 2880, "OffsetEndMs": 3200}, {"Word": "the", "OffsetStartMs": 3250, "OffsetEndMs": 3555}, {"Word": "training", "OffsetStartMs": 3555, "OffsetEndMs": 3855}, {"Word": "process", "OffsetStartMs": 3855, "OffsetEndMs": 4250}, {"Word": "you", "OffsetStartMs": 4330, "OffsetEndMs": 4590}, {"Word": "can", "OffsetStartMs": 4590, "OffsetEndMs": 4755}, {"Word": "look", "OffsetStartMs": 4755, "OffsetEndMs": 5060}, {"Word": "exclusively", "OffsetStartMs": 5260, "OffsetEndMs": 5940}, {"Word": "at", "OffsetStartMs": 5940, "OffsetEndMs": 6180}, {"Word": "the", "OffsetStartMs": 6180, "OffsetEndMs": 6390}, {"Word": "generator", "OffsetStartMs": 6390, "OffsetEndMs": 6920}, {"Word": "component", "OffsetStartMs": 6970, "OffsetEndMs": 7370}, {"Word": "and", "OffsetStartMs": 7960, "OffsetEndMs": 8360}, {"Word": "use", "OffsetStartMs": 8500, "OffsetEndMs": 8820}, {"Word": "it", "OffsetStartMs": 8820, "OffsetEndMs": 9060}, {"Word": "to", "OffsetStartMs": 9060, "OffsetEndMs": 9240}, {"Word": "then", "OffsetStartMs": 9240, "OffsetEndMs": 9500}, {"Word": "create", "OffsetStartMs": 9730, "OffsetEndMs": 10130}, {"Word": "new", "OffsetStartMs": 10330, "OffsetEndMs": 10730}, {"Word": "data", "OffsetStartMs": 10750, "OffsetEndMs": 11130}, {"Word": "instances", "OffsetStartMs": 11130, "OffsetEndMs": 11930}], "SpeechSpeed": 12.8}, {"FinalSentence": "All this is done by starting from random noise and trying to learn a model that goes from random noise to the real data distribution. And effectively what gans are doing is learning a function that transforms that distribution of random noise to some target.", "SliceSentence": "All this is done by starting from random noise and trying to learn a model that goes from random noise to the real data distribution . Andeffectively what gans are doing is learning a function that transforms that distribution of random noise to some target", "StartMs": 2917120, "EndMs": 2937300, "WordsNum": 45, "Words": [{"Word": "All", "OffsetStartMs": 100, "OffsetEndMs": 405}, {"Word": "this", "OffsetStartMs": 405, "OffsetEndMs": 600}, {"Word": "is", "OffsetStartMs": 600, "OffsetEndMs": 780}, {"Word": "done", "OffsetStartMs": 780, "OffsetEndMs": 1070}, {"Word": "by", "OffsetStartMs": 1450, "OffsetEndMs": 1850}, {"Word": "starting", "OffsetStartMs": 2320, "OffsetEndMs": 2720}, {"Word": "from", "OffsetStartMs": 2740, "OffsetEndMs": 3045}, {"Word": "random", "OffsetStartMs": 3045, "OffsetEndMs": 3350}, {"Word": "noise", "OffsetStartMs": 3400, "OffsetEndMs": 3800}, {"Word": "and", "OffsetStartMs": 4270, "OffsetEndMs": 4635}, {"Word": "trying", "OffsetStartMs": 4635, "OffsetEndMs": 4965}, {"Word": "to", "OffsetStartMs": 4965, "OffsetEndMs": 5205}, {"Word": "learn", "OffsetStartMs": 5205, "OffsetEndMs": 5480}, {"Word": "a", "OffsetStartMs": 5680, "OffsetEndMs": 5970}, {"Word": "model", "OffsetStartMs": 5970, "OffsetEndMs": 6255}, {"Word": "that", "OffsetStartMs": 6255, "OffsetEndMs": 6555}, {"Word": "goes", "OffsetStartMs": 6555, "OffsetEndMs": 6780}, {"Word": "from", "OffsetStartMs": 6780, "OffsetEndMs": 7020}, {"Word": "random", "OffsetStartMs": 7020, "OffsetEndMs": 7340}, {"Word": "noise", "OffsetStartMs": 7360, "OffsetEndMs": 7760}, {"Word": "to", "OffsetStartMs": 8230, "OffsetEndMs": 8625}, {"Word": "the", "OffsetStartMs": 8625, "OffsetEndMs": 8910}, {"Word": "real", "OffsetStartMs": 8910, "OffsetEndMs": 9165}, {"Word": "data", "OffsetStartMs": 9165, "OffsetEndMs": 9530}, {"Word": "distribution", "OffsetStartMs": 9610, "OffsetEndMs": 10010}, {"Word": ".", "OffsetStartMs": 10870, "OffsetEndMs": 11220}, {"Word": "Andeffectively", "OffsetStartMs": 11220, "OffsetEndMs": 11570}, {"Word": "what", "OffsetStartMs": 11740, "OffsetEndMs": 12045}, {"Word": "gans", "OffsetStartMs": 12045, "OffsetEndMs": 12300}, {"Word": "are", "OffsetStartMs": 12300, "OffsetEndMs": 12525}, {"Word": "doing", "OffsetStartMs": 12525, "OffsetEndMs": 12810}, {"Word": "is", "OffsetStartMs": 12810, "OffsetEndMs": 13125}, {"Word": "learning", "OffsetStartMs": 13125, "OffsetEndMs": 13440}, {"Word": "a", "OffsetStartMs": 13440, "OffsetEndMs": 13710}, {"Word": "function", "OffsetStartMs": 13710, "OffsetEndMs": 14000}, {"Word": "that", "OffsetStartMs": 14410, "OffsetEndMs": 14810}, {"Word": "transforms", "OffsetStartMs": 15070, "OffsetEndMs": 15555}, {"Word": "that", "OffsetStartMs": 15555, "OffsetEndMs": 15810}, {"Word": "distribution", "OffsetStartMs": 15810, "OffsetEndMs": 16190}, {"Word": "of", "OffsetStartMs": 16390, "OffsetEndMs": 16790}, {"Word": "random", "OffsetStartMs": 16810, "OffsetEndMs": 17205}, {"Word": "noise", "OffsetStartMs": 17205, "OffsetEndMs": 17600}, {"Word": "to", "OffsetStartMs": 18130, "OffsetEndMs": 18465}, {"Word": "some", "OffsetStartMs": 18465, "OffsetEndMs": 18765}, {"Word": "target", "OffsetStartMs": 18765, "OffsetEndMs": 19130}], "SpeechSpeed": 12.7}, {"FinalSentence": "What this mapping does is it allows us to take a particular observation of noise in that noise space and map it to some output, a particular output in our target data space.", "SliceSentence": "What this mapping does is it allows us to take a particular observation of noise in that noise space and map it to some output a particular output in our target data space", "StartMs": 2937380, "EndMs": 2951640, "WordsNum": 33, "Words": [{"Word": "What", "OffsetStartMs": 70, "OffsetEndMs": 375}, {"Word": "this", "OffsetStartMs": 375, "OffsetEndMs": 585}, {"Word": "mapping", "OffsetStartMs": 585, "OffsetEndMs": 1130}, {"Word": "does", "OffsetStartMs": 1690, "OffsetEndMs": 2090}, {"Word": "is", "OffsetStartMs": 2140, "OffsetEndMs": 2355}, {"Word": "it", "OffsetStartMs": 2355, "OffsetEndMs": 2565}, {"Word": "allows", "OffsetStartMs": 2565, "OffsetEndMs": 2940}, {"Word": "us", "OffsetStartMs": 2940, "OffsetEndMs": 3255}, {"Word": "to", "OffsetStartMs": 3255, "OffsetEndMs": 3570}, {"Word": "take", "OffsetStartMs": 3570, "OffsetEndMs": 3855}, {"Word": "a", "OffsetStartMs": 3855, "OffsetEndMs": 4155}, {"Word": "particular", "OffsetStartMs": 4155, "OffsetEndMs": 4550}, {"Word": "observation", "OffsetStartMs": 5140, "OffsetEndMs": 5540}, {"Word": "of", "OffsetStartMs": 5590, "OffsetEndMs": 5880}, {"Word": "noise", "OffsetStartMs": 5880, "OffsetEndMs": 6170}, {"Word": "in", "OffsetStartMs": 6520, "OffsetEndMs": 6810}, {"Word": "that", "OffsetStartMs": 6810, "OffsetEndMs": 7035}, {"Word": "noise", "OffsetStartMs": 7035, "OffsetEndMs": 7335}, {"Word": "space", "OffsetStartMs": 7335, "OffsetEndMs": 7700}, {"Word": "and", "OffsetStartMs": 8380, "OffsetEndMs": 8780}, {"Word": "map", "OffsetStartMs": 9040, "OffsetEndMs": 9375}, {"Word": "it", "OffsetStartMs": 9375, "OffsetEndMs": 9645}, {"Word": "to", "OffsetStartMs": 9645, "OffsetEndMs": 9885}, {"Word": "some", "OffsetStartMs": 9885, "OffsetEndMs": 10190}, {"Word": "output", "OffsetStartMs": 10510, "OffsetEndMs": 10830}, {"Word": "a", "OffsetStartMs": 10830, "OffsetEndMs": 11085}, {"Word": "particular", "OffsetStartMs": 11085, "OffsetEndMs": 11420}, {"Word": "output", "OffsetStartMs": 11650, "OffsetEndMs": 11970}, {"Word": "in", "OffsetStartMs": 11970, "OffsetEndMs": 12195}, {"Word": "our", "OffsetStartMs": 12195, "OffsetEndMs": 12420}, {"Word": "target", "OffsetStartMs": 12420, "OffsetEndMs": 12720}, {"Word": "data", "OffsetStartMs": 12720, "OffsetEndMs": 13080}, {"Word": "space", "OffsetStartMs": 13080, "OffsetEndMs": 13460}], "SpeechSpeed": 12.0}, {"FinalSentence": "And in turn, if we consider some other random sample of noise, if we feed it through the generator of g, it's going to produce a completely new instance falling somewhere else on that true data distribution manifold.", "SliceSentence": "And in turn if we consider some other random sample of noise if we feed it through the generator of g it's going to produce a completely new instance falling somewhere else on that true data distribution manifold", "StartMs": 2952060, "EndMs": 2966280, "WordsNum": 38, "Words": [{"Word": "And", "OffsetStartMs": 70, "OffsetEndMs": 360}, {"Word": "in", "OffsetStartMs": 360, "OffsetEndMs": 570}, {"Word": "turn", "OffsetStartMs": 570, "OffsetEndMs": 890}, {"Word": "if", "OffsetStartMs": 1030, "OffsetEndMs": 1320}, {"Word": "we", "OffsetStartMs": 1320, "OffsetEndMs": 1575}, {"Word": "consider", "OffsetStartMs": 1575, "OffsetEndMs": 1890}, {"Word": "some", "OffsetStartMs": 1890, "OffsetEndMs": 2160}, {"Word": "other", "OffsetStartMs": 2160, "OffsetEndMs": 2445}, {"Word": "random", "OffsetStartMs": 2445, "OffsetEndMs": 2810}, {"Word": "sample", "OffsetStartMs": 2860, "OffsetEndMs": 3210}, {"Word": "of", "OffsetStartMs": 3210, "OffsetEndMs": 3450}, {"Word": "noise", "OffsetStartMs": 3450, "OffsetEndMs": 3740}, {"Word": "if", "OffsetStartMs": 4150, "OffsetEndMs": 4425}, {"Word": "we", "OffsetStartMs": 4425, "OffsetEndMs": 4620}, {"Word": "feed", "OffsetStartMs": 4620, "OffsetEndMs": 4815}, {"Word": "it", "OffsetStartMs": 4815, "OffsetEndMs": 4980}, {"Word": "through", "OffsetStartMs": 4980, "OffsetEndMs": 5160}, {"Word": "the", "OffsetStartMs": 5160, "OffsetEndMs": 5325}, {"Word": "generator", "OffsetStartMs": 5325, "OffsetEndMs": 5715}, {"Word": "of", "OffsetStartMs": 5715, "OffsetEndMs": 5970}, {"Word": "g", "OffsetStartMs": 5970, "OffsetEndMs": 6320}, {"Word": "it's", "OffsetStartMs": 6520, "OffsetEndMs": 6885}, {"Word": "going", "OffsetStartMs": 6885, "OffsetEndMs": 7005}, {"Word": "to", "OffsetStartMs": 7005, "OffsetEndMs": 7215}, {"Word": "produce", "OffsetStartMs": 7215, "OffsetEndMs": 7455}, {"Word": "a", "OffsetStartMs": 7455, "OffsetEndMs": 7725}, {"Word": "completely", "OffsetStartMs": 7725, "OffsetEndMs": 8090}, {"Word": "new", "OffsetStartMs": 8110, "OffsetEndMs": 8510}, {"Word": "instance", "OffsetStartMs": 8650, "OffsetEndMs": 9050}, {"Word": "falling", "OffsetStartMs": 9670, "OffsetEndMs": 10070}, {"Word": "somewhere", "OffsetStartMs": 10120, "OffsetEndMs": 10520}, {"Word": "else", "OffsetStartMs": 10540, "OffsetEndMs": 10935}, {"Word": "on", "OffsetStartMs": 10935, "OffsetEndMs": 11265}, {"Word": "that", "OffsetStartMs": 11265, "OffsetEndMs": 11550}, {"Word": "true", "OffsetStartMs": 11550, "OffsetEndMs": 11900}, {"Word": "data", "OffsetStartMs": 11950, "OffsetEndMs": 12350}, {"Word": "distribution", "OffsetStartMs": 12430, "OffsetEndMs": 12830}, {"Word": "manifold", "OffsetStartMs": 12910, "OffsetEndMs": 13610}], "SpeechSpeed": 14.9}, {"FinalSentence": "And indeed, what we can actually do is interpolate and traverse between trajectories in the noise space that then map to traversals and interpolations in the target data space.", "SliceSentence": "And indeed what we can actually do is interpolate and traverse between trajectories in the noise space that then map to traversals and interpolations in the target data space", "StartMs": 2966280, "EndMs": 2982240, "WordsNum": 29, "Words": [{"Word": "And", "OffsetStartMs": 100, "OffsetEndMs": 495}, {"Word": "indeed", "OffsetStartMs": 495, "OffsetEndMs": 890}, {"Word": "what", "OffsetStartMs": 1090, "OffsetEndMs": 1365}, {"Word": "we", "OffsetStartMs": 1365, "OffsetEndMs": 1500}, {"Word": "can", "OffsetStartMs": 1500, "OffsetEndMs": 1760}, {"Word": "actually", "OffsetStartMs": 1870, "OffsetEndMs": 2190}, {"Word": "do", "OffsetStartMs": 2190, "OffsetEndMs": 2510}, {"Word": "is", "OffsetStartMs": 2530, "OffsetEndMs": 2930}, {"Word": "interpolate", "OffsetStartMs": 3370, "OffsetEndMs": 4040}, {"Word": "and", "OffsetStartMs": 4150, "OffsetEndMs": 4500}, {"Word": "traverse", "OffsetStartMs": 4500, "OffsetEndMs": 5060}, {"Word": "between", "OffsetStartMs": 5260, "OffsetEndMs": 5660}, {"Word": "trajectories", "OffsetStartMs": 5890, "OffsetEndMs": 6660}, {"Word": "in", "OffsetStartMs": 6660, "OffsetEndMs": 6915}, {"Word": "the", "OffsetStartMs": 6915, "OffsetEndMs": 7095}, {"Word": "noise", "OffsetStartMs": 7095, "OffsetEndMs": 7350}, {"Word": "space", "OffsetStartMs": 7350, "OffsetEndMs": 7730}, {"Word": "that", "OffsetStartMs": 8260, "OffsetEndMs": 8610}, {"Word": "then", "OffsetStartMs": 8610, "OffsetEndMs": 8940}, {"Word": "map", "OffsetStartMs": 8940, "OffsetEndMs": 9320}, {"Word": "to", "OffsetStartMs": 9700, "OffsetEndMs": 10100}, {"Word": "traversals", "OffsetStartMs": 10690, "OffsetEndMs": 11510}, {"Word": "and", "OffsetStartMs": 11860, "OffsetEndMs": 12240}, {"Word": "interpolations", "OffsetStartMs": 12240, "OffsetEndMs": 13010}, {"Word": "in", "OffsetStartMs": 13480, "OffsetEndMs": 13830}, {"Word": "the", "OffsetStartMs": 13830, "OffsetEndMs": 14130}, {"Word": "target", "OffsetStartMs": 14130, "OffsetEndMs": 14480}, {"Word": "data", "OffsetStartMs": 14500, "OffsetEndMs": 14880}, {"Word": "space", "OffsetStartMs": 14880, "OffsetEndMs": 15260}], "SpeechSpeed": 10.9}, {"FinalSentence": "And this is really, really cool because now you can think about an initial point and a target point and all the steps that are going to take you to synthesize and go between those images in that target data distribution.", "SliceSentence": "And this is really really cool because now you can think about an initial point and a target point and all the steps that are going to take you to synthesize and go between those images in that target data distribution", "StartMs": 2982240, "EndMs": 2996880, "WordsNum": 41, "Words": [{"Word": "And", "OffsetStartMs": 0, "OffsetEndMs": 270}, {"Word": "this", "OffsetStartMs": 270, "OffsetEndMs": 435}, {"Word": "is", "OffsetStartMs": 435, "OffsetEndMs": 630}, {"Word": "really", "OffsetStartMs": 630, "OffsetEndMs": 900}, {"Word": "really", "OffsetStartMs": 900, "OffsetEndMs": 1200}, {"Word": "cool", "OffsetStartMs": 1200, "OffsetEndMs": 1545}, {"Word": "because", "OffsetStartMs": 1545, "OffsetEndMs": 1830}, {"Word": "now", "OffsetStartMs": 1830, "OffsetEndMs": 2040}, {"Word": "you", "OffsetStartMs": 2040, "OffsetEndMs": 2235}, {"Word": "can", "OffsetStartMs": 2235, "OffsetEndMs": 2400}, {"Word": "think", "OffsetStartMs": 2400, "OffsetEndMs": 2610}, {"Word": "about", "OffsetStartMs": 2610, "OffsetEndMs": 2930}, {"Word": "an", "OffsetStartMs": 2980, "OffsetEndMs": 3330}, {"Word": "initial", "OffsetStartMs": 3330, "OffsetEndMs": 3660}, {"Word": "point", "OffsetStartMs": 3660, "OffsetEndMs": 4040}, {"Word": "and", "OffsetStartMs": 4420, "OffsetEndMs": 4695}, {"Word": "a", "OffsetStartMs": 4695, "OffsetEndMs": 4875}, {"Word": "target", "OffsetStartMs": 4875, "OffsetEndMs": 5160}, {"Word": "point", "OffsetStartMs": 5160, "OffsetEndMs": 5540}, {"Word": "and", "OffsetStartMs": 5980, "OffsetEndMs": 6270}, {"Word": "all", "OffsetStartMs": 6270, "OffsetEndMs": 6495}, {"Word": "the", "OffsetStartMs": 6495, "OffsetEndMs": 6720}, {"Word": "steps", "OffsetStartMs": 6720, "OffsetEndMs": 6930}, {"Word": "that", "OffsetStartMs": 6930, "OffsetEndMs": 7095}, {"Word": "are", "OffsetStartMs": 7095, "OffsetEndMs": 7215}, {"Word": "going", "OffsetStartMs": 7215, "OffsetEndMs": 7410}, {"Word": "to", "OffsetStartMs": 7410, "OffsetEndMs": 7620}, {"Word": "take", "OffsetStartMs": 7620, "OffsetEndMs": 7830}, {"Word": "you", "OffsetStartMs": 7830, "OffsetEndMs": 8150}, {"Word": "to", "OffsetStartMs": 8530, "OffsetEndMs": 8930}, {"Word": "synthesize", "OffsetStartMs": 9130, "OffsetEndMs": 9840}, {"Word": "and", "OffsetStartMs": 9840, "OffsetEndMs": 10220}, {"Word": "go", "OffsetStartMs": 10300, "OffsetEndMs": 10700}, {"Word": "between", "OffsetStartMs": 10750, "OffsetEndMs": 11055}, {"Word": "those", "OffsetStartMs": 11055, "OffsetEndMs": 11295}, {"Word": "images", "OffsetStartMs": 11295, "OffsetEndMs": 11630}, {"Word": "in", "OffsetStartMs": 11770, "OffsetEndMs": 12060}, {"Word": "that", "OffsetStartMs": 12060, "OffsetEndMs": 12285}, {"Word": "target", "OffsetStartMs": 12285, "OffsetEndMs": 12615}, {"Word": "data", "OffsetStartMs": 12615, "OffsetEndMs": 13010}, {"Word": "distribution", "OffsetStartMs": 13090, "OffsetEndMs": 13490}], "SpeechSpeed": 14.9}, {"FinalSentence": "So hopefully this gives a sense of this concept of generative modeling for the purpose of creating new data instances.", "SliceSentence": "So hopefully this gives a sense of this concept of generative modeling for the purpose of creating new data instances", "StartMs": 2997580, "EndMs": 3007200, "WordsNum": 20, "Words": [{"Word": "So", "OffsetStartMs": 160, "OffsetEndMs": 560}, {"Word": "hopefully", "OffsetStartMs": 790, "OffsetEndMs": 1185}, {"Word": "this", "OffsetStartMs": 1185, "OffsetEndMs": 1580}, {"Word": "gives", "OffsetStartMs": 2650, "OffsetEndMs": 2940}, {"Word": "a", "OffsetStartMs": 2940, "OffsetEndMs": 3105}, {"Word": "sense", "OffsetStartMs": 3105, "OffsetEndMs": 3375}, {"Word": "of", "OffsetStartMs": 3375, "OffsetEndMs": 3660}, {"Word": "this", "OffsetStartMs": 3660, "OffsetEndMs": 3915}, {"Word": "concept", "OffsetStartMs": 3915, "OffsetEndMs": 4280}, {"Word": "of", "OffsetStartMs": 4390, "OffsetEndMs": 4680}, {"Word": "generative", "OffsetStartMs": 4680, "OffsetEndMs": 5115}, {"Word": "modeling", "OffsetStartMs": 5115, "OffsetEndMs": 5595}, {"Word": "for", "OffsetStartMs": 5595, "OffsetEndMs": 5865}, {"Word": "the", "OffsetStartMs": 5865, "OffsetEndMs": 6060}, {"Word": "purpose", "OffsetStartMs": 6060, "OffsetEndMs": 6350}, {"Word": "of", "OffsetStartMs": 6430, "OffsetEndMs": 6830}, {"Word": "creating", "OffsetStartMs": 7030, "OffsetEndMs": 7430}, {"Word": "new", "OffsetStartMs": 7570, "OffsetEndMs": 7890}, {"Word": "data", "OffsetStartMs": 7890, "OffsetEndMs": 8145}, {"Word": "instances", "OffsetStartMs": 8145, "OffsetEndMs": 8930}], "SpeechSpeed": 12.2}, {"FinalSentence": "And that notion of interpolation and data transformation leads very nicely to some of the recent advances and applications of gans.", "SliceSentence": "And that notion of interpolation and data transformation leads very nicely to some of the recent advances and applications of gans", "StartMs": 3007200, "EndMs": 3017300, "WordsNum": 21, "Words": [{"Word": "And", "OffsetStartMs": 0, "OffsetEndMs": 380}, {"Word": "that", "OffsetStartMs": 640, "OffsetEndMs": 1040}, {"Word": "notion", "OffsetStartMs": 1360, "OffsetEndMs": 1725}, {"Word": "of", "OffsetStartMs": 1725, "OffsetEndMs": 1965}, {"Word": "interpolation", "OffsetStartMs": 1965, "OffsetEndMs": 2660}, {"Word": "and", "OffsetStartMs": 2710, "OffsetEndMs": 3030}, {"Word": "data", "OffsetStartMs": 3030, "OffsetEndMs": 3330}, {"Word": "transformation", "OffsetStartMs": 3330, "OffsetEndMs": 3710}, {"Word": "leads", "OffsetStartMs": 4600, "OffsetEndMs": 4965}, {"Word": "very", "OffsetStartMs": 4965, "OffsetEndMs": 5280}, {"Word": "nicely", "OffsetStartMs": 5280, "OffsetEndMs": 5630}, {"Word": "to", "OffsetStartMs": 5710, "OffsetEndMs": 6015}, {"Word": "some", "OffsetStartMs": 6015, "OffsetEndMs": 6195}, {"Word": "of", "OffsetStartMs": 6195, "OffsetEndMs": 6345}, {"Word": "the", "OffsetStartMs": 6345, "OffsetEndMs": 6525}, {"Word": "recent", "OffsetStartMs": 6525, "OffsetEndMs": 6830}, {"Word": "advances", "OffsetStartMs": 7030, "OffsetEndMs": 7730}, {"Word": "and", "OffsetStartMs": 7780, "OffsetEndMs": 8180}, {"Word": "applications", "OffsetStartMs": 8230, "OffsetEndMs": 8625}, {"Word": "of", "OffsetStartMs": 8625, "OffsetEndMs": 8910}, {"Word": "gans", "OffsetStartMs": 8910, "OffsetEndMs": 9230}], "SpeechSpeed": 12.9}, {"FinalSentence": "Where one particularly commonly employed idea is to try to iteratively grow again to get more and more detailed image generations, progressively adding layers over the course of training to then refine the examples generated by the generator.", "SliceSentence": "Where one particularly commonly employed idea is to try to iteratively grow again to get more and more detailed image generations progressively adding layers over the course of training to then refine the examples generated by the generator", "StartMs": 3017300, "EndMs": 3036360, "WordsNum": 38, "Words": [{"Word": "Where", "OffsetStartMs": 100, "OffsetEndMs": 450}, {"Word": "one", "OffsetStartMs": 450, "OffsetEndMs": 800}, {"Word": "particularly", "OffsetStartMs": 1180, "OffsetEndMs": 1580}, {"Word": "commonly", "OffsetStartMs": 1750, "OffsetEndMs": 2150}, {"Word": "employed", "OffsetStartMs": 2410, "OffsetEndMs": 2810}, {"Word": "idea", "OffsetStartMs": 2860, "OffsetEndMs": 3260}, {"Word": "is", "OffsetStartMs": 3460, "OffsetEndMs": 3765}, {"Word": "to", "OffsetStartMs": 3765, "OffsetEndMs": 4005}, {"Word": "try", "OffsetStartMs": 4005, "OffsetEndMs": 4340}, {"Word": "to", "OffsetStartMs": 4360, "OffsetEndMs": 4760}, {"Word": "iteratively", "OffsetStartMs": 4960, "OffsetEndMs": 5760}, {"Word": "grow", "OffsetStartMs": 5760, "OffsetEndMs": 6110}, {"Word": "again", "OffsetStartMs": 6130, "OffsetEndMs": 6530}, {"Word": "to", "OffsetStartMs": 6970, "OffsetEndMs": 7275}, {"Word": "get", "OffsetStartMs": 7275, "OffsetEndMs": 7530}, {"Word": "more", "OffsetStartMs": 7530, "OffsetEndMs": 7830}, {"Word": "and", "OffsetStartMs": 7830, "OffsetEndMs": 8100}, {"Word": "more", "OffsetStartMs": 8100, "OffsetEndMs": 8420}, {"Word": "detailed", "OffsetStartMs": 8590, "OffsetEndMs": 8955}, {"Word": "image", "OffsetStartMs": 8955, "OffsetEndMs": 9320}, {"Word": "generations", "OffsetStartMs": 9430, "OffsetEndMs": 9830}, {"Word": "progressively", "OffsetStartMs": 10780, "OffsetEndMs": 11625}, {"Word": "adding", "OffsetStartMs": 11625, "OffsetEndMs": 11930}, {"Word": "layers", "OffsetStartMs": 12220, "OffsetEndMs": 12800}, {"Word": "over", "OffsetStartMs": 12880, "OffsetEndMs": 13230}, {"Word": "the", "OffsetStartMs": 13230, "OffsetEndMs": 13455}, {"Word": "course", "OffsetStartMs": 13455, "OffsetEndMs": 13620}, {"Word": "of", "OffsetStartMs": 13620, "OffsetEndMs": 13830}, {"Word": "training", "OffsetStartMs": 13830, "OffsetEndMs": 14150}, {"Word": "to", "OffsetStartMs": 14320, "OffsetEndMs": 14595}, {"Word": "then", "OffsetStartMs": 14595, "OffsetEndMs": 14850}, {"Word": "refine", "OffsetStartMs": 14850, "OffsetEndMs": 15420}, {"Word": "the", "OffsetStartMs": 15420, "OffsetEndMs": 15800}, {"Word": "examples", "OffsetStartMs": 15910, "OffsetEndMs": 16310}, {"Word": "generated", "OffsetStartMs": 16720, "OffsetEndMs": 17120}, {"Word": "by", "OffsetStartMs": 17290, "OffsetEndMs": 17690}, {"Word": "the", "OffsetStartMs": 17710, "OffsetEndMs": 17970}, {"Word": "generator", "OffsetStartMs": 17970, "OffsetEndMs": 18470}], "SpeechSpeed": 12.6}, {"FinalSentence": "And this is the approach that was used to generate those synthetic, those images of those synthetic faces that I showed at the beginning of this lecture, this idea of using g that is refined iteratively to produce higher resolution images.", "SliceSentence": "And this is the approach that was used to generate those synthetic those images of those synthetic faces that I showed at the beginning of this lecture this idea of using g that is refined iteratively to produce higher resolution images", "StartMs": 3036860, "EndMs": 3054300, "WordsNum": 41, "Words": [{"Word": "And", "OffsetStartMs": 160, "OffsetEndMs": 435}, {"Word": "this", "OffsetStartMs": 435, "OffsetEndMs": 585}, {"Word": "is", "OffsetStartMs": 585, "OffsetEndMs": 735}, {"Word": "the", "OffsetStartMs": 735, "OffsetEndMs": 960}, {"Word": "approach", "OffsetStartMs": 960, "OffsetEndMs": 1275}, {"Word": "that", "OffsetStartMs": 1275, "OffsetEndMs": 1530}, {"Word": "was", "OffsetStartMs": 1530, "OffsetEndMs": 1755}, {"Word": "used", "OffsetStartMs": 1755, "OffsetEndMs": 2090}, {"Word": "to", "OffsetStartMs": 2500, "OffsetEndMs": 2900}, {"Word": "generate", "OffsetStartMs": 3220, "OffsetEndMs": 3620}, {"Word": "those", "OffsetStartMs": 3700, "OffsetEndMs": 4035}, {"Word": "synthetic", "OffsetStartMs": 4035, "OffsetEndMs": 4550}, {"Word": "those", "OffsetStartMs": 4870, "OffsetEndMs": 5220}, {"Word": "images", "OffsetStartMs": 5220, "OffsetEndMs": 5570}, {"Word": "of", "OffsetStartMs": 5620, "OffsetEndMs": 5895}, {"Word": "those", "OffsetStartMs": 5895, "OffsetEndMs": 6075}, {"Word": "synthetic", "OffsetStartMs": 6075, "OffsetEndMs": 6510}, {"Word": "faces", "OffsetStartMs": 6510, "OffsetEndMs": 6860}, {"Word": "that", "OffsetStartMs": 7000, "OffsetEndMs": 7320}, {"Word": "I", "OffsetStartMs": 7320, "OffsetEndMs": 7590}, {"Word": "showed", "OffsetStartMs": 7590, "OffsetEndMs": 7830}, {"Word": "at", "OffsetStartMs": 7830, "OffsetEndMs": 7995}, {"Word": "the", "OffsetStartMs": 7995, "OffsetEndMs": 8175}, {"Word": "beginning", "OffsetStartMs": 8175, "OffsetEndMs": 8400}, {"Word": "of", "OffsetStartMs": 8400, "OffsetEndMs": 8580}, {"Word": "this", "OffsetStartMs": 8580, "OffsetEndMs": 8730}, {"Word": "lecture", "OffsetStartMs": 8730, "OffsetEndMs": 9020}, {"Word": "this", "OffsetStartMs": 9520, "OffsetEndMs": 9900}, {"Word": "idea", "OffsetStartMs": 9900, "OffsetEndMs": 10200}, {"Word": "of", "OffsetStartMs": 10200, "OffsetEndMs": 10520}, {"Word": "using", "OffsetStartMs": 10750, "OffsetEndMs": 11150}, {"Word": "g", "OffsetStartMs": 11200, "OffsetEndMs": 11600}, {"Word": "that", "OffsetStartMs": 11950, "OffsetEndMs": 12240}, {"Word": "is", "OffsetStartMs": 12240, "OffsetEndMs": 12510}, {"Word": "refined", "OffsetStartMs": 12510, "OffsetEndMs": 13100}, {"Word": "iteratively", "OffsetStartMs": 13180, "OffsetEndMs": 13950}, {"Word": "to", "OffsetStartMs": 13950, "OffsetEndMs": 14265}, {"Word": "produce", "OffsetStartMs": 14265, "OffsetEndMs": 14625}, {"Word": "higher", "OffsetStartMs": 14625, "OffsetEndMs": 14940}, {"Word": "resolution", "OffsetStartMs": 14940, "OffsetEndMs": 15290}, {"Word": "images", "OffsetStartMs": 15550, "OffsetEndMs": 15950}], "SpeechSpeed": 13.5}, {"FinalSentence": "Another way we can extend this concept is to extend the Gan architecture to consider particular tasks and impose further structure on the network itself. One particular idea is to say, okay, what if we have a particular label or some factor that we want to condition the generation on.", "SliceSentence": "Another way we can extend this concept is to extend the Gan architecture to consider particular tasks and impose further structure on the network itself . Oneparticular idea is to say okay what if we have a particular label or some factor that we want to condition the generation on", "StartMs": 3054820, "EndMs": 3077320, "WordsNum": 50, "Words": [{"Word": "Another", "OffsetStartMs": 280, "OffsetEndMs": 630}, {"Word": "way", "OffsetStartMs": 630, "OffsetEndMs": 885}, {"Word": "we", "OffsetStartMs": 885, "OffsetEndMs": 1050}, {"Word": "can", "OffsetStartMs": 1050, "OffsetEndMs": 1275}, {"Word": "extend", "OffsetStartMs": 1275, "OffsetEndMs": 1560}, {"Word": "this", "OffsetStartMs": 1560, "OffsetEndMs": 1785}, {"Word": "concept", "OffsetStartMs": 1785, "OffsetEndMs": 2090}, {"Word": "is", "OffsetStartMs": 2680, "OffsetEndMs": 3080}, {"Word": "to", "OffsetStartMs": 3130, "OffsetEndMs": 3530}, {"Word": "extend", "OffsetStartMs": 4030, "OffsetEndMs": 4335}, {"Word": "the", "OffsetStartMs": 4335, "OffsetEndMs": 4515}, {"Word": "Gan", "OffsetStartMs": 4515, "OffsetEndMs": 4755}, {"Word": "architecture", "OffsetStartMs": 4755, "OffsetEndMs": 5090}, {"Word": "to", "OffsetStartMs": 5590, "OffsetEndMs": 5990}, {"Word": "consider", "OffsetStartMs": 6310, "OffsetEndMs": 6710}, {"Word": "particular", "OffsetStartMs": 6850, "OffsetEndMs": 7250}, {"Word": "tasks", "OffsetStartMs": 7630, "OffsetEndMs": 8030}, {"Word": "and", "OffsetStartMs": 8500, "OffsetEndMs": 8760}, {"Word": "impose", "OffsetStartMs": 8760, "OffsetEndMs": 9165}, {"Word": "further", "OffsetStartMs": 9165, "OffsetEndMs": 9525}, {"Word": "structure", "OffsetStartMs": 9525, "OffsetEndMs": 9920}, {"Word": "on", "OffsetStartMs": 10240, "OffsetEndMs": 10545}, {"Word": "the", "OffsetStartMs": 10545, "OffsetEndMs": 10710}, {"Word": "network", "OffsetStartMs": 10710, "OffsetEndMs": 10970}, {"Word": "itself", "OffsetStartMs": 11380, "OffsetEndMs": 11780}, {"Word": ".", "OffsetStartMs": 12670, "OffsetEndMs": 13050}, {"Word": "Oneparticular", "OffsetStartMs": 13050, "OffsetEndMs": 13430}, {"Word": "idea", "OffsetStartMs": 13510, "OffsetEndMs": 13845}, {"Word": "is", "OffsetStartMs": 13845, "OffsetEndMs": 14130}, {"Word": "to", "OffsetStartMs": 14130, "OffsetEndMs": 14370}, {"Word": "say", "OffsetStartMs": 14370, "OffsetEndMs": 14660}, {"Word": "okay", "OffsetStartMs": 14740, "OffsetEndMs": 15140}, {"Word": "what", "OffsetStartMs": 15460, "OffsetEndMs": 15720}, {"Word": "if", "OffsetStartMs": 15720, "OffsetEndMs": 15870}, {"Word": "we", "OffsetStartMs": 15870, "OffsetEndMs": 16035}, {"Word": "have", "OffsetStartMs": 16035, "OffsetEndMs": 16185}, {"Word": "a", "OffsetStartMs": 16185, "OffsetEndMs": 16425}, {"Word": "particular", "OffsetStartMs": 16425, "OffsetEndMs": 16790}, {"Word": "label", "OffsetStartMs": 16840, "OffsetEndMs": 17240}, {"Word": "or", "OffsetStartMs": 17470, "OffsetEndMs": 17870}, {"Word": "some", "OffsetStartMs": 18340, "OffsetEndMs": 18675}, {"Word": "factor", "OffsetStartMs": 18675, "OffsetEndMs": 19010}, {"Word": "that", "OffsetStartMs": 19030, "OffsetEndMs": 19320}, {"Word": "we", "OffsetStartMs": 19320, "OffsetEndMs": 19500}, {"Word": "want", "OffsetStartMs": 19500, "OffsetEndMs": 19740}, {"Word": "to", "OffsetStartMs": 19740, "OffsetEndMs": 20090}, {"Word": "condition", "OffsetStartMs": 20380, "OffsetEndMs": 20760}, {"Word": "the", "OffsetStartMs": 20760, "OffsetEndMs": 21015}, {"Word": "generation", "OffsetStartMs": 21015, "OffsetEndMs": 21290}, {"Word": "on", "OffsetStartMs": 21520, "OffsetEndMs": 21920}], "SpeechSpeed": 12.5}, {"FinalSentence": "We call the c and it supplied to both the generator and the discriminator.", "SliceSentence": "We call the c and it supplied to both the generator and the discriminator", "StartMs": 3077720, "EndMs": 3083180, "WordsNum": 14, "Words": [{"Word": "We", "OffsetStartMs": 100, "OffsetEndMs": 390}, {"Word": "call", "OffsetStartMs": 390, "OffsetEndMs": 570}, {"Word": "the", "OffsetStartMs": 570, "OffsetEndMs": 780}, {"Word": "c", "OffsetStartMs": 780, "OffsetEndMs": 1100}, {"Word": "and", "OffsetStartMs": 1240, "OffsetEndMs": 1545}, {"Word": "it", "OffsetStartMs": 1545, "OffsetEndMs": 1785}, {"Word": "supplied", "OffsetStartMs": 1785, "OffsetEndMs": 2250}, {"Word": "to", "OffsetStartMs": 2250, "OffsetEndMs": 2475}, {"Word": "both", "OffsetStartMs": 2475, "OffsetEndMs": 2750}, {"Word": "the", "OffsetStartMs": 2770, "OffsetEndMs": 3090}, {"Word": "generator", "OffsetStartMs": 3090, "OffsetEndMs": 3585}, {"Word": "and", "OffsetStartMs": 3585, "OffsetEndMs": 3795}, {"Word": "the", "OffsetStartMs": 3795, "OffsetEndMs": 3945}, {"Word": "discriminator", "OffsetStartMs": 3945, "OffsetEndMs": 4610}], "SpeechSpeed": 13.6}, {"FinalSentence": "What this will allow us to achieve is paired translation between different types of data. So, for example, we can have images of a street view and we can have images of the segmentation of that street view and we can build again that can directly translate between the street view and the segmentation.", "SliceSentence": "What this will allow us to achieve is paired translation between different types of data . Sofor example we can have images of a street view and we can have images of the segmentation of that street view and we can build again that can directly translate between the street view and the segmentation", "StartMs": 3083460, "EndMs": 3107080, "WordsNum": 54, "Words": [{"Word": "What", "OffsetStartMs": 130, "OffsetEndMs": 435}, {"Word": "this", "OffsetStartMs": 435, "OffsetEndMs": 660}, {"Word": "will", "OffsetStartMs": 660, "OffsetEndMs": 930}, {"Word": "allow", "OffsetStartMs": 930, "OffsetEndMs": 1185}, {"Word": "us", "OffsetStartMs": 1185, "OffsetEndMs": 1395}, {"Word": "to", "OffsetStartMs": 1395, "OffsetEndMs": 1665}, {"Word": "achieve", "OffsetStartMs": 1665, "OffsetEndMs": 2025}, {"Word": "is", "OffsetStartMs": 2025, "OffsetEndMs": 2420}, {"Word": "paired", "OffsetStartMs": 2770, "OffsetEndMs": 3270}, {"Word": "translation", "OffsetStartMs": 3270, "OffsetEndMs": 3620}, {"Word": "between", "OffsetStartMs": 4210, "OffsetEndMs": 4610}, {"Word": "different", "OffsetStartMs": 4990, "OffsetEndMs": 5390}, {"Word": "types", "OffsetStartMs": 5410, "OffsetEndMs": 5810}, {"Word": "of", "OffsetStartMs": 5830, "OffsetEndMs": 6230}, {"Word": "data", "OffsetStartMs": 6610, "OffsetEndMs": 7010}, {"Word": ".", "OffsetStartMs": 7360, "OffsetEndMs": 7665}, {"Word": "Sofor", "OffsetStartMs": 7665, "OffsetEndMs": 7875}, {"Word": "example", "OffsetStartMs": 7875, "OffsetEndMs": 8180}, {"Word": "we", "OffsetStartMs": 8710, "OffsetEndMs": 8985}, {"Word": "can", "OffsetStartMs": 8985, "OffsetEndMs": 9150}, {"Word": "have", "OffsetStartMs": 9150, "OffsetEndMs": 9440}, {"Word": "images", "OffsetStartMs": 9460, "OffsetEndMs": 9860}, {"Word": "of", "OffsetStartMs": 10420, "OffsetEndMs": 10820}, {"Word": "a", "OffsetStartMs": 10840, "OffsetEndMs": 11240}, {"Word": "street", "OffsetStartMs": 11500, "OffsetEndMs": 11850}, {"Word": "view", "OffsetStartMs": 11850, "OffsetEndMs": 12200}, {"Word": "and", "OffsetStartMs": 12340, "OffsetEndMs": 12645}, {"Word": "we", "OffsetStartMs": 12645, "OffsetEndMs": 12825}, {"Word": "can", "OffsetStartMs": 12825, "OffsetEndMs": 13050}, {"Word": "have", "OffsetStartMs": 13050, "OffsetEndMs": 13335}, {"Word": "images", "OffsetStartMs": 13335, "OffsetEndMs": 13670}, {"Word": "of", "OffsetStartMs": 13780, "OffsetEndMs": 14100}, {"Word": "the", "OffsetStartMs": 14100, "OffsetEndMs": 14310}, {"Word": "segmentation", "OffsetStartMs": 14310, "OffsetEndMs": 14985}, {"Word": "of", "OffsetStartMs": 14985, "OffsetEndMs": 15255}, {"Word": "that", "OffsetStartMs": 15255, "OffsetEndMs": 15530}, {"Word": "street", "OffsetStartMs": 15550, "OffsetEndMs": 15870}, {"Word": "view", "OffsetStartMs": 15870, "OffsetEndMs": 16190}, {"Word": "and", "OffsetStartMs": 16660, "OffsetEndMs": 16950}, {"Word": "we", "OffsetStartMs": 16950, "OffsetEndMs": 17100}, {"Word": "can", "OffsetStartMs": 17100, "OffsetEndMs": 17265}, {"Word": "build", "OffsetStartMs": 17265, "OffsetEndMs": 17565}, {"Word": "again", "OffsetStartMs": 17565, "OffsetEndMs": 17925}, {"Word": "that", "OffsetStartMs": 17925, "OffsetEndMs": 18255}, {"Word": "can", "OffsetStartMs": 18255, "OffsetEndMs": 18615}, {"Word": "directly", "OffsetStartMs": 18615, "OffsetEndMs": 19010}, {"Word": "translate", "OffsetStartMs": 19390, "OffsetEndMs": 19785}, {"Word": "between", "OffsetStartMs": 19785, "OffsetEndMs": 20180}, {"Word": "the", "OffsetStartMs": 20500, "OffsetEndMs": 20900}, {"Word": "street", "OffsetStartMs": 21010, "OffsetEndMs": 21330}, {"Word": "view", "OffsetStartMs": 21330, "OffsetEndMs": 21650}, {"Word": "and", "OffsetStartMs": 21850, "OffsetEndMs": 22170}, {"Word": "the", "OffsetStartMs": 22170, "OffsetEndMs": 22365}, {"Word": "segmentation", "OffsetStartMs": 22365, "OffsetEndMs": 23000}], "SpeechSpeed": 12.6}, {"FinalSentence": "Let's make this more concrete by considering some particular examples.", "SliceSentence": "Let 's make this more concrete by considering some particular examples", "StartMs": 3107080, "EndMs": 3111640, "WordsNum": 11, "Words": [{"Word": "Let", "OffsetStartMs": 220, "OffsetEndMs": 465}, {"Word": "'s", "OffsetStartMs": 465, "OffsetEndMs": 585}, {"Word": "make", "OffsetStartMs": 585, "OffsetEndMs": 750}, {"Word": "this", "OffsetStartMs": 750, "OffsetEndMs": 930}, {"Word": "more", "OffsetStartMs": 930, "OffsetEndMs": 1220}, {"Word": "concrete", "OffsetStartMs": 1270, "OffsetEndMs": 1590}, {"Word": "by", "OffsetStartMs": 1590, "OffsetEndMs": 1905}, {"Word": "considering", "OffsetStartMs": 1905, "OffsetEndMs": 2295}, {"Word": "some", "OffsetStartMs": 2295, "OffsetEndMs": 2690}, {"Word": "particular", "OffsetStartMs": 2770, "OffsetEndMs": 3170}, {"Word": "examples", "OffsetStartMs": 3280, "OffsetEndMs": 3680}], "SpeechSpeed": 15.1}, {"FinalSentence": "So what I just described was going from a segmentation label to a street scene.", "SliceSentence": "So what I just described was going from a segmentation label to a street scene", "StartMs": 3111640, "EndMs": 3117940, "WordsNum": 15, "Words": [{"Word": "So", "OffsetStartMs": 40, "OffsetEndMs": 440}, {"Word": "what", "OffsetStartMs": 790, "OffsetEndMs": 1050}, {"Word": "I", "OffsetStartMs": 1050, "OffsetEndMs": 1185}, {"Word": "just", "OffsetStartMs": 1185, "OffsetEndMs": 1455}, {"Word": "described", "OffsetStartMs": 1455, "OffsetEndMs": 1845}, {"Word": "was", "OffsetStartMs": 1845, "OffsetEndMs": 2240}, {"Word": "going", "OffsetStartMs": 2530, "OffsetEndMs": 2895}, {"Word": "from", "OffsetStartMs": 2895, "OffsetEndMs": 3195}, {"Word": "a", "OffsetStartMs": 3195, "OffsetEndMs": 3435}, {"Word": "segmentation", "OffsetStartMs": 3435, "OffsetEndMs": 4095}, {"Word": "label", "OffsetStartMs": 4095, "OffsetEndMs": 4490}, {"Word": "to", "OffsetStartMs": 4570, "OffsetEndMs": 4830}, {"Word": "a", "OffsetStartMs": 4830, "OffsetEndMs": 5025}, {"Word": "street", "OffsetStartMs": 5025, "OffsetEndMs": 5310}, {"Word": "scene", "OffsetStartMs": 5310, "OffsetEndMs": 5660}], "SpeechSpeed": 12.4}, {"FinalSentence": "We can also translate between a satellite view aerial satellite image to what is the roadmap equivalent of that aerial satellite image or a particular annotation or labels of the image of a building to the actual visual realization and visual facade of that building.", "SliceSentence": "We can also translate between a satellite view aerial satellite image to what is the roadmap equivalent of that aerial satellite image or a particular annotation or labels of the image of a building to the actual visual realization and visual facade of that building", "StartMs": 3117940, "EndMs": 3140180, "WordsNum": 45, "Words": [{"Word": "We", "OffsetStartMs": 100, "OffsetEndMs": 375}, {"Word": "can", "OffsetStartMs": 375, "OffsetEndMs": 630}, {"Word": "also", "OffsetStartMs": 630, "OffsetEndMs": 1010}, {"Word": "translate", "OffsetStartMs": 1090, "OffsetEndMs": 1470}, {"Word": "between", "OffsetStartMs": 1470, "OffsetEndMs": 1740}, {"Word": "a", "OffsetStartMs": 1740, "OffsetEndMs": 1950}, {"Word": "satellite", "OffsetStartMs": 1950, "OffsetEndMs": 2520}, {"Word": "view", "OffsetStartMs": 2520, "OffsetEndMs": 2870}, {"Word": "aerial", "OffsetStartMs": 3430, "OffsetEndMs": 4005}, {"Word": "satellite", "OffsetStartMs": 4005, "OffsetEndMs": 4455}, {"Word": "image", "OffsetStartMs": 4455, "OffsetEndMs": 4760}, {"Word": "to", "OffsetStartMs": 5200, "OffsetEndMs": 5520}, {"Word": "what", "OffsetStartMs": 5520, "OffsetEndMs": 5775}, {"Word": "is", "OffsetStartMs": 5775, "OffsetEndMs": 6060}, {"Word": "the", "OffsetStartMs": 6060, "OffsetEndMs": 6410}, {"Word": "roadmap", "OffsetStartMs": 6670, "OffsetEndMs": 7370}, {"Word": "equivalent", "OffsetStartMs": 7450, "OffsetEndMs": 7850}, {"Word": "of", "OffsetStartMs": 8020, "OffsetEndMs": 8340}, {"Word": "that", "OffsetStartMs": 8340, "OffsetEndMs": 8660}, {"Word": "aerial", "OffsetStartMs": 9160, "OffsetEndMs": 9705}, {"Word": "satellite", "OffsetStartMs": 9705, "OffsetEndMs": 10155}, {"Word": "image", "OffsetStartMs": 10155, "OffsetEndMs": 10460}, {"Word": "or", "OffsetStartMs": 11230, "OffsetEndMs": 11630}, {"Word": "a", "OffsetStartMs": 12010, "OffsetEndMs": 12410}, {"Word": "particular", "OffsetStartMs": 12730, "OffsetEndMs": 13125}, {"Word": "annotation", "OffsetStartMs": 13125, "OffsetEndMs": 13820}, {"Word": "or", "OffsetStartMs": 13870, "OffsetEndMs": 14175}, {"Word": "labels", "OffsetStartMs": 14175, "OffsetEndMs": 14670}, {"Word": "of", "OffsetStartMs": 14670, "OffsetEndMs": 15020}, {"Word": "the", "OffsetStartMs": 15190, "OffsetEndMs": 15435}, {"Word": "image", "OffsetStartMs": 15435, "OffsetEndMs": 15600}, {"Word": "of", "OffsetStartMs": 15600, "OffsetEndMs": 15780}, {"Word": "a", "OffsetStartMs": 15780, "OffsetEndMs": 15900}, {"Word": "building", "OffsetStartMs": 15900, "OffsetEndMs": 16160}, {"Word": "to", "OffsetStartMs": 16450, "OffsetEndMs": 16740}, {"Word": "the", "OffsetStartMs": 16740, "OffsetEndMs": 17030}, {"Word": "actual", "OffsetStartMs": 17110, "OffsetEndMs": 17510}, {"Word": "visual", "OffsetStartMs": 18070, "OffsetEndMs": 18470}, {"Word": "realization", "OffsetStartMs": 19210, "OffsetEndMs": 19875}, {"Word": "and", "OffsetStartMs": 19875, "OffsetEndMs": 20130}, {"Word": "visual", "OffsetStartMs": 20130, "OffsetEndMs": 20400}, {"Word": "facade", "OffsetStartMs": 20400, "OffsetEndMs": 20880}, {"Word": "of", "OffsetStartMs": 20880, "OffsetEndMs": 21060}, {"Word": "that", "OffsetStartMs": 21060, "OffsetEndMs": 21225}, {"Word": "building", "OffsetStartMs": 21225, "OffsetEndMs": 21530}], "SpeechSpeed": 12.0}, {"FinalSentence": "We can translate between different lighting conditions day to night.", "SliceSentence": "We can translate between different lighting conditions day to night", "StartMs": 3140180, "EndMs": 3144800, "WordsNum": 10, "Words": [{"Word": "We", "OffsetStartMs": 100, "OffsetEndMs": 360}, {"Word": "can", "OffsetStartMs": 360, "OffsetEndMs": 620}, {"Word": "translate", "OffsetStartMs": 700, "OffsetEndMs": 1100}, {"Word": "between", "OffsetStartMs": 1120, "OffsetEndMs": 1425}, {"Word": "different", "OffsetStartMs": 1425, "OffsetEndMs": 1680}, {"Word": "lighting", "OffsetStartMs": 1680, "OffsetEndMs": 2030}, {"Word": "conditions", "OffsetStartMs": 2170, "OffsetEndMs": 2570}, {"Word": "day", "OffsetStartMs": 2920, "OffsetEndMs": 3300}, {"Word": "to", "OffsetStartMs": 3300, "OffsetEndMs": 3540}, {"Word": "night", "OffsetStartMs": 3540, "OffsetEndMs": 3800}], "SpeechSpeed": 14.5}, {"FinalSentence": "Black and white to color outlines to a colored photo.", "SliceSentence": "Black and white to color outlines to a colored photo", "StartMs": 3144880, "EndMs": 3151400, "WordsNum": 10, "Words": [{"Word": "Black", "OffsetStartMs": 130, "OffsetEndMs": 420}, {"Word": "and", "OffsetStartMs": 420, "OffsetEndMs": 600}, {"Word": "white", "OffsetStartMs": 600, "OffsetEndMs": 870}, {"Word": "to", "OffsetStartMs": 870, "OffsetEndMs": 1140}, {"Word": "color", "OffsetStartMs": 1140, "OffsetEndMs": 1430}, {"Word": "outlines", "OffsetStartMs": 1810, "OffsetEndMs": 2510}, {"Word": "to", "OffsetStartMs": 2740, "OffsetEndMs": 3060}, {"Word": "a", "OffsetStartMs": 3060, "OffsetEndMs": 3300}, {"Word": "colored", "OffsetStartMs": 3300, "OffsetEndMs": 3620}, {"Word": "photo", "OffsetStartMs": 5230, "OffsetEndMs": 5630}], "SpeechSpeed": 8.0}, {"FinalSentence": "All these cases, and I think in particular the, the most interesting and impactful to me is this translation between street view and aerial view. And this is used to consider, for example, if you have data from Google maps, how you can go between a street view of the map to the aerial image of that.", "SliceSentence": "All these cases and I think in particular the the most interesting and impactful to me is this translation between street view and aerial view . Andthis is used to consider for example if you have data from Google maps how you can go between a street view of the map to the aerial image of that", "StartMs": 3151400, "EndMs": 3173800, "WordsNum": 57, "Words": [{"Word": "All", "OffsetStartMs": 40, "OffsetEndMs": 345}, {"Word": "these", "OffsetStartMs": 345, "OffsetEndMs": 585}, {"Word": "cases", "OffsetStartMs": 585, "OffsetEndMs": 920}, {"Word": "and", "OffsetStartMs": 1390, "OffsetEndMs": 1635}, {"Word": "I", "OffsetStartMs": 1635, "OffsetEndMs": 1770}, {"Word": "think", "OffsetStartMs": 1770, "OffsetEndMs": 2010}, {"Word": "in", "OffsetStartMs": 2010, "OffsetEndMs": 2340}, {"Word": "particular", "OffsetStartMs": 2340, "OffsetEndMs": 2720}, {"Word": "the", "OffsetStartMs": 2740, "OffsetEndMs": 3045}, {"Word": "the", "OffsetStartMs": 3045, "OffsetEndMs": 3225}, {"Word": "most", "OffsetStartMs": 3225, "OffsetEndMs": 3500}, {"Word": "interesting", "OffsetStartMs": 3880, "OffsetEndMs": 4140}, {"Word": "and", "OffsetStartMs": 4140, "OffsetEndMs": 4400}, {"Word": "impactful", "OffsetStartMs": 4690, "OffsetEndMs": 5220}, {"Word": "to", "OffsetStartMs": 5220, "OffsetEndMs": 5355}, {"Word": "me", "OffsetStartMs": 5355, "OffsetEndMs": 5600}, {"Word": "is", "OffsetStartMs": 5890, "OffsetEndMs": 6180}, {"Word": "this", "OffsetStartMs": 6180, "OffsetEndMs": 6420}, {"Word": "translation", "OffsetStartMs": 6420, "OffsetEndMs": 6770}, {"Word": "between", "OffsetStartMs": 7180, "OffsetEndMs": 7580}, {"Word": "street", "OffsetStartMs": 7750, "OffsetEndMs": 8085}, {"Word": "view", "OffsetStartMs": 8085, "OffsetEndMs": 8340}, {"Word": "and", "OffsetStartMs": 8340, "OffsetEndMs": 8550}, {"Word": "aerial", "OffsetStartMs": 8550, "OffsetEndMs": 8970}, {"Word": "view", "OffsetStartMs": 8970, "OffsetEndMs": 9260}, {"Word": ".", "OffsetStartMs": 9610, "OffsetEndMs": 9930}, {"Word": "Andthis", "OffsetStartMs": 9930, "OffsetEndMs": 10200}, {"Word": "is", "OffsetStartMs": 10200, "OffsetEndMs": 10550}, {"Word": "used", "OffsetStartMs": 11620, "OffsetEndMs": 12000}, {"Word": "to", "OffsetStartMs": 12000, "OffsetEndMs": 12360}, {"Word": "consider", "OffsetStartMs": 12360, "OffsetEndMs": 12675}, {"Word": "for", "OffsetStartMs": 12675, "OffsetEndMs": 12915}, {"Word": "example", "OffsetStartMs": 12915, "OffsetEndMs": 13155}, {"Word": "if", "OffsetStartMs": 13155, "OffsetEndMs": 13350}, {"Word": "you", "OffsetStartMs": 13350, "OffsetEndMs": 13500}, {"Word": "have", "OffsetStartMs": 13500, "OffsetEndMs": 13725}, {"Word": "data", "OffsetStartMs": 13725, "OffsetEndMs": 14055}, {"Word": "from", "OffsetStartMs": 14055, "OffsetEndMs": 14450}, {"Word": "Google", "OffsetStartMs": 15040, "OffsetEndMs": 15390}, {"Word": "maps", "OffsetStartMs": 15390, "OffsetEndMs": 15740}, {"Word": "how", "OffsetStartMs": 16000, "OffsetEndMs": 16305}, {"Word": "you", "OffsetStartMs": 16305, "OffsetEndMs": 16500}, {"Word": "can", "OffsetStartMs": 16500, "OffsetEndMs": 16680}, {"Word": "go", "OffsetStartMs": 16680, "OffsetEndMs": 16970}, {"Word": "between", "OffsetStartMs": 16990, "OffsetEndMs": 17390}, {"Word": "a", "OffsetStartMs": 17590, "OffsetEndMs": 17990}, {"Word": "street", "OffsetStartMs": 18220, "OffsetEndMs": 18540}, {"Word": "view", "OffsetStartMs": 18540, "OffsetEndMs": 18860}, {"Word": "of", "OffsetStartMs": 18940, "OffsetEndMs": 19215}, {"Word": "the", "OffsetStartMs": 19215, "OffsetEndMs": 19350}, {"Word": "map", "OffsetStartMs": 19350, "OffsetEndMs": 19610}, {"Word": "to", "OffsetStartMs": 20050, "OffsetEndMs": 20340}, {"Word": "the", "OffsetStartMs": 20340, "OffsetEndMs": 20505}, {"Word": "aerial", "OffsetStartMs": 20505, "OffsetEndMs": 20985}, {"Word": "image", "OffsetStartMs": 20985, "OffsetEndMs": 21345}, {"Word": "of", "OffsetStartMs": 21345, "OffsetEndMs": 21600}, {"Word": "that", "OffsetStartMs": 21600, "OffsetEndMs": 21890}], "SpeechSpeed": 13.1}, {"FinalSentence": "Finally, again extending the same concept of translation between one domain to another, another idea is that of completely unpaired translation, and this uses a particular Gan architecture called cyan.", "SliceSentence": "Finally again extending the same concept of translation between one domain to another another idea is that of completely unpaired translation and this uses a particular Gan architecture called cyan", "StartMs": 3175180, "EndMs": 3192240, "WordsNum": 30, "Words": [{"Word": "Finally", "OffsetStartMs": 70, "OffsetEndMs": 470}, {"Word": "again", "OffsetStartMs": 1360, "OffsetEndMs": 1760}, {"Word": "extending", "OffsetStartMs": 2710, "OffsetEndMs": 3165}, {"Word": "the", "OffsetStartMs": 3165, "OffsetEndMs": 3345}, {"Word": "same", "OffsetStartMs": 3345, "OffsetEndMs": 3600}, {"Word": "concept", "OffsetStartMs": 3600, "OffsetEndMs": 3950}, {"Word": "of", "OffsetStartMs": 4030, "OffsetEndMs": 4335}, {"Word": "translation", "OffsetStartMs": 4335, "OffsetEndMs": 4640}, {"Word": "between", "OffsetStartMs": 5650, "OffsetEndMs": 5970}, {"Word": "one", "OffsetStartMs": 5970, "OffsetEndMs": 6225}, {"Word": "domain", "OffsetStartMs": 6225, "OffsetEndMs": 6560}, {"Word": "to", "OffsetStartMs": 6580, "OffsetEndMs": 6870}, {"Word": "another", "OffsetStartMs": 6870, "OffsetEndMs": 7160}, {"Word": "another", "OffsetStartMs": 8020, "OffsetEndMs": 8420}, {"Word": "idea", "OffsetStartMs": 8530, "OffsetEndMs": 8895}, {"Word": "is", "OffsetStartMs": 8895, "OffsetEndMs": 9150}, {"Word": "that", "OffsetStartMs": 9150, "OffsetEndMs": 9345}, {"Word": "of", "OffsetStartMs": 9345, "OffsetEndMs": 9650}, {"Word": "completely", "OffsetStartMs": 9730, "OffsetEndMs": 10130}, {"Word": "unpaired", "OffsetStartMs": 10240, "OffsetEndMs": 10970}, {"Word": "translation", "OffsetStartMs": 11380, "OffsetEndMs": 11780}, {"Word": "and", "OffsetStartMs": 12550, "OffsetEndMs": 12825}, {"Word": "this", "OffsetStartMs": 12825, "OffsetEndMs": 13020}, {"Word": "uses", "OffsetStartMs": 13020, "OffsetEndMs": 13340}, {"Word": "a", "OffsetStartMs": 13390, "OffsetEndMs": 13740}, {"Word": "particular", "OffsetStartMs": 13740, "OffsetEndMs": 14090}, {"Word": "Gan", "OffsetStartMs": 14230, "OffsetEndMs": 14580}, {"Word": "architecture", "OffsetStartMs": 14580, "OffsetEndMs": 14900}, {"Word": "called", "OffsetStartMs": 15280, "OffsetEndMs": 15675}, {"Word": "cyan", "OffsetStartMs": 15675, "OffsetEndMs": 16430}], "SpeechSpeed": 11.5}, {"FinalSentence": "So in this video that I'm showing here, the model takes as input a bunch of images in one domain. And it doesn't necessarily have to have a corresponding image in another target domain, but it is trained to try to generate examples in that target domain that roughly correspond to the source domain, transferring the style of the source onto the target and vice versa. So this example is showing the translation of images in horse domain to zebra domain.", "SliceSentence": "So in this video that I'm showing here the model takes as input a bunch of images in one domain . Andit doesn't necessarily have to have a corresponding image in another target domain but it is trained to try to generate examples in that target domain that roughly correspond to the source domain transferring the style of the source onto the target and vice versa . Sothis example is showing the translation of images in horse domain to zebra domain", "StartMs": 3192280, "EndMs": 3227540, "WordsNum": 81, "Words": [{"Word": "So", "OffsetStartMs": 370, "OffsetEndMs": 690}, {"Word": "in", "OffsetStartMs": 690, "OffsetEndMs": 900}, {"Word": "this", "OffsetStartMs": 900, "OffsetEndMs": 1110}, {"Word": "video", "OffsetStartMs": 1110, "OffsetEndMs": 1380}, {"Word": "that", "OffsetStartMs": 1380, "OffsetEndMs": 1575}, {"Word": "I'm", "OffsetStartMs": 1575, "OffsetEndMs": 1785}, {"Word": "showing", "OffsetStartMs": 1785, "OffsetEndMs": 2040}, {"Word": "here", "OffsetStartMs": 2040, "OffsetEndMs": 2420}, {"Word": "the", "OffsetStartMs": 2680, "OffsetEndMs": 2970}, {"Word": "model", "OffsetStartMs": 2970, "OffsetEndMs": 3260}, {"Word": "takes", "OffsetStartMs": 3610, "OffsetEndMs": 3945}, {"Word": "as", "OffsetStartMs": 3945, "OffsetEndMs": 4280}, {"Word": "input", "OffsetStartMs": 4330, "OffsetEndMs": 4620}, {"Word": "a", "OffsetStartMs": 4620, "OffsetEndMs": 4800}, {"Word": "bunch", "OffsetStartMs": 4800, "OffsetEndMs": 5025}, {"Word": "of", "OffsetStartMs": 5025, "OffsetEndMs": 5360}, {"Word": "images", "OffsetStartMs": 5470, "OffsetEndMs": 5870}, {"Word": "in", "OffsetStartMs": 5950, "OffsetEndMs": 6240}, {"Word": "one", "OffsetStartMs": 6240, "OffsetEndMs": 6450}, {"Word": "domain", "OffsetStartMs": 6450, "OffsetEndMs": 6770}, {"Word": ".", "OffsetStartMs": 7420, "OffsetEndMs": 7815}, {"Word": "Andit", "OffsetStartMs": 7815, "OffsetEndMs": 8085}, {"Word": "doesn't", "OffsetStartMs": 8085, "OffsetEndMs": 8540}, {"Word": "necessarily", "OffsetStartMs": 8590, "OffsetEndMs": 8985}, {"Word": "have", "OffsetStartMs": 8985, "OffsetEndMs": 9270}, {"Word": "to", "OffsetStartMs": 9270, "OffsetEndMs": 9405}, {"Word": "have", "OffsetStartMs": 9405, "OffsetEndMs": 9510}, {"Word": "a", "OffsetStartMs": 9510, "OffsetEndMs": 9660}, {"Word": "corresponding", "OffsetStartMs": 9660, "OffsetEndMs": 10290}, {"Word": "image", "OffsetStartMs": 10290, "OffsetEndMs": 10560}, {"Word": "in", "OffsetStartMs": 10560, "OffsetEndMs": 10860}, {"Word": "another", "OffsetStartMs": 10860, "OffsetEndMs": 11175}, {"Word": "target", "OffsetStartMs": 11175, "OffsetEndMs": 11535}, {"Word": "domain", "OffsetStartMs": 11535, "OffsetEndMs": 11900}, {"Word": "but", "OffsetStartMs": 12640, "OffsetEndMs": 12900}, {"Word": "it", "OffsetStartMs": 12900, "OffsetEndMs": 13005}, {"Word": "is", "OffsetStartMs": 13005, "OffsetEndMs": 13215}, {"Word": "trained", "OffsetStartMs": 13215, "OffsetEndMs": 13575}, {"Word": "to", "OffsetStartMs": 13575, "OffsetEndMs": 13890}, {"Word": "try", "OffsetStartMs": 13890, "OffsetEndMs": 14145}, {"Word": "to", "OffsetStartMs": 14145, "OffsetEndMs": 14400}, {"Word": "generate", "OffsetStartMs": 14400, "OffsetEndMs": 14720}, {"Word": "examples", "OffsetStartMs": 15490, "OffsetEndMs": 15890}, {"Word": "in", "OffsetStartMs": 16000, "OffsetEndMs": 16275}, {"Word": "that", "OffsetStartMs": 16275, "OffsetEndMs": 16470}, {"Word": "target", "OffsetStartMs": 16470, "OffsetEndMs": 16755}, {"Word": "domain", "OffsetStartMs": 16755, "OffsetEndMs": 17120}, {"Word": "that", "OffsetStartMs": 17740, "OffsetEndMs": 18140}, {"Word": "roughly", "OffsetStartMs": 18460, "OffsetEndMs": 18860}, {"Word": "correspond", "OffsetStartMs": 19120, "OffsetEndMs": 19520}, {"Word": "to", "OffsetStartMs": 19990, "OffsetEndMs": 20390}, {"Word": "the", "OffsetStartMs": 20530, "OffsetEndMs": 20820}, {"Word": "source", "OffsetStartMs": 20820, "OffsetEndMs": 21060}, {"Word": "domain", "OffsetStartMs": 21060, "OffsetEndMs": 21410}, {"Word": "transferring", "OffsetStartMs": 22060, "OffsetEndMs": 22710}, {"Word": "the", "OffsetStartMs": 22710, "OffsetEndMs": 22935}, {"Word": "style", "OffsetStartMs": 22935, "OffsetEndMs": 23240}, {"Word": "of", "OffsetStartMs": 23290, "OffsetEndMs": 23580}, {"Word": "the", "OffsetStartMs": 23580, "OffsetEndMs": 23760}, {"Word": "source", "OffsetStartMs": 23760, "OffsetEndMs": 24050}, {"Word": "onto", "OffsetStartMs": 24070, "OffsetEndMs": 24450}, {"Word": "the", "OffsetStartMs": 24450, "OffsetEndMs": 24705}, {"Word": "target", "OffsetStartMs": 24705, "OffsetEndMs": 24980}, {"Word": "and", "OffsetStartMs": 25390, "OffsetEndMs": 25790}, {"Word": "vice", "OffsetStartMs": 25840, "OffsetEndMs": 26175}, {"Word": "versa", "OffsetStartMs": 26175, "OffsetEndMs": 26750}, {"Word": ".", "OffsetStartMs": 27340, "OffsetEndMs": 27740}, {"Word": "Sothis", "OffsetStartMs": 27760, "OffsetEndMs": 28110}, {"Word": "example", "OffsetStartMs": 28110, "OffsetEndMs": 28455}, {"Word": "is", "OffsetStartMs": 28455, "OffsetEndMs": 28770}, {"Word": "showing", "OffsetStartMs": 28770, "OffsetEndMs": 29090}, {"Word": "the", "OffsetStartMs": 29620, "OffsetEndMs": 30020}, {"Word": "translation", "OffsetStartMs": 30070, "OffsetEndMs": 30470}, {"Word": "of", "OffsetStartMs": 30610, "OffsetEndMs": 30900}, {"Word": "images", "OffsetStartMs": 30900, "OffsetEndMs": 31190}, {"Word": "in", "OffsetStartMs": 31690, "OffsetEndMs": 32085}, {"Word": "horse", "OffsetStartMs": 32085, "OffsetEndMs": 32445}, {"Word": "domain", "OffsetStartMs": 32445, "OffsetEndMs": 32810}, {"Word": "to", "OffsetStartMs": 33400, "OffsetEndMs": 33800}, {"Word": "zebra", "OffsetStartMs": 33910, "OffsetEndMs": 34380}, {"Word": "domain", "OffsetStartMs": 34380, "OffsetEndMs": 34670}], "SpeechSpeed": 12.7}, {"FinalSentence": "The concept here is this cyclic dependency, right? You have two gans that are connected together VIA this cyclic loss, transforming between one domain and another.", "SliceSentence": "The concept here is this cyclic dependency right You have two gans that are connected together VIA this cyclic loss transforming between one domain and another", "StartMs": 3227920, "EndMs": 3240740, "WordsNum": 26, "Words": [{"Word": "The", "OffsetStartMs": 100, "OffsetEndMs": 390}, {"Word": "concept", "OffsetStartMs": 390, "OffsetEndMs": 680}, {"Word": "here", "OffsetStartMs": 760, "OffsetEndMs": 1065}, {"Word": "is", "OffsetStartMs": 1065, "OffsetEndMs": 1275}, {"Word": "this", "OffsetStartMs": 1275, "OffsetEndMs": 1580}, {"Word": "cyclic", "OffsetStartMs": 1720, "OffsetEndMs": 2355}, {"Word": "dependency", "OffsetStartMs": 2355, "OffsetEndMs": 3170}, {"Word": "right", "OffsetStartMs": 3280, "OffsetEndMs": 3680}, {"Word": "You", "OffsetStartMs": 3790, "OffsetEndMs": 4095}, {"Word": "have", "OffsetStartMs": 4095, "OffsetEndMs": 4335}, {"Word": "two", "OffsetStartMs": 4335, "OffsetEndMs": 4575}, {"Word": "gans", "OffsetStartMs": 4575, "OffsetEndMs": 4905}, {"Word": "that", "OffsetStartMs": 4905, "OffsetEndMs": 5160}, {"Word": "are", "OffsetStartMs": 5160, "OffsetEndMs": 5370}, {"Word": "connected", "OffsetStartMs": 5370, "OffsetEndMs": 5720}, {"Word": "together", "OffsetStartMs": 5740, "OffsetEndMs": 6140}, {"Word": "VIA", "OffsetStartMs": 6400, "OffsetEndMs": 6780}, {"Word": "this", "OffsetStartMs": 6780, "OffsetEndMs": 7160}, {"Word": "cyclic", "OffsetStartMs": 7960, "OffsetEndMs": 8505}, {"Word": "loss", "OffsetStartMs": 8505, "OffsetEndMs": 8840}, {"Word": "transforming", "OffsetStartMs": 9550, "OffsetEndMs": 10140}, {"Word": "between", "OffsetStartMs": 10140, "OffsetEndMs": 10455}, {"Word": "one", "OffsetStartMs": 10455, "OffsetEndMs": 10755}, {"Word": "domain", "OffsetStartMs": 10755, "OffsetEndMs": 11120}, {"Word": "and", "OffsetStartMs": 11410, "OffsetEndMs": 11745}, {"Word": "another", "OffsetStartMs": 11745, "OffsetEndMs": 12080}], "SpeechSpeed": 12.4}, {"FinalSentence": "And really like all the examples that we've seen so far in this lecture, the intuition is this idea of distribution transformation. Normally with g, you're going from noise to some target with the cycle. Again, you're trying to go from some source distribution, some data manifold X to a target distribution, another data manifold y.", "SliceSentence": "And really like all the examples that we've seen so far in this lecture the intuition is this idea of distribution transformation . Normallywith g you're going from noise to some target with the cycle . Againyou're trying to go from some source distribution some data manifold X to a target distribution another data manifold y", "StartMs": 3241180, "EndMs": 3265080, "WordsNum": 56, "Words": [{"Word": "And", "OffsetStartMs": 160, "OffsetEndMs": 465}, {"Word": "really", "OffsetStartMs": 465, "OffsetEndMs": 720}, {"Word": "like", "OffsetStartMs": 720, "OffsetEndMs": 1005}, {"Word": "all", "OffsetStartMs": 1005, "OffsetEndMs": 1260}, {"Word": "the", "OffsetStartMs": 1260, "OffsetEndMs": 1515}, {"Word": "examples", "OffsetStartMs": 1515, "OffsetEndMs": 1850}, {"Word": "that", "OffsetStartMs": 1960, "OffsetEndMs": 2235}, {"Word": "we've", "OffsetStartMs": 2235, "OffsetEndMs": 2520}, {"Word": "seen", "OffsetStartMs": 2520, "OffsetEndMs": 2810}, {"Word": "so", "OffsetStartMs": 3130, "OffsetEndMs": 3420}, {"Word": "far", "OffsetStartMs": 3420, "OffsetEndMs": 3600}, {"Word": "in", "OffsetStartMs": 3600, "OffsetEndMs": 3750}, {"Word": "this", "OffsetStartMs": 3750, "OffsetEndMs": 3915}, {"Word": "lecture", "OffsetStartMs": 3915, "OffsetEndMs": 4220}, {"Word": "the", "OffsetStartMs": 4660, "OffsetEndMs": 4920}, {"Word": "intuition", "OffsetStartMs": 4920, "OffsetEndMs": 5445}, {"Word": "is", "OffsetStartMs": 5445, "OffsetEndMs": 5745}, {"Word": "this", "OffsetStartMs": 5745, "OffsetEndMs": 6045}, {"Word": "idea", "OffsetStartMs": 6045, "OffsetEndMs": 6345}, {"Word": "of", "OffsetStartMs": 6345, "OffsetEndMs": 6630}, {"Word": "distribution", "OffsetStartMs": 6630, "OffsetEndMs": 7010}, {"Word": "transformation", "OffsetStartMs": 7150, "OffsetEndMs": 7550}, {"Word": ".", "OffsetStartMs": 8770, "OffsetEndMs": 9170}, {"Word": "Normallywith", "OffsetStartMs": 9220, "OffsetEndMs": 9570}, {"Word": "g", "OffsetStartMs": 9570, "OffsetEndMs": 9900}, {"Word": "you're", "OffsetStartMs": 9900, "OffsetEndMs": 10230}, {"Word": "going", "OffsetStartMs": 10230, "OffsetEndMs": 10440}, {"Word": "from", "OffsetStartMs": 10440, "OffsetEndMs": 10710}, {"Word": "noise", "OffsetStartMs": 10710, "OffsetEndMs": 11030}, {"Word": "to", "OffsetStartMs": 11110, "OffsetEndMs": 11385}, {"Word": "some", "OffsetStartMs": 11385, "OffsetEndMs": 11595}, {"Word": "target", "OffsetStartMs": 11595, "OffsetEndMs": 11930}, {"Word": "with", "OffsetStartMs": 12640, "OffsetEndMs": 12915}, {"Word": "the", "OffsetStartMs": 12915, "OffsetEndMs": 13080}, {"Word": "cycle", "OffsetStartMs": 13080, "OffsetEndMs": 13365}, {"Word": ".", "OffsetStartMs": 13365, "OffsetEndMs": 13760}, {"Word": "Againyou're", "OffsetStartMs": 13840, "OffsetEndMs": 14220}, {"Word": "trying", "OffsetStartMs": 14220, "OffsetEndMs": 14430}, {"Word": "to", "OffsetStartMs": 14430, "OffsetEndMs": 14625}, {"Word": "go", "OffsetStartMs": 14625, "OffsetEndMs": 14835}, {"Word": "from", "OffsetStartMs": 14835, "OffsetEndMs": 15120}, {"Word": "some", "OffsetStartMs": 15120, "OffsetEndMs": 15470}, {"Word": "source", "OffsetStartMs": 15790, "OffsetEndMs": 16190}, {"Word": "distribution", "OffsetStartMs": 16750, "OffsetEndMs": 17150}, {"Word": "some", "OffsetStartMs": 17650, "OffsetEndMs": 17985}, {"Word": "data", "OffsetStartMs": 17985, "OffsetEndMs": 18255}, {"Word": "manifold", "OffsetStartMs": 18255, "OffsetEndMs": 18795}, {"Word": "X", "OffsetStartMs": 18795, "OffsetEndMs": 19130}, {"Word": "to", "OffsetStartMs": 19480, "OffsetEndMs": 19725}, {"Word": "a", "OffsetStartMs": 19725, "OffsetEndMs": 19875}, {"Word": "target", "OffsetStartMs": 19875, "OffsetEndMs": 20180}, {"Word": "distribution", "OffsetStartMs": 21010, "OffsetEndMs": 21410}, {"Word": "another", "OffsetStartMs": 21730, "OffsetEndMs": 22095}, {"Word": "data", "OffsetStartMs": 22095, "OffsetEndMs": 22380}, {"Word": "manifold", "OffsetStartMs": 22380, "OffsetEndMs": 22965}, {"Word": "y", "OffsetStartMs": 22965, "OffsetEndMs": 23360}], "SpeechSpeed": 13.6}, {"FinalSentence": "And this is really, really not only cool, but also powerful in thinking about how we can translate across these different distributions flexibly.", "SliceSentence": "And this is really really not only cool but also powerful in thinking about how we can translate across these different distributions flexibly", "StartMs": 3265260, "EndMs": 3275840, "WordsNum": 23, "Words": [{"Word": "And", "OffsetStartMs": 160, "OffsetEndMs": 435}, {"Word": "this", "OffsetStartMs": 435, "OffsetEndMs": 585}, {"Word": "is", "OffsetStartMs": 585, "OffsetEndMs": 810}, {"Word": "really", "OffsetStartMs": 810, "OffsetEndMs": 1160}, {"Word": "really", "OffsetStartMs": 1210, "OffsetEndMs": 1610}, {"Word": "not", "OffsetStartMs": 1960, "OffsetEndMs": 2250}, {"Word": "only", "OffsetStartMs": 2250, "OffsetEndMs": 2520}, {"Word": "cool", "OffsetStartMs": 2520, "OffsetEndMs": 2900}, {"Word": "but", "OffsetStartMs": 2950, "OffsetEndMs": 3350}, {"Word": "also", "OffsetStartMs": 3370, "OffsetEndMs": 3675}, {"Word": "powerful", "OffsetStartMs": 3675, "OffsetEndMs": 3980}, {"Word": "in", "OffsetStartMs": 4030, "OffsetEndMs": 4430}, {"Word": "thinking", "OffsetStartMs": 4510, "OffsetEndMs": 4905}, {"Word": "about", "OffsetStartMs": 4905, "OffsetEndMs": 5300}, {"Word": "how", "OffsetStartMs": 5440, "OffsetEndMs": 5760}, {"Word": "we", "OffsetStartMs": 5760, "OffsetEndMs": 5955}, {"Word": "can", "OffsetStartMs": 5955, "OffsetEndMs": 6230}, {"Word": "translate", "OffsetStartMs": 6370, "OffsetEndMs": 6770}, {"Word": "across", "OffsetStartMs": 7090, "OffsetEndMs": 7470}, {"Word": "these", "OffsetStartMs": 7470, "OffsetEndMs": 7770}, {"Word": "different", "OffsetStartMs": 7770, "OffsetEndMs": 8090}, {"Word": "distributions", "OffsetStartMs": 8170, "OffsetEndMs": 8690}, {"Word": "flexibly", "OffsetStartMs": 8980, "OffsetEndMs": 9740}], "SpeechSpeed": 13.4}, {"FinalSentence": "And in fact, this allows us to do transformations not only to images, but to speech and audio as well.", "SliceSentence": "And in fact this allows us to do transformations not only to images but to speech and audio as well", "StartMs": 3275840, "EndMs": 3284200, "WordsNum": 20, "Words": [{"Word": "And", "OffsetStartMs": 10, "OffsetEndMs": 285}, {"Word": "in", "OffsetStartMs": 285, "OffsetEndMs": 465}, {"Word": "fact", "OffsetStartMs": 465, "OffsetEndMs": 770}, {"Word": "this", "OffsetStartMs": 1090, "OffsetEndMs": 1490}, {"Word": "allows", "OffsetStartMs": 1900, "OffsetEndMs": 2265}, {"Word": "us", "OffsetStartMs": 2265, "OffsetEndMs": 2535}, {"Word": "to", "OffsetStartMs": 2535, "OffsetEndMs": 2730}, {"Word": "do", "OffsetStartMs": 2730, "OffsetEndMs": 3020}, {"Word": "transformations", "OffsetStartMs": 3040, "OffsetEndMs": 3800}, {"Word": "not", "OffsetStartMs": 3910, "OffsetEndMs": 4200}, {"Word": "only", "OffsetStartMs": 4200, "OffsetEndMs": 4440}, {"Word": "to", "OffsetStartMs": 4440, "OffsetEndMs": 4665}, {"Word": "images", "OffsetStartMs": 4665, "OffsetEndMs": 4940}, {"Word": "but", "OffsetStartMs": 5440, "OffsetEndMs": 5745}, {"Word": "to", "OffsetStartMs": 5745, "OffsetEndMs": 5970}, {"Word": "speech", "OffsetStartMs": 5970, "OffsetEndMs": 6285}, {"Word": "and", "OffsetStartMs": 6285, "OffsetEndMs": 6585}, {"Word": "audio", "OffsetStartMs": 6585, "OffsetEndMs": 6890}, {"Word": "as", "OffsetStartMs": 6940, "OffsetEndMs": 7245}, {"Word": "well", "OffsetStartMs": 7245, "OffsetEndMs": 7550}], "SpeechSpeed": 11.8}, {"FinalSentence": "So in the case of speech and audio, turns out that you can take sound waves. Represent.", "SliceSentence": "So in the case of speech and audio turns out that you can take sound waves .Represent.", "StartMs": 3284200, "EndMs": 3290760, "WordsNum": 17, "Words": [{"Word": "So", "OffsetStartMs": 10, "OffsetEndMs": 375}, {"Word": "in", "OffsetStartMs": 375, "OffsetEndMs": 615}, {"Word": "the", "OffsetStartMs": 615, "OffsetEndMs": 780}, {"Word": "case", "OffsetStartMs": 780, "OffsetEndMs": 975}, {"Word": "of", "OffsetStartMs": 975, "OffsetEndMs": 1200}, {"Word": "speech", "OffsetStartMs": 1200, "OffsetEndMs": 1410}, {"Word": "and", "OffsetStartMs": 1410, "OffsetEndMs": 1590}, {"Word": "audio", "OffsetStartMs": 1590, "OffsetEndMs": 1880}, {"Word": "turns", "OffsetStartMs": 2410, "OffsetEndMs": 2730}, {"Word": "out", "OffsetStartMs": 2730, "OffsetEndMs": 2955}, {"Word": "that", "OffsetStartMs": 2955, "OffsetEndMs": 3120}, {"Word": "you", "OffsetStartMs": 3120, "OffsetEndMs": 3255}, {"Word": "can", "OffsetStartMs": 3255, "OffsetEndMs": 3450}, {"Word": "take", "OffsetStartMs": 3450, "OffsetEndMs": 3720}, {"Word": "sound", "OffsetStartMs": 3720, "OffsetEndMs": 4005}, {"Word": "waves", "OffsetStartMs": 4005, "OffsetEndMs": 4340}, {"Word": ".Represent.", "OffsetStartMs": 4810, "OffsetEndMs": 5210}], "SpeechSpeed": 12.8}, {"FinalSentence": "Compactly in a spectrogram image and use a cycle g to then translate and transform speech from one person's voice in one domain to another person's voice in another domain, right? These are two independent data distributions that we define.", "SliceSentence": "Compactly in a spectrogram image and use a cycle g to then translate and transform speech from one person's voice in one domain to another person's voice in another domain right These are two independent data distributions that we define", "StartMs": 3290760, "EndMs": 3309300, "WordsNum": 40, "Words": [{"Word": "Compactly", "OffsetStartMs": 220, "OffsetEndMs": 1020}, {"Word": "in", "OffsetStartMs": 1020, "OffsetEndMs": 1170}, {"Word": "a", "OffsetStartMs": 1170, "OffsetEndMs": 1335}, {"Word": "spectrogram", "OffsetStartMs": 1335, "OffsetEndMs": 1905}, {"Word": "image", "OffsetStartMs": 1905, "OffsetEndMs": 2240}, {"Word": "and", "OffsetStartMs": 2740, "OffsetEndMs": 3075}, {"Word": "use", "OffsetStartMs": 3075, "OffsetEndMs": 3315}, {"Word": "a", "OffsetStartMs": 3315, "OffsetEndMs": 3510}, {"Word": "cycle", "OffsetStartMs": 3510, "OffsetEndMs": 3795}, {"Word": "g", "OffsetStartMs": 3795, "OffsetEndMs": 4190}, {"Word": "to", "OffsetStartMs": 4420, "OffsetEndMs": 4695}, {"Word": "then", "OffsetStartMs": 4695, "OffsetEndMs": 4970}, {"Word": "translate", "OffsetStartMs": 5590, "OffsetEndMs": 5990}, {"Word": "and", "OffsetStartMs": 6310, "OffsetEndMs": 6710}, {"Word": "transform", "OffsetStartMs": 7120, "OffsetEndMs": 7520}, {"Word": "speech", "OffsetStartMs": 7810, "OffsetEndMs": 8210}, {"Word": "from", "OffsetStartMs": 8410, "OffsetEndMs": 8730}, {"Word": "one", "OffsetStartMs": 8730, "OffsetEndMs": 8985}, {"Word": "person's", "OffsetStartMs": 8985, "OffsetEndMs": 9480}, {"Word": "voice", "OffsetStartMs": 9480, "OffsetEndMs": 9740}, {"Word": "in", "OffsetStartMs": 10090, "OffsetEndMs": 10410}, {"Word": "one", "OffsetStartMs": 10410, "OffsetEndMs": 10650}, {"Word": "domain", "OffsetStartMs": 10650, "OffsetEndMs": 10970}, {"Word": "to", "OffsetStartMs": 11320, "OffsetEndMs": 11640}, {"Word": "another", "OffsetStartMs": 11640, "OffsetEndMs": 11940}, {"Word": "person's", "OffsetStartMs": 11940, "OffsetEndMs": 12465}, {"Word": "voice", "OffsetStartMs": 12465, "OffsetEndMs": 12740}, {"Word": "in", "OffsetStartMs": 13090, "OffsetEndMs": 13410}, {"Word": "another", "OffsetStartMs": 13410, "OffsetEndMs": 13680}, {"Word": "domain", "OffsetStartMs": 13680, "OffsetEndMs": 14030}, {"Word": "right", "OffsetStartMs": 14320, "OffsetEndMs": 14700}, {"Word": "These", "OffsetStartMs": 14700, "OffsetEndMs": 14940}, {"Word": "are", "OffsetStartMs": 14940, "OffsetEndMs": 15135}, {"Word": "two", "OffsetStartMs": 15135, "OffsetEndMs": 15470}, {"Word": "independent", "OffsetStartMs": 15580, "OffsetEndMs": 15980}, {"Word": "data", "OffsetStartMs": 16180, "OffsetEndMs": 16580}, {"Word": "distributions", "OffsetStartMs": 16660, "OffsetEndMs": 17150}, {"Word": "that", "OffsetStartMs": 17170, "OffsetEndMs": 17445}, {"Word": "we", "OffsetStartMs": 17445, "OffsetEndMs": 17670}, {"Word": "define", "OffsetStartMs": 17670, "OffsetEndMs": 18020}], "SpeechSpeed": 12.8}, {"FinalSentence": "Maybe you're getting a sense of where I'm hinting at. Maybe not, but in fact, this was exactly how we developed the model to synthesize the audio behind Obama's voice that we saw in yesterday's introductory lecture. What we did was we trained a cycle g to take data in Alexander's voice and transform it into data in the manifold of Obama's voice.", "SliceSentence": "Maybe you're getting a sense of where I'm hinting at . Maybenot but in fact this was exactly how we developed the model to synthesize the audio behind Obama's voice that we saw in yesterday's introductory lecture . Whatwe did was we trained a cycle g to take data in Alexander's voice and transform it into data in the manifold of Obama's voice", "StartMs": 3309540, "EndMs": 3336920, "WordsNum": 63, "Words": [{"Word": "Maybe", "OffsetStartMs": 160, "OffsetEndMs": 495}, {"Word": "you're", "OffsetStartMs": 495, "OffsetEndMs": 765}, {"Word": "getting", "OffsetStartMs": 765, "OffsetEndMs": 945}, {"Word": "a", "OffsetStartMs": 945, "OffsetEndMs": 1185}, {"Word": "sense", "OffsetStartMs": 1185, "OffsetEndMs": 1395}, {"Word": "of", "OffsetStartMs": 1395, "OffsetEndMs": 1560}, {"Word": "where", "OffsetStartMs": 1560, "OffsetEndMs": 1680}, {"Word": "I'm", "OffsetStartMs": 1680, "OffsetEndMs": 1890}, {"Word": "hinting", "OffsetStartMs": 1890, "OffsetEndMs": 2190}, {"Word": "at", "OffsetStartMs": 2190, "OffsetEndMs": 2385}, {"Word": ".", "OffsetStartMs": 2385, "OffsetEndMs": 2655}, {"Word": "Maybenot", "OffsetStartMs": 2655, "OffsetEndMs": 2990}, {"Word": "but", "OffsetStartMs": 3400, "OffsetEndMs": 3660}, {"Word": "in", "OffsetStartMs": 3660, "OffsetEndMs": 3840}, {"Word": "fact", "OffsetStartMs": 3840, "OffsetEndMs": 4125}, {"Word": "this", "OffsetStartMs": 4125, "OffsetEndMs": 4380}, {"Word": "was", "OffsetStartMs": 4380, "OffsetEndMs": 4670}, {"Word": "exactly", "OffsetStartMs": 4690, "OffsetEndMs": 5090}, {"Word": "how", "OffsetStartMs": 5260, "OffsetEndMs": 5660}, {"Word": "we", "OffsetStartMs": 6010, "OffsetEndMs": 6410}, {"Word": "developed", "OffsetStartMs": 6550, "OffsetEndMs": 6950}, {"Word": "the", "OffsetStartMs": 7060, "OffsetEndMs": 7335}, {"Word": "model", "OffsetStartMs": 7335, "OffsetEndMs": 7610}, {"Word": "to", "OffsetStartMs": 8110, "OffsetEndMs": 8510}, {"Word": "synthesize", "OffsetStartMs": 8650, "OffsetEndMs": 9360}, {"Word": "the", "OffsetStartMs": 9360, "OffsetEndMs": 9585}, {"Word": "audio", "OffsetStartMs": 9585, "OffsetEndMs": 9860}, {"Word": "behind", "OffsetStartMs": 10120, "OffsetEndMs": 10520}, {"Word": "Obama's", "OffsetStartMs": 10810, "OffsetEndMs": 11325}, {"Word": "voice", "OffsetStartMs": 11325, "OffsetEndMs": 11600}, {"Word": "that", "OffsetStartMs": 11890, "OffsetEndMs": 12180}, {"Word": "we", "OffsetStartMs": 12180, "OffsetEndMs": 12375}, {"Word": "saw", "OffsetStartMs": 12375, "OffsetEndMs": 12680}, {"Word": "in", "OffsetStartMs": 12850, "OffsetEndMs": 13140}, {"Word": "yesterday's", "OffsetStartMs": 13140, "OffsetEndMs": 13770}, {"Word": "introductory", "OffsetStartMs": 13770, "OffsetEndMs": 14430}, {"Word": "lecture", "OffsetStartMs": 14430, "OffsetEndMs": 14720}, {"Word": ".", "OffsetStartMs": 15670, "OffsetEndMs": 15945}, {"Word": "Whatwe", "OffsetStartMs": 15945, "OffsetEndMs": 16110}, {"Word": "did", "OffsetStartMs": 16110, "OffsetEndMs": 16335}, {"Word": "was", "OffsetStartMs": 16335, "OffsetEndMs": 16590}, {"Word": "we", "OffsetStartMs": 16590, "OffsetEndMs": 16845}, {"Word": "trained", "OffsetStartMs": 16845, "OffsetEndMs": 17160}, {"Word": "a", "OffsetStartMs": 17160, "OffsetEndMs": 17505}, {"Word": "cycle", "OffsetStartMs": 17505, "OffsetEndMs": 17865}, {"Word": "g", "OffsetStartMs": 17865, "OffsetEndMs": 18260}, {"Word": "to", "OffsetStartMs": 18670, "OffsetEndMs": 19070}, {"Word": "take", "OffsetStartMs": 19090, "OffsetEndMs": 19485}, {"Word": "data", "OffsetStartMs": 19485, "OffsetEndMs": 19880}, {"Word": "in", "OffsetStartMs": 20110, "OffsetEndMs": 20510}, {"Word": "Alexander's", "OffsetStartMs": 20530, "OffsetEndMs": 21090}, {"Word": "voice", "OffsetStartMs": 21090, "OffsetEndMs": 21350}, {"Word": "and", "OffsetStartMs": 21940, "OffsetEndMs": 22340}, {"Word": "transform", "OffsetStartMs": 22690, "OffsetEndMs": 23010}, {"Word": "it", "OffsetStartMs": 23010, "OffsetEndMs": 23330}, {"Word": "into", "OffsetStartMs": 23680, "OffsetEndMs": 24045}, {"Word": "data", "OffsetStartMs": 24045, "OffsetEndMs": 24410}, {"Word": "in", "OffsetStartMs": 24550, "OffsetEndMs": 24810}, {"Word": "the", "OffsetStartMs": 24810, "OffsetEndMs": 24945}, {"Word": "manifold", "OffsetStartMs": 24945, "OffsetEndMs": 25530}, {"Word": "of", "OffsetStartMs": 25530, "OffsetEndMs": 25880}, {"Word": "Obama's", "OffsetStartMs": 26020, "OffsetEndMs": 26580}, {"Word": "voice", "OffsetStartMs": 26580, "OffsetEndMs": 26840}], "SpeechSpeed": 12.5}, {"FinalSentence": "So we can visualize how that spectrogram waveform looks like for Alexander's voice versus Obama's voice that was completely synthesized using this cycle approach.", "SliceSentence": "So we can visualize how that spectrogram waveform looks like for Alexander's voice versus Obama's voice that was completely synthesized using this cycle approach", "StartMs": 3337360, "EndMs": 3354620, "WordsNum": 24, "Words": [{"Word": "So", "OffsetStartMs": 160, "OffsetEndMs": 525}, {"Word": "we", "OffsetStartMs": 525, "OffsetEndMs": 765}, {"Word": "can", "OffsetStartMs": 765, "OffsetEndMs": 930}, {"Word": "visualize", "OffsetStartMs": 930, "OffsetEndMs": 1530}, {"Word": "how", "OffsetStartMs": 1530, "OffsetEndMs": 1830}, {"Word": "that", "OffsetStartMs": 1830, "OffsetEndMs": 2085}, {"Word": "spectrogram", "OffsetStartMs": 2085, "OffsetEndMs": 2730}, {"Word": "waveform", "OffsetStartMs": 2730, "OffsetEndMs": 3380}, {"Word": "looks", "OffsetStartMs": 3730, "OffsetEndMs": 4050}, {"Word": "like", "OffsetStartMs": 4050, "OffsetEndMs": 4290}, {"Word": "for", "OffsetStartMs": 4290, "OffsetEndMs": 4610}, {"Word": "Alexander's", "OffsetStartMs": 4630, "OffsetEndMs": 5175}, {"Word": "voice", "OffsetStartMs": 5175, "OffsetEndMs": 5420}, {"Word": "versus", "OffsetStartMs": 5560, "OffsetEndMs": 5960}, {"Word": "Obama's", "OffsetStartMs": 6190, "OffsetEndMs": 6720}, {"Word": "voice", "OffsetStartMs": 6720, "OffsetEndMs": 6980}, {"Word": "that", "OffsetStartMs": 7090, "OffsetEndMs": 7350}, {"Word": "was", "OffsetStartMs": 7350, "OffsetEndMs": 7610}, {"Word": "completely", "OffsetStartMs": 7630, "OffsetEndMs": 8010}, {"Word": "synthesized", "OffsetStartMs": 8010, "OffsetEndMs": 8750}, {"Word": "using", "OffsetStartMs": 8950, "OffsetEndMs": 9345}, {"Word": "this", "OffsetStartMs": 9345, "OffsetEndMs": 9740}, {"Word": "cycle", "OffsetStartMs": 9880, "OffsetEndMs": 10280}, {"Word": "approach", "OffsetStartMs": 10900, "OffsetEndMs": 11300}], "SpeechSpeed": 9.3}, {"FinalSentence": "The.", "SliceSentence": "The", "StartMs": 3355360, "EndMs": 3356680, "WordsNum": 1, "Words": [{"Word": "The", "OffsetStartMs": 970, "OffsetEndMs": 1290}], "SpeechSpeed": 2.3}, {"FinalSentence": "Here at MIT.", "SliceSentence": "Here at MIT", "StartMs": 3359120, "EndMs": 3362500, "WordsNum": 3, "Words": [{"Word": "Here", "OffsetStartMs": 10, "OffsetEndMs": 410}, {"Word": "at", "OffsetStartMs": 760, "OffsetEndMs": 1160}, {"Word": "MIT", "OffsetStartMs": 1240, "OffsetEndMs": 1640}], "SpeechSpeed": 3.3}, {"FinalSentence": "I replayed it, okay, but basically what we did was Alexander spoke that exact phrase that was played yesterday, and we had the train cycle again, model, and we can deploy it then on that exact audio to transform it from the domain of Alexander's voice to Obama s voice.", "SliceSentence": "I replayed it okay but basically what we did was Alexander spoke that exact phrase that was played yesterday and we had the train cycle again model and we can deploy it then on that exact audio to transform it from the domain of Alexander's voice to Obama s voice", "StartMs": 3363160, "EndMs": 3384600, "WordsNum": 50, "Words": [{"Word": "I", "OffsetStartMs": 100, "OffsetEndMs": 500}, {"Word": "replayed", "OffsetStartMs": 1780, "OffsetEndMs": 2265}, {"Word": "it", "OffsetStartMs": 2265, "OffsetEndMs": 2510}, {"Word": "okay", "OffsetStartMs": 2650, "OffsetEndMs": 3050}, {"Word": "but", "OffsetStartMs": 3280, "OffsetEndMs": 3680}, {"Word": "basically", "OffsetStartMs": 3700, "OffsetEndMs": 4100}, {"Word": "what", "OffsetStartMs": 4180, "OffsetEndMs": 4455}, {"Word": "we", "OffsetStartMs": 4455, "OffsetEndMs": 4620}, {"Word": "did", "OffsetStartMs": 4620, "OffsetEndMs": 4860}, {"Word": "was", "OffsetStartMs": 4860, "OffsetEndMs": 5210}, {"Word": "Alexander", "OffsetStartMs": 5380, "OffsetEndMs": 5780}, {"Word": "spoke", "OffsetStartMs": 5860, "OffsetEndMs": 6165}, {"Word": "that", "OffsetStartMs": 6165, "OffsetEndMs": 6470}, {"Word": "exact", "OffsetStartMs": 6490, "OffsetEndMs": 6890}, {"Word": "phrase", "OffsetStartMs": 7390, "OffsetEndMs": 7790}, {"Word": "that", "OffsetStartMs": 7870, "OffsetEndMs": 8205}, {"Word": "was", "OffsetStartMs": 8205, "OffsetEndMs": 8490}, {"Word": "played", "OffsetStartMs": 8490, "OffsetEndMs": 8840}, {"Word": "yesterday", "OffsetStartMs": 9040, "OffsetEndMs": 9440}, {"Word": "and", "OffsetStartMs": 10270, "OffsetEndMs": 10575}, {"Word": "we", "OffsetStartMs": 10575, "OffsetEndMs": 10785}, {"Word": "had", "OffsetStartMs": 10785, "OffsetEndMs": 10995}, {"Word": "the", "OffsetStartMs": 10995, "OffsetEndMs": 11190}, {"Word": "train", "OffsetStartMs": 11190, "OffsetEndMs": 11415}, {"Word": "cycle", "OffsetStartMs": 11415, "OffsetEndMs": 11715}, {"Word": "again", "OffsetStartMs": 11715, "OffsetEndMs": 12000}, {"Word": "model", "OffsetStartMs": 12000, "OffsetEndMs": 12320}, {"Word": "and", "OffsetStartMs": 12790, "OffsetEndMs": 13080}, {"Word": "we", "OffsetStartMs": 13080, "OffsetEndMs": 13215}, {"Word": "can", "OffsetStartMs": 13215, "OffsetEndMs": 13440}, {"Word": "deploy", "OffsetStartMs": 13440, "OffsetEndMs": 13695}, {"Word": "it", "OffsetStartMs": 13695, "OffsetEndMs": 13845}, {"Word": "then", "OffsetStartMs": 13845, "OffsetEndMs": 14040}, {"Word": "on", "OffsetStartMs": 14040, "OffsetEndMs": 14295}, {"Word": "that", "OffsetStartMs": 14295, "OffsetEndMs": 14595}, {"Word": "exact", "OffsetStartMs": 14595, "OffsetEndMs": 14910}, {"Word": "audio", "OffsetStartMs": 14910, "OffsetEndMs": 15260}, {"Word": "to", "OffsetStartMs": 15670, "OffsetEndMs": 16070}, {"Word": "transform", "OffsetStartMs": 16180, "OffsetEndMs": 16500}, {"Word": "it", "OffsetStartMs": 16500, "OffsetEndMs": 16820}, {"Word": "from", "OffsetStartMs": 17080, "OffsetEndMs": 17480}, {"Word": "the", "OffsetStartMs": 17560, "OffsetEndMs": 17850}, {"Word": "domain", "OffsetStartMs": 17850, "OffsetEndMs": 18140}, {"Word": "of", "OffsetStartMs": 18190, "OffsetEndMs": 18590}, {"Word": "Alexander's", "OffsetStartMs": 18640, "OffsetEndMs": 19155}, {"Word": "voice", "OffsetStartMs": 19155, "OffsetEndMs": 19400}, {"Word": "to", "OffsetStartMs": 19540, "OffsetEndMs": 19940}, {"Word": "Obama", "OffsetStartMs": 20050, "OffsetEndMs": 20355}, {"Word": "s", "OffsetStartMs": 20355, "OffsetEndMs": 20535}, {"Word": "voice", "OffsetStartMs": 20535, "OffsetEndMs": 20810}], "SpeechSpeed": 12.3}, {"FinalSentence": "Generating the synthetic audio that was played for that video clip.", "SliceSentence": "Generating the synthetic audio that was played for that video clip", "StartMs": 3384600, "EndMs": 3389400, "WordsNum": 11, "Words": [{"Word": "Generating", "OffsetStartMs": 0, "OffsetEndMs": 510}, {"Word": "the", "OffsetStartMs": 510, "OffsetEndMs": 890}, {"Word": "synthetic", "OffsetStartMs": 1120, "OffsetEndMs": 1650}, {"Word": "audio", "OffsetStartMs": 1650, "OffsetEndMs": 2000}, {"Word": "that", "OffsetStartMs": 2230, "OffsetEndMs": 2490}, {"Word": "was", "OffsetStartMs": 2490, "OffsetEndMs": 2670}, {"Word": "played", "OffsetStartMs": 2670, "OffsetEndMs": 2910}, {"Word": "for", "OffsetStartMs": 2910, "OffsetEndMs": 3090}, {"Word": "that", "OffsetStartMs": 3090, "OffsetEndMs": 3255}, {"Word": "video", "OffsetStartMs": 3255, "OffsetEndMs": 3540}, {"Word": "clip", "OffsetStartMs": 3540, "OffsetEndMs": 3950}], "SpeechSpeed": 13.8}, {"FinalSentence": "Okay, before I accidentally played again, I.", "SliceSentence": "Okay before I accidentally played again I", "StartMs": 3389400, "EndMs": 3396860, "WordsNum": 7, "Words": [{"Word": "Okay", "OffsetStartMs": 2860, "OffsetEndMs": 3240}, {"Word": "before", "OffsetStartMs": 3240, "OffsetEndMs": 3570}, {"Word": "I", "OffsetStartMs": 3570, "OffsetEndMs": 3920}, {"Word": "accidentally", "OffsetStartMs": 4060, "OffsetEndMs": 4850}, {"Word": "played", "OffsetStartMs": 5560, "OffsetEndMs": 5925}, {"Word": "again", "OffsetStartMs": 5925, "OffsetEndMs": 6240}, {"Word": "I", "OffsetStartMs": 6240, "OffsetEndMs": 6590}], "SpeechSpeed": 5.5}, {"FinalSentence": "Jump now to the summary slide. So today in this lecture we've learned deep generative models specifically talking mostly about latent variable models, auto encoders, variational auto encoders where our goal is to learn this low dimensional latent encoding of the data, as well as generative adversarial networks where we have these competing generator and discriminator components that are trying to synthesize synthetic examples.", "SliceSentence": "Jump now to the summary slide . Sotoday in this lecture we've learned deep generative models specifically talking mostly about latent variable models auto encoders variational auto encoders where our goal is to learn this low dimensional latent encoding of the data as well as generative adversarial networks where we have these competing generator and discriminator components that are trying to synthesize synthetic examples", "StartMs": 3396860, "EndMs": 3426420, "WordsNum": 64, "Words": [{"Word": "Jump", "OffsetStartMs": 0, "OffsetEndMs": 225}, {"Word": "now", "OffsetStartMs": 225, "OffsetEndMs": 560}, {"Word": "to", "OffsetStartMs": 580, "OffsetEndMs": 885}, {"Word": "the", "OffsetStartMs": 885, "OffsetEndMs": 1050}, {"Word": "summary", "OffsetStartMs": 1050, "OffsetEndMs": 1310}, {"Word": "slide", "OffsetStartMs": 1330, "OffsetEndMs": 1730}, {"Word": ".", "OffsetStartMs": 2380, "OffsetEndMs": 2775}, {"Word": "Sotoday", "OffsetStartMs": 2775, "OffsetEndMs": 3135}, {"Word": "in", "OffsetStartMs": 3135, "OffsetEndMs": 3360}, {"Word": "this", "OffsetStartMs": 3360, "OffsetEndMs": 3510}, {"Word": "lecture", "OffsetStartMs": 3510, "OffsetEndMs": 3800}, {"Word": "we've", "OffsetStartMs": 3820, "OffsetEndMs": 4185}, {"Word": "learned", "OffsetStartMs": 4185, "OffsetEndMs": 4430}, {"Word": "deep", "OffsetStartMs": 4960, "OffsetEndMs": 5265}, {"Word": "generative", "OffsetStartMs": 5265, "OffsetEndMs": 5700}, {"Word": "models", "OffsetStartMs": 5700, "OffsetEndMs": 5960}, {"Word": "specifically", "OffsetStartMs": 6040, "OffsetEndMs": 6440}, {"Word": "talking", "OffsetStartMs": 7030, "OffsetEndMs": 7410}, {"Word": "mostly", "OffsetStartMs": 7410, "OffsetEndMs": 7785}, {"Word": "about", "OffsetStartMs": 7785, "OffsetEndMs": 8100}, {"Word": "latent", "OffsetStartMs": 8100, "OffsetEndMs": 8490}, {"Word": "variable", "OffsetStartMs": 8490, "OffsetEndMs": 8780}, {"Word": "models", "OffsetStartMs": 8980, "OffsetEndMs": 9380}, {"Word": "auto", "OffsetStartMs": 10090, "OffsetEndMs": 10425}, {"Word": "encoders", "OffsetStartMs": 10425, "OffsetEndMs": 11090}, {"Word": "variational", "OffsetStartMs": 11110, "OffsetEndMs": 11690}, {"Word": "auto", "OffsetStartMs": 11710, "OffsetEndMs": 12045}, {"Word": "encoders", "OffsetStartMs": 12045, "OffsetEndMs": 12680}, {"Word": "where", "OffsetStartMs": 12820, "OffsetEndMs": 13080}, {"Word": "our", "OffsetStartMs": 13080, "OffsetEndMs": 13260}, {"Word": "goal", "OffsetStartMs": 13260, "OffsetEndMs": 13530}, {"Word": "is", "OffsetStartMs": 13530, "OffsetEndMs": 13800}, {"Word": "to", "OffsetStartMs": 13800, "OffsetEndMs": 13995}, {"Word": "learn", "OffsetStartMs": 13995, "OffsetEndMs": 14220}, {"Word": "this", "OffsetStartMs": 14220, "OffsetEndMs": 14550}, {"Word": "low", "OffsetStartMs": 14550, "OffsetEndMs": 14835}, {"Word": "dimensional", "OffsetStartMs": 14835, "OffsetEndMs": 15560}, {"Word": "latent", "OffsetStartMs": 15640, "OffsetEndMs": 16140}, {"Word": "encoding", "OffsetStartMs": 16140, "OffsetEndMs": 16650}, {"Word": "of", "OffsetStartMs": 16650, "OffsetEndMs": 16770}, {"Word": "the", "OffsetStartMs": 16770, "OffsetEndMs": 16905}, {"Word": "data", "OffsetStartMs": 16905, "OffsetEndMs": 17180}, {"Word": "as", "OffsetStartMs": 17920, "OffsetEndMs": 18240}, {"Word": "well", "OffsetStartMs": 18240, "OffsetEndMs": 18495}, {"Word": "as", "OffsetStartMs": 18495, "OffsetEndMs": 18830}, {"Word": "generative", "OffsetStartMs": 19210, "OffsetEndMs": 19800}, {"Word": "adversarial", "OffsetStartMs": 19800, "OffsetEndMs": 20445}, {"Word": "networks", "OffsetStartMs": 20445, "OffsetEndMs": 20720}, {"Word": "where", "OffsetStartMs": 21070, "OffsetEndMs": 21345}, {"Word": "we", "OffsetStartMs": 21345, "OffsetEndMs": 21510}, {"Word": "have", "OffsetStartMs": 21510, "OffsetEndMs": 21720}, {"Word": "these", "OffsetStartMs": 21720, "OffsetEndMs": 22040}, {"Word": "competing", "OffsetStartMs": 22060, "OffsetEndMs": 22610}, {"Word": "generator", "OffsetStartMs": 22750, "OffsetEndMs": 23355}, {"Word": "and", "OffsetStartMs": 23355, "OffsetEndMs": 23690}, {"Word": "discriminator", "OffsetStartMs": 23860, "OffsetEndMs": 24650}, {"Word": "components", "OffsetStartMs": 24700, "OffsetEndMs": 25100}, {"Word": "that", "OffsetStartMs": 25510, "OffsetEndMs": 25770}, {"Word": "are", "OffsetStartMs": 25770, "OffsetEndMs": 25950}, {"Word": "trying", "OffsetStartMs": 25950, "OffsetEndMs": 26205}, {"Word": "to", "OffsetStartMs": 26205, "OffsetEndMs": 26430}, {"Word": "synthesize", "OffsetStartMs": 26430, "OffsetEndMs": 27020}, {"Word": "synthetic", "OffsetStartMs": 27760, "OffsetEndMs": 28310}, {"Word": "examples", "OffsetStartMs": 28510, "OffsetEndMs": 28910}], "SpeechSpeed": 14.4}, {"FinalSentence": "We've talked about these core foundational generative methods, but it turns out, as I alluded to in the beginning of the lecture, that in this past year in particular, we've seen truly, truly tremendous advances in generative modeling, many of which have not been from those two methods, those two foundational methods that we described.", "SliceSentence": "We've talked about these core foundational generative methods but it turns out as I alluded to in the beginning of the lecture that in this past year in particular we've seen truly truly tremendous advances in generative modeling many of which have not been from those two methods those two foundational methods that we described", "StartMs": 3427440, "EndMs": 3450400, "WordsNum": 55, "Words": [{"Word": "We've", "OffsetStartMs": 70, "OffsetEndMs": 435}, {"Word": "talked", "OffsetStartMs": 435, "OffsetEndMs": 675}, {"Word": "about", "OffsetStartMs": 675, "OffsetEndMs": 945}, {"Word": "these", "OffsetStartMs": 945, "OffsetEndMs": 1215}, {"Word": "core", "OffsetStartMs": 1215, "OffsetEndMs": 1580}, {"Word": "foundational", "OffsetStartMs": 1690, "OffsetEndMs": 2300}, {"Word": "generative", "OffsetStartMs": 2350, "OffsetEndMs": 2910}, {"Word": "methods", "OffsetStartMs": 2910, "OffsetEndMs": 3200}, {"Word": "but", "OffsetStartMs": 4060, "OffsetEndMs": 4460}, {"Word": "it", "OffsetStartMs": 4630, "OffsetEndMs": 4935}, {"Word": "turns", "OffsetStartMs": 4935, "OffsetEndMs": 5145}, {"Word": "out", "OffsetStartMs": 5145, "OffsetEndMs": 5415}, {"Word": "as", "OffsetStartMs": 5415, "OffsetEndMs": 5655}, {"Word": "I", "OffsetStartMs": 5655, "OffsetEndMs": 5790}, {"Word": "alluded", "OffsetStartMs": 5790, "OffsetEndMs": 6255}, {"Word": "to", "OffsetStartMs": 6255, "OffsetEndMs": 6560}, {"Word": "in", "OffsetStartMs": 6760, "OffsetEndMs": 7050}, {"Word": "the", "OffsetStartMs": 7050, "OffsetEndMs": 7245}, {"Word": "beginning", "OffsetStartMs": 7245, "OffsetEndMs": 7455}, {"Word": "of", "OffsetStartMs": 7455, "OffsetEndMs": 7620}, {"Word": "the", "OffsetStartMs": 7620, "OffsetEndMs": 7740}, {"Word": "lecture", "OffsetStartMs": 7740, "OffsetEndMs": 8000}, {"Word": "that", "OffsetStartMs": 8830, "OffsetEndMs": 9230}, {"Word": "in", "OffsetStartMs": 9310, "OffsetEndMs": 9600}, {"Word": "this", "OffsetStartMs": 9600, "OffsetEndMs": 9825}, {"Word": "past", "OffsetStartMs": 9825, "OffsetEndMs": 10140}, {"Word": "year", "OffsetStartMs": 10140, "OffsetEndMs": 10410}, {"Word": "in", "OffsetStartMs": 10410, "OffsetEndMs": 10665}, {"Word": "particular", "OffsetStartMs": 10665, "OffsetEndMs": 11030}, {"Word": "we've", "OffsetStartMs": 11260, "OffsetEndMs": 11685}, {"Word": "seen", "OffsetStartMs": 11685, "OffsetEndMs": 11990}, {"Word": "truly", "OffsetStartMs": 12220, "OffsetEndMs": 12620}, {"Word": "truly", "OffsetStartMs": 12670, "OffsetEndMs": 13035}, {"Word": "tremendous", "OffsetStartMs": 13035, "OffsetEndMs": 13400}, {"Word": "advances", "OffsetStartMs": 13660, "OffsetEndMs": 14235}, {"Word": "in", "OffsetStartMs": 14235, "OffsetEndMs": 14430}, {"Word": "generative", "OffsetStartMs": 14430, "OffsetEndMs": 14835}, {"Word": "modeling", "OffsetStartMs": 14835, "OffsetEndMs": 15380}, {"Word": "many", "OffsetStartMs": 15940, "OffsetEndMs": 16275}, {"Word": "of", "OffsetStartMs": 16275, "OffsetEndMs": 16500}, {"Word": "which", "OffsetStartMs": 16500, "OffsetEndMs": 16790}, {"Word": "have", "OffsetStartMs": 17080, "OffsetEndMs": 17415}, {"Word": "not", "OffsetStartMs": 17415, "OffsetEndMs": 17745}, {"Word": "been", "OffsetStartMs": 17745, "OffsetEndMs": 18135}, {"Word": "from", "OffsetStartMs": 18135, "OffsetEndMs": 18530}, {"Word": "those", "OffsetStartMs": 18640, "OffsetEndMs": 19005}, {"Word": "two", "OffsetStartMs": 19005, "OffsetEndMs": 19260}, {"Word": "methods", "OffsetStartMs": 19260, "OffsetEndMs": 19550}, {"Word": "those", "OffsetStartMs": 19960, "OffsetEndMs": 20280}, {"Word": "two", "OffsetStartMs": 20280, "OffsetEndMs": 20490}, {"Word": "foundational", "OffsetStartMs": 20490, "OffsetEndMs": 21015}, {"Word": "methods", "OffsetStartMs": 21015, "OffsetEndMs": 21405}, {"Word": "that", "OffsetStartMs": 21405, "OffsetEndMs": 21675}, {"Word": "we", "OffsetStartMs": 21675, "OffsetEndMs": 21945}, {"Word": "described", "OffsetStartMs": 21945, "OffsetEndMs": 22340}], "SpeechSpeed": 14.3}, {"FinalSentence": "But rather a new approach called diffusion modeling.", "SliceSentence": "But rather a new approach called diffusion modeling", "StartMs": 3450400, "EndMs": 3454480, "WordsNum": 8, "Words": [{"Word": "But", "OffsetStartMs": 100, "OffsetEndMs": 390}, {"Word": "rather", "OffsetStartMs": 390, "OffsetEndMs": 645}, {"Word": "a", "OffsetStartMs": 645, "OffsetEndMs": 915}, {"Word": "new", "OffsetStartMs": 915, "OffsetEndMs": 1220}, {"Word": "approach", "OffsetStartMs": 1270, "OffsetEndMs": 1670}, {"Word": "called", "OffsetStartMs": 1810, "OffsetEndMs": 2210}, {"Word": "diffusion", "OffsetStartMs": 2260, "OffsetEndMs": 2775}, {"Word": "modeling", "OffsetStartMs": 2775, "OffsetEndMs": 3380}], "SpeechSpeed": 12.5}, {"FinalSentence": "Diffusion models are driving are the driving tools behind the tremendous advances in generative AI that we've seen in this past year in particular.", "SliceSentence": "Diffusion models are driving are the driving tools behind the tremendous advances in generative AI that we've seen in this past year in particular", "StartMs": 3454480, "EndMs": 3465780, "WordsNum": 24, "Words": [{"Word": "Diffusion", "OffsetStartMs": 220, "OffsetEndMs": 765}, {"Word": "models", "OffsetStartMs": 765, "OffsetEndMs": 1130}, {"Word": "are", "OffsetStartMs": 1210, "OffsetEndMs": 1575}, {"Word": "driving", "OffsetStartMs": 1575, "OffsetEndMs": 1940}, {"Word": "are", "OffsetStartMs": 2740, "OffsetEndMs": 3015}, {"Word": "the", "OffsetStartMs": 3015, "OffsetEndMs": 3180}, {"Word": "driving", "OffsetStartMs": 3180, "OffsetEndMs": 3470}, {"Word": "tools", "OffsetStartMs": 3580, "OffsetEndMs": 3980}, {"Word": "behind", "OffsetStartMs": 4090, "OffsetEndMs": 4490}, {"Word": "the", "OffsetStartMs": 4780, "OffsetEndMs": 5180}, {"Word": "tremendous", "OffsetStartMs": 5200, "OffsetEndMs": 5600}, {"Word": "advances", "OffsetStartMs": 5920, "OffsetEndMs": 6620}, {"Word": "in", "OffsetStartMs": 6670, "OffsetEndMs": 6975}, {"Word": "generative", "OffsetStartMs": 6975, "OffsetEndMs": 7515}, {"Word": "AI", "OffsetStartMs": 7515, "OffsetEndMs": 7880}, {"Word": "that", "OffsetStartMs": 8020, "OffsetEndMs": 8295}, {"Word": "we've", "OffsetStartMs": 8295, "OffsetEndMs": 8535}, {"Word": "seen", "OffsetStartMs": 8535, "OffsetEndMs": 8700}, {"Word": "in", "OffsetStartMs": 8700, "OffsetEndMs": 8865}, {"Word": "this", "OffsetStartMs": 8865, "OffsetEndMs": 9045}, {"Word": "past", "OffsetStartMs": 9045, "OffsetEndMs": 9315}, {"Word": "year", "OffsetStartMs": 9315, "OffsetEndMs": 9675}, {"Word": "in", "OffsetStartMs": 9675, "OffsetEndMs": 10020}, {"Word": "particular", "OffsetStartMs": 10020, "OffsetEndMs": 10370}], "SpeechSpeed": 12.9}, {"FinalSentence": "These gans, they're learning these transformations, these encodings, but they're largely restricted to generating examples that fall similar to the data space that they've seen before.", "SliceSentence": "These gans they're learning these transformations these encodings but they're largely restricted to generating examples that fall similar to the data space that they've seen before", "StartMs": 3466000, "EndMs": 3480660, "WordsNum": 26, "Words": [{"Word": "These", "OffsetStartMs": 130, "OffsetEndMs": 530}, {"Word": "gans", "OffsetStartMs": 1090, "OffsetEndMs": 1520}, {"Word": "they're", "OffsetStartMs": 1930, "OffsetEndMs": 2280}, {"Word": "learning", "OffsetStartMs": 2280, "OffsetEndMs": 2520}, {"Word": "these", "OffsetStartMs": 2520, "OffsetEndMs": 2820}, {"Word": "transformations", "OffsetStartMs": 2820, "OffsetEndMs": 3500}, {"Word": "these", "OffsetStartMs": 3520, "OffsetEndMs": 3795}, {"Word": "encodings", "OffsetStartMs": 3795, "OffsetEndMs": 4460}, {"Word": "but", "OffsetStartMs": 4750, "OffsetEndMs": 5025}, {"Word": "they're", "OffsetStartMs": 5025, "OffsetEndMs": 5265}, {"Word": "largely", "OffsetStartMs": 5265, "OffsetEndMs": 5540}, {"Word": "restricted", "OffsetStartMs": 6100, "OffsetEndMs": 6740}, {"Word": "to", "OffsetStartMs": 6790, "OffsetEndMs": 7190}, {"Word": "generating", "OffsetStartMs": 8080, "OffsetEndMs": 8720}, {"Word": "examples", "OffsetStartMs": 8830, "OffsetEndMs": 9230}, {"Word": "that", "OffsetStartMs": 9460, "OffsetEndMs": 9840}, {"Word": "fall", "OffsetStartMs": 9840, "OffsetEndMs": 10220}, {"Word": "similar", "OffsetStartMs": 10390, "OffsetEndMs": 10790}, {"Word": "to", "OffsetStartMs": 11020, "OffsetEndMs": 11420}, {"Word": "the", "OffsetStartMs": 11440, "OffsetEndMs": 11840}, {"Word": "data", "OffsetStartMs": 12040, "OffsetEndMs": 12435}, {"Word": "space", "OffsetStartMs": 12435, "OffsetEndMs": 12825}, {"Word": "that", "OffsetStartMs": 12825, "OffsetEndMs": 13095}, {"Word": "they've", "OffsetStartMs": 13095, "OffsetEndMs": 13320}, {"Word": "seen", "OffsetStartMs": 13320, "OffsetEndMs": 13485}, {"Word": "before", "OffsetStartMs": 13485, "OffsetEndMs": 13790}], "SpeechSpeed": 12.3}, {"FinalSentence": "Diffusion models have this ability to now hallucinate and envision and imagine completely new objects and instances, which we as humans may not have seen or even thought about parts of the design space that are not covered by the training data.", "SliceSentence": "Diffusion models have this ability to now hallucinate and envision and imagine completely new objects and instances which we as humans may not have seen or even thought about parts of the design space that are not covered by the training data", "StartMs": 3481200, "EndMs": 3498900, "WordsNum": 42, "Words": [{"Word": "Diffusion", "OffsetStartMs": 70, "OffsetEndMs": 630}, {"Word": "models", "OffsetStartMs": 630, "OffsetEndMs": 1010}, {"Word": "have", "OffsetStartMs": 1270, "OffsetEndMs": 1575}, {"Word": "this", "OffsetStartMs": 1575, "OffsetEndMs": 1800}, {"Word": "ability", "OffsetStartMs": 1800, "OffsetEndMs": 2120}, {"Word": "to", "OffsetStartMs": 2140, "OffsetEndMs": 2415}, {"Word": "now", "OffsetStartMs": 2415, "OffsetEndMs": 2690}, {"Word": "hallucinate", "OffsetStartMs": 2890, "OffsetEndMs": 3645}, {"Word": "and", "OffsetStartMs": 3645, "OffsetEndMs": 3855}, {"Word": "envision", "OffsetStartMs": 3855, "OffsetEndMs": 4290}, {"Word": "and", "OffsetStartMs": 4290, "OffsetEndMs": 4575}, {"Word": "imagine", "OffsetStartMs": 4575, "OffsetEndMs": 4910}, {"Word": "completely", "OffsetStartMs": 5620, "OffsetEndMs": 6020}, {"Word": "new", "OffsetStartMs": 6070, "OffsetEndMs": 6470}, {"Word": "objects", "OffsetStartMs": 6700, "OffsetEndMs": 7035}, {"Word": "and", "OffsetStartMs": 7035, "OffsetEndMs": 7260}, {"Word": "instances", "OffsetStartMs": 7260, "OffsetEndMs": 8000}, {"Word": "which", "OffsetStartMs": 8140, "OffsetEndMs": 8520}, {"Word": "we", "OffsetStartMs": 8520, "OffsetEndMs": 8850}, {"Word": "as", "OffsetStartMs": 8850, "OffsetEndMs": 9120}, {"Word": "humans", "OffsetStartMs": 9120, "OffsetEndMs": 9440}, {"Word": "may", "OffsetStartMs": 9790, "OffsetEndMs": 10095}, {"Word": "not", "OffsetStartMs": 10095, "OffsetEndMs": 10290}, {"Word": "have", "OffsetStartMs": 10290, "OffsetEndMs": 10500}, {"Word": "seen", "OffsetStartMs": 10500, "OffsetEndMs": 10820}, {"Word": "or", "OffsetStartMs": 11050, "OffsetEndMs": 11340}, {"Word": "even", "OffsetStartMs": 11340, "OffsetEndMs": 11580}, {"Word": "thought", "OffsetStartMs": 11580, "OffsetEndMs": 11850}, {"Word": "about", "OffsetStartMs": 11850, "OffsetEndMs": 12170}, {"Word": "parts", "OffsetStartMs": 12850, "OffsetEndMs": 13170}, {"Word": "of", "OffsetStartMs": 13170, "OffsetEndMs": 13350}, {"Word": "the", "OffsetStartMs": 13350, "OffsetEndMs": 13545}, {"Word": "design", "OffsetStartMs": 13545, "OffsetEndMs": 13880}, {"Word": "space", "OffsetStartMs": 13900, "OffsetEndMs": 14300}, {"Word": "that", "OffsetStartMs": 14530, "OffsetEndMs": 14820}, {"Word": "are", "OffsetStartMs": 14820, "OffsetEndMs": 15030}, {"Word": "not", "OffsetStartMs": 15030, "OffsetEndMs": 15350}, {"Word": "covered", "OffsetStartMs": 15520, "OffsetEndMs": 15920}, {"Word": "by", "OffsetStartMs": 15940, "OffsetEndMs": 16245}, {"Word": "the", "OffsetStartMs": 16245, "OffsetEndMs": 16440}, {"Word": "training", "OffsetStartMs": 16440, "OffsetEndMs": 16695}, {"Word": "data", "OffsetStartMs": 16695, "OffsetEndMs": 17060}], "SpeechSpeed": 13.7}, {"FinalSentence": "So an example here is this AI generated art, which art, if you will, which was created by a diffusion model, and I think not only does this get at.", "SliceSentence": "So an example here is this AI generated art which art if you will which was created by a diffusion model and I think not only does this get at", "StartMs": 3498900, "EndMs": 3511240, "WordsNum": 30, "Words": [{"Word": "So", "OffsetStartMs": 40, "OffsetEndMs": 435}, {"Word": "an", "OffsetStartMs": 435, "OffsetEndMs": 765}, {"Word": "example", "OffsetStartMs": 765, "OffsetEndMs": 1100}, {"Word": "here", "OffsetStartMs": 1120, "OffsetEndMs": 1410}, {"Word": "is", "OffsetStartMs": 1410, "OffsetEndMs": 1590}, {"Word": "this", "OffsetStartMs": 1590, "OffsetEndMs": 1860}, {"Word": "AI", "OffsetStartMs": 1860, "OffsetEndMs": 2175}, {"Word": "generated", "OffsetStartMs": 2175, "OffsetEndMs": 2510}, {"Word": "art", "OffsetStartMs": 2620, "OffsetEndMs": 3020}, {"Word": "which", "OffsetStartMs": 3340, "OffsetEndMs": 3740}, {"Word": "art", "OffsetStartMs": 3910, "OffsetEndMs": 4245}, {"Word": "if", "OffsetStartMs": 4245, "OffsetEndMs": 4455}, {"Word": "you", "OffsetStartMs": 4455, "OffsetEndMs": 4590}, {"Word": "will", "OffsetStartMs": 4590, "OffsetEndMs": 4850}, {"Word": "which", "OffsetStartMs": 6100, "OffsetEndMs": 6375}, {"Word": "was", "OffsetStartMs": 6375, "OffsetEndMs": 6600}, {"Word": "created", "OffsetStartMs": 6600, "OffsetEndMs": 6930}, {"Word": "by", "OffsetStartMs": 6930, "OffsetEndMs": 7290}, {"Word": "a", "OffsetStartMs": 7290, "OffsetEndMs": 7545}, {"Word": "diffusion", "OffsetStartMs": 7545, "OffsetEndMs": 7890}, {"Word": "model", "OffsetStartMs": 7890, "OffsetEndMs": 8240}, {"Word": "and", "OffsetStartMs": 8800, "OffsetEndMs": 9045}, {"Word": "I", "OffsetStartMs": 9045, "OffsetEndMs": 9165}, {"Word": "think", "OffsetStartMs": 9165, "OffsetEndMs": 9440}, {"Word": "not", "OffsetStartMs": 9730, "OffsetEndMs": 10020}, {"Word": "only", "OffsetStartMs": 10020, "OffsetEndMs": 10275}, {"Word": "does", "OffsetStartMs": 10275, "OffsetEndMs": 10530}, {"Word": "this", "OffsetStartMs": 10530, "OffsetEndMs": 10820}, {"Word": "get", "OffsetStartMs": 10960, "OffsetEndMs": 11295}, {"Word": "at", "OffsetStartMs": 11295, "OffsetEndMs": 11630}], "SpeechSpeed": 11.5}, {"FinalSentence": "Some of the limits and capabilities of these powerful models, but also questions about what does it mean to create new instances? What are the limits and bounds of these models, and how do they, how can we think about their advances with respect to human capabilities and human intelligence?", "SliceSentence": "Some of the limits and capabilities of these powerful models but also questions about what does it mean to create new instances What are the limits and bounds of these models and how do they how can we think about their advances with respect to human capabilities and human intelligence", "StartMs": 3511240, "EndMs": 3531920, "WordsNum": 50, "Words": [{"Word": "Some", "OffsetStartMs": 0, "OffsetEndMs": 210}, {"Word": "of", "OffsetStartMs": 210, "OffsetEndMs": 345}, {"Word": "the", "OffsetStartMs": 345, "OffsetEndMs": 620}, {"Word": "limits", "OffsetStartMs": 670, "OffsetEndMs": 1070}, {"Word": "and", "OffsetStartMs": 1150, "OffsetEndMs": 1550}, {"Word": "capabilities", "OffsetStartMs": 1840, "OffsetEndMs": 2240}, {"Word": "of", "OffsetStartMs": 2560, "OffsetEndMs": 2835}, {"Word": "these", "OffsetStartMs": 2835, "OffsetEndMs": 3030}, {"Word": "powerful", "OffsetStartMs": 3030, "OffsetEndMs": 3350}, {"Word": "models", "OffsetStartMs": 3370, "OffsetEndMs": 3770}, {"Word": "but", "OffsetStartMs": 4150, "OffsetEndMs": 4545}, {"Word": "also", "OffsetStartMs": 4545, "OffsetEndMs": 4875}, {"Word": "questions", "OffsetStartMs": 4875, "OffsetEndMs": 5210}, {"Word": "about", "OffsetStartMs": 5380, "OffsetEndMs": 5780}, {"Word": "what", "OffsetStartMs": 6220, "OffsetEndMs": 6510}, {"Word": "does", "OffsetStartMs": 6510, "OffsetEndMs": 6660}, {"Word": "it", "OffsetStartMs": 6660, "OffsetEndMs": 6795}, {"Word": "mean", "OffsetStartMs": 6795, "OffsetEndMs": 7070}, {"Word": "to", "OffsetStartMs": 7150, "OffsetEndMs": 7550}, {"Word": "create", "OffsetStartMs": 7930, "OffsetEndMs": 8330}, {"Word": "new", "OffsetStartMs": 8710, "OffsetEndMs": 9075}, {"Word": "instances", "OffsetStartMs": 9075, "OffsetEndMs": 9860}, {"Word": "What", "OffsetStartMs": 10120, "OffsetEndMs": 10440}, {"Word": "are", "OffsetStartMs": 10440, "OffsetEndMs": 10635}, {"Word": "the", "OffsetStartMs": 10635, "OffsetEndMs": 10800}, {"Word": "limits", "OffsetStartMs": 10800, "OffsetEndMs": 11090}, {"Word": "and", "OffsetStartMs": 11470, "OffsetEndMs": 11760}, {"Word": "bounds", "OffsetStartMs": 11760, "OffsetEndMs": 12080}, {"Word": "of", "OffsetStartMs": 12130, "OffsetEndMs": 12390}, {"Word": "these", "OffsetStartMs": 12390, "OffsetEndMs": 12555}, {"Word": "models", "OffsetStartMs": 12555, "OffsetEndMs": 12860}, {"Word": "and", "OffsetStartMs": 13240, "OffsetEndMs": 13575}, {"Word": "how", "OffsetStartMs": 13575, "OffsetEndMs": 13845}, {"Word": "do", "OffsetStartMs": 13845, "OffsetEndMs": 14040}, {"Word": "they", "OffsetStartMs": 14040, "OffsetEndMs": 14300}, {"Word": "how", "OffsetStartMs": 14680, "OffsetEndMs": 14970}, {"Word": "can", "OffsetStartMs": 14970, "OffsetEndMs": 15105}, {"Word": "we", "OffsetStartMs": 15105, "OffsetEndMs": 15240}, {"Word": "think", "OffsetStartMs": 15240, "OffsetEndMs": 15450}, {"Word": "about", "OffsetStartMs": 15450, "OffsetEndMs": 15690}, {"Word": "their", "OffsetStartMs": 15690, "OffsetEndMs": 15960}, {"Word": "advances", "OffsetStartMs": 15960, "OffsetEndMs": 16515}, {"Word": "with", "OffsetStartMs": 16515, "OffsetEndMs": 16820}, {"Word": "respect", "OffsetStartMs": 16840, "OffsetEndMs": 17240}, {"Word": "to", "OffsetStartMs": 17290, "OffsetEndMs": 17565}, {"Word": "human", "OffsetStartMs": 17565, "OffsetEndMs": 17820}, {"Word": "capabilities", "OffsetStartMs": 17820, "OffsetEndMs": 18200}, {"Word": "and", "OffsetStartMs": 18820, "OffsetEndMs": 19125}, {"Word": "human", "OffsetStartMs": 19125, "OffsetEndMs": 19430}, {"Word": "intelligence", "OffsetStartMs": 19480, "OffsetEndMs": 19880}], "SpeechSpeed": 13.8}, {"FinalSentence": "And so I'm, I'm really excited that on thursday in lecture seven on new frontiers in deep learning, we're going to take a really deep dive into diffusion models, talk about their fundamentals, talk about not only applications to images, but other fields as well, in which we're seeing these models really start to make transformative advances because they are indeed at the very cutting edge and very much the new frontier of generative AI today.", "SliceSentence": "And so I'm I'm really excited that on thursday in lecture seven on new frontiers in deep learning we're going to take a really deep dive into diffusion models talk about their fundamentals talk about not only applications to images but other fields as well in which we're seeing these models really start to make transformative advances because they are indeed at the very cutting edge and very much the new frontier of generative AI today", "StartMs": 3532380, "EndMs": 3559840, "WordsNum": 76, "Words": [{"Word": "And", "OffsetStartMs": 160, "OffsetEndMs": 450}, {"Word": "so", "OffsetStartMs": 450, "OffsetEndMs": 615}, {"Word": "I'm", "OffsetStartMs": 615, "OffsetEndMs": 915}, {"Word": "I'm", "OffsetStartMs": 915, "OffsetEndMs": 1200}, {"Word": "really", "OffsetStartMs": 1200, "OffsetEndMs": 1460}, {"Word": "excited", "OffsetStartMs": 1510, "OffsetEndMs": 1860}, {"Word": "that", "OffsetStartMs": 1860, "OffsetEndMs": 2085}, {"Word": "on", "OffsetStartMs": 2085, "OffsetEndMs": 2295}, {"Word": "thursday", "OffsetStartMs": 2295, "OffsetEndMs": 2630}, {"Word": "in", "OffsetStartMs": 2740, "OffsetEndMs": 3045}, {"Word": "lecture", "OffsetStartMs": 3045, "OffsetEndMs": 3350}, {"Word": "seven", "OffsetStartMs": 3370, "OffsetEndMs": 3770}, {"Word": "on", "OffsetStartMs": 4060, "OffsetEndMs": 4460}, {"Word": "new", "OffsetStartMs": 4600, "OffsetEndMs": 4920}, {"Word": "frontiers", "OffsetStartMs": 4920, "OffsetEndMs": 5400}, {"Word": "in", "OffsetStartMs": 5400, "OffsetEndMs": 5595}, {"Word": "deep", "OffsetStartMs": 5595, "OffsetEndMs": 5775}, {"Word": "learning", "OffsetStartMs": 5775, "OffsetEndMs": 6080}, {"Word": "we're", "OffsetStartMs": 6430, "OffsetEndMs": 6765}, {"Word": "going", "OffsetStartMs": 6765, "OffsetEndMs": 6900}, {"Word": "to", "OffsetStartMs": 6900, "OffsetEndMs": 7065}, {"Word": "take", "OffsetStartMs": 7065, "OffsetEndMs": 7200}, {"Word": "a", "OffsetStartMs": 7200, "OffsetEndMs": 7335}, {"Word": "really", "OffsetStartMs": 7335, "OffsetEndMs": 7545}, {"Word": "deep", "OffsetStartMs": 7545, "OffsetEndMs": 7830}, {"Word": "dive", "OffsetStartMs": 7830, "OffsetEndMs": 8175}, {"Word": "into", "OffsetStartMs": 8175, "OffsetEndMs": 8505}, {"Word": "diffusion", "OffsetStartMs": 8505, "OffsetEndMs": 8955}, {"Word": "models", "OffsetStartMs": 8955, "OffsetEndMs": 9320}, {"Word": "talk", "OffsetStartMs": 9730, "OffsetEndMs": 10065}, {"Word": "about", "OffsetStartMs": 10065, "OffsetEndMs": 10305}, {"Word": "their", "OffsetStartMs": 10305, "OffsetEndMs": 10500}, {"Word": "fundamentals", "OffsetStartMs": 10500, "OffsetEndMs": 11270}, {"Word": "talk", "OffsetStartMs": 11650, "OffsetEndMs": 11985}, {"Word": "about", "OffsetStartMs": 11985, "OffsetEndMs": 12285}, {"Word": "not", "OffsetStartMs": 12285, "OffsetEndMs": 12570}, {"Word": "only", "OffsetStartMs": 12570, "OffsetEndMs": 12890}, {"Word": "applications", "OffsetStartMs": 13150, "OffsetEndMs": 13545}, {"Word": "to", "OffsetStartMs": 13545, "OffsetEndMs": 13785}, {"Word": "images", "OffsetStartMs": 13785, "OffsetEndMs": 14030}, {"Word": "but", "OffsetStartMs": 14440, "OffsetEndMs": 14730}, {"Word": "other", "OffsetStartMs": 14730, "OffsetEndMs": 15000}, {"Word": "fields", "OffsetStartMs": 15000, "OffsetEndMs": 15300}, {"Word": "as", "OffsetStartMs": 15300, "OffsetEndMs": 15540}, {"Word": "well", "OffsetStartMs": 15540, "OffsetEndMs": 15860}, {"Word": "in", "OffsetStartMs": 16090, "OffsetEndMs": 16380}, {"Word": "which", "OffsetStartMs": 16380, "OffsetEndMs": 16590}, {"Word": "we're", "OffsetStartMs": 16590, "OffsetEndMs": 16905}, {"Word": "seeing", "OffsetStartMs": 16905, "OffsetEndMs": 17145}, {"Word": "these", "OffsetStartMs": 17145, "OffsetEndMs": 17415}, {"Word": "models", "OffsetStartMs": 17415, "OffsetEndMs": 17750}, {"Word": "really", "OffsetStartMs": 17800, "OffsetEndMs": 18200}, {"Word": "start", "OffsetStartMs": 18250, "OffsetEndMs": 18555}, {"Word": "to", "OffsetStartMs": 18555, "OffsetEndMs": 18720}, {"Word": "make", "OffsetStartMs": 18720, "OffsetEndMs": 18980}, {"Word": "transformative", "OffsetStartMs": 19150, "OffsetEndMs": 19820}, {"Word": "advances", "OffsetStartMs": 20020, "OffsetEndMs": 20690}, {"Word": "because", "OffsetStartMs": 21190, "OffsetEndMs": 21525}, {"Word": "they", "OffsetStartMs": 21525, "OffsetEndMs": 21705}, {"Word": "are", "OffsetStartMs": 21705, "OffsetEndMs": 21915}, {"Word": "indeed", "OffsetStartMs": 21915, "OffsetEndMs": 22200}, {"Word": "at", "OffsetStartMs": 22200, "OffsetEndMs": 22410}, {"Word": "the", "OffsetStartMs": 22410, "OffsetEndMs": 22560}, {"Word": "very", "OffsetStartMs": 22560, "OffsetEndMs": 22785}, {"Word": "cutting", "OffsetStartMs": 22785, "OffsetEndMs": 23070}, {"Word": "edge", "OffsetStartMs": 23070, "OffsetEndMs": 23390}, {"Word": "and", "OffsetStartMs": 23620, "OffsetEndMs": 23925}, {"Word": "very", "OffsetStartMs": 23925, "OffsetEndMs": 24150}, {"Word": "much", "OffsetStartMs": 24150, "OffsetEndMs": 24420}, {"Word": "the", "OffsetStartMs": 24420, "OffsetEndMs": 24630}, {"Word": "new", "OffsetStartMs": 24630, "OffsetEndMs": 24795}, {"Word": "frontier", "OffsetStartMs": 24795, "OffsetEndMs": 25320}, {"Word": "of", "OffsetStartMs": 25320, "OffsetEndMs": 25560}, {"Word": "generative", "OffsetStartMs": 25560, "OffsetEndMs": 26120}, {"Word": "AI", "OffsetStartMs": 26290, "OffsetEndMs": 26640}, {"Word": "today", "OffsetStartMs": 26640, "OffsetEndMs": 26990}], "SpeechSpeed": 16.0}, {"FinalSentence": "All right. So with that.", "SliceSentence": "All right . Sowith that", "StartMs": 3560340, "EndMs": 3562940, "WordsNum": 5, "Words": [{"Word": "All", "OffsetStartMs": 130, "OffsetEndMs": 390}, {"Word": "right", "OffsetStartMs": 390, "OffsetEndMs": 650}, {"Word": ".", "OffsetStartMs": 820, "OffsetEndMs": 1170}, {"Word": "Sowith", "OffsetStartMs": 1170, "OffsetEndMs": 1425}, {"Word": "that", "OffsetStartMs": 1425, "OffsetEndMs": 1730}], "SpeechSpeed": 8.5}, {"FinalSentence": "Tease and and hopefully set the stage for lecture seven on thursday and conclude and remind you all that we have now about an hour for open office hour. Time for you to work on your software labs. Come to us, ask any questions you may have as well as the tas who will be here as well.", "SliceSentence": "Tease and and hopefully set the stage for lecture seven on thursday and conclude and remind you all that we have now about an hour for open office hour . Timefor you to work on your software labs . Cometo us ask any questions you may have as well as the tas who will be here as well", "StartMs": 3562960, "EndMs": 3586960, "WordsNum": 58, "Words": [{"Word": "Tease", "OffsetStartMs": 220, "OffsetEndMs": 660}, {"Word": "and", "OffsetStartMs": 660, "OffsetEndMs": 885}, {"Word": "and", "OffsetStartMs": 885, "OffsetEndMs": 1220}, {"Word": "hopefully", "OffsetStartMs": 2470, "OffsetEndMs": 2870}, {"Word": "set", "OffsetStartMs": 2890, "OffsetEndMs": 3180}, {"Word": "the", "OffsetStartMs": 3180, "OffsetEndMs": 3345}, {"Word": "stage", "OffsetStartMs": 3345, "OffsetEndMs": 3620}, {"Word": "for", "OffsetStartMs": 3730, "OffsetEndMs": 4080}, {"Word": "lecture", "OffsetStartMs": 4080, "OffsetEndMs": 4425}, {"Word": "seven", "OffsetStartMs": 4425, "OffsetEndMs": 4820}, {"Word": "on", "OffsetStartMs": 4900, "OffsetEndMs": 5235}, {"Word": "thursday", "OffsetStartMs": 5235, "OffsetEndMs": 5570}, {"Word": "and", "OffsetStartMs": 6340, "OffsetEndMs": 6740}, {"Word": "conclude", "OffsetStartMs": 8500, "OffsetEndMs": 8970}, {"Word": "and", "OffsetStartMs": 8970, "OffsetEndMs": 9290}, {"Word": "remind", "OffsetStartMs": 9370, "OffsetEndMs": 9705}, {"Word": "you", "OffsetStartMs": 9705, "OffsetEndMs": 9900}, {"Word": "all", "OffsetStartMs": 9900, "OffsetEndMs": 10095}, {"Word": "that", "OffsetStartMs": 10095, "OffsetEndMs": 10410}, {"Word": "we", "OffsetStartMs": 10410, "OffsetEndMs": 10680}, {"Word": "have", "OffsetStartMs": 10680, "OffsetEndMs": 10890}, {"Word": "now", "OffsetStartMs": 10890, "OffsetEndMs": 11210}, {"Word": "about", "OffsetStartMs": 11800, "OffsetEndMs": 12105}, {"Word": "an", "OffsetStartMs": 12105, "OffsetEndMs": 12285}, {"Word": "hour", "OffsetStartMs": 12285, "OffsetEndMs": 12560}, {"Word": "for", "OffsetStartMs": 12670, "OffsetEndMs": 13070}, {"Word": "open", "OffsetStartMs": 13330, "OffsetEndMs": 13680}, {"Word": "office", "OffsetStartMs": 13680, "OffsetEndMs": 13890}, {"Word": "hour", "OffsetStartMs": 13890, "OffsetEndMs": 14115}, {"Word": ".", "OffsetStartMs": 14115, "OffsetEndMs": 14480}, {"Word": "Timefor", "OffsetStartMs": 14740, "OffsetEndMs": 15000}, {"Word": "you", "OffsetStartMs": 15000, "OffsetEndMs": 15165}, {"Word": "to", "OffsetStartMs": 15165, "OffsetEndMs": 15345}, {"Word": "work", "OffsetStartMs": 15345, "OffsetEndMs": 15555}, {"Word": "on", "OffsetStartMs": 15555, "OffsetEndMs": 15795}, {"Word": "your", "OffsetStartMs": 15795, "OffsetEndMs": 16005}, {"Word": "software", "OffsetStartMs": 16005, "OffsetEndMs": 16305}, {"Word": "labs", "OffsetStartMs": 16305, "OffsetEndMs": 16880}, {"Word": ".", "OffsetStartMs": 17020, "OffsetEndMs": 17355}, {"Word": "Cometo", "OffsetStartMs": 17355, "OffsetEndMs": 17550}, {"Word": "us", "OffsetStartMs": 17550, "OffsetEndMs": 17810}, {"Word": "ask", "OffsetStartMs": 18340, "OffsetEndMs": 18660}, {"Word": "any", "OffsetStartMs": 18660, "OffsetEndMs": 18900}, {"Word": "questions", "OffsetStartMs": 18900, "OffsetEndMs": 19200}, {"Word": "you", "OffsetStartMs": 19200, "OffsetEndMs": 19440}, {"Word": "may", "OffsetStartMs": 19440, "OffsetEndMs": 19605}, {"Word": "have", "OffsetStartMs": 19605, "OffsetEndMs": 19910}, {"Word": "as", "OffsetStartMs": 20770, "OffsetEndMs": 21075}, {"Word": "well", "OffsetStartMs": 21075, "OffsetEndMs": 21240}, {"Word": "as", "OffsetStartMs": 21240, "OffsetEndMs": 21375}, {"Word": "the", "OffsetStartMs": 21375, "OffsetEndMs": 21555}, {"Word": "tas", "OffsetStartMs": 21555, "OffsetEndMs": 21825}, {"Word": "who", "OffsetStartMs": 21825, "OffsetEndMs": 22050}, {"Word": "will", "OffsetStartMs": 22050, "OffsetEndMs": 22200}, {"Word": "be", "OffsetStartMs": 22200, "OffsetEndMs": 22490}, {"Word": "here", "OffsetStartMs": 22600, "OffsetEndMs": 22965}, {"Word": "as", "OffsetStartMs": 22965, "OffsetEndMs": 23250}, {"Word": "well", "OffsetStartMs": 23250, "OffsetEndMs": 23570}], "SpeechSpeed": 11.7}, {"FinalSentence": "Thank you so much.", "SliceSentence": "Thank you so much", "StartMs": 3586960, "EndMs": 3592057, "WordsNum": 4, "Words": [{"Word": "Thank", "OffsetStartMs": 70, "OffsetEndMs": 360}, {"Word": "you", "OffsetStartMs": 360, "OffsetEndMs": 525}, {"Word": "so", "OffsetStartMs": 525, "OffsetEndMs": 660}, {"Word": "much", "OffsetStartMs": 660, "OffsetEndMs": 920}], "SpeechSpeed": 3.3}]}, "RequestId": "43acf7f9-55ef-44f3-b1cd-1ab23897300d"}