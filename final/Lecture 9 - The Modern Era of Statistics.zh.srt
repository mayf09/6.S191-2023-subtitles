1
00:00:09,270 --> 00:00:10,780
谢谢，大家好，

2
00:00:11,040 --> 00:00:12,550
感谢 Alexander 的介绍。

3
00:00:13,630 --> 00:00:18,200
好的，非常高兴谈论这个统计的现代时代，

4
00:00:18,820 --> 00:00:20,900
你在整个讲座中都听到了，

5
00:00:21,250 --> 00:00:26,110
可能有很多关于深度学习和实现这一点的技术，

6
00:00:26,430 --> 00:00:27,820
但我想说的是，

7
00:00:27,930 --> 00:00:30,310
我想说为什么管用，

8
00:00:30,540 --> 00:00:31,895
所以给你一些直觉，

9
00:00:31,895 --> 00:00:36,520
关于我们在这个系统的理论分析方面所处的位置，

10
00:00:37,200 --> 00:00:40,390
因为很多人认为机器学习是一个特别的领域，

11
00:00:40,710 --> 00:00:43,010
而深度学习是非常特别的，

12
00:00:43,010 --> 00:00:45,940
这里改变了几个超级参数，一切都开始工作，

13
00:00:46,350 --> 00:00:47,525
但事实并非如此，

14
00:00:47,525 --> 00:00:49,460
所以我们有一些线索，

15
00:00:49,460 --> 00:00:51,880
比如整件事是关于什么的，好的。

16
00:00:53,100 --> 00:00:55,660
好的，为了激励大家，

17
00:00:56,370 --> 00:00:58,630
我想告诉你们这个，

18
00:00:59,400 --> 00:01:02,150
我认为这是一张非常常见的照片，

19
00:01:02,290 --> 00:01:07,910
你可以看到 2012 年后更多的倍增法则被打破了，

20
00:01:08,260 --> 00:01:12,170
我们进入了一种新的模式，

21
00:01:12,640 --> 00:01:16,960
就像我们在 y 轴上增长的这样，

22
00:01:16,960 --> 00:01:19,290
你看到的就是，

23
00:01:19,430 --> 00:01:22,375
这个模型的能耗，甚至可能是准确的，

24
00:01:22,375 --> 00:01:27,210
这个模型的精确度，或者说这些模型的泛化能力越来越高，

25
00:01:27,590 --> 00:01:29,830
随着我们对增大它们的规模，

26
00:01:29,830 --> 00:01:32,190
这就是我们到目前为止所观察到的情况。

27
00:01:32,800 --> 00:01:35,060
这就是我所说的现代，

28
00:01:35,140 --> 00:01:38,450
因为我们竭尽全力地增加它们的大小，

29
00:01:39,250 --> 00:01:42,970
这些照片可以向你展示，

30
00:01:42,970 --> 00:01:46,560
这个大型语言模型的一些比例，

31
00:01:46,970 --> 00:01:51,360
你可以看到我们有高达 5400 亿个参数的模型，

32
00:01:51,980 --> 00:01:56,280
这些模型如何执行表示学习超出了我们的理解。

33
00:01:56,920 --> 00:02:00,175
而且它不仅在语言模型领域，

34
00:02:00,175 --> 00:02:02,320
而且也跨不同的领域，

35
00:02:02,320 --> 00:02:07,560
例如，在时间序列建模中，在医疗诊断中，在金融时间序列中，

36
00:02:07,820 --> 00:02:11,280
我们有新技术，这些技术随着规模的增加而变得越来越好，

37
00:02:11,720 --> 00:02:14,340
这似乎就是这样，

38
00:02:15,080 --> 00:02:16,710
跨越不同的数据模式，

39
00:02:16,910 --> 00:02:22,860
也许 2014 年我们在生成式模型之前出现的数据模式，

40
00:02:23,880 --> 00:02:29,090
这样的生成性模型到这样的生成性模型，

41
00:02:29,230 --> 00:02:31,470
所以，质量大幅提高，

42
00:02:31,470 --> 00:02:32,720
不仅是因为规模，

43
00:02:33,010 --> 00:02:40,030
也是因为潜在的结构使我们能够扩展这种神经网络，

44
00:02:40,410 --> 00:02:41,735
因为我们已经知道，

45
00:02:41,735 --> 00:02:45,400
如果你必须将两层神经网络堆叠在一起，

46
00:02:45,720 --> 00:02:47,920
你就有了一个通用的逼近器，

47
00:02:48,240 --> 00:02:51,430
那么，为什么我们现在不能扩大规模呢，

48
00:02:51,630 --> 00:02:54,555
我们必须找到正确的结构为了做到这一点，

49
00:02:54,555 --> 00:02:58,160
例如，扩散是那些实际呈现的结构之一。

50
00:02:58,940 --> 00:03:01,350
所以看起来越大越好，

51
00:03:01,760 --> 00:03:02,640
但是为什么呢，

52
00:03:02,870 --> 00:03:04,950
好的，让我们来找出原因。

53
00:03:06,610 --> 00:03:08,090
所以你们都知道，

54
00:03:08,410 --> 00:03:11,160
我假设你们都知道如何解这两个方程，

55
00:03:11,160 --> 00:03:14,150
所以 n 个方程需要 n 个未知数，对吗，

56
00:03:14,470 --> 00:03:15,350
那么，你们中有多少人，

57
00:03:15,430 --> 00:03:17,570
还知道如何解决这种事情？

58
00:03:20,050 --> 00:03:22,820
是的，我觉得很好，

59
00:03:23,050 --> 00:03:25,370
但是，深度学习的疯狂之处在于，

60
00:03:25,810 --> 00:03:26,990
它说的是，

61
00:03:27,160 --> 00:03:31,580
是的，使这些 x 和 y 的数目越来越大，

62
00:03:31,720 --> 00:03:33,110
对于这两个方程式，

63
00:03:33,670 --> 00:03:37,055
事情就会开始，工作得更好，

64
00:03:37,055 --> 00:03:38,440
更好意味着什么，

65
00:03:38,940 --> 00:03:42,520
当你有两个方程式，而你有很多未知数，

66
00:03:43,270 --> 00:03:45,060
这怎么说得通。

67
00:03:45,060 --> 00:03:48,980
让我们对数据集进行分析和数值分析，

68
00:03:49,360 --> 00:03:52,155
你们以前都看过这个数据集，

69
00:03:52,155 --> 00:03:54,650
它是手写的数字，

70
00:03:55,150 --> 00:03:57,410
它有 60k 个点，

71
00:03:57,880 --> 00:04:01,160
它有 28x28 大比例的图像，

72
00:04:02,000 --> 00:04:03,160
在今天的模型中，

73
00:04:03,540 --> 00:04:07,780
它们有数百万个参数来模拟 6 万张图像，

74
00:04:08,580 --> 00:04:13,060
所以，这个数据集的性能一直在提高，

75
00:04:13,590 --> 00:04:15,970
随着我们扩展神经网络，

76
00:04:16,770 --> 00:04:19,145
这有什么意义呢，

77
00:04:19,145 --> 00:04:24,610
比如，你从 60k 图像学到的信息，

78
00:04:24,960 --> 00:04:27,610
使用数百万个数据参数，

79
00:04:28,680 --> 00:04:29,470
我们学到了什么？

80
00:04:30,590 --> 00:04:36,000
现在，我们从理论上知道，泛化误差或测试误差有这样的比例关系，

81
00:04:36,320 --> 00:04:39,210
它与系统参数个数成正比，

82
00:04:39,350 --> 00:04:43,980
与系统参数个数在数据集大小上的平方根成正比，

83
00:04:44,120 --> 00:04:46,770
这意味着如果我增加系统的参数数量，

84
00:04:47,390 --> 00:04:51,720
那么我预计在某个点上，泛化或误差会很高，

85
00:04:53,010 --> 00:04:56,860
那么，为什么我们让它们变得越来越大，但它们起作用了呢。

86
00:04:58,530 --> 00:05:01,360
在 ImageNet 或其他大规模数据集的情况下，

87
00:05:01,560 --> 00:05:02,890
非常常见的机器学习，

88
00:05:02,940 --> 00:05:05,290
我们大概有 140 万张图像，

89
00:05:06,160 --> 00:05:08,460
尺寸为 256x256x3 ，

90
00:05:08,720 --> 00:05:12,270
这些模型有数亿个参数，

91
00:05:12,560 --> 00:05:15,090
可以匹配这 140 万张图像。

92
00:05:16,520 --> 00:05:18,060
在 NLP 中，正如我们之前所展示的，

93
00:05:18,110 --> 00:05:20,695
我们有几十亿的数据点，

94
00:05:20,695 --> 00:05:22,440
然后是千亿的模型。

95
00:05:23,780 --> 00:05:28,105
然后，也许是最好的，我最喜欢的示例，

96
00:05:28,105 --> 00:05:31,080
在生成式 AI 中这个尺寸提高性能，

97
00:05:31,660 --> 00:05:32,665
当你有提示时，

98
00:05:32,665 --> 00:05:36,270
这就像是生成式 AI 接收文本输入并输出图像，

99
00:05:37,140 --> 00:05:39,260
所以这个系统的提示或输入是，

100
00:05:39,520 --> 00:05:41,145
一张袋鼠的肖像照片，

101
00:05:41,145 --> 00:05:44,810
穿着橙色的连帽衫和蓝色的太阳镜，

102
00:05:45,040 --> 00:05:47,600
站在悉尼歌剧院前的草地上，

103
00:05:47,920 --> 00:05:50,630
胸前举着一个牌子，上面写着欢迎朋友。

104
00:05:51,550 --> 00:05:52,400
正如我们所看到的，

105
00:05:52,510 --> 00:05:54,240
在每一张图像的顶部，

106
00:05:54,240 --> 00:05:56,210
我们有模型的大小，

107
00:05:56,860 --> 00:06:00,200
随着我们改善模型的大小，

108
00:06:00,310 --> 00:06:01,460
质量也会提高，

109
00:06:01,510 --> 00:06:05,060
我们越来越接近我们提供的描述，

110
00:06:08,440 --> 00:06:10,100
作为系统的输入，

111
00:06:10,940 --> 00:06:12,835
比如第一张图片 350 ，

112
00:06:12,835 --> 00:06:15,390
它仍然拥有输入的所有组件，

113
00:06:15,560 --> 00:06:17,460
但它没有最后一张好，

114
00:06:18,370 --> 00:06:20,270
它遗漏了几件事。

115
00:06:22,010 --> 00:06:24,960
好的，这发生了，

116
00:06:25,010 --> 00:06:29,070
现在让我们找出一种方法来解释这个。

117
00:06:29,300 --> 00:06:33,690
好的，你们中有多少人听说过一种叫做双重下降的现象？

118
00:06:37,360 --> 00:06:39,490
一、二。

119
00:06:41,950 --> 00:06:42,680
好的，那么，

120
00:06:43,770 --> 00:06:47,500
好的，所以首先这不是一个学习曲线，

121
00:06:48,160 --> 00:06:50,040
x 轴显示模型大小，

122
00:06:51,460 --> 00:06:55,280
你有一个图像分类问题 CIFAR-10 ，

123
00:06:55,900 --> 00:07:00,110
这是你希望对这些图像进行分类的十个种类，

124
00:07:00,190 --> 00:07:01,640
现在在 x 轴上，

125
00:07:01,930 --> 00:07:04,010
你增加网络的大小，

126
00:07:05,740 --> 00:07:08,630
在 y 轴上，我们可以看到测试误差。

127
00:07:09,160 --> 00:07:11,450
好的，让我们把注意力集中在，

128
00:07:13,550 --> 00:07:17,170
在基本过程的紫色一侧，

129
00:07:17,170 --> 00:07:18,990
因为这是在训练过程的末尾，

130
00:07:19,220 --> 00:07:21,420
如果你查看在过程的末尾的测试错误。

131
00:07:22,080 --> 00:07:24,770
经典统计学告诉我们，

132
00:07:24,770 --> 00:07:29,590
随着你的改进，当你把神经网络的规模增加到某个点，

133
00:07:29,670 --> 00:07:30,940
你会发现一个标称的点，

134
00:07:31,260 --> 00:07:36,140
模型的性能，你所拥有的泛化是最佳的，

135
00:07:36,900 --> 00:07:38,085
从那一刻起，

136
00:07:38,085 --> 00:07:40,430
如果你增加网络的规模，你就过拟合了，

137
00:07:40,870 --> 00:07:41,505
这意味着什么，

138
00:07:41,505 --> 00:07:43,380
这意味着精确度，

139
00:07:43,380 --> 00:07:47,390
第一个钟型开始上升，

140
00:07:47,500 --> 00:07:50,210
正如你所看到的，这个部分，

141
00:07:50,560 --> 00:07:54,315
他们预测那个东西会上升，

142
00:07:54,315 --> 00:07:55,580
当我们缩放模型时，

143
00:07:56,190 --> 00:07:58,775
但我们观察到的现象是，

144
00:07:58,775 --> 00:08:02,710
随着我们对规模的扩大，存在第二次下降，

145
00:08:02,940 --> 00:08:04,790
所以这被称为双下降现象，

146
00:08:04,790 --> 00:08:07,150
我们已经知道的第一次下降，

147
00:08:07,590 --> 00:08:09,680
在现代，我们计算出，

148
00:08:09,680 --> 00:08:12,220
当我们扩展这个神经网络，模型的大小，

149
00:08:12,840 --> 00:08:16,210
这是在许多不同的体系结构中观察到的，

150
00:08:16,350 --> 00:08:20,200
好的，随着我们的扩展，它可以是一个共振架构，

151
00:08:20,310 --> 00:08:21,910
它可以是神经网络上的卷积，

152
00:08:22,320 --> 00:08:25,690
它可以是 LSTM 或多路感知器或任何其他的，

153
00:08:26,330 --> 00:08:28,350
但随着我们增加尺寸，

154
00:08:28,430 --> 00:08:30,060
这就是我们看到的那种现象。

155
00:08:31,060 --> 00:08:36,810
现在，让我让它变得简单一点，

156
00:08:37,420 --> 00:08:40,080
精确度而言，这是经典的统计数据，

157
00:08:41,280 --> 00:08:42,890
在前一个中，我们看到的是错误，

158
00:08:43,600 --> 00:08:44,780
现在我们看到的是准确性，

159
00:08:45,240 --> 00:08:47,180
我们上升到某个点，

160
00:08:47,470 --> 00:08:49,220
然后随着我们增加模型的大小，

161
00:08:49,780 --> 00:08:51,050
我们开始过拟合，

162
00:08:52,270 --> 00:08:53,810
现在，上升到某个点，

163
00:08:54,280 --> 00:08:55,010
如果你有，

164
00:08:56,840 --> 00:08:59,440
新的实验结果表明，

165
00:08:59,550 --> 00:09:00,580
这是这样的情况，

166
00:09:01,230 --> 00:09:04,810
上升到某个点，我们上升，

167
00:09:04,890 --> 00:09:07,600
然后又有了性能的改善，

168
00:09:09,100 --> 00:09:11,790
这个机制被称为全参数机制，

169
00:09:11,790 --> 00:09:13,070
我会告诉你更多，

170
00:09:13,210 --> 00:09:15,470
我会给你更多的实质内容，

171
00:09:15,820 --> 00:09:19,040
为什么我们把它们称为过度参数化机制，

172
00:09:19,090 --> 00:09:20,070
这应该是非常明显的，

173
00:09:20,070 --> 00:09:26,400
但是，我把它放在机器学习语言的理论和技术方面。

174
00:09:27,310 --> 00:09:30,740
好的，我们可以从这张图中观察到的一件事是，

175
00:09:30,850 --> 00:09:34,425
在这个过度参数化的过程中，最后的精度是，

176
00:09:34,425 --> 00:09:40,485
它比你从一个合理大小的模型得到的第一个精度略好，

177
00:09:40,485 --> 00:09:42,500
精度也好不到哪里去，

178
00:09:43,040 --> 00:09:45,230
但深度学习的发现是，

179
00:09:45,230 --> 00:09:47,170
当我们处于过度参数化的机制时，

180
00:09:47,580 --> 00:09:51,160
我们会得到一种新类型的行为开始出现，

181
00:09:51,780 --> 00:09:52,640
什么样的行为，

182
00:09:53,200 --> 00:09:56,520
过度参数化制度中出现的特征，

183
00:09:56,520 --> 00:09:59,030
是我接下来要谈的。

184
00:09:59,620 --> 00:10:01,050
所以其中一件事是，

185
00:10:04,350 --> 00:10:07,240
随着我们的网络规模越来越大，

186
00:10:07,590 --> 00:10:11,500
它们会学习可以传递给不同任务的概念，

187
00:10:11,640 --> 00:10:13,930
这意味着它们可以在不同的任务中泛化，

188
00:10:14,430 --> 00:10:16,090
这意味着它们学到的那些概念，

189
00:10:16,380 --> 00:10:19,430
它们可以被转移到执行更多的任务，

190
00:10:19,430 --> 00:10:21,880
甚至不是它们接受过训练的单一任务，

191
00:10:22,440 --> 00:10:23,560
好的，所以，

192
00:10:24,220 --> 00:10:26,650
似乎你给了它们更多的泛化能力，

193
00:10:26,650 --> 00:10:30,900
并越来越接近那种 AI 的一般表现形式，

194
00:10:31,560 --> 00:10:33,560
我现在还不敢说 AI ，

195
00:10:33,560 --> 00:10:36,790
但这是我们观察的那种事情，

196
00:10:36,990 --> 00:10:38,410
它们学习的那种概念，

197
00:10:38,790 --> 00:10:43,360
它们能够跨不同领域执行不同的任务，

198
00:10:43,590 --> 00:10:44,620
它们变得越来越好。

199
00:10:45,710 --> 00:10:47,470
我们得到的另一个观察结果是，

200
00:10:47,470 --> 00:10:49,110
规模提高了稳健性，

201
00:10:49,220 --> 00:10:53,040
深度学习模型的健壮意味着什么，

202
00:10:53,660 --> 00:10:56,410
这意味着，如果我在输出有噪声的情况下，

203
00:10:56,700 --> 00:10:57,760
[每一位]都有噪声，

204
00:10:58,230 --> 00:11:00,940
在输出，它不会完全崩溃，

205
00:11:01,230 --> 00:11:03,940
所以，投入的变化与产出的变化成正比，

206
00:11:04,560 --> 00:11:05,550
所以健壮性意味着，

207
00:11:05,550 --> 00:11:08,300
你能够控制误差和输出，

208
00:11:08,530 --> 00:11:11,720
如果输入有一点误差或偏差。

209
00:11:12,040 --> 00:11:14,180
所以这条曲线显示了，

210
00:11:14,650 --> 00:11:16,490
这些神经网络的规模，

211
00:11:17,350 --> 00:11:20,450
我们看到大小，健壮性提高了。

212
00:11:20,770 --> 00:11:23,720
好的，我将更详细地讨论这一点，

213
00:11:24,370 --> 00:11:26,450
因为这是我们用来阐述理论的部分，

214
00:11:26,920 --> 00:11:28,070
从深度学习的角度。

215
00:11:28,800 --> 00:11:35,500
并不是所有的东西都随着大小的增长而提高，

216
00:11:35,700 --> 00:11:39,370
例如，偏见和问责的问题，

217
00:11:39,420 --> 00:11:42,700
以及对少数族裔样本的微小准确性的问题，

218
00:11:42,870 --> 00:11:45,040
当我们扩大规模时，它们会变得更糟。

219
00:11:45,330 --> 00:11:49,150
这就是我们对这类情况的证据，

220
00:11:49,440 --> 00:11:50,410
所以，你需要小心，

221
00:11:50,730 --> 00:11:52,420
当你在我们的社会中部署这一技术时。

222
00:11:53,250 --> 00:11:56,270
智能的另一个非常重要的部分是推理，

223
00:11:56,270 --> 00:12:01,870
逻辑地讨论不同现象的能力就是推理，

224
00:12:02,070 --> 00:12:05,210
推理基本上是不变的。

225
00:12:05,210 --> 00:12:06,700
如果你只是缩放一个模型，

226
00:12:07,630 --> 00:12:11,270
除非你给系统提供一个模拟引擎，

227
00:12:11,470 --> 00:12:13,190
比如说你想做物理推理，

228
00:12:13,420 --> 00:12:14,570
假设有两个立方体，

229
00:12:14,800 --> 00:12:17,690
它们都在 x 轴上移动，

230
00:12:17,740 --> 00:12:19,430
其中一个比另一个更快，

231
00:12:19,840 --> 00:12:23,450
所以你作为一个人在你的大脑里有一个模拟引擎，

232
00:12:23,830 --> 00:12:26,030
你可以模拟那种现实，

233
00:12:26,560 --> 00:12:29,360
所以，如果你为语言模型提供这种现实，

234
00:12:30,930 --> 00:12:33,040
模拟的结果给那个语言模型，

235
00:12:33,150 --> 00:12:35,500
你会看到推理再次增加，

236
00:12:35,640 --> 00:12:38,350
所以这一部分也是非常重要的。

237
00:12:38,960 --> 00:12:41,020
现在，我们的部分就像，

238
00:12:41,310 --> 00:12:43,180
我在这里展示的所有这些结果，

239
00:12:43,350 --> 00:12:44,890
它们都是非常实验性的，

240
00:12:45,000 --> 00:12:48,470
有一家大公司参与，

241
00:12:48,470 --> 00:12:50,200
实际执行这种分析，

242
00:12:50,820 --> 00:12:53,290
以看到这些大型模型的行为，

243
00:12:53,400 --> 00:12:55,330
但是，我们有没有一个实际的理论，

244
00:12:55,500 --> 00:13:00,310
对于我们所看到的这个模型或这个行为，从根本上是正确的，

245
00:13:00,720 --> 00:13:02,860
让我把重点放在健壮性上。

246
00:13:04,840 --> 00:13:12,080
这个图表来自 MIT Alexander Madry 小组，

247
00:13:12,100 --> 00:13:15,290
他们研究神经网络的稳健性，

248
00:13:16,390 --> 00:13:17,090
他们的所做的，

249
00:13:17,650 --> 00:13:20,090
我的意思是，不管这三条线是什么，

250
00:13:20,200 --> 00:13:22,100
他们所做的，他们试图攻击输入图像，

251
00:13:23,460 --> 00:13:25,780
然后计算模型的精度，

252
00:13:27,070 --> 00:13:30,350
再次，我们在 x 轴上看到规模和精度，

253
00:13:30,550 --> 00:13:33,770
随着我们增加网络容量，

254
00:13:34,640 --> 00:13:36,970
在这里图像分类中，

255
00:13:37,680 --> 00:13:40,180
我们看到了健壮性的跃升，

256
00:13:40,260 --> 00:13:43,990
这意味着他们进行的攻击或干扰输入图像，

257
00:13:44,610 --> 00:13:47,440
使用被称为投影梯度下降的攻击，

258
00:13:48,030 --> 00:13:49,535
这就像你，

259
00:13:49,535 --> 00:13:51,860
你就会得到非常好的精确度，

260
00:13:51,860 --> 00:13:55,180
当你将网络的规模增加到一定程度后，

261
00:13:55,290 --> 00:14:01,690
然后就会有一个性能的转变，

262
00:14:02,040 --> 00:14:04,390
正如我所说的，这一点已经通过实验得到了证实，

263
00:14:04,980 --> 00:14:06,890
我们说，好的，

264
00:14:06,890 --> 00:14:10,780
这些结果的结论是，规模提高了稳健性。

265
00:14:11,970 --> 00:14:15,140
但是后来，获得最佳论文奖的，

266
00:14:15,140 --> 00:14:20,770
在神经信息处理系统 2021 会议上，

267
00:14:20,940 --> 00:14:23,830
出来说，规模是稳健性的法则。

268
00:14:24,320 --> 00:14:25,150
好的，这意味着什么，

269
00:14:25,290 --> 00:14:25,970
好的，这意味着，

270
00:14:25,970 --> 00:14:30,220
让我们来阐明，规模是如何从根本上促进稳健性的。

271
00:14:32,020 --> 00:14:36,420
所以，关于这件事，我会讲一些更技术性的东西，

272
00:14:36,470 --> 00:14:38,230
希望你们都能跟上，

273
00:14:38,230 --> 00:14:39,265
但你们可以问问题，

274
00:14:39,265 --> 00:14:41,635
即使是现在，如果你有问题，

275
00:14:41,635 --> 00:14:45,100
让我先说完这个，然后我们再回答一些问题。

276
00:14:45,100 --> 00:14:49,345
所以我们假设修正任何合理的函数，

277
00:14:49,345 --> 00:14:50,610
什么是合理的函数，

278
00:14:51,020 --> 00:14:53,960
基本上是一个具有平滑的函数，

279
00:14:54,070 --> 00:14:55,605
比如一个 sigmoid 函数，

280
00:14:55,605 --> 00:14:57,195
这是一个非常合理的函数，

281
00:14:57,195 --> 00:15:01,830
一个疯狂的函数就像你有一个像不同模式的跳跃，

282
00:15:01,830 --> 00:15:04,100
你有一个合理的函数，

283
00:15:04,630 --> 00:15:09,075
它是参数化的，

284
00:15:09,075 --> 00:15:09,855
就像一个 sigmoid 函数，

285
00:15:09,855 --> 00:15:11,000
你可以对它进行参数化，

286
00:15:11,350 --> 00:15:14,870
然后它被多极化，就像它在参数中也有合理的大小一样，

287
00:15:15,280 --> 00:15:17,760
它不是 Kolmogorov-Arnold 类型的网络，

288
00:15:17,760 --> 00:15:18,620
那是什么意思，

289
00:15:19,000 --> 00:15:19,610
它的意思是，

290
00:15:21,650 --> 00:15:26,910
我给你看的是 Arnold 和 Kolmogorov 发现的描述，

291
00:15:27,170 --> 00:15:28,105
这表明，

292
00:15:28,105 --> 00:15:34,920
我们看到的这种分解可以逼近任何连续函数，多元连续函数。

293
00:15:35,820 --> 00:15:37,840
好的，这是两个非线性函数，

294
00:15:38,520 --> 00:15:44,110
加法运算符应用，加入内部的过程，

295
00:15:44,460 --> 00:15:47,660
但是这种函数的一个问题是，

296
00:15:47,660 --> 00:15:52,690
它们不平滑，像[]提到的，

297
00:15:53,340 --> 00:15:54,430
它们表现出狂野的行为，

298
00:15:54,450 --> 00:15:55,565
它们可能是任何东西，

299
00:15:55,565 --> 00:15:57,700
内部函数中的函数可以是任何东西，

300
00:15:57,810 --> 00:16:01,860
所以让我们排除这种函数，

301
00:16:02,060 --> 00:16:03,510
让我们只讨论神经网络，

302
00:16:04,070 --> 00:16:07,080
好的，非常合理的函数和真正的函数。

303
00:16:07,850 --> 00:16:11,280
现在，我们对 m 个数据集的情况进行采样 n 个数据点，

304
00:16:11,300 --> 00:16:14,620
你有 60 万个数据点，真正的高维，

305
00:16:14,620 --> 00:16:17,995
我的意思是28乘以28乘以1，所以它就像728，对吗？所以不是那样的。

306
00:16:17,995 --> 00:16:19,650
所以是 728(784) ，

307
00:16:19,790 --> 00:16:22,750
所以，它不是那么真的高维，

308
00:16:22,750 --> 00:16:26,580
但是 ImageNet 是 256x256x3 ，

309
00:16:26,810 --> 00:16:28,710
所以是真正的高维，

310
00:16:30,440 --> 00:16:33,440
然后添加标签噪音，

311
00:16:33,460 --> 00:16:35,475
为什么我们要在标签上添加噪音，

312
00:16:35,475 --> 00:16:36,410
那是什么意思，

313
00:16:36,910 --> 00:16:39,560
这意味着我们想要让神经网络的问题变得更加困难，

314
00:16:39,910 --> 00:16:44,150
这意味着它不应该是高维输入对比输出类，

315
00:16:44,440 --> 00:16:46,220
不应该是微不足道的，

316
00:16:46,300 --> 00:16:48,470
所以我们加上一些噪音，一点的标签噪音，

317
00:16:48,940 --> 00:16:52,790
就产生了一个复杂的问题，

318
00:16:52,960 --> 00:16:56,420
好的，这意味着如果你拥有，所有的标签都是随机的，

319
00:16:56,740 --> 00:16:58,310
这个问题真的很复杂，

320
00:16:58,360 --> 00:17:00,710
所以，你想添加一点随机噪声。

321
00:17:01,660 --> 00:17:05,420
然后，为了记住这个数据集，

322
00:17:05,530 --> 00:17:06,980
记忆意味着什么，

323
00:17:07,240 --> 00:17:08,630
这意味着，如果我有一个函数，

324
00:17:08,680 --> 00:17:10,500
我在拟合一个参数模型，

325
00:17:10,500 --> 00:17:11,720
比如一个神经网络，

326
00:17:12,040 --> 00:17:16,785
我想要在训练中完全拟合每一个数据点，

327
00:17:16,785 --> 00:17:21,830
这意味着我想在我的训练中实现零损失，

328
00:17:22,280 --> 00:17:23,395
这意味着就像记忆一样，

329
00:17:23,395 --> 00:17:25,410
所以在学习过程中记忆的定义。

330
00:17:27,580 --> 00:17:31,650
现在，将训练误差优化到低于噪声水平，

331
00:17:31,650 --> 00:17:33,600
低于噪声水平，那是什么意思，

332
00:17:33,600 --> 00:17:37,130
同样，你们必须知道的另一个定义是，

333
00:17:37,150 --> 00:17:40,220
就像我说的，我们想要使这个过程复杂化，

334
00:17:40,600 --> 00:17:42,680
这样它就不是一个微不足道的映射，

335
00:17:42,880 --> 00:17:43,940
所以你加上噪音，

336
00:17:44,050 --> 00:17:48,260
然后当你的准确率比你注入的噪声量高一点时，

337
00:17:48,520 --> 00:17:52,790
例如，对于 m ，它是 m 数据集训练的难点部分，

338
00:17:52,840 --> 00:17:53,750
我们假设你，

339
00:17:53,860 --> 00:17:59,300
所有类型的机器学习模型都可以在 m 数据集上达到 92% 91% 的准确率，

340
00:17:59,580 --> 00:18:00,950
但是，最难的是什么，

341
00:18:01,150 --> 00:18:05,810
最难的是最后 2%-5% 才能达到百分之百，

342
00:18:06,410 --> 00:18:07,510
这就是最难的部分，

343
00:18:07,510 --> 00:18:10,830
这就是我们所说的低于噪音水平，

344
00:18:11,360 --> 00:18:16,140
这意味着，如果我们能够非常准确地了解这个过程。

345
00:18:17,460 --> 00:18:22,520
现在，要在 Lipschitz 条件下做到这种健壮性，

346
00:18:23,970 --> 00:18:25,690
谁知道什么是 Lipschitz 函数，

347
00:18:29,580 --> 00:18:30,830
五，六，好的，

348
00:18:31,780 --> 00:18:33,440
好的，所以 Lipschitz ，

349
00:18:34,630 --> 00:18:36,930
好的，我把这个放在这里，

350
00:18:36,930 --> 00:18:38,940
所以，就像我说的，

351
00:18:38,940 --> 00:18:41,750
你移动你的输入 ε ，

352
00:18:42,100 --> 00:18:45,230
好的，在函数输入上有一点微扰，

353
00:18:45,920 --> 00:18:48,460
然后，如果输出也是以 ε 移动，

354
00:18:49,080 --> 00:18:52,150
或与 ε 成正比的方式移动，

355
00:18:52,650 --> 00:18:54,040
那就意味着这个函数是 Lipschitz 的，

356
00:18:54,270 --> 00:18:56,260
所以你有一种受控的过程，

357
00:18:56,880 --> 00:19:01,660
更改输入不会显著更改函数的输出，

358
00:19:02,320 --> 00:19:03,540
这就是所谓的 Lipschitz 函数。

359
00:19:06,360 --> 00:19:10,940
现在，是的，所以你记住了这些数据，

360
00:19:11,850 --> 00:19:14,350
你想要健壮地记忆，

361
00:19:14,820 --> 00:19:16,340
所以，如果你想这样做，

362
00:19:16,870 --> 00:19:24,790
对你的神经网络进行参数化至少等于 n 是绝对必要的，

363
00:19:25,020 --> 00:19:27,640
n 是你的数据集的维度，

364
00:19:27,690 --> 00:19:30,160
也就是 60k 乘以 d ，

365
00:19:30,210 --> 00:19:34,260
d 是你的每个输入的维度，

366
00:19:34,760 --> 00:19:36,960
假设你的输入是一个 m 数据集，

367
00:19:37,160 --> 00:19:39,880
我的意思是，稍后我会给你一个例子，

368
00:19:39,880 --> 00:19:44,820
但是，假设输入是 728 ， [10 的 3 次方]，

369
00:19:45,450 --> 00:19:48,130
而数据集的数量是 60K ，

370
00:19:48,540 --> 00:19:52,600
然后， m 数据集的最小大小必须是 [10 的 8 次方]，

371
00:19:53,610 --> 00:19:57,520
神经网络模型大小是 [10 的 9 次方]，

372
00:19:57,960 --> 00:20:01,360
来健壮地学习 m 数据集，

373
00:20:01,740 --> 00:20:03,340
这是一个巨大的神经网络，

374
00:20:03,910 --> 00:20:07,220
但这是我们最近的基本解释之一，

375
00:20:07,510 --> 00:20:09,890
关于深度学习理论，

376
00:20:10,690 --> 00:20:14,090
为什么它被称为戏剧性的超越参数化，

377
00:20:14,710 --> 00:20:17,690
因为直观地说，就像我们之前展示的那样，

378
00:20:18,040 --> 00:20:21,470
记忆 n 个数据点需要 n 个参数，

379
00:20:21,760 --> 00:20:25,280
我们有 [] 和 []，

380
00:20:25,450 --> 00:20:29,520
他们展示了两个具有阈值激活函数的两层神经网络，

381
00:20:29,520 --> 00:20:30,950
他们在 1988 年证明，

382
00:20:31,300 --> 00:20:34,190
你需要的参数的数量 p ，

383
00:20:34,510 --> 00:20:38,210
几乎等同于你拥有的数据集，数据点的数量的数量级，

384
00:20:38,380 --> 00:20:41,270
从理论上讲，这将是足够的，

385
00:20:41,710 --> 00:20:44,780
然后他们最近在 ReLU 网上展示了这一点，

386
00:20:45,700 --> 00:20:48,990
我们甚至在神经正切核中也有这一点，

387
00:20:49,430 --> 00:20:52,650
那么，你们当中有多少人熟悉神经正切核，

388
00:20:56,750 --> 00:21:01,470
三局三胜，一，二。

389
00:21:01,980 --> 00:21:03,800
是的，所以神经正切核是，

390
00:21:04,540 --> 00:21:10,810
所以，想象一下梯度下降的训练和神经网络的过程，

391
00:21:11,820 --> 00:21:17,320
从训练开始到训练结束的整个过程是一个动态的过程，

392
00:21:17,790 --> 00:21:21,610
这意味着，随着你更进一步，你将更新系统的权重，

393
00:21:22,140 --> 00:21:27,040
给定一个数据集，给定一个神经网络以及给定优化器的参数的情况下，

394
00:21:27,930 --> 00:21:31,585
这种学习动态可以收敛，

395
00:21:31,585 --> 00:21:35,910
如果我可以用一个动态过程来建模，

396
00:21:36,830 --> 00:21:41,670
我的微分方程式解释了神经网络的梯度下降更新是如何工作的。

397
00:21:42,120 --> 00:21:47,700
现在，如果我将神经网络的大小增加到无限宽，

398
00:21:48,980 --> 00:21:51,360
我增加神经网络到无限宽，

399
00:21:51,950 --> 00:21:56,460
然后这种动态学习就有了一个封闭形式的解，

400
00:21:56,900 --> 00:21:58,440
这意味着它实际上有一个解，

401
00:21:59,360 --> 00:22:00,370
这是一种核心方法，

402
00:22:00,370 --> 00:22:02,310
所以从根本上说，你最终将拥有一个内核，

403
00:22:02,880 --> 00:22:08,270
这个核心以无限的方式解释了你学习过程的整个行为和动态，

404
00:22:08,470 --> 00:22:10,370
这就是神经正切核理论，

405
00:22:10,780 --> 00:22:15,360
我们有一个博士生坐在那里，

406
00:22:15,920 --> 00:22:18,360
Noel Loo ，他正在专注于这个问题，

407
00:22:18,470 --> 00:22:24,580
这是他正在研究的博士生话题，在 Daniela 实验室。

408
00:22:26,470 --> 00:22:30,830
好的，现在让我们离开这个理论，

409
00:22:31,180 --> 00:22:32,600
让我们举一个例子，

410
00:22:32,830 --> 00:22:34,280
所以我们有 MNIST 数据集，

411
00:22:34,390 --> 00:22:38,120
它有大约 10 的 5 次方的参数，

412
00:22:38,620 --> 00:22:42,410
每个数据点的维度是 10 的 3 次方，

413
00:22:42,520 --> 00:22:44,330
728 是它的尺寸，

414
00:22:45,010 --> 00:22:48,990
然后我们看到了一种健壮性的转变，

415
00:22:48,990 --> 00:22:52,490
至少你需要有 10 的 6 次方个参数，

416
00:22:52,600 --> 00:22:54,800
才能稳健地拟合 MNIST 数据集。

417
00:22:55,790 --> 00:22:58,110
但是还有几个点是我们想要的，

418
00:22:58,850 --> 00:23:02,935
理论论文中的稳健性概念

419
00:23:02,935 --> 00:23:05,740
与 Lipschitz 中的概念略有不同，

420
00:23:05,740 --> 00:23:10,340
那个我们在健壮性法则中展示的，

421
00:23:10,720 --> 00:23:12,380
然后另一点是，

422
00:23:12,490 --> 00:23:14,000
法则似乎是矛盾的，

423
00:23:14,140 --> 00:23:15,480
因为如果你乘以，

424
00:23:15,480 --> 00:23:19,200
我们刚才说的法则就是 n 乘以 d ，

425
00:23:19,200 --> 00:23:22,100
这是你所能得到的最小样本数，你可以转换，

426
00:23:22,630 --> 00:23:24,890
但是，如果你做 10 乘以，

427
00:23:25,660 --> 00:23:30,290
10 的 5 次方乘以 10 的 3 次方是 10 的 8 次方，

428
00:23:30,430 --> 00:23:36,360
这比在现实中观察到的 10 的 6 次方要大得多。

429
00:23:37,390 --> 00:23:41,290
但是，你还必须注意的一件事是，

430
00:23:41,290 --> 00:23:44,760
关于数据集，有一种东西被称为有效维度，

431
00:23:45,020 --> 00:23:47,130
有效维度意味着，

432
00:23:47,450 --> 00:23:48,690
当我向你们展示一幅图像时，

433
00:23:48,890 --> 00:23:50,880
图像的主要组成部分，

434
00:23:51,140 --> 00:23:53,490
所以，找出图像的主要成分，

435
00:23:53,750 --> 00:23:56,605
即图像有多小，信息是什么，

436
00:23:56,605 --> 00:23:59,640
信息与像素本身的大小不同，

437
00:23:59,720 --> 00:24:01,320
信息要小得多，

438
00:24:01,970 --> 00:24:03,570
所以，有效维度是，

439
00:24:03,620 --> 00:24:07,440
很难确定给定数据集的有效维度是多少，

440
00:24:07,550 --> 00:24:09,025
但对于 MNIST 数据集，

441
00:24:09,025 --> 00:24:10,860
它是 10 的 1 次方，

442
00:24:10,910 --> 00:24:12,780
现在我们有 10 的 5 次方，

443
00:24:13,010 --> 00:24:17,100
如果有效维度基本上是 10 的 1 次方，

444
00:24:17,210 --> 00:24:19,090
那么你会得到相同的，

445
00:24:19,090 --> 00:24:25,110
你可以用实验来证实用稳健性法则观察到的理论结果。

446
00:24:25,580 --> 00:24:27,685
现在，噪音标签，正如我所说的，

447
00:24:27,685 --> 00:24:29,910
它是学习训练中困难的部分，

448
00:24:30,570 --> 00:24:36,310
然后，关于 ImageNet 的预测表现出稳健性的法则，

449
00:24:36,480 --> 00:24:39,520
因为我们还没有训练超大型的网络，

450
00:24:40,080 --> 00:24:44,050
到目前为止，我们训练的网络似乎都很小，

451
00:24:44,160 --> 00:24:47,195
我们仍然没有训练真正的大型神经网络，

452
00:24:47,195 --> 00:24:52,600
但是它们必须是 10 的 12 次方或 10 的 10 次方数量级，

453
00:24:53,040 --> 00:24:56,560
这就是对稳健性法则的预测。

454
00:24:57,220 --> 00:25:00,740
好的，现在让我们回到这张图片上，

455
00:25:00,740 --> 00:25:04,510
所以我所说的所有这些网络和稳健性法则，

456
00:25:04,950 --> 00:25:06,580
基本上在那个机制下，

457
00:25:06,990 --> 00:25:09,940
在那个机制下，我向你展示了我们有很好的普遍性，

458
00:25:11,050 --> 00:25:13,580
我们得到更多的健壮性，可能更多的健壮性，

459
00:25:13,750 --> 00:25:18,650
然后推理我们还有一个问题，那就是如何实现它，

460
00:25:18,880 --> 00:25:21,140
然后是偏见和公平，这是非常重要的，

461
00:25:21,790 --> 00:25:24,470
能源消耗和模型的责任。

462
00:25:26,180 --> 00:25:27,420
有一种方法，

463
00:25:27,470 --> 00:25:29,845
这是研究的重点，

464
00:25:29,845 --> 00:25:31,680
我们在 Daniela Rus 的实验室所做的，

465
00:25:32,060 --> 00:25:36,420
与 Alexander 和我们的其他几名研究生一起，

466
00:25:37,720 --> 00:25:41,450
就是找出我们如何在解决超参数机制，

467
00:25:42,130 --> 00:25:46,190
解决所有这些[社会技术]挑战。

468
00:25:47,370 --> 00:25:49,000
我们是如何做到这一点的，

469
00:25:49,350 --> 00:25:50,500
我们回到了源头，

470
00:25:52,270 --> 00:25:55,070
我们调查了大脑，

471
00:25:55,240 --> 00:25:57,980
我们研究了如何从大脑中获得灵感，

472
00:25:58,870 --> 00:26:04,010
以改进我们在神经网络中的架构偏见，

473
00:26:04,540 --> 00:26:06,440
以打破健壮性法则。

474
00:26:08,430 --> 00:26:11,980
然后我们发明了一种叫做液态神经网络的东西，

475
00:26:12,000 --> 00:26:18,130
它的直接灵感来自于神经元和突触在大脑中相互作用的方式，

476
00:26:18,240 --> 00:26:21,920
这就是我们开始我们的重点，

477
00:26:21,920 --> 00:26:23,405
在我演讲的后半部分，

478
00:26:23,405 --> 00:26:29,050
我只想谈谈液态神经网络及其在现代统计学领域的意义。

479
00:26:30,780 --> 00:26:33,220
所以，就像我说的，我们从神经系统开始，

480
00:26:35,010 --> 00:26:37,515
然后，为了了解他们的帮助，

481
00:26:37,515 --> 00:26:40,820
你想要下去，你可以研究神经回路，

482
00:26:41,260 --> 00:26:43,940
神经回路是由神经元组成的回路，

483
00:26:44,020 --> 00:26:50,900
然后它们可以获得感觉输入并生成一些类型的输出，

484
00:26:51,430 --> 00:26:53,010
然后我们进行了更深入的研究，

485
00:26:53,010 --> 00:26:57,530
我们研究了单个神经元，是如何相互交流，

486
00:26:57,820 --> 00:26:59,990
接收彼此之间的信息的，

487
00:27:00,490 --> 00:27:04,370
然后我们得出了一个方程或公式，

488
00:27:04,480 --> 00:27:06,770
对于神经元和突触相互作用，

489
00:27:06,940 --> 00:27:11,270
它足够抽象，这样我们就可以进行计算，高效的计算，

490
00:27:11,560 --> 00:27:17,870
但同时也有更多关于计算如何在大脑中发生的细节，

491
00:27:18,500 --> 00:27:24,210
而不仅仅是门槛或激活，我们看到的那种函数。

492
00:27:24,320 --> 00:27:26,610
所以，让我们更深入地了解这个。

493
00:27:27,120 --> 00:27:27,980
我们展示了，

494
00:27:28,000 --> 00:27:33,380
如果你真的对神经网络进行了更多生物学上可信的表示，

495
00:27:33,610 --> 00:27:34,970
你就可以获得更多的表现力，

496
00:27:35,590 --> 00:27:40,820
你可以用一种更自然的方式来处理记忆，

497
00:27:41,750 --> 00:27:44,490
你得到了一些性质，比如因果关系，

498
00:27:44,660 --> 00:27:47,190
这是我们没有讨论过的，

499
00:27:47,570 --> 00:27:49,470
任务的因果关系是什么，

500
00:27:49,610 --> 00:27:50,820
我们真的能学到这些吗，

501
00:27:51,460 --> 00:27:53,300
你可以达到健壮性，

502
00:27:53,590 --> 00:27:56,240
你不需要像大的一样疯狂，

503
00:27:56,650 --> 00:27:58,365
在那个机制之外，

504
00:27:58,365 --> 00:28:00,290
你可以执行一个生成性模型，

505
00:28:00,490 --> 00:28:03,710
这是我之前描述的，

506
00:28:04,270 --> 00:28:06,050
你甚至可以进行推断，

507
00:28:06,430 --> 00:28:07,200
这意味着你可以，

508
00:28:07,200 --> 00:28:10,760
你甚至可以超越你所接受过训练的那种数据，

509
00:28:10,870 --> 00:28:12,890
这意味着你可以跳出分布，

510
00:28:13,360 --> 00:28:15,170
我们之前不能做的事情，

511
00:28:15,190 --> 00:28:19,670
我们关注的领域是机器人，现实世界，

512
00:28:19,690 --> 00:28:22,610
比如我们所说的混合视野决策，

513
00:28:22,840 --> 00:28:26,300
意思是如果你有一个机器人在一个真实的环境中交互，

514
00:28:26,530 --> 00:28:31,470
现在如何将这种网络带入现实世界，

515
00:28:31,470 --> 00:28:34,070
这也是我们研究的重点。

516
00:28:37,610 --> 00:28:42,140
是的，所以，这种类型的神经网络的基础是什么，

517
00:28:42,160 --> 00:28:46,670
我说的基础是两个神经元或两个细胞之间的相互作用，

518
00:28:47,110 --> 00:28:49,250
对这一过程的一些观察。

519
00:28:49,720 --> 00:28:50,985
第一个观察是，

520
00:28:50,985 --> 00:28:55,700
大脑中两个神经元之间的相互作用是一个连续的时间过程，

521
00:28:56,620 --> 00:28:58,845
所以这是需要解释的，

522
00:28:58,845 --> 00:29:00,890
所以我们不是在谈论离散过程。

523
00:29:01,880 --> 00:29:03,720
另一件事是突触释放，

524
00:29:03,830 --> 00:29:04,840
现在在神经网络种，

525
00:29:04,840 --> 00:29:06,520
当你相互连接节点时，

526
00:29:06,520 --> 00:29:08,520
你用标量权重将它们连接起来，

527
00:29:09,140 --> 00:29:10,910
现在，如果我告诉你，

528
00:29:10,910 --> 00:29:12,820
当两个神经元相互作用时，

529
00:29:13,020 --> 00:29:14,770
它不是一个标量权重，

530
00:29:15,000 --> 00:29:16,900
而是一个概率分布，

531
00:29:17,280 --> 00:29:21,550
一个细胞产生的多少种神经递质

532
00:29:21,780 --> 00:29:24,850
将结合到另一个细胞的通道上，

533
00:29:24,900 --> 00:29:27,965
以及它如何真正激活另一个细胞，

534
00:29:27,965 --> 00:29:30,830
所以，节点之间的通信是非常复杂的，

535
00:29:30,830 --> 00:29:33,490
这是智能的基本构建块之一，

536
00:29:33,990 --> 00:29:39,670
我们已经在人工神经网络中抽象出标量权重的方式。

537
00:29:40,540 --> 00:29:43,005
现在，另一个点是，

538
00:29:43,005 --> 00:29:51,860
我们在大脑中有大量的并行化和大量的重复、反馈、记忆和稀疏的那种结构，

539
00:29:52,120 --> 00:29:53,690
而这正是我们所缺失的，

540
00:29:55,530 --> 00:29:59,800
不是完全的，但一些从人工网络中消失了，

541
00:29:59,820 --> 00:30:01,060
我们有一点偏离了。

542
00:30:01,260 --> 00:30:03,245
现在我想说的是，

543
00:30:03,245 --> 00:30:05,290
如果我们整合所有这些构件，

544
00:30:05,670 --> 00:30:07,895
我们可能会得到更好的表示，

545
00:30:07,895 --> 00:30:09,850
学习更灵活的模型和健壮性，

546
00:30:10,140 --> 00:30:12,490
同时能够解释这些结果，

547
00:30:12,750 --> 00:30:15,710
因为第一个原因，

548
00:30:15,710 --> 00:30:19,480
整个过程是建立在连续时间过程之上的，

549
00:30:19,560 --> 00:30:21,790
让我们进入连续时间过程，

550
00:30:22,200 --> 00:30:25,570
就神经网络而言，连续时间过程。

551
00:30:26,360 --> 00:30:29,070
这里我给你们展示一个方程式，

552
00:30:29,510 --> 00:30:31,170
所以 f 是一个神经网络，

553
00:30:31,430 --> 00:30:35,250
它可以是一个五层，六层神经网络，完全相连，

554
00:30:35,940 --> 00:30:43,550
但是这个 f 有 n 层，宽度 k ，然后它有一个激活函数，

555
00:30:44,350 --> 00:30:47,190
它是一个接收输入的函数，

556
00:30:47,190 --> 00:30:49,910
它接收来自其他细胞的循环连接，

557
00:30:51,560 --> 00:30:54,610
它也接受外部输入，比如这个 I ，

558
00:30:55,020 --> 00:30:57,130
并且它是由 θ 参数化的，

559
00:30:57,780 --> 00:31:04,570
这个神经网络将隐藏状态的导数参数化，而不是隐藏状态本身，

560
00:31:05,170 --> 00:31:07,580
这建立了一个连续时间的神经网络，

561
00:31:08,650 --> 00:31:10,520
现在，如果你有一个连续的时间过程，

562
00:31:10,690 --> 00:31:13,700
这意味着神经网络的更新或输出，

563
00:31:13,960 --> 00:31:19,190
是生成隐藏状态的导数的更新，而不是隐藏状态本身，

564
00:31:19,540 --> 00:31:22,710
你可以给出[连续时间动态]，

565
00:31:22,710 --> 00:31:24,590
对于我们以前从未探索过的神经网络。

566
00:31:25,160 --> 00:31:28,180
那么，对于神经网络，这意味着什么，

567
00:31:28,680 --> 00:31:31,120
我们来看看这张图片，

568
00:31:31,740 --> 00:31:33,880
你们当中有多少人听说过残差网络？

569
00:31:38,220 --> 00:31:43,120
好的，残差网络是深度神经网络有一种跳过连接，

570
00:31:43,140 --> 00:31:46,210
比如从一层到另一层，你可以跳过连接，

571
00:31:46,530 --> 00:31:48,935
跳过连接的模型是这样的，

572
00:31:48,935 --> 00:31:52,390
ht+1 等于 ht 加上 f 什么，

573
00:31:52,910 --> 00:31:58,200
ht 类似于一种跳过连接。

574
00:31:58,820 --> 00:32:01,390
现在在 y 轴上，

575
00:32:01,410 --> 00:32:03,640
我们看到的是神经网络的深度，

576
00:32:03,900 --> 00:32:08,080
这里的每个黑点，

577
00:32:08,700 --> 00:32:11,375
显示了系统中发生的计算，

578
00:32:11,375 --> 00:32:14,030
所以当你有一个神经网络是层级的，

579
00:32:14,030 --> 00:32:15,470
我们称之为层级，

580
00:32:15,470 --> 00:32:19,120
因为图片显示了垂直轴上的层，

581
00:32:19,470 --> 00:32:21,050
所以，如果你查看垂直轴，

582
00:32:21,050 --> 00:32:23,230
你会看到计算发生在每一层，

583
00:32:24,500 --> 00:32:27,910
因为输入是从第一层到第二层，

584
00:32:27,910 --> 00:32:29,700
然后是下一层，下一层，

585
00:32:30,050 --> 00:32:31,830
但是如果你有一个连续的过程，

586
00:32:32,150 --> 00:32:34,080
连续的过程等于这个过程，

587
00:32:34,460 --> 00:32:39,660
你有能力在矢量场中的任意点计算，

588
00:32:39,860 --> 00:32:42,060
所以如果你知道什么是微分方程，

589
00:32:42,500 --> 00:32:47,790
他们如何把整个空间变成一个矢量场，

590
00:32:48,080 --> 00:32:49,410
你怎么去，

591
00:32:49,520 --> 00:32:53,250
你可以做自适应计算，

592
00:32:53,330 --> 00:32:56,700
这是连续时间过程的巨大好处之一。

593
00:32:57,320 --> 00:32:59,610
现在，就你们以前见过的东西来说，

594
00:32:59,720 --> 00:33:00,960
标准的递归神经网络，

595
00:33:02,420 --> 00:33:03,940
你在这里上过课，

596
00:33:03,940 --> 00:33:08,965
所以神经网络 f 计算隐藏状态的下一步，

597
00:33:08,965 --> 00:33:12,570
所以，它是[]下一步的一种[]过程，

598
00:33:13,160 --> 00:33:16,120
神经 ODE 通过这样的神经网络来更新状态，

599
00:33:16,900 --> 00:33:18,690
以连续时间的方式，

600
00:33:19,070 --> 00:33:24,150
然后这个微分方程有一个更好，更稳定的版本，

601
00:33:24,320 --> 00:33:28,080
叫做连续时间或 CTRNN 循环网络，

602
00:33:28,310 --> 00:33:30,360
在连续时间循环网络中，

603
00:33:30,470 --> 00:33:31,740
它们有一个衰减因子，

604
00:33:31,790 --> 00:33:36,000
所以这个微分是一个线性的 ODE 或微分方程，

605
00:33:36,410 --> 00:33:40,600
描述了神经网络的动态性，

606
00:33:41,430 --> 00:33:42,730
神经网络的隐藏状态。

607
00:33:43,080 --> 00:33:46,810
现在，在你会获得什么样的好处方面，

608
00:33:47,130 --> 00:33:48,340
让我们看看最上面的图，

609
00:33:48,390 --> 00:33:55,360
这些是从对应于螺旋动力学的数据数据结构图，

610
00:33:55,710 --> 00:33:57,760
如果你有一个二维神经网络，

611
00:33:58,170 --> 00:34:00,490
这种螺旋动力学能够，

612
00:34:00,510 --> 00:34:04,000
你有一种[前卫的插补]，

613
00:34:04,600 --> 00:34:06,180
但是如果你有一个连续的时间过程，

614
00:34:06,590 --> 00:34:08,545
它可以非常顺利地计算，

615
00:34:08,545 --> 00:34:11,875
甚至可以推广到这个看不见的区域，

616
00:34:11,875 --> 00:34:13,200
这个的红色部分，

617
00:34:13,430 --> 00:34:14,400
正如我们在这里看到的，

618
00:34:14,660 --> 00:34:19,230
正常的需求网络错过了这种螺旋式的动态，

619
00:34:19,400 --> 00:34:20,730
所以在连续的时间过程中，

620
00:34:21,140 --> 00:34:25,710
它只能相信你能得到越来越好的表现，

621
00:34:26,360 --> 00:34:28,680
但这里的问题是，

622
00:34:30,410 --> 00:34:34,770
如果你真的把这个模型带到实践中，

623
00:34:35,030 --> 00:34:39,985
一个简单的 LSTM 网络比这种类型的网络工作得更好，

624
00:34:39,985 --> 00:34:45,630
所以，到目前为止，你可以使用 LSTM 网络超越我们在这里展示的所有东西，

625
00:34:45,740 --> 00:34:49,830
那么，创建如此复杂的架构和东西有什么意义？

626
00:34:50,120 --> 00:34:55,210
这就是我们认为我们从大自然带来的连续时间过程，

627
00:34:55,470 --> 00:34:58,960
可以帮助我们建立更好的归纳偏见的地方。

628
00:34:59,560 --> 00:35:04,700
所以，我们引入了一种名为液态时间常数网络的神经网络，简称 LTC ，

629
00:35:05,200 --> 00:35:08,655
LTC 由神经元和突触构成，

630
00:35:08,655 --> 00:35:12,375
神经元模型就是这样一个连续的过程，

631
00:35:12,375 --> 00:35:15,380
这是一个线性微分方程，

632
00:35:15,880 --> 00:35:17,990
它接受突触输入 S ，

633
00:35:19,300 --> 00:35:20,910
这是一个线性微分方程，

634
00:35:23,520 --> 00:35:24,910
神经元和突触，

635
00:35:24,990 --> 00:35:27,940
现在我们有一个突触模型 S(t) 是一个函数，

636
00:35:28,530 --> 00:35:32,710
它有一个神经网络乘以一个叫做势差的术语，

637
00:35:34,260 --> 00:35:41,020
这种非线性类似于真实神经元中突触之间的非线性行为，

638
00:35:41,280 --> 00:35:46,850
如果你有突触连接，它们是由非线性设计的，

639
00:35:46,850 --> 00:35:49,120
因为这是事实。

640
00:35:49,640 --> 00:35:53,170
然后，如果你把这个 S 代入这个线性方程，

641
00:35:53,940 --> 00:35:57,740
你会得到一个看起来很复杂的微分方程，

642
00:35:57,740 --> 00:36:00,670
但你会看到这个微分方程式的含义，

643
00:36:01,080 --> 00:36:05,620
它有一个神经网络作为 x(t) 的系数，

644
00:36:05,670 --> 00:36:07,150
就是这里的 x(t) ，

645
00:36:09,030 --> 00:36:10,780
这个神经网络是输入依赖的，

646
00:36:11,370 --> 00:36:18,400
这意味着神经网络的输入定义了这个微分方程式的行为，

647
00:36:18,480 --> 00:36:20,710
所以它设定了微分方程的行为，

648
00:36:20,970 --> 00:36:24,040
当你在部署这个系统时，

649
00:36:24,300 --> 00:36:27,460
它可以适应输入，

650
00:36:27,570 --> 00:36:29,500
所以这个神经网络，这个系统，

651
00:36:29,610 --> 00:36:32,440
如果你在实践中有它，它是输入依赖的，

652
00:36:33,060 --> 00:36:36,470
当你改变作为输入结果的输入时，

653
00:36:36,640 --> 00:36:38,840
这个微分方程式的行为也会改变。

654
00:36:40,780 --> 00:36:44,270
现在，在连接结构方面，

655
00:36:44,350 --> 00:36:47,235
如果你看看可能有的连接结构的范围，

656
00:36:47,235 --> 00:36:48,860
你在标准世界网络中有的，

657
00:36:49,360 --> 00:36:53,600
你会有 sigmoid ，激活函数，

658
00:36:54,070 --> 00:36:56,420
你可能有两个节点之间的相互连接，

659
00:36:56,710 --> 00:36:58,545
你可能有外部输入，

660
00:36:58,545 --> 00:37:01,970
你可能有一个标准神经网络的循环连接。

661
00:37:02,260 --> 00:37:03,500
现在，对于液态神经网络，

662
00:37:03,760 --> 00:37:06,950
相反，系统中的每个节点都是一个微分方程，

663
00:37:07,600 --> 00:37:12,200
xj 和 xi ，它们有动态，

664
00:37:12,490 --> 00:37:14,930
然后它们通过突触联系在一起，

665
00:37:15,460 --> 00:37:20,510
然后有非线性过程控制突触相互作用，

666
00:37:21,000 --> 00:37:22,520
所以现在在某种意义上，

667
00:37:22,540 --> 00:37:27,440
你可以认为液态神经网络是过程，

668
00:37:27,580 --> 00:37:33,920
有着突触系统的非线性过程，而不是神经元。

669
00:37:34,870 --> 00:37:35,790
所以在神经网络中，

670
00:37:35,790 --> 00:37:37,110
我们有激活函数，

671
00:37:37,110 --> 00:37:38,570
它们是系统的非线性，

672
00:37:38,830 --> 00:37:42,410
现在你可以认为系统的非线性作用在突触上，或者系统的权重。

673
00:37:43,040 --> 00:37:44,020
现在，就实践而言，

674
00:37:44,610 --> 00:37:45,880
让我们来看看这个应用程序，

675
00:37:46,260 --> 00:37:48,130
我们训练一个人工神经网络，

676
00:37:48,300 --> 00:37:49,630
它可以控制一辆车，

677
00:37:50,040 --> 00:37:51,940
它可以在这种环境下驾驶汽车，

678
00:37:52,620 --> 00:37:55,750
我们在这张中间图像的两侧所显示的内容，

679
00:37:56,500 --> 00:37:58,620
是两个神经元的活动，

680
00:37:59,000 --> 00:38:02,580
分别是标准神经网络和液态神经网络，

681
00:38:02,930 --> 00:38:10,440
在 x 轴上，我们看到的是时间常数或敏感的输出行为，

682
00:38:10,520 --> 00:38:13,560
控制着车辆的转向角度，

683
00:38:14,280 --> 00:38:16,840
x 轴上控制的灵敏度，

684
00:38:17,670 --> 00:38:21,850
在 y 轴上，我们可以看到转向角，

685
00:38:22,080 --> 00:38:24,335
颜色还表示输出，

686
00:38:24,335 --> 00:38:29,350
转向角和神经网络输出之间的映射输出。

687
00:38:29,670 --> 00:38:31,300
好的，现在我们看到，

688
00:38:31,620 --> 00:38:33,320
我们添加了液态神经网络，

689
00:38:33,320 --> 00:38:35,380
我们有一个额外的自由度，

690
00:38:35,670 --> 00:38:39,890
这些网络可以设置它的敏感度，

691
00:38:40,030 --> 00:38:41,030
一个液态神经网络，

692
00:38:41,910 --> 00:38:45,370
取决于我们是不是转弯，是不是直走，

693
00:38:45,540 --> 00:38:50,210
如果你是直走，时间常数要比较谨慎，

694
00:38:50,210 --> 00:38:51,640
当你转弯的时候，

695
00:38:51,840 --> 00:38:52,655
所以你的神经网络，

696
00:38:52,655 --> 00:38:54,550
你想要更快，

697
00:38:54,690 --> 00:38:58,700
以便能够在那种事件中进行实际控制，

698
00:38:58,700 --> 00:38:59,680
当你转弯的时候，

699
00:39:00,060 --> 00:39:02,015
这就是你可以添加的程度，

700
00:39:02,015 --> 00:39:04,570
甚至在神经元层面上也可以解释这些系统。

701
00:39:05,640 --> 00:39:08,950
现在，让我们来看看液态神经网络的案例研究，

702
00:39:10,130 --> 00:39:14,670
通常情况下，你会看到自动驾驶应用程序的深度神经网络，

703
00:39:15,750 --> 00:39:19,010
我们在网络上有一个卷积堆栈，

704
00:39:19,010 --> 00:39:20,645
它们接收摄像头的输入，

705
00:39:20,645 --> 00:39:25,600
并在输出端输出一种转向角。

706
00:39:26,680 --> 00:39:28,790
这种神经网络，

707
00:39:28,870 --> 00:39:30,015
我们可以做的事情之一，

708
00:39:30,015 --> 00:39:32,720
首先，它们在这个系统中有很多参数，

709
00:39:33,420 --> 00:39:34,185
我们要做的是，

710
00:39:34,185 --> 00:39:38,240
我们想去掉这个神经网络的完全连通层，

711
00:39:38,470 --> 00:39:40,910
用递归神经网络过程来代替它，

712
00:39:41,290 --> 00:39:44,055
我们想取代它的一种递归神经网络过程，

713
00:39:44,055 --> 00:39:50,270
使用液态神经网络， LSTM 和正常的连续时间神经网络。

714
00:39:50,870 --> 00:39:52,530
现在，如果我替换这个，

715
00:39:52,640 --> 00:39:55,260
我最终会有四个不同的变体，

716
00:39:56,610 --> 00:39:57,640
这四种变体，

717
00:39:57,690 --> 00:39:59,405
其中之一被称为 NCP ，

718
00:39:59,405 --> 00:40:03,310
这是神经回路策略，具有一个四层架构，

719
00:40:03,630 --> 00:40:07,990
这个系统的每个节点都是由一个 LTC 神经元定义的，

720
00:40:08,370 --> 00:40:10,120
我刚才展示给你们的方程，

721
00:40:10,200 --> 00:40:13,090
它与网络的其他部分稀疏地连接在一起。

722
00:40:13,660 --> 00:40:15,810
所以我们这里有一个稀疏的神经网络结构，

723
00:40:16,070 --> 00:40:17,395
然后我们有一个神经网络，

724
00:40:17,395 --> 00:40:19,075
它以 LSDM 作为控制信号，

725
00:40:19,075 --> 00:40:21,450
它通过卷积神经网络接收感知。

726
00:40:22,280 --> 00:40:23,615
然后我们有 CT-RNN ，

727
00:40:23,615 --> 00:40:25,310
我们有一个卷积神经网络，

728
00:40:25,310 --> 00:40:29,110
现在我想向你展示这些不同类型的网络的驾驶性能，

729
00:40:29,400 --> 00:40:33,550
以及这些系统增加了什么样的特征。

730
00:40:33,960 --> 00:40:36,280
首先让我们来看看这些仪表板，

731
00:40:36,450 --> 00:40:38,680
在那里我向你展示了神经网络的卷积，

732
00:40:38,790 --> 00:40:40,840
然后是完全连接的层，

733
00:40:40,890 --> 00:40:43,820
一个正常的、非常标准的深度学习系统，

734
00:40:43,820 --> 00:40:47,650
它接收摄像头输入并已经学会了控制这辆车，

735
00:40:47,970 --> 00:40:52,450
好的，这些摄像头的输入和输出决定是驾驶决策。

736
00:40:52,990 --> 00:40:55,610
现在，在左下角，我们所看到的，

737
00:40:56,880 --> 00:40:59,465
我们看到了这个系统的决策过程，

738
00:40:59,465 --> 00:41:02,800
如果你意识到输入上有一点噪音，

739
00:41:02,940 --> 00:41:05,405
我在输入端添加了一些噪声，

740
00:41:05,405 --> 00:41:08,770
这样我们就可以看到这个过程决策的健壮性。

741
00:41:09,090 --> 00:41:09,940
正如我们所看到的，

742
00:41:10,530 --> 00:41:14,500
做出决策的较亮区域，

743
00:41:14,700 --> 00:41:16,870
是神经网络正在关注的，

744
00:41:17,895 --> 00:41:19,550
当它做出驾驶决定的时候。

745
00:41:20,180 --> 00:41:24,550
我们看到，注意力基本上分散在系统的顶部，有一点噪音。

746
00:41:25,380 --> 00:41:28,090
现在，如果你做同样的事情并增加噪声，

747
00:41:28,320 --> 00:41:35,930
我们就用 19 个液态神经元来替换那个完全连接的神经网络层，

748
00:41:36,880 --> 00:41:41,210
你可以得到相同环境的车道保持的性能，

749
00:41:41,440 --> 00:41:46,970
让系统的注意力集中在道路地平线上，

750
00:41:47,200 --> 00:41:49,370
就像我们实际驾驶的方式，

751
00:41:49,750 --> 00:41:51,470
所以，事实是，

752
00:41:52,280 --> 00:41:54,700
执行此任务所需的参数，

753
00:41:55,480 --> 00:42:00,630
19 个神经元，在神经网络上有一个非常小的卷积作为感知模型，

754
00:42:01,100 --> 00:42:02,365
这是吸引人的部分，

755
00:42:02,365 --> 00:42:06,780
我们从大脑获得的把感应偏见放在神经网络中。

756
00:42:07,040 --> 00:42:08,125
所以如果你建模，

757
00:42:08,125 --> 00:42:11,155
你有一组神经元，

758
00:42:11,155 --> 00:42:13,225
你可以通过它们的动态，

759
00:42:13,225 --> 00:42:14,050
你可以分析它们，

760
00:42:14,050 --> 00:42:15,900
你可以理解那个系统的过程。

761
00:42:16,530 --> 00:42:18,290
你得到的好处就像现实世界的好处，

762
00:42:18,290 --> 00:42:20,225
例如，如果在 x 轴上，

763
00:42:20,225 --> 00:42:21,610
当我增加噪音时，

764
00:42:22,320 --> 00:42:23,435
我增加了噪音，

765
00:42:23,435 --> 00:42:25,450
我增加了输入的噪声量，

766
00:42:25,890 --> 00:42:28,510
在 y 轴上我计算了输出，

767
00:42:28,830 --> 00:42:31,900
发生在驾驶过程中，撞车的次数，

768
00:42:31,950 --> 00:42:34,630
当网络想要把车开到外面时，

769
00:42:34,920 --> 00:42:37,120
我们看到这些是其他网络，

770
00:42:37,140 --> 00:42:40,600
我们在这里看到液态神经网络，

771
00:42:40,890 --> 00:42:43,780
将水平保持在极低的水平， LTC 。

772
00:42:44,070 --> 00:42:49,120
如果你看看这四种不同网络变体的关注图，

773
00:42:49,410 --> 00:42:53,230
当它们部署在环境中时，它们是如何做出驾驶决策的，

774
00:42:53,670 --> 00:42:58,450
我们看到，不同网络的注意力一致性是不同的，

775
00:42:58,920 --> 00:43:02,590
我们有一个液态神经网络，保持了它的关注点，

776
00:43:03,260 --> 00:43:05,780
这是这件事的好处之一，

777
00:43:05,780 --> 00:43:06,910
但随后我们会问为什么，

778
00:43:07,290 --> 00:43:12,520
为什么液态神经网络可以专注于实际任务，

779
00:43:12,690 --> 00:43:14,015
也就是这里的车道保持，

780
00:43:14,015 --> 00:43:17,390
没有驾驶，只有一个简单的驾驶例子，

781
00:43:17,390 --> 00:43:20,980
只有一条路，你想留在路上。

782
00:43:22,310 --> 00:43:22,710
然后，

783
00:43:25,080 --> 00:43:26,090
现在，就像我说的，

784
00:43:26,090 --> 00:43:30,430
通过液体神经网络学习的表示法更有因果性，

785
00:43:30,960 --> 00:43:32,165
所以这意味着它们可以，

786
00:43:32,165 --> 00:43:35,200
它们可以真正集中精力，找出任务的本质。

787
00:43:35,900 --> 00:43:38,670
然后如果你研究机器学习建模，

788
00:43:38,900 --> 00:43:42,190
统计建模就像是最起码的因果建模，

789
00:43:42,190 --> 00:43:43,890
就是你只是提取，

790
00:43:44,450 --> 00:43:47,010
这些是因果模型的分类，

791
00:43:47,420 --> 00:43:49,060
你在轴的底部所有的，

792
00:43:49,060 --> 00:43:51,780
你有可以从数据中学习的统计模型，

793
00:43:51,950 --> 00:43:56,970
但它们不能实际建立输入和输出之间的因果关系。

794
00:43:57,340 --> 00:44:00,085
我们可以拥有的最好的模型类型是物理模型，

795
00:44:00,085 --> 00:44:02,400
它描述了一个过程的确切动态，

796
00:44:02,600 --> 00:44:04,500
而不是因果模型，

797
00:44:04,700 --> 00:44:08,070
在中间，你可以看到一系列不同类型的因果模型，

798
00:44:08,450 --> 00:44:10,500
所以我们意识到的一件事是，

799
00:44:10,520 --> 00:44:16,410
液态神经网络是一种被称为动态因果模型的东西，

800
00:44:17,780 --> 00:44:22,770
动态因果模型是能够使其动态适应的模型，

801
00:44:23,920 --> 00:44:27,770
这样他们就可以提取一个任务的本质，

802
00:44:27,940 --> 00:44:33,080
并真正找出一个任务的输入输出关系，

803
00:44:33,370 --> 00:44:38,240
基于一个被这里的微分方程排除的机制。

804
00:44:38,410 --> 00:44:40,670
所以，它有参数 A B 和 C ，

805
00:44:40,960 --> 00:44:44,205
它们解释了对系统的内部干预，

806
00:44:44,205 --> 00:44:46,490
如果我在系统中间改变了一些东西，

807
00:44:46,810 --> 00:44:49,070
那里有一个机制，可以控制那个过程，

808
00:44:49,510 --> 00:44:53,960
如果某个东西来自系统的外部，干预系统的内部，

809
00:44:54,250 --> 00:44:56,390
那么你实际上会进入，

810
00:44:56,620 --> 00:44:59,570
你可以用动态因果模型来控制那种过程。

811
00:45:00,730 --> 00:45:02,665
现在，有一点，

812
00:45:02,665 --> 00:45:08,970
我想要讲一下神经网络的因果模型过程，

813
00:45:09,110 --> 00:45:12,570
基本上，一个微分方程式就可以形成一个因果结构，

814
00:45:13,360 --> 00:45:14,425
这是什么意思，

815
00:45:14,425 --> 00:45:17,485
这意味着它可以从目前的情况预测，

816
00:45:17,485 --> 00:45:21,040
我们可以预测一个过程的未来一步，

817
00:45:21,040 --> 00:45:22,230
那个时间的因果关系。

818
00:45:22,580 --> 00:45:23,725
另一件事是，

819
00:45:23,725 --> 00:45:26,130
如果我改变了一些东西或干预了一个系统，

820
00:45:26,600 --> 00:45:29,830
我如何能够真正控制那个干预，

821
00:45:29,830 --> 00:45:33,150
或者我能解释我在这个系统中的干预，

822
00:45:33,320 --> 00:45:35,070
所以这就构成了这两个点，

823
00:45:35,390 --> 00:45:40,260
能够说明未来制度的演变和干预，

824
00:45:40,600 --> 00:45:42,670
以及能够解释系统中的干预。

825
00:45:42,670 --> 00:45:43,860
所以，如果你有这两个模型，

826
00:45:44,060 --> 00:45:45,840
那么你就有了一个因果结构。

827
00:45:47,570 --> 00:45:51,610
所以，我跳过这一部分，

828
00:45:51,610 --> 00:45:52,920
我只是想告诉你，

829
00:45:53,060 --> 00:45:54,870
我的意思是，我想向你展示更多关于，

830
00:45:55,190 --> 00:46:00,720
你是如何推动这种液态网络和因果模型之间的联系的，

831
00:46:01,010 --> 00:46:01,945
但我分享这张幻灯片，

832
00:46:01,945 --> 00:46:02,620
为了让你们看到，

833
00:46:02,620 --> 00:46:06,210
明天还有一位教授会讲授这个主题，

834
00:46:06,230 --> 00:46:10,350
希望她能讲到这些部分。

835
00:46:11,980 --> 00:46:17,985
还有几个关于网络的性能，

836
00:46:17,985 --> 00:46:20,030
以及拥有因果模型的含义。

837
00:46:20,380 --> 00:46:21,540
现在，让我们来看看这个环境，

838
00:46:21,540 --> 00:46:22,820
我们训练了一些神经网络，

839
00:46:23,830 --> 00:46:29,450
这些神经网络是学习在非结构化环境中飞向目标的，

840
00:46:30,220 --> 00:46:31,910
所以我们收集了一些数据，

841
00:46:32,140 --> 00:46:34,100
我们训练了神经网络实例，

842
00:46:34,450 --> 00:46:35,790
然后我们测试了这个，

843
00:46:35,790 --> 00:46:38,415
然后我们得到了我们训练的神经网络，

844
00:46:38,415 --> 00:46:43,280
就像这些场景是无人机在森林里，

845
00:46:43,630 --> 00:46:46,430
无人机正在向目标导航。

846
00:46:46,480 --> 00:46:50,240
好的，现在我们从模拟的几条轨迹中收集数据，

847
00:46:50,500 --> 00:46:53,120
然后我们获取这些数据，

848
00:46:53,410 --> 00:46:54,380
我们训练神经网络，

849
00:46:54,850 --> 00:46:56,625
我们把神经网络带回无人机上，

850
00:46:56,625 --> 00:46:58,680
我们在无人机上对它们进行测试，

851
00:46:58,680 --> 00:47:02,780
看看自己能否学会导航这个任务，

852
00:47:03,100 --> 00:47:07,280
连编程任务的目的是什么都不用，

853
00:47:07,820 --> 00:47:11,560
基本上，任务的目标必须从数据本身中提取出来，

854
00:47:11,820 --> 00:47:13,580
正如我们在右边看到的，

855
00:47:13,580 --> 00:47:15,610
我们看到了这些网络的决策过程，

856
00:47:16,080 --> 00:47:19,570
液态神经网络学习专注于目标，

857
00:47:19,920 --> 00:47:21,365
当目标变得可见时，

858
00:47:21,365 --> 00:47:24,910
这意味着它实际上意识到这个过程中最重要的部分，

859
00:47:25,140 --> 00:47:26,630
真正专注于目标，

860
00:47:26,630 --> 00:47:32,600
即使存在一种系统的非结构化输入，

861
00:47:33,100 --> 00:47:37,640
现在，如果我们比较这个神经回路策略的注意图，

862
00:47:37,720 --> 00:47:42,440
这是第二列与其他注意图相比，

863
00:47:42,880 --> 00:47:46,430
我们看到，唯一从这个数据中学习的网络

864
00:47:46,630 --> 00:47:49,460
关注这个目标的是液态神经网络，

865
00:47:50,060 --> 00:47:52,040
这就是你所拥有的那种暗示，

866
00:47:52,040 --> 00:47:56,230
所以，你可以使用液态神经网络来了解任务的因果关系，

867
00:47:56,940 --> 00:48:02,590
与其他类型的神经网络相比，它的参数数量要少得多。

868
00:48:03,000 --> 00:48:04,445
现在，就像我告诉你的，

869
00:48:04,445 --> 00:48:07,180
两个神经元之间的关系，

870
00:48:07,900 --> 00:48:11,670
可以用一个由神经元方程和突触方程定义的微分方程来定义，

871
00:48:12,020 --> 00:48:15,870
我们最近解了这个微分方程，也是封闭形式的，

872
00:48:16,560 --> 00:48:19,100
然后这就产生了一种新型的神经网络，

873
00:48:19,810 --> 00:48:21,380
它也是一种封闭的形式，

874
00:48:21,610 --> 00:48:25,790
连续时间的神经网络，你叫它们 CFC ，

875
00:48:25,900 --> 00:48:27,500
这些是封闭形式的液态网络，

876
00:48:27,670 --> 00:48:29,180
它们有相同的行为，

877
00:48:29,500 --> 00:48:32,360
但它们定义的封闭形式。

878
00:48:32,900 --> 00:48:34,765
那么，这意味着什么，

879
00:48:34,765 --> 00:48:36,540
这意味着，如果我有一个微分方程，

880
00:48:36,740 --> 00:48:38,185
你可以看到最上面的 ODE ，

881
00:48:38,185 --> 00:48:40,290
如果我模拟这个 ODE ，

882
00:48:40,580 --> 00:48:46,980
闭合形式的解会给出和微分方程本身非常相同的行为，

883
00:48:47,210 --> 00:48:50,550
但它不需要任何数值解算器，

884
00:48:50,990 --> 00:48:54,840
所以它不需要任何形式的复杂的数值解算器，

885
00:48:54,890 --> 00:49:00,385
所以，你可以将液态神经网络扩展到更大的实例，

886
00:49:00,385 --> 00:49:04,650
如果你想在建模动态方面提高网络的性能。

887
00:49:05,290 --> 00:49:10,520
液态神经网络，我们在这里看到了一系列不同类型的高级递归网络，

888
00:49:10,870 --> 00:49:16,640
我们看到了闭合形式液态神经网络的变体和 LTC 本身，

889
00:49:16,840 --> 00:49:21,830
它们在模拟物理动态方面的表现明显好于其他系统。

890
00:49:22,970 --> 00:49:24,960
我想要说明的最后一件事是，

891
00:49:25,100 --> 00:49:31,110
理解因果关系和理解一个任务的因果关系

892
00:49:31,130 --> 00:49:33,000
和不能理解它之间的区别。

893
00:49:33,140 --> 00:49:35,020
现在你看到的是一架无人机，

894
00:49:35,020 --> 00:49:37,710
它是一个想要导航到目标的[中介]，

895
00:49:38,060 --> 00:49:39,270
环境中有一个目标，

896
00:49:39,560 --> 00:49:44,070
现在我们收集了一架无人机在这片森林中朝这个目标航行的痕迹，

897
00:49:45,020 --> 00:49:47,790
然后我们收集这些数据，

898
00:49:48,020 --> 00:49:49,770
然后训练神经网络，

899
00:49:49,970 --> 00:49:52,710
现在我们把无人机上的神经网络带回来，

900
00:49:52,820 --> 00:49:56,040
看看它们是否学会了向目标导航。

901
00:49:56,210 --> 00:49:59,220
现在，我将展示一个 LSTM 神经网络的性能，

902
00:50:01,080 --> 00:50:02,020
所以，正如我们看到的，

903
00:50:04,120 --> 00:50:07,140
LSTM 基本上完全是东张西望，

904
00:50:07,140 --> 00:50:09,650
不能真正控制无人机，

905
00:50:09,820 --> 00:50:11,870
如果你看一下系统的注意力地图，

906
00:50:12,250 --> 00:50:14,760
实际上可以看到整个地方，

907
00:50:14,760 --> 00:50:18,770
它没有真正从数据中意识到任务的目标，

908
00:50:18,820 --> 00:50:21,110
所以它不能真正联系任何东西，

909
00:50:21,130 --> 00:50:23,000
也不能从数据中学到有意义的东西。

910
00:50:24,080 --> 00:50:26,965
然后这里是在液态神经网络上的相同任务，

911
00:50:26,965 --> 00:50:28,560
请看这里的注意力图，

912
00:50:28,730 --> 00:50:32,280
因为无人机正在向那个目标移动，

913
00:50:33,260 --> 00:50:36,750
这是一种灵活性，

914
00:50:36,950 --> 00:50:42,720
你可以从神经网络中了解任务的实际原因和结果。

915
00:50:43,510 --> 00:50:45,650
现在，好的，我现在要结束了，

916
00:50:46,580 --> 00:50:47,700
我给你看了这些情节，

917
00:50:47,750 --> 00:50:49,980
我向你展示了有过度的参数化机制，

918
00:50:50,000 --> 00:50:55,485
我们有一个你可以在这个机制中获得好处的想法，

919
00:50:55,485 --> 00:51:00,920
我们对神经网络有什么样直观理解，理论理解，

920
00:51:01,420 --> 00:51:04,365
然后我向你展示了像液态神经网络这样的神经网络，

921
00:51:04,365 --> 00:51:06,110
它有来自大脑的归纳偏见，

922
00:51:06,550 --> 00:51:10,340
可以解决一些问题，

923
00:51:10,360 --> 00:51:14,990
例如，稳健性，它比超参数网络要小得多，

924
00:51:15,310 --> 00:51:18,860
所以，并不是说你必须总是戏剧性地过度参数化神经网络，

925
00:51:19,270 --> 00:51:24,050
你可以有归纳偏差来获得良好的性能。

926
00:51:24,580 --> 00:51:25,170
总结一下，

927
00:51:25,880 --> 00:51:27,245
健壮性法则是真实存在的，

928
00:51:27,245 --> 00:51:32,470
所以这是一个理论得出的东西是参数的数量，

929
00:51:32,670 --> 00:51:37,100
它必须很大，如果你想要有有效的维度，

930
00:51:37,100 --> 00:51:39,010
所以我们有一个想法，

931
00:51:39,120 --> 00:51:41,080
我将在这里谈论有效维度，

932
00:51:41,400 --> 00:51:44,945
过度参数化无疑提高了泛化和健壮性，

933
00:51:44,945 --> 00:51:47,230
但它存在一些社会技术挑战，

934
00:51:48,260 --> 00:51:51,325
所以，归纳偏见或[]架构，

935
00:51:51,325 --> 00:51:53,215
为什么我们有不同类型的架构，

936
00:51:53,215 --> 00:51:55,680
为什么研究大脑是一件好事，

937
00:51:55,820 --> 00:51:59,635
因为我们可以在设计神经网络时变得更聪明，

938
00:51:59,635 --> 00:52:03,360
而不仅仅是盲目地超参数化，

939
00:52:03,410 --> 00:52:08,350
所以我们可以把一些想法结合起来，真正了解正在发生的事情，

940
00:52:08,350 --> 00:52:13,830
液态神经网络，它们可以在过度参数化的机制之外实现健壮的表示学习，

941
00:52:14,330 --> 00:52:16,680
因为它们的原因机制，

942
00:52:17,000 --> 00:52:19,765
它们减少了网络的[]，

943
00:52:19,765 --> 00:52:21,475
所以这是我的猜测，

944
00:52:21,475 --> 00:52:24,970
我们必须真正思考这里的理论含义，

945
00:52:24,970 --> 00:52:26,340
但我认为，

946
00:52:26,780 --> 00:52:32,670
液态神经网络之所以能够通过或打破网络健壮性这一普遍规律，

947
00:52:33,220 --> 00:52:39,540
是因为它们可以从数据中提取出更好或更小的有效维度，

948
00:52:39,740 --> 00:52:40,860
所以你有数据集，

949
00:52:41,000 --> 00:52:45,630
如果有效维度被一个参数化的神经网络降低了，

950
00:52:46,070 --> 00:52:48,360
那么这个定律仍然成立。

951
00:52:48,710 --> 00:52:49,740
考虑到数据的数量。

952
00:52:49,970 --> 00:52:51,390
我的演讲到此结束，

953
00:52:51,710 --> 00:52:54,485
我在这里最后放了几个资源，

954
00:52:54,485 --> 00:52:56,530
如果你想接触到液态神经网络，

955
00:52:56,970 --> 00:52:59,345
我们已经整理了非常好的文档，

956
00:52:59,345 --> 00:53:03,790
我想你会喜欢把这些系统用于你自己的应用程序。

957
00:53:04,220 --> 00:53:05,130
谢谢大家的关注。

