1
00:00:09,460 --> 00:00:11,690
I'm really, really excited about this lecture,

2
00:00:11,830 --> 00:00:14,450
because as Alexander introduced yesterday,

3
00:00:15,580 --> 00:00:18,980
right now we're in this tremendous age of generative AI,

4
00:00:19,420 --> 00:00:23,630
and today we're going to learn the foundations of deep generative modeling,

5
00:00:23,890 --> 00:00:26,000
where we're going to talk about building systems,

6
00:00:26,590 --> 00:00:29,180
that can not only look for patterns in data,

7
00:00:29,710 --> 00:00:31,700
but can actually go a step beyond this

8
00:00:32,050 --> 00:00:36,530
to generate brand new data instances based on those learned patterns,

9
00:00:37,690 --> 00:00:40,830
this is an incredibly complex and powerful idea,

10
00:00:40,830 --> 00:00:41,610
and as I mentioned,

11
00:00:41,610 --> 00:00:43,610
it's a particular subset of deep learning,

12
00:00:43,990 --> 00:00:49,430
that has actually really exploded in the past couple of years and this year in particular.

13
00:00:50,540 --> 00:00:54,570
So to start, and to demonstrate how powerful these algorithms are,

14
00:00:55,130 --> 00:00:59,370
let me show you these three different faces,

15
00:01:01,010 --> 00:01:03,060
I want you to take a minute think,

16
00:01:04,400 --> 00:01:06,610
think about which face you think is real,

17
00:01:07,420 --> 00:01:09,210
raise your hand, if you think it's face A,

18
00:01:10,730 --> 00:01:12,000
okay, see a couple of people,

19
00:01:12,560 --> 00:01:13,260
Face B,

20
00:01:15,340 --> 00:01:16,190
many more people,

21
00:01:17,320 --> 00:01:18,020
face C,

22
00:01:21,060 --> 00:01:21,790
second place,

23
00:01:22,620 --> 00:01:25,540
well, the truth is that all of you are wrong,

24
00:01:26,670 --> 00:01:28,750
all three of these faces are fake,

25
00:01:29,820 --> 00:01:31,510
these people do not exist,

26
00:01:31,830 --> 00:01:34,960
these images were synthesized by deep generative models,

27
00:01:35,490 --> 00:01:37,510
trained on data of human faces

28
00:01:37,800 --> 00:01:40,660
and asked to produce new instances.

29
00:01:41,650 --> 00:01:46,580
Now, I think that this demonstration kind of demonstrates the power of these ideas

30
00:01:46,900 --> 00:01:49,310
and the power of this notion of generative modeling.

31
00:01:49,840 --> 00:01:53,720
So let's get a little more concrete about how we can formalize this.

32
00:01:54,690 --> 00:01:55,780
So far in this course,

33
00:01:55,950 --> 00:01:59,650
we've been looking at what we call problems of supervised learning,

34
00:02:00,390 --> 00:02:01,780
meaning that we're given data

35
00:02:02,370 --> 00:02:05,140
and associated with that data is a set of labels,

36
00:02:05,940 --> 00:02:11,180
our goal is to learn a function that maps that data to the labels,

37
00:02:11,770 --> 00:02:14,060
Now, we're in a course on deep learning,

38
00:02:14,140 --> 00:02:18,500
so we've been concerned with functional mappings that are defined by deep neural networks,

39
00:02:19,180 --> 00:02:21,230
but really, that function could be anything,

40
00:02:21,280 --> 00:02:22,430
neural networks are powerful,

41
00:02:22,510 --> 00:02:25,040
but we could use other techniques as well.

42
00:02:26,620 --> 00:02:30,110
In contrast, there's another class of problems in machine learning,

43
00:02:30,580 --> 00:02:33,080
that we refer to as unsupervised learning,

44
00:02:33,700 --> 00:02:35,690
where we take data,

45
00:02:36,130 --> 00:02:39,620
but now we're given only data, no labels,

46
00:02:40,060 --> 00:02:42,980
and our goal is to try to build some method,

47
00:02:43,390 --> 00:02:47,420
that can understand the hidden underlying structure of that data,

48
00:02:48,590 --> 00:02:50,245
what this allows us to do is,

49
00:02:50,245 --> 00:02:55,140
it gives us new insights into the foundational representation of the data

50
00:02:55,700 --> 00:02:57,060
and as we'll see later,

51
00:02:58,010 --> 00:03:00,960
actually enables us to generate new data instances.

52
00:03:01,790 --> 00:03:03,090
Now, this class of problems,

53
00:03:03,530 --> 00:03:06,210
this definition of unsupervised learning,

54
00:03:06,710 --> 00:03:09,960
captures the types of models that we're going to talk about today

55
00:03:10,250 --> 00:03:12,570
in the focus on generative modeling,

56
00:03:13,700 --> 00:03:15,960
which is an example of unsupervised learning

57
00:03:16,220 --> 00:03:19,650
and is united by this goal of the problem,

58
00:03:19,670 --> 00:03:22,530
where we're given only samples from a training set,

59
00:03:23,120 --> 00:03:24,820
and we want to learn a model,

60
00:03:24,900 --> 00:03:29,170
that represents the distribution of the data that the model is seeing.

61
00:03:30,270 --> 00:03:33,700
Generative modeling takes two general forms,

62
00:03:34,650 --> 00:03:36,430
first, density estimation

63
00:03:36,750 --> 00:03:38,440
and second, sample generation.

64
00:03:39,760 --> 00:03:41,090
In density estimation,

65
00:03:41,110 --> 00:03:44,630
the task is given some data examples,

66
00:03:45,490 --> 00:03:47,570
our goal is to train a model,

67
00:03:48,040 --> 00:03:51,470
that learns an underlying probability distribution,

68
00:03:52,180 --> 00:03:55,700
that describes where the data came from.

69
00:03:57,080 --> 00:03:58,170
With sample generation,

70
00:03:58,850 --> 00:04:00,450
the idea is similar,

71
00:04:00,560 --> 00:04:04,290
but the focus is more on actually generating new instances,

72
00:04:05,120 --> 00:04:07,560
our goal with sample generation is to,

73
00:04:07,670 --> 00:04:11,460
again, learn this model of this underlying probability distribution,

74
00:04:12,350 --> 00:04:15,175
but then use that model to sample from it

75
00:04:15,175 --> 00:04:16,980
and generate new instances,

76
00:04:17,330 --> 00:04:20,280
that are similar to the data that we've seen,

77
00:04:20,870 --> 00:04:25,560
approximately falling along, ideally that same real data distribution.

78
00:04:27,060 --> 00:04:30,520
Now, in both these cases of density estimation and sample generation,

79
00:04:31,260 --> 00:04:33,010
the underlying question is the same,

80
00:04:33,750 --> 00:04:37,030
our learning task is to try to build a model,

81
00:04:37,170 --> 00:04:39,580
that learns this probability distribution,

82
00:04:39,990 --> 00:04:44,260
that is as close as possible to the true data distribution.

83
00:04:46,540 --> 00:04:50,870
Okay, so with this definition and this concept of generative modeling,

84
00:04:51,430 --> 00:04:54,915
what are some ways that we can actually deploy generative modeling

85
00:04:54,915 --> 00:04:58,430
forward in the real world for high impact applications,

86
00:04:59,770 --> 00:05:04,185
well, part of the reason that generative models are so powerful is,

87
00:05:04,185 --> 00:05:09,410
that they have this ability to uncover the underlying features in a dataset

88
00:05:09,490 --> 00:05:11,480
and encode it in an efficient way.

89
00:05:12,190 --> 00:05:15,890
So, for example, if we're considering the problem of facial detection

90
00:05:16,270 --> 00:05:19,250
and we're given a dataset with many, many different faces,

91
00:05:20,230 --> 00:05:22,305
starting out without inspecting this data,

92
00:05:22,305 --> 00:05:26,510
we may not know what the distribution of faces in this dataset is,

93
00:05:26,710 --> 00:05:29,510
with respect to features we may be caring about,

94
00:05:29,770 --> 00:05:35,630
for example the pose of the head, clothing, glasses, skin tone, hair, etc,

95
00:05:36,860 --> 00:05:37,940
and it can be the case,

96
00:05:37,940 --> 00:05:42,340
that our training data may be very, very biased towards particular features

97
00:05:42,690 --> 00:05:44,740
without us even realizing this,

98
00:05:45,700 --> 00:05:46,970
using generative models,

99
00:05:47,110 --> 00:05:51,260
we can actually identify the distributions of these underlying features

100
00:05:51,280 --> 00:05:55,310
in a completely automatic way without any labeling,

101
00:05:55,980 --> 00:05:59,810
in order to understand what features may be overrepresented in the data,

102
00:06:00,460 --> 00:06:03,200
what features may be underrepresented in the data.

103
00:06:04,050 --> 00:06:08,615
And this is the focus of today and tomorrow's software labs,

104
00:06:08,615 --> 00:06:12,190
which are going to be part of the software lab competition,

105
00:06:12,930 --> 00:06:15,880
developing generative models that can do this task

106
00:06:16,200 --> 00:06:19,540
and using it to uncover and diagnose biases,

107
00:06:19,680 --> 00:06:22,630
that can exist within facial detection models.

108
00:06:25,050 --> 00:06:26,975
Another really powerful example is,

109
00:06:26,975 --> 00:06:31,540
in the case of outlier detection, identifying rare events.

110
00:06:32,340 --> 00:06:36,220
So, let's consider the example of self driving autonomous cars,

111
00:06:37,040 --> 00:06:40,290
with an autonomous car, let's say it's driving out in the real world,

112
00:06:40,790 --> 00:06:42,820
we really really want to make sure that,

113
00:06:42,820 --> 00:06:46,645
that car can be able to handle all the possible scenarios

114
00:06:46,645 --> 00:06:49,110
and all the possible cases it may encounter,

115
00:06:49,700 --> 00:06:53,430
including edge cases like a deer coming in front of the car

116
00:06:53,660 --> 00:06:55,740
or some unexpected rare events,

117
00:06:56,300 --> 00:06:59,340
not just, you know, the typical straight freeway driving,

118
00:06:59,450 --> 00:07:02,280
that it may see the majority of the time.

119
00:07:03,250 --> 00:07:04,400
With generative models,

120
00:07:04,600 --> 00:07:07,460
we can use this idea of density estimation

121
00:07:07,630 --> 00:07:14,120
to be able to identify rare and anomalous events within the training data

122
00:07:14,260 --> 00:07:15,900
and as they're occurring,

123
00:07:15,900 --> 00:07:17,900
as the model sees them, for the first time.

124
00:07:19,490 --> 00:07:25,290
So hopefully this paints this picture of what generative modeling the underlying concept is,

125
00:07:25,310 --> 00:07:26,815
and a couple of different ways

126
00:07:26,815 --> 00:07:33,060
in which we can actually deploy these ideas for powerful and impactful real world applications.

127
00:07:35,060 --> 00:07:39,550
In today's lecture, we're going to focus on a broad class of generative models,

128
00:07:39,550 --> 00:07:41,520
that we call latent variable models

129
00:07:42,050 --> 00:07:47,220
and specifically distill down into two subtypes of latent variable models.

130
00:07:48,740 --> 00:07:52,140
First things, first, I've introduced this term latent variable,

131
00:07:52,700 --> 00:07:57,030
but I haven't told you or described to you what that actually is,

132
00:07:58,350 --> 00:07:59,660
I think a great example,

133
00:07:59,660 --> 00:08:02,830
and one of my favorite examples throughout this entire course,

134
00:08:03,600 --> 00:08:05,980
that gets at this idea of the latent variable,

135
00:08:06,450 --> 00:08:09,220
is this little story from Plato's republic,

136
00:08:09,960 --> 00:08:12,340
which is known as the myth of the cave,

137
00:08:13,410 --> 00:08:14,200
in this myth,

138
00:08:14,340 --> 00:08:15,880
there is a group of prisoners,

139
00:08:16,380 --> 00:08:18,125
and as part of their punishment,

140
00:08:18,125 --> 00:08:20,080
they're constrained to face a wall,

141
00:08:20,970 --> 00:08:24,700
now the only things that prisoners can observe are

142
00:08:24,810 --> 00:08:30,220
shadows of objects that are passing in front of a fire that's behind them,

143
00:08:30,600 --> 00:08:35,440
and they're observing the casting of the shadows on the wall of this cave,

144
00:08:36,780 --> 00:08:37,610
to the prisoners,

145
00:08:37,610 --> 00:08:39,800
those shadows are the only things they see,

146
00:08:39,800 --> 00:08:41,960
their observations, they can measure them,

147
00:08:41,960 --> 00:08:42,910
they can give them names,

148
00:08:43,410 --> 00:08:45,280
because to them that's their reality,

149
00:08:46,380 --> 00:08:50,810
but they're unable to directly see the underlying objects,

150
00:08:50,810 --> 00:08:54,070
the true factors themselves, that are casting those shadows,

151
00:08:55,180 --> 00:08:59,150
those objects here are like latent variables in machine learning,

152
00:09:00,030 --> 00:09:01,690
they're not directly observable,

153
00:09:02,160 --> 00:09:06,580
but they are the true underlying features or explanatory factors,

154
00:09:06,720 --> 00:09:12,880
that create the observed differences and variables that we can see and observe.

155
00:09:15,030 --> 00:09:18,640
And this gets at the goal of generative modeling,

156
00:09:18,930 --> 00:09:22,330
which is to find ways that we can actually learn these hidden features,

157
00:09:22,440 --> 00:09:24,340
these underlying latent variables,

158
00:09:24,660 --> 00:09:28,750
even when we're only given observations of the observed data.

159
00:09:31,530 --> 00:09:35,240
So let's start by discussing a very simple generative model,

160
00:09:35,240 --> 00:09:39,640
that tries to do this through the idea of encoding the data input,

161
00:09:40,320 --> 00:09:43,220
the models we're going to talk about are called autoencoders,

162
00:09:44,050 --> 00:09:46,940
and to take a look at how an autoencoder works,

163
00:09:47,290 --> 00:09:48,710
we'll go through step by step,

164
00:09:49,330 --> 00:09:53,750
starting with the first step of taking some raw input data

165
00:09:54,430 --> 00:09:57,860
and passing it through a series of neural network layers,

166
00:09:58,820 --> 00:10:06,630
now, the output of this, of this first step is what we refer to as a low dimensional latent space,

167
00:10:07,070 --> 00:10:10,980
it's an encoded representation of those underlying features,

168
00:10:11,780 --> 00:10:15,640
and that's our goal in trying to train this model and predict those features,

169
00:10:17,120 --> 00:10:20,790
the reason a model like this is called an encoder or an autoencoder

170
00:10:21,080 --> 00:10:26,970
is that it's mapping the data X into this vector of latent variables z.

171
00:10:27,950 --> 00:10:29,845
Now, let's ask ourselves a question,

172
00:10:29,845 --> 00:10:30,840
let's pause for a moment,

173
00:10:31,720 --> 00:10:38,670
why may we care about having this latent variable vector z be in a low dimensional space,

174
00:10:40,620 --> 00:10:41,650
anyone have any ideas?

175
00:10:49,870 --> 00:10:53,690
Alright, maybe there are some ideas, yes.

176
00:10:57,070 --> 00:10:58,760
The suggestion was that it's more efficient,

177
00:10:58,810 --> 00:11:00,975
yes, that gets at it,

178
00:11:00,975 --> 00:11:02,360
the heart of the, of the question.

179
00:11:02,920 --> 00:11:05,985
The idea of having that low dimensional latent space is that,

180
00:11:05,985 --> 00:11:11,385
it's a very efficient, compact encoding of the rich, high dimensional data,

181
00:11:11,385 --> 00:11:12,500
that we may start with.

182
00:11:13,410 --> 00:11:16,175
As you pointed out, what this means is that,

183
00:11:16,175 --> 00:11:21,100
we're able to compress data into this small feature representation of vector,

184
00:11:22,380 --> 00:11:25,390
that captures this compactness and richness

185
00:11:25,890 --> 00:11:28,990
without requiring so much memory or so much storage.

186
00:11:30,250 --> 00:11:34,670
So how do we actually train the network to learn this latent variable vector,

187
00:11:36,270 --> 00:11:37,895
since we don't have training data,

188
00:11:37,895 --> 00:11:41,110
we can't explicitly observe these latent variables x,

189
00:11:41,730 --> 00:11:43,930
we need to do something more clever,

190
00:11:44,770 --> 00:11:46,725
what the autoencoder does is

191
00:11:46,725 --> 00:11:54,650
it builds a way to decode this latent variable vector back up to the original data space,

192
00:11:55,300 --> 00:12:00,830
trying to reconstruct the original image from that compressed, efficient latent encoding.

193
00:12:01,480 --> 00:12:05,030
And once again, we can use a series of neural network layers,

194
00:12:05,350 --> 00:12:08,270
such as convolutional layers, fully connected layers,

195
00:12:08,590 --> 00:12:14,510
but now to map back from that lower dimensional space back upwards to the input space,

196
00:12:15,880 --> 00:12:20,870
this generates a reconstructed output, which we can denote as x hat,

197
00:12:21,400 --> 00:12:25,730
since it's an imperfect reconstruction of our original input data.

198
00:12:27,070 --> 00:12:28,250
To train this network,

199
00:12:28,990 --> 00:12:30,380
all we have to do is

200
00:12:30,490 --> 00:12:34,610
compare the outputted reconstruction and the original input data

201
00:12:34,900 --> 00:12:38,180
and say, how do we make these as similar as possible,

202
00:12:38,350 --> 00:12:43,400
we can minimize the distance between that input and our reconstructed output.

203
00:12:44,080 --> 00:12:45,380
So, for example, for an image,

204
00:12:45,850 --> 00:12:52,190
we can compare the pixel wise difference between the input data and the reconstructed output,

205
00:12:52,450 --> 00:12:56,510
just subtracting the images from one another and squaring that difference

206
00:12:56,830 --> 00:13:02,510
to capture the pixel wise divergence between the input and the reconstruction.

207
00:13:04,990 --> 00:13:07,290
What I hope you'll notice and appreciate is

208
00:13:07,290 --> 00:13:08,840
in that definition of the loss,

209
00:13:09,790 --> 00:13:11,930
it doesn't require any labels,

210
00:13:11,950 --> 00:13:14,670
the only components of that loss are

211
00:13:14,670 --> 00:13:19,460
the original input data x and the reconstructed output x hat.

212
00:13:21,280 --> 00:13:24,120
So I've simplified now this diagram

213
00:13:24,120 --> 00:13:27,570
by abstracting away those individual neural network layers

214
00:13:27,570 --> 00:13:31,040
in both the encoder and decoder components of this.

215
00:13:32,000 --> 00:13:38,730
And again, this idea of not requiring any labels gets back to the idea of unsupervised learning,

216
00:13:39,290 --> 00:13:45,180
since what we've done is we've been able to learn an encoded quantity, our latent variables,

217
00:13:45,650 --> 00:13:49,110
that we cannot observe without any explicit labels,

218
00:13:49,310 --> 00:13:51,840
all we started from was the raw data itself.

219
00:13:53,790 --> 00:13:57,460
It turns out that as as the question and answer got out,

220
00:13:57,660 --> 00:14:02,075
that dimensionality of the latent space has a huge impact

221
00:14:02,075 --> 00:14:08,860
on the quality of the generated reconstructions and how compressed that information bottleneck is.

222
00:14:10,020 --> 00:14:12,040
Autoencoding is a form of compression,

223
00:14:12,300 --> 00:14:15,520
and so the lower the dimensionality of the latent space,

224
00:14:15,990 --> 00:14:19,270
the less good our reconstructions are going to be,

225
00:14:19,920 --> 00:14:21,980
but the higher the dimensionality,

226
00:14:22,000 --> 00:14:25,730
the more, the less efficient that encoding is going to be.

227
00:14:27,440 --> 00:14:29,760
So to summarize this first part,

228
00:14:29,990 --> 00:14:35,400
this idea of an autoencoder is using this bottleneck, compressed, hidden latent layer

229
00:14:35,750 --> 00:14:41,160
to try to bring the network down to learn a compact, efficient representation of the data,

230
00:14:42,000 --> 00:14:44,000
we don't require any labels,

231
00:14:44,000 --> 00:14:45,610
this is completely unsupervised,

232
00:14:46,080 --> 00:14:47,240
and so in this way,

233
00:14:47,240 --> 00:14:52,180
we're able to automatically encode information within the data itself

234
00:14:52,200 --> 00:14:58,440
to learn this latent space, autoencoding information, autoencoding data.

235
00:14:59,960 --> 00:15:02,460
Now, this is a pretty simple model,

236
00:15:03,200 --> 00:15:10,170
and it turns out that in practice, this idea of self encoding or autoencoding has a bit of a twist on it

237
00:15:10,520 --> 00:15:13,950
to allow us to actually generate new examples,

238
00:15:14,090 --> 00:15:17,790
that are not only reconstructions of the input data itself.

239
00:15:18,400 --> 00:15:22,910
And this leads us to the concept of variational autoencoders or VAEs,

240
00:15:24,620 --> 00:15:27,330
with the traditional autoencoder that we just saw,

241
00:15:27,950 --> 00:15:31,140
if we pay closer attention to the latent layer,

242
00:15:31,580 --> 00:15:34,230
which is shown in that orange salmon color,

243
00:15:35,150 --> 00:15:39,000
that latent layer is just a normal layer in the neural network,

244
00:15:39,350 --> 00:15:41,340
it's completely deterministic,

245
00:15:41,850 --> 00:15:44,290
what that means is once we've trained the network,

246
00:15:44,370 --> 00:15:45,670
once the weights are set,

247
00:15:46,110 --> 00:15:48,700
anytime we pass a given input in

248
00:15:49,110 --> 00:15:52,600
and go back through the latent layer, decode back out,

249
00:15:52,800 --> 00:15:55,300
we're going to get the same exact reconstruction,

250
00:15:55,650 --> 00:15:56,800
the weights aren't changing,

251
00:15:57,030 --> 00:15:58,270
it's deterministic.

252
00:15:59,230 --> 00:15:59,900
In contrast,

253
00:16:01,060 --> 00:16:06,895
variational autoencoders, VAEs introduce an element of randomness,

254
00:16:06,895 --> 00:16:10,680
a probabilistic twist on this idea of autoencoding,

255
00:16:11,240 --> 00:16:18,040
what this will allow us to do is to actually generate new images, similar to or new data instances,

256
00:16:18,330 --> 00:16:20,140
that are similar to the input data,

257
00:16:20,610 --> 00:16:23,770
but not forced to be strict reconstructions.

258
00:16:24,870 --> 00:16:27,520
In practice, with a variational autoencoder,

259
00:16:27,870 --> 00:16:33,460
we've replaced that single deterministic layer with a random sampling operation,

260
00:16:35,380 --> 00:16:39,320
now, instead of learning just the latent variables directly themselves,

261
00:16:39,760 --> 00:16:44,240
for each latent variable, we define a mean and a standard deviation,

262
00:16:44,680 --> 00:16:48,680
that captures a probability distribution over that latent variable.

263
00:16:50,440 --> 00:16:51,240
What we've done is,

264
00:16:51,240 --> 00:16:53,900
we've gone from a single vector of latent variable z

265
00:16:54,340 --> 00:16:59,930
to a vector of means μ and a vector of standard deviations σ,

266
00:17:00,160 --> 00:17:04,790
that parameterize the probability distributions around those latent variables.

267
00:17:06,520 --> 00:17:08,085
what this will allow us to do is

268
00:17:08,085 --> 00:17:13,010
now sample using this element of randomness, this element of probability,

269
00:17:13,510 --> 00:17:18,350
to then obtain a probabilistic representation of the latent space itself.

270
00:17:19,590 --> 00:17:21,005
As you hopefully can tell, right,

271
00:17:21,005 --> 00:17:24,400
this is very, very, very similar to the autoencoder itself,

272
00:17:24,840 --> 00:17:27,400
but we've just added this probabilistic twist,

273
00:17:27,720 --> 00:17:30,280
where we can sample in that intermediate space

274
00:17:30,930 --> 00:17:33,550
to get these samples of latent variables.

275
00:17:36,020 --> 00:17:41,930
Okay, now, to get a little more into the depth of how this is actually learned,

276
00:17:41,930 --> 00:17:43,270
how this is actually trained,

277
00:17:44,220 --> 00:17:45,610
with defining the VAE,

278
00:17:46,230 --> 00:17:48,790
we've eliminated this deterministic nature

279
00:17:49,380 --> 00:17:53,680
to now have these encoders and decoders that are probabilistic,

280
00:17:54,420 --> 00:18:00,730
the encoder is computing a probability distribution of the latent variable z,

281
00:18:00,990 --> 00:18:02,830
given input data x,

282
00:18:03,680 --> 00:18:06,130
while the decoder is doing the inverse,

283
00:18:06,510 --> 00:18:11,530
trying to learn a probability distribution back in the input data space,

284
00:18:11,970 --> 00:18:14,290
given the latent variables z,

285
00:18:15,200 --> 00:18:19,350
and we define separate sets of weights Φ and θ,

286
00:18:19,430 --> 00:18:25,290
to define the network weights for the encoder and decoder components of the v.

287
00:18:27,370 --> 00:18:29,990
All right, so when we get now

288
00:18:30,070 --> 00:18:34,520
to how we actually optimize and learn the network weights in the VAE,

289
00:18:35,440 --> 00:18:37,710
first step is to define a loss function, right,

290
00:18:37,710 --> 00:18:40,370
that's the core element to training a neural network,

291
00:18:41,490 --> 00:18:46,990
our loss is going to be a function of the data and a function of the neural network weights,

292
00:18:47,010 --> 00:18:47,770
just like before,

293
00:18:48,730 --> 00:18:53,390
but we have these two components, these two terms that define our VAE loss,

294
00:18:54,270 --> 00:18:57,220
first, we see the reconstruction loss just like before,

295
00:18:57,840 --> 00:19:02,920
where the goal is to capture the difference between our input data and the reconstructed output,

296
00:19:03,680 --> 00:19:07,440
and now for the VAE, we've introduced a second term to the loss,

297
00:19:07,970 --> 00:19:10,260
what we call the regularization term,

298
00:19:11,210 --> 00:19:14,790
often, you'll maybe even see this referred to as a VAE loss

299
00:19:15,680 --> 00:19:23,190
and we'll go into, we'll go into describing what this regularization term means and what it's doing.

300
00:19:25,420 --> 00:19:29,660
To do that and to understand, remember and, and keep in mind,

301
00:19:30,100 --> 00:19:32,210
that in all neural network operations,

302
00:19:32,380 --> 00:19:35,900
our goal is to try to optimize the network weights

303
00:19:36,130 --> 00:19:41,360
with respect to the data, with respect to minimizing this objective loss,

304
00:19:42,140 --> 00:19:46,250
and so here we're concerned with the network weights Φ and θ,

305
00:19:46,250 --> 00:19:49,930
that define the weights of the encoder and the decoder.

306
00:19:51,300 --> 00:19:52,870
We consider these two terms,

307
00:19:53,550 --> 00:19:55,300
first, the reconstruction loss,

308
00:19:56,160 --> 00:20:00,190
again the reconstruction loss is very, very similar, same as before,

309
00:20:00,810 --> 00:20:03,730
you can think of it as the error or the likelihood,

310
00:20:03,900 --> 00:20:08,920
that effectively captures the difference between your input and your outputs,

311
00:20:09,240 --> 00:20:12,220
and again, we can train this in an unsupervised way,

312
00:20:12,420 --> 00:20:16,990
not requiring any labels to force the latent space and the network

313
00:20:17,070 --> 00:20:20,200
to learn how to effectively reconstruct the input data.

314
00:20:21,880 --> 00:20:23,835
The second term, the regularization term,

315
00:20:23,835 --> 00:20:26,145
is now where things get a bit more interesting,

316
00:20:26,145 --> 00:20:29,630
so let's go on into this in a little bit more detail.

317
00:20:31,000 --> 00:20:33,050
Because we have this probability distribution

318
00:20:34,390 --> 00:20:39,380
and we're trying to compute this encoding and then decode back up,

319
00:20:40,320 --> 00:20:42,730
as part of regularizing,

320
00:20:43,470 --> 00:20:47,680
we want to take that inference over the latent distribution

321
00:20:48,360 --> 00:20:51,010
and constrain it to behave nicely, if you will,

322
00:20:51,660 --> 00:20:53,390
the way we do that is

323
00:20:53,390 --> 00:20:56,320
we place what we call a prior on the latent distribution,

324
00:20:57,090 --> 00:21:03,880
and what this is is some initial hypothesis or guess about what that latent variable space may look like,

325
00:21:04,530 --> 00:21:08,960
this helps us and helps the network to enforce a latent space

326
00:21:08,960 --> 00:21:11,680
that roughly tries to follow this prior distribution,

327
00:21:13,050 --> 00:21:16,420
and this prior is denoted as p of z, right,

328
00:21:17,470 --> 00:21:21,590
that term D, that's effectively the regularization term,

329
00:21:22,090 --> 00:21:26,270
it's capturing a distance between our encoding of the latent variables

330
00:21:26,530 --> 00:21:32,090
and our prior hypothesis about what the structure of that latent space should look like,

331
00:21:32,830 --> 00:21:34,275
so over the course of training,

332
00:21:34,275 --> 00:21:36,270
we're trying to enforce that,

333
00:21:36,270 --> 00:21:44,240
each of those latent variables adapts a, adapts a probability distribution that's similar to that prior.

334
00:21:46,790 --> 00:21:51,600
A common choice when training VAEs and developing these models is

335
00:21:51,920 --> 00:21:57,780
to enforce the latent variables to be roughly standard normal gouging distributions,

336
00:21:58,670 --> 00:22:02,070
meaning that they are centered around mean zero

337
00:22:02,180 --> 00:22:04,170
and they have a standard deviation of one,

338
00:22:05,300 --> 00:22:06,895
what this allows us to do is

339
00:22:06,895 --> 00:22:13,770
to encourage the encoder to put the latent variables roughly around a centered space,

340
00:22:14,540 --> 00:22:16,500
distributing the encoding smoothly,

341
00:22:16,910 --> 00:22:22,380
so that we don't get too much divergence away from that smooth space,

342
00:22:23,240 --> 00:22:28,620
which can occur if the network tries to cheat and try to simply memorize the data,

343
00:22:30,240 --> 00:22:34,300
by placing the gaussian standard normal prior on the latent space,

344
00:22:34,890 --> 00:22:37,840
we can define a concrete mathematical term,

345
00:22:38,190 --> 00:22:45,130
that captures the distance the divergence between our encoded latent variables and this prior,

346
00:22:45,930 --> 00:22:48,940
and this is called the KL divergence,

347
00:22:49,860 --> 00:22:52,090
when our prior is a standard normal,

348
00:22:52,680 --> 00:22:57,790
the KL divergence takes the form of the equation that I'm showing up on the screen,

349
00:22:58,710 --> 00:23:03,490
but what I want you to really get away come away with is that,

350
00:23:03,840 --> 00:23:10,330
the concept of trying to smooth things out and to capture this divergence

351
00:23:10,500 --> 00:23:13,570
and this difference between the prior and the latent encoding,

352
00:23:13,650 --> 00:23:16,150
is all this kl term is trying to capture.

353
00:23:17,680 --> 00:23:21,080
So it's a bit of math, and I I acknowledge that,

354
00:23:21,310 --> 00:23:23,805
but what I want to next go into is

355
00:23:23,805 --> 00:23:27,650
really what is the intuition behind this regularization operation,

356
00:23:28,420 --> 00:23:29,805
why do we do this

357
00:23:29,805 --> 00:23:33,860
and why does the normal prior, in particular, work effectively for VAEs.

358
00:23:34,960 --> 00:23:39,800
So let's consider what properties we want our latent space to adopt

359
00:23:39,940 --> 00:23:41,990
and for this regularization to achieve,

360
00:23:43,040 --> 00:23:45,600
the first is this goal of continuity,

361
00:23:46,280 --> 00:23:49,890
we don't what we mean by continuity is that,

362
00:23:50,120 --> 00:23:53,340
if there are points in the latent space that are close together,

363
00:23:54,170 --> 00:23:56,160
ideally after decoding,

364
00:23:56,360 --> 00:24:00,060
we should recover two reconstructions that are similar in content,

365
00:24:00,440 --> 00:24:02,310
that make sense that they're close together.

366
00:24:03,310 --> 00:24:06,500
The second key property is this idea of completeness,

367
00:24:07,340 --> 00:24:09,690
we don't want there to be gaps in the latent space,

368
00:24:09,980 --> 00:24:13,675
we want to be able to decode and sample from the latent space

369
00:24:13,675 --> 00:24:16,350
in a way that is smooth and a way that is connected.

370
00:24:17,940 --> 00:24:19,120
To get more concrete,

371
00:24:20,760 --> 00:24:25,360
let's ask what could be the consequences of not regularizing our latent space at all,

372
00:24:26,100 --> 00:24:28,390
well, if we don't regularize,

373
00:24:28,590 --> 00:24:30,305
we can end up with instances,

374
00:24:30,305 --> 00:24:33,130
where there are points that are close in the latent space,

375
00:24:33,510 --> 00:24:37,960
but don't end up with similar decodings or similar reconstructions,

376
00:24:38,790 --> 00:24:44,140
similarly, we could have points that don't lead to meaningful reconstructions at all,

377
00:24:44,430 --> 00:24:45,680
they're somehow encoded,

378
00:24:45,680 --> 00:24:47,800
but we can't decode effectively.

379
00:24:49,440 --> 00:24:54,850
Regularization allows us to realize points that end up close into latent space

380
00:24:55,320 --> 00:24:59,920
and also are similarly reconstructed and meaningfully reconstructed.

381
00:25:02,460 --> 00:25:05,830
Okay, so continuing with this example,

382
00:25:05,970 --> 00:25:10,445
the example that I showed there and I didn't get into details,

383
00:25:10,445 --> 00:25:13,300
was showing these shapes, these shapes of different colors

384
00:25:13,560 --> 00:25:17,320
and that were trying to be encoded in some lower dimensional space,

385
00:25:19,090 --> 00:25:20,300
with regularization,

386
00:25:21,610 --> 00:25:27,660
we are able to achieve this by trying to minimize that regularization term,

387
00:25:27,660 --> 00:25:35,240
it's not sufficient to just employ the reconstruction loss alone to achieve this continuity and this completeness,

388
00:25:36,730 --> 00:25:39,470
because of the fact that without regularization,

389
00:25:39,550 --> 00:25:46,400
just encoding and reconstructing does not guarantee the properties of continuity and completeness,

390
00:25:47,970 --> 00:25:49,210
we overcome this,

391
00:25:50,650 --> 00:25:57,870
these issues of having potentially pointed distributions, having discontinuities, having disparate means,

392
00:25:57,870 --> 00:26:01,820
that could end up in the latent space without the effect of regularization,

393
00:26:02,880 --> 00:26:03,935
we overcome this,

394
00:26:03,935 --> 00:26:13,420
by now regularizing the mean and the variance of the encoded latent distributions according to that normal prior,

395
00:26:14,440 --> 00:26:21,980
what this allows is for the learned distributions of those latent variables to effectively overlap in the latent space,

396
00:26:22,390 --> 00:26:29,000
because everything is regularized to have, according to this prior, of mean zero, standard deviation one,

397
00:26:29,650 --> 00:26:31,070
and that centers the means,

398
00:26:31,940 --> 00:26:37,570
regularizes the variances for each of those independent latent variable distributions.

399
00:26:38,930 --> 00:26:43,150
Together, the effect of this regularization in net is that

400
00:26:43,150 --> 00:26:46,590
we can achieve continuity and completeness in the latent space,

401
00:26:47,480 --> 00:26:53,760
points and distances that are close should correspond to similar reconstructions that we get out.

402
00:26:55,040 --> 00:26:58,560
So hopefully this gets at some of the intuition

403
00:26:58,790 --> 00:27:02,820
behind the idea of the VAE, behind the idea of the regularization

404
00:27:03,140 --> 00:27:07,500
and trying to enforce the structured normal prior on the latent space.

405
00:27:09,500 --> 00:27:10,470
With this in hand,

406
00:27:10,640 --> 00:27:12,720
with the two components of our loss function

407
00:27:13,370 --> 00:27:19,260
reconstructing the inputs, regularizing learning to try to achieve continuity and completeness,

408
00:27:19,760 --> 00:27:23,880
we can now think about how we define a forward pass through the network,

409
00:27:24,350 --> 00:27:26,220
going from an input example

410
00:27:26,780 --> 00:27:31,770
and being able to decode and sample from the latent variables to look at new examples.

411
00:27:32,970 --> 00:27:34,505
Our last critical step is

412
00:27:34,505 --> 00:27:39,760
how the actual back propagation training algorithm is defined and how we achieve this,

413
00:27:41,060 --> 00:27:45,870
the key, as I introduce with VAEs, is this notion of randomness of sampling

414
00:27:46,220 --> 00:27:52,290
that we have introduced by defining these probability distributions over each of the latent variables,

415
00:27:53,390 --> 00:27:55,375
the problem this gives us is that,

416
00:27:55,375 --> 00:28:00,960
we cannot back propagate directly through anything that has an element of sampling,

417
00:28:01,280 --> 00:28:03,630
anything that has an element of randomness,

418
00:28:05,220 --> 00:28:10,180
back propagation requires completely deterministic nodes, deterministic layers

419
00:28:10,290 --> 00:28:16,030
to be able to successfully apply gradient descent and the back propagation algorithm.

420
00:28:17,800 --> 00:28:22,845
The breakthrough idea that enabled VAE to be trained completely end to end was

421
00:28:22,845 --> 00:28:28,010
this idea of reparameterization within that sampling layer,

422
00:28:28,860 --> 00:28:32,435
and I'll give you the key idea about how this operation works,

423
00:28:32,435 --> 00:28:35,080
it's actually really quite level, quite clever.

424
00:28:36,270 --> 00:28:40,720
So, as I said, when we have a notion of randomness of probability,

425
00:28:41,310 --> 00:28:44,140
we can't sample directly through that layer,

426
00:28:45,800 --> 00:28:47,610
instead, with reparameterization,

427
00:28:47,960 --> 00:28:53,400
what we do is we redefine how a latent variable vector is sampled,

428
00:28:54,040 --> 00:28:57,570
as a sum of a fixed deterministic mean μ,

429
00:28:58,430 --> 00:29:02,100
a fixed vector of standard deviation σ,

430
00:29:02,570 --> 00:29:11,010
and now the trick is that we divert all the randomness, all the sampling to a random constant ε,

431
00:29:11,480 --> 00:29:14,370
that's drawn from a normal distribution,

432
00:29:15,470 --> 00:29:17,730
so mean itself is fixed,

433
00:29:18,170 --> 00:29:19,560
standard deviation is fixed,

434
00:29:19,850 --> 00:29:24,510
all the randomness and the sampling occurs according to that ε constant,

435
00:29:25,330 --> 00:29:29,990
we can then scale the mean and standard deviation by that random constant

436
00:29:30,490 --> 00:29:35,450
to re-achieve the sampling operation within the latent variables themselves.

437
00:29:37,050 --> 00:29:38,390
What this actually looks like,

438
00:29:38,390 --> 00:29:45,700
and an illustration that breaks down this concept of reparameterization and divergence, is as follows.

439
00:29:46,550 --> 00:29:48,120
So looking, looking here, right,

440
00:29:48,350 --> 00:29:49,420
what I've shown is,

441
00:29:49,420 --> 00:29:56,730
these completely deterministic steps in blue and the sampling random steps in orange,

442
00:29:57,650 --> 00:30:04,470
originally, if our latent variables are what effectively are capturing the randomness, the sampling themselves,

443
00:30:05,150 --> 00:30:06,205
we have this problem,

444
00:30:06,205 --> 00:30:08,080
in that we can't back propagate,

445
00:30:08,080 --> 00:30:13,620
we can't train directly through anything that has stochasticity that has randomness,

446
00:30:14,680 --> 00:30:18,240
what reparameterization allows us to do is,

447
00:30:18,240 --> 00:30:19,820
it shifts this diagram,

448
00:30:20,170 --> 00:30:24,980
where now we've completely diverted that sampling operation off to the side,

449
00:30:25,510 --> 00:30:27,260
to this constant ε,

450
00:30:27,670 --> 00:30:29,510
which is drawn from a normal prior,

451
00:30:30,220 --> 00:30:33,050
and now when we look back at our latent variable,

452
00:30:33,370 --> 00:30:37,370
it is deterministic with respect to that sampling operation,

453
00:30:38,580 --> 00:30:39,695
what this means is that,

454
00:30:39,695 --> 00:30:44,230
we can back propagate to update our network weights completely end to end,

455
00:30:45,210 --> 00:30:51,760
without having to worry about direct randomness, direct stochasticity within those latent variables z,

456
00:30:52,960 --> 00:30:54,770
this trick is really, really powerful,

457
00:30:54,910 --> 00:31:03,050
because it enabled the ability to train these VAEs completely end to end in through back propagation algorithm.

458
00:31:05,070 --> 00:31:10,030
Alright, so at this point, we've gone through the core architecture of VAEs,

459
00:31:10,530 --> 00:31:12,730
we've introduced these two terms of the loss,

460
00:31:12,780 --> 00:31:14,860
we've seen how we can train it end to end.

461
00:31:15,640 --> 00:31:19,245
Now, let's consider what these latent variables are actually capturing

462
00:31:19,245 --> 00:31:20,060
and what they represent,

463
00:31:22,510 --> 00:31:25,490
when we impose this distributional prior,

464
00:31:26,290 --> 00:31:30,230
what it allows us to do is to sample effectively from the latent space

465
00:31:30,820 --> 00:31:35,870
and actually slowly perturb the value of single latent variables,

466
00:31:36,460 --> 00:31:37,760
keeping the other ones fixed,

467
00:31:38,650 --> 00:31:40,335
and what you can observe,

468
00:31:40,335 --> 00:31:42,285
and what you can see here is that

469
00:31:42,285 --> 00:31:46,220
by doing that perturbation that tuning of the value of the latent variables,

470
00:31:47,280 --> 00:31:50,440
we can run the decoder of the VAE every time,

471
00:31:50,730 --> 00:31:53,710
reconstruct the output every time we do that tuning,

472
00:31:54,300 --> 00:31:59,060
and what you'll see hopefully with this example with the face is that,

473
00:31:59,060 --> 00:32:05,680
an individual latent variable is capturing something semantically informative, something meaningful,

474
00:32:06,480 --> 00:32:09,430
and we see that by this perturbation, by this tuning,

475
00:32:10,110 --> 00:32:14,450
in this example, the face, as you hopefully can appreciate, is shifting,

476
00:32:14,450 --> 00:32:15,700
the pose is shifting,

477
00:32:15,930 --> 00:32:20,350
and all this is driven by is the perturbation of a single latent variable,

478
00:32:21,280 --> 00:32:23,240
tuning the value of that latent variable

479
00:32:23,500 --> 00:32:26,870
and seeing how that affects the decoded reconstruction.

480
00:32:28,160 --> 00:32:34,620
The network is actually able to learn these different encoded features, these different latent variables,

481
00:32:35,210 --> 00:32:38,910
such that by perturbing the values of them individually,

482
00:32:39,500 --> 00:32:45,030
we can interpret and make sense of what those latent variables mean and what they represent.

483
00:32:46,750 --> 00:32:48,620
To make this more concrete,

484
00:32:49,720 --> 00:32:53,895
we can consider even multiple latent variables simultaneously,

485
00:32:53,895 --> 00:32:55,370
compare one against the other,

486
00:32:55,930 --> 00:33:00,740
and ideally, we want those latent features to be as independent as possible

487
00:33:01,270 --> 00:33:07,760
in order to get at the most compact and richest representation and compact encoding.

488
00:33:08,320 --> 00:33:10,590
So here again, in this example of faces,

489
00:33:11,030 --> 00:33:13,020
we're walking along two axis,

490
00:33:13,940 --> 00:33:15,880
head pose on the x axis

491
00:33:16,260 --> 00:33:21,070
and what appears to be kind of a notion of a smile on the y axis.

492
00:33:21,650 --> 00:33:22,740
And you can see that,

493
00:33:22,910 --> 00:33:24,360
with these reconstructions,

494
00:33:24,680 --> 00:33:26,670
we can actually perturb these features

495
00:33:27,080 --> 00:33:32,760
to be able to perturb the end effect in the reconstructed space.

496
00:33:34,450 --> 00:33:37,070
And so ultimately, with with VAE,

497
00:33:37,210 --> 00:33:43,040
our goal is to try to enforce as much information to be captured in that encoding as possible,

498
00:33:43,750 --> 00:33:48,920
we want these latent features to be independent and ideally disentangled.

499
00:33:50,120 --> 00:33:54,085
it turns out that there is a very clever and simple way

500
00:33:54,085 --> 00:33:58,920
to try to encourage this independence and this disentanglement,

501
00:33:59,980 --> 00:34:04,040
while this may look a little complicated with the math and a bit scary,

502
00:34:04,570 --> 00:34:06,590
I will break this down

503
00:34:06,700 --> 00:34:15,260
with the idea of how a very simple concept enforces this independent latent encoding and this disentanglement.

504
00:34:16,200 --> 00:34:19,450
All this term is showing is those two components of the loss,

505
00:34:19,920 --> 00:34:22,750
the reconstruction term, the regularization term,

506
00:34:22,980 --> 00:34:24,520
that's what I want you to focus on.

507
00:34:25,700 --> 00:34:33,540
The idea of latent space disentanglement really arose with this concept of β β-VAEs,

508
00:34:34,310 --> 00:34:36,325
what β-VAEs do is,

509
00:34:36,325 --> 00:34:38,460
they introduce this parameter β

510
00:34:38,960 --> 00:34:41,280
and what it is it's awaiting constant,

511
00:34:41,990 --> 00:34:49,470
the awaiting constant controls, how powerful that regularization term is in the overall loss of the VAE,

512
00:34:50,560 --> 00:34:53,880
and it turns out that by increasing the value of β,

513
00:34:54,290 --> 00:34:59,830
you can try to encourage greater disentanglement, more efficient encoding

514
00:34:59,830 --> 00:35:04,440
to enforce these latent variables to be uncorrelated with each other.

515
00:35:05,530 --> 00:35:12,765
Now, if you're interested in mathematically why β-VAEs enforce this disentanglement,

516
00:35:12,765 --> 00:35:15,690
there are many papers in the literature and proofs

517
00:35:15,690 --> 00:35:17,510
and discussions as to why this occurs,

518
00:35:17,740 --> 00:35:19,790
and we can point you in those directions,

519
00:35:20,500 --> 00:35:23,930
but to get a sense of what this actually affects downstream,

520
00:35:24,430 --> 00:35:28,490
when we look at face reconstruction as a task of interest

521
00:35:29,020 --> 00:35:33,470
with a standard VAE, no β term, or rather a β of one,

522
00:35:34,730 --> 00:35:36,450
you can hopefully appreciate that,

523
00:35:37,070 --> 00:35:40,020
the features of the rotation of the head,

524
00:35:40,190 --> 00:35:42,600
the pose and the rotation of the head

525
00:35:42,770 --> 00:35:50,460
is also actually ends up being correlated with smile and the facial, the mouth expression in the mouth position,

526
00:35:51,110 --> 00:35:53,370
in that as the head pose is changing,

527
00:35:53,750 --> 00:35:57,330
the apparent smile or the position of the mouth is also changing,

528
00:35:58,570 --> 00:36:03,320
but with β-VAEs, empirically we can observe that,

529
00:36:03,880 --> 00:36:07,610
with imposing these β values much, much, much greater than one,

530
00:36:08,020 --> 00:36:11,090
we can try to enforce greater disentanglement,

531
00:36:11,410 --> 00:36:15,440
where now we can consider only a single latent variable head pose

532
00:36:15,850 --> 00:36:21,020
and the smile, the position of the mouth in these images is more constant

533
00:36:21,700 --> 00:36:23,930
compared to the standard VAE.

534
00:36:26,210 --> 00:36:31,410
Alright, so this is really all the core math, the core operations,

535
00:36:31,520 --> 00:36:33,520
the core architecture of the VAE,

536
00:36:33,520 --> 00:36:37,500
that we're going to cover in today's lecture and in this class in general.

537
00:36:38,750 --> 00:36:42,235
To close this section, and as a final note,

538
00:36:42,235 --> 00:36:45,000
I want to remind you back to the motivating example,

539
00:36:45,440 --> 00:36:49,050
that I introduced at the beginning of this lecture, facial detection.

540
00:36:49,750 --> 00:36:55,160
Where now hopefully you've understood this concept of latent variable learning and encoding,

541
00:36:55,300 --> 00:36:59,060
and how this may be useful for a task like facial detection,

542
00:36:59,380 --> 00:37:04,610
where we may want to learn those distributions of the underlying features in the data,

543
00:37:05,320 --> 00:37:09,800
and indeed, you're going to get hands on practice in the software labs

544
00:37:10,630 --> 00:37:13,245
to build variational autoencoders,

545
00:37:13,245 --> 00:37:18,820
that can automatically uncover features underlying facial detection data sets

546
00:37:19,170 --> 00:37:23,980
and use this to actually understand underlying and hidden biases,

547
00:37:24,120 --> 00:37:26,920
that may exist with those data and with those models.

548
00:37:27,890 --> 00:37:29,280
And it doesn't just stop there,

549
00:37:29,510 --> 00:37:32,490
tomorrow we'll have a very, very exciting guest lecture

550
00:37:33,170 --> 00:37:35,520
on robust and trustworthy deep learning,

551
00:37:35,870 --> 00:37:38,040
which will take this concept a step further

552
00:37:38,540 --> 00:37:43,530
to realize how we can use this idea of generative models and latent variable learning

553
00:37:43,910 --> 00:37:47,100
to not only uncover and diagnose biases,

554
00:37:47,420 --> 00:37:52,350
but actually solve and mitigate some of those harmful effects of those biases

555
00:37:52,520 --> 00:37:56,310
in neural networks for facial detection and other applications.

556
00:37:57,830 --> 00:38:01,680
Alright, so to summarize quickly the key points of VAEs,

557
00:38:02,240 --> 00:38:08,400
we've gone through how they're able to compress data into this compact encoded representation,

558
00:38:09,140 --> 00:38:10,435
from this representation,

559
00:38:10,435 --> 00:38:15,240
we can generate reconstructions of the input in a completely unsupervised fashion,

560
00:38:17,160 --> 00:38:21,850
we can train them end to end using the reparameterization trick,

561
00:38:22,680 --> 00:38:29,740
we can understand the semantic interpretation of individual latent variables by perturbing their values,

562
00:38:30,630 --> 00:38:34,210
and finally, we can sample from the latent space

563
00:38:34,230 --> 00:38:38,680
to generate new examples by passing back up through the decoder.

564
00:38:40,050 --> 00:38:46,570
So VAE are looking at this idea of latent variable encoding and density estimation as their core problem,

565
00:38:47,550 --> 00:38:51,665
what if now we only focus on the quality of the generated samples,

566
00:38:51,665 --> 00:38:54,640
and that's the task that we care more about.

567
00:38:55,690 --> 00:38:58,910
For that, we're going to transition to a new type of generative model

568
00:38:59,470 --> 00:39:02,690
called a generative adversarial network or GAN,

569
00:39:04,040 --> 00:39:06,475
where with GANs, our goal is really that,

570
00:39:06,475 --> 00:39:12,900
we care more about how well we generate new instances that are similar to the existing data,

571
00:39:13,610 --> 00:39:18,930
meaning that we want to try to sample from a potentially very complex distribution,

572
00:39:19,610 --> 00:39:22,140
that the model is trying to approximate,

573
00:39:23,370 --> 00:39:27,670
it can be extremely, extremely difficult to learn that distribution directly,

574
00:39:27,840 --> 00:39:30,250
because it's complex, it's high dimensional

575
00:39:30,450 --> 00:39:33,790
and we want to be able to get around that complexity,

576
00:39:34,510 --> 00:39:36,320
what GANs do is they say,

577
00:39:36,340 --> 00:39:39,675
okay, what if we start from something super, super simple,

578
00:39:39,675 --> 00:39:43,190
as simple as it can get completely random noise,

579
00:39:43,900 --> 00:39:46,160
could we build a neural network architecture,

580
00:39:46,930 --> 00:39:52,790
that can learn to generate synthetic examples from complete random noise.

581
00:39:54,210 --> 00:39:57,070
And this is the underlying concept of GANs,

582
00:39:57,810 --> 00:40:01,060
where the goal is to train this generator network,

583
00:40:01,500 --> 00:40:06,970
that learns a transformation from noise to the training data distribution,

584
00:40:07,840 --> 00:40:13,290
with the goal of making the generated examples as close to the real [] as possible.

585
00:40:14,910 --> 00:40:18,370
With GANs, the breakthrough idea here was

586
00:40:18,630 --> 00:40:23,260
to interface these two neural networks together,

587
00:40:24,060 --> 00:40:27,850
one being a generator and one being a discriminator,

588
00:40:28,480 --> 00:40:31,850
and these two components, the generator and discriminator,

589
00:40:32,140 --> 00:40:34,730
are at war, at competition with each other,

590
00:40:35,650 --> 00:40:39,195
specifically, the goal of the generator network is

591
00:40:39,195 --> 00:40:40,700
to look at random noise

592
00:40:41,170 --> 00:40:45,920
and try to produce an imitation of the data that's as close to real as possible,

593
00:40:47,100 --> 00:40:53,530
the discriminator then takes the output of the generator as well as some real data examples,

594
00:40:54,090 --> 00:40:57,670
and tries to learn a classification decision,

595
00:40:58,750 --> 00:41:00,740
distinguishing real from fake,

596
00:41:01,480 --> 00:41:02,965
and effectively in the GAN,

597
00:41:02,965 --> 00:41:06,810
these two components are going back and forth, competing each other,

598
00:41:07,520 --> 00:41:12,600
trying to force the discriminator to better learn this distinction between real and fake,

599
00:41:13,250 --> 00:41:21,060
while the generator is trying to fool and outperform the ability of the discriminator to make that classification.

600
00:41:22,780 --> 00:41:25,490
So that's the overlying concept,

601
00:41:26,080 --> 00:41:29,900
but what I'm really excited about is the next example,

602
00:41:29,920 --> 00:41:34,850
which is one of my absolute favorite illustrations and walkthroughs in this class,

603
00:41:35,230 --> 00:41:37,910
and it gets at the intuition behind GANs,

604
00:41:38,230 --> 00:41:40,280
how they work and the underlying concept.

605
00:41:42,800 --> 00:41:44,760
Okay, we're going to look at a 1D example,

606
00:41:44,960 --> 00:41:46,240
points on a line, right,

607
00:41:46,240 --> 00:41:48,180
that's the data that we're working with,

608
00:41:48,760 --> 00:41:52,070
and again, the generator starts from random noise,

609
00:41:52,390 --> 00:41:53,715
produces some fake data,

610
00:41:53,715 --> 00:41:56,750
they're going to fall somewhere on this one dimensional line.

611
00:41:57,870 --> 00:42:01,930
Now the next step is the discriminator then sees these points,

612
00:42:02,920 --> 00:42:05,420
and it also sees some real data,

613
00:42:06,460 --> 00:42:11,450
the goal of the discriminator is to be trained to output a probability,

614
00:42:11,770 --> 00:42:15,890
that an instance it sees is real or fake.

615
00:42:17,130 --> 00:42:19,630
And initially, in the beginning before training,

616
00:42:20,070 --> 00:42:21,340
it's not trained, right,

617
00:42:21,600 --> 00:42:23,650
so its predictions may not be very good,

618
00:42:24,240 --> 00:42:25,955
but over the course of training,

619
00:42:25,955 --> 00:42:27,100
you're going to train it

620
00:42:27,480 --> 00:42:33,370
and it hopefully will start increasing the probability for those examples that are real

621
00:42:33,870 --> 00:42:37,990
and decreasing the probability for those examples that are fake,

622
00:42:38,750 --> 00:42:41,610
overall goal is to predict what is real,

623
00:42:42,600 --> 00:42:46,025
until eventually the discriminator reaches this point,

624
00:42:46,025 --> 00:42:51,880
where it has a perfect separation, perfect classification of real versus fake.

625
00:42:53,040 --> 00:42:55,600
Okay, so at this point, the discriminator thinks,

626
00:42:55,680 --> 00:42:56,830
okay, I've done my job,

627
00:42:57,330 --> 00:42:59,560
now we go back to the generator

628
00:43:00,180 --> 00:43:03,070
and it sees the examples of where the real data lie,

629
00:43:04,140 --> 00:43:08,510
and it can be forced to start moving its generated fake data

630
00:43:09,100 --> 00:43:12,980
closer and closer, increasingly closer to the real data,

631
00:43:14,310 --> 00:43:16,295
we can then go back to the discriminator,

632
00:43:16,295 --> 00:43:20,110
which receives these newly synthesized examples from the generator,

633
00:43:20,670 --> 00:43:26,980
and repeats that same process of estimating the probability that any given point is real,

634
00:43:28,220 --> 00:43:32,250
and learning to increase the probability of the true real examples,

635
00:43:32,990 --> 00:43:35,250
decrease the probability of the fake points,

636
00:43:36,580 --> 00:43:39,230
adjusting, adjusting over the course of its training.

637
00:43:40,530 --> 00:43:45,130
And finally, we can go back and repeat to the generator again one last time,

638
00:43:45,390 --> 00:43:51,540
the generator starts moving those fake points closer, closer and closer to the real data,

639
00:43:52,070 --> 00:43:56,460
such that the fake data is almost following the distribution of the real data.

640
00:43:58,180 --> 00:44:03,765
At this point, it becomes very, very hard for the discriminator to distinguish

641
00:44:03,765 --> 00:44:06,080
between what is real and what is fake,

642
00:44:06,800 --> 00:44:12,670
while the generator will continue to try to create fake data points to fool the discriminator,

643
00:44:14,000 --> 00:44:15,750
this is really the key concept,

644
00:44:15,800 --> 00:44:21,870
the underlying intuition behind how the components of the GAN are essentially competing with each other,

645
00:44:22,220 --> 00:44:26,610
going back and forth between the generator and the discriminator,

646
00:44:27,690 --> 00:44:33,040
and in fact, this is this intuitive concept is how the GAN is trained in practice,

647
00:44:33,870 --> 00:44:38,080
where the generator first tries to synthesize new examples,

648
00:44:38,370 --> 00:44:41,200
synthetic examples to fool the discriminator,

649
00:44:41,730 --> 00:44:47,140
and the goal of the discriminator is to take both the fake examples and the real data

650
00:44:47,340 --> 00:44:50,440
to try to identify the synthesized instances.

651
00:44:51,980 --> 00:44:55,260
In training, what this means is that the objective,

652
00:44:56,240 --> 00:45:01,000
the loss for the generator and discriminator have to be at odds with each other,

653
00:45:01,260 --> 00:45:02,500
they're adversarial,

654
00:45:02,550 --> 00:45:08,620
and that is what gives rise to the component of adversarial in generative adversarial network,

655
00:45:09,960 --> 00:45:14,860
these adversarial objectives are then put together

656
00:45:14,970 --> 00:45:19,210
to then define what it means to arrive at a stable global optimum,

657
00:45:19,680 --> 00:45:24,730
where the generator is capable of producing the true data distribution,

658
00:45:25,200 --> 00:45:27,730
that would completely fool the discriminator,

659
00:45:30,440 --> 00:45:34,740
concretely, this can be defined mathematically in terms of a loss objective

660
00:45:35,510 --> 00:45:38,850
and again though I'm, I'm showing math,

661
00:45:39,110 --> 00:45:40,990
I can, we can distill this down

662
00:45:40,990 --> 00:45:47,910
and go through what each of these terms reflect in terms of that core intuitive idea and conceptual idea,

663
00:45:48,110 --> 00:45:51,960
that hopefully that 1D example conveyed.

664
00:45:53,140 --> 00:45:57,440
So we'll first consider the perspective of the discriminator D,

665
00:45:58,210 --> 00:46:01,700
its goal is to maximize probability that its decisions,

666
00:46:02,920 --> 00:46:03,795
in its decisions,

667
00:46:03,795 --> 00:46:08,510
that real data are classified real, fake data classified as fake,

668
00:46:09,330 --> 00:46:14,950
so here the first term G(z) is the generator's output,

669
00:46:15,420 --> 00:46:23,110
and D(G(z)) is the discriminator's estimate of that generated output as being fake,

670
00:46:25,200 --> 00:46:27,550
D(x), x is the real data,

671
00:46:27,810 --> 00:46:33,040
and so D(x) is the estimate of the probability that a real instance is fake,

672
00:46:33,780 --> 00:46:38,570
1-D(x) is the estimate that that real instance is real,

673
00:46:39,580 --> 00:46:41,955
so here in both these cases,

674
00:46:41,955 --> 00:46:46,910
the discriminator is producing a decision about fake data, real data,

675
00:46:47,200 --> 00:46:53,810
and together it wants to try to maximize the probability that it's getting answers correct, right.

676
00:46:56,360 --> 00:46:59,730
Now with the generator, we have those same exact terms,

677
00:47:00,320 --> 00:47:04,580
but keep in mind the generator is never able to affect

678
00:47:04,720 --> 00:47:08,600
anything that the discriminator decision is actually doing,

679
00:47:09,160 --> 00:47:11,840
besides generating new data examples.

680
00:47:12,900 --> 00:47:15,830
So for the generator, its objective is simply

681
00:47:16,570 --> 00:47:22,460
to minimize the probability that the generated data is identified as fake.

682
00:47:24,800 --> 00:47:28,200
Together, we want to then put this together

683
00:47:28,220 --> 00:47:32,970
to define what it means for the generator to synthesize fake images

684
00:47:33,320 --> 00:47:35,580
that hopefully fool the discriminator.

685
00:47:37,030 --> 00:47:39,260
All in all, right, this term,

686
00:47:40,030 --> 00:47:43,370
besides the math, besides the particularities of this definition,

687
00:47:44,140 --> 00:47:48,110
what I want you to get away from this, from this section on GANs,

688
00:47:48,790 --> 00:47:52,340
is that we have this dual competing objective,

689
00:47:52,990 --> 00:47:57,770
where the generator is trying to synthesize these synthetic examples,

690
00:47:58,270 --> 00:48:02,330
that ideally fool the best discriminator possible,

691
00:48:03,100 --> 00:48:06,560
and in doing so, the goal is to build up a network,

692
00:48:07,810 --> 00:48:11,240
via this adversarial training, this adversarial competition

693
00:48:11,740 --> 00:48:14,630
to use the generator to create new data,

694
00:48:14,740 --> 00:48:20,810
that best mimics the true data distribution and its completely synthetic new instances.

695
00:48:23,120 --> 00:48:27,150
What this amounts to in practice is that after the training process,

696
00:48:27,230 --> 00:48:30,270
you can look exclusively at the generator component

697
00:48:30,860 --> 00:48:34,830
and use it to then create new data instances.

698
00:48:37,220 --> 00:48:40,920
All this is done by starting from random noise

699
00:48:41,390 --> 00:48:47,130
and trying to learn a model that goes from random noise to the real data distribution.

700
00:48:47,990 --> 00:48:51,120
And effectively what gans are doing is learning a function,

701
00:48:51,530 --> 00:48:56,250
that transforms that distribution of random noise to some target,

702
00:48:57,450 --> 00:48:59,735
what this mapping does is,

703
00:48:59,735 --> 00:49:05,080
it allows us to take a particular observation of noise in that noise space

704
00:49:05,760 --> 00:49:10,840
and map it to some output, a particular output in our target data space,

705
00:49:12,130 --> 00:49:15,800
and in turn, if we consider some other random sample of noise,

706
00:49:16,210 --> 00:49:18,380
if we feed it through the generator of GAN,

707
00:49:18,580 --> 00:49:21,110
it's going to produce a completely new instance,

708
00:49:21,730 --> 00:49:25,670
falling somewhere else on that true data distribution manifold,

709
00:49:26,380 --> 00:49:29,210
and indeed, what we can actually do is

710
00:49:29,650 --> 00:49:34,010
interpolate and traverse between trajectories in the noise space,

711
00:49:34,540 --> 00:49:41,540
that then map to traversals and interpolations in the target data space,

712
00:49:42,240 --> 00:49:43,785
and this is really, really cool,

713
00:49:43,785 --> 00:49:47,780
because now you can think about an initial point and a target point

714
00:49:48,220 --> 00:49:50,390
and all the steps that are going to take you

715
00:49:50,770 --> 00:49:55,730
to synthesize and go between those images in that target data distribution.

716
00:49:57,740 --> 00:50:06,510
So hopefully this gives a sense of this concept of generative modeling for the purpose of creating new data instances.

717
00:50:07,200 --> 00:50:10,910
And that notion of interpolation and data transformation

718
00:50:11,800 --> 00:50:16,430
leads very nicely to some of the recent advances and applications of GANs,

719
00:50:17,400 --> 00:50:21,065
where one particularly commonly employed idea is

720
00:50:21,065 --> 00:50:27,130
to try to iteratively grow the GANs to get more and more detailed image generations,

721
00:50:28,080 --> 00:50:31,450
progressively adding layers over the course of training

722
00:50:31,620 --> 00:50:35,770
to then refine the examples generated by the generator.

723
00:50:37,020 --> 00:50:43,720
And this is the approach that was used to generate those synthetic, those images of those synthetic faces,

724
00:50:43,860 --> 00:50:45,880
that I showed at the beginning of this lecture,

725
00:50:46,380 --> 00:50:52,810
this idea of using GAN that is refined iteratively to produce higher resolution images.

726
00:50:55,100 --> 00:50:57,900
Another way we can extend this concept is

727
00:50:57,950 --> 00:51:02,850
to extend the GAN architecture to consider particular tasks

728
00:51:03,320 --> 00:51:06,600
and impose further structure on the network itself,

729
00:51:07,490 --> 00:51:09,480
one particular idea is to say,

730
00:51:09,560 --> 00:51:13,830
okay, what if we have a particular label or some factor,

731
00:51:13,850 --> 00:51:16,740
that we want to condition the generation on,

732
00:51:17,820 --> 00:51:18,820
we call the c

733
00:51:18,960 --> 00:51:22,330
and it supplied to both the generator and the discriminator,

734
00:51:23,590 --> 00:51:30,470
what this will allow us to achieve is paired translation between different types of data,

735
00:51:30,820 --> 00:51:35,660
so, for example, we can have images of a street view

736
00:51:35,800 --> 00:51:39,650
and we can have images of the segmentation of that street view

737
00:51:40,120 --> 00:51:46,460
and we can build again that can directly translate between the street view and the segmentation.

738
00:51:47,300 --> 00:51:50,760
Let's make this more concrete by considering some particular examples,

739
00:51:51,680 --> 00:51:57,300
so what I just described was going from a segmentation label to a street scene,

740
00:51:58,040 --> 00:52:02,700
we can also translate between a satellite view, aerial satellite image

741
00:52:03,140 --> 00:52:08,400
to what is the roadmap equivalent of that aerial satellite image

742
00:52:09,170 --> 00:52:14,100
or a particular annotation or labels of the image of a building

743
00:52:14,390 --> 00:52:19,470
to the actual visual realization and visual facade of that building,

744
00:52:20,280 --> 00:52:23,980
we can translate between different lighting conditions, day to night,

745
00:52:25,010 --> 00:52:26,310
black and white to color,

746
00:52:26,690 --> 00:52:30,510
outlines to a colored photo.

747
00:52:31,440 --> 00:52:32,320
All these cases,

748
00:52:32,790 --> 00:52:37,580
and I think in particular the, the most interesting and impactful to me is

749
00:52:37,580 --> 00:52:40,660
this translation between street view and aerial view,

750
00:52:41,010 --> 00:52:44,075
and this is used to consider,

751
00:52:44,075 --> 00:52:47,140
for example, if you have data from Google maps,

752
00:52:47,400 --> 00:52:53,290
how you can go between a street view of the map to the aerial image of that.

753
00:52:55,250 --> 00:53:02,340
Finally, again extending the same concept of translation between one domain to another,

754
00:53:03,200 --> 00:53:06,960
another idea is that of completely unpaired translation,

755
00:53:07,730 --> 00:53:11,610
and this uses a particular GAN architecture, called CycleGAN.

756
00:53:12,650 --> 00:53:14,700
So in this video that I'm showing here,

757
00:53:14,960 --> 00:53:19,050
the model takes as input a bunch of images in one domain,

758
00:53:19,700 --> 00:53:24,180
and it doesn't necessarily have to have a corresponding image in another target domain,

759
00:53:24,920 --> 00:53:33,690
but it is trained to try to generate examples in that target domain that roughly correspond to the source domain,

760
00:53:34,340 --> 00:53:39,030
transferring the style of the source onto the target and vice versa.

761
00:53:39,620 --> 00:53:46,950
So this example is showing the translation of images in horse domain to zebra domain,

762
00:53:48,020 --> 00:53:51,600
the concept here is this cyclic dependency, right,

763
00:53:51,710 --> 00:53:56,760
you have two GANs that are connected together via this cyclic loss,

764
00:53:57,470 --> 00:54:00,000
transforming between one domain and another.

765
00:54:01,340 --> 00:54:05,400
And really like all the examples that we've seen so far in this lecture,

766
00:54:05,840 --> 00:54:08,730
the intuition is this idea of distribution transformation,

767
00:54:09,950 --> 00:54:13,110
normally, with GAN, you're going from noise to some target,

768
00:54:13,820 --> 00:54:18,330
with the CycleGAN, you're trying to go from some source distribution,

769
00:54:18,830 --> 00:54:24,540
some data manifold X to a target distribution, another data manifold Y,

770
00:54:25,420 --> 00:54:28,160
and this is really, really not only cool,

771
00:54:28,210 --> 00:54:35,000
but also powerful in thinking about how we can translate across these different distributions flexibly.

772
00:54:35,850 --> 00:54:40,780
And in fact, this allows us to do transformations not only to images,

773
00:54:41,280 --> 00:54:43,390
but to speech and audio as well,

774
00:54:44,210 --> 00:54:46,080
so in the case of speech and audio,

775
00:54:46,610 --> 00:54:53,000
turns out that you can take sound waves represent compactly in a spectrogram image

776
00:54:53,500 --> 00:54:54,950
and use a CycleGAN

777
00:54:55,180 --> 00:55:05,460
to then translate and transform speech from one person's voice in one domain to another person's voice in another domain, right,

778
00:55:05,460 --> 00:55:08,780
these are two independent data distributions that we define.

779
00:55:09,700 --> 00:55:12,530
Maybe you're getting a sense of where I'm hinting at, maybe not,

780
00:55:12,940 --> 00:55:21,140
but in fact, this was exactly how we developed the model to synthesize the audio behind Obama's voice,

781
00:55:21,430 --> 00:55:24,260
that we saw in yesterday's introductory lecture,

782
00:55:25,210 --> 00:55:26,130
what we did was,

783
00:55:26,130 --> 00:55:27,800
we trained a CycleGAN

784
00:55:28,210 --> 00:55:30,890
to take data in Alexander's voice

785
00:55:31,480 --> 00:55:36,380
and transform it into data in the manifold of Obama's voice,

786
00:55:37,520 --> 00:55:44,340
so we can visualize how that spectrogram waveform looks like for Alexander's voice versus Obama's voice,

787
00:55:44,450 --> 00:55:48,660
that was completely synthesized using this CycleGAN approach.

788
00:55:59,130 --> 00:56:00,760
Here at MIT.

789
00:56:03,260 --> 00:56:05,670
I replayed it,

790
00:56:05,810 --> 00:56:08,370
okay, but basically what we did was

791
00:56:08,540 --> 00:56:12,600
Alexander spoke that exact phrase that was played yesterday,

792
00:56:13,430 --> 00:56:15,480
and we had the train CycleGAN model,

793
00:56:15,950 --> 00:56:18,420
and we can deploy it then on that exact audio

794
00:56:18,830 --> 00:56:23,970
to transform it from the domain of Alexander's voice to Obama s voice,

795
00:56:24,600 --> 00:56:28,550
generating the synthetic audio that was played for that video clip.

796
00:56:32,260 --> 00:56:35,640
Okay, before I accidentally played again,

797
00:56:35,640 --> 00:56:38,590
I jump now to the summary slide.

798
00:56:39,240 --> 00:56:40,660
So today in this lecture,

799
00:56:40,680 --> 00:56:42,820
we've learned deep generative models,

800
00:56:42,900 --> 00:56:49,540
specifically talking mostly about latent variable models, autoencoders, variational autoencoders,

801
00:56:49,680 --> 00:56:54,040
where our goal is to learn this low dimensional latent encoding of the data,

802
00:56:54,780 --> 00:56:57,580
as well as generative adversarial networks,

803
00:56:57,930 --> 00:57:01,960
where we have these competing generator and discriminator components,

804
00:57:02,370 --> 00:57:05,770
that are trying to synthesize synthetic examples.

805
00:57:07,510 --> 00:57:10,640
We've talked about these core foundational generative methods,

806
00:57:11,500 --> 00:57:15,440
but it turns out, as I alluded to in the beginning of the lecture,

807
00:57:16,270 --> 00:57:18,470
that in this past year in particular,

808
00:57:18,700 --> 00:57:22,820
we've seen truly, truly tremendous advances in generative modeling,

809
00:57:23,380 --> 00:57:26,990
many of which have not been from those two methods,

810
00:57:27,400 --> 00:57:29,780
those two foundational methods that we described,

811
00:57:30,500 --> 00:57:33,780
but rather a new approach called diffusion modeling.

812
00:57:34,700 --> 00:57:42,360
Diffusion models are driving are the driving tools behind the tremendous advances in generative AI,

813
00:57:42,500 --> 00:57:44,850
that we've seen in this past year in particular,

814
00:57:46,130 --> 00:57:50,460
these GANs, they're learning these transformations, these encodings,

815
00:57:50,750 --> 00:57:59,790
but they're largely restricted to generating examples that fall similar to the data space that they've seen before,

816
00:58:01,270 --> 00:58:03,320
diffusion models have this ability

817
00:58:03,340 --> 00:58:09,200
to now hallucinate and envision and imagine completely new objects and instances,

818
00:58:09,340 --> 00:58:13,370
which we as humans may not have seen or even thought about,

819
00:58:14,050 --> 00:58:18,260
parts of the design space that are not covered by the training data.

820
00:58:18,940 --> 00:58:21,920
So an example here is this AI generated art,

821
00:58:22,240 --> 00:58:23,750
which art, if you will,

822
00:58:25,000 --> 00:58:27,140
which was created by a diffusion model,

823
00:58:27,700 --> 00:58:35,010
and I think not only does this get at some of the limits and capabilities of these powerful models,

824
00:58:35,390 --> 00:58:41,100
but also questions about what does it mean to create new instances,

825
00:58:41,360 --> 00:58:44,100
what are the limits and bounds of these models,

826
00:58:44,480 --> 00:58:45,540
and how do they,

827
00:58:45,920 --> 00:58:51,120
how can we think about their advances with respect to human capabilities and human intelligence.

828
00:58:52,540 --> 00:58:54,465
And so I'm, I'm really excited that,

829
00:58:54,465 --> 00:58:58,460
on Thursday in lecture seven on new frontiers in deep learning,

830
00:58:58,810 --> 00:59:01,700
we're going to take a really deep dive into diffusion models,

831
00:59:02,110 --> 00:59:03,650
talk about their fundamentals,

832
00:59:04,030 --> 00:59:06,410
talk about not only applications to images,

833
00:59:06,820 --> 00:59:08,240
but other fields as well,

834
00:59:08,470 --> 00:59:13,070
in which we're seeing these models really start to make transformative advances,

835
00:59:13,570 --> 00:59:19,370
because they are indeed at the very cutting edge and very much the new frontier of generative AI today.

836
00:59:20,470 --> 00:59:22,070
Alright, so with that,

837
00:59:23,180 --> 00:59:28,530
tease and and hopefully set the stage for lecture seven on Thursday

838
00:59:29,300 --> 00:59:33,370
and conclude and remind you all that,

839
00:59:33,370 --> 00:59:37,075
we have now about an hour for open office hour,

840
00:59:37,075 --> 00:59:39,840
time for you to work on your software labs,

841
00:59:39,980 --> 00:59:42,870
come to us, ask any questions you may have,

842
00:59:43,730 --> 00:59:46,530
as well as the TAs who will be here as well.

843
00:59:47,030 --> 00:59:47,880
Thank you so much.

