1
00:00:09,660 --> 00:00:11,740
我真的很兴奋，特别是这次演讲，

2
00:00:11,760 --> 00:00:13,340
这是一个非常特别的演讲，

3
00:00:13,340 --> 00:00:15,280
关于健壮和值得信赖的深度学习，

4
00:00:15,420 --> 00:00:19,150
由我们这门令人惊叹的课程的赞助商之一 Themis AI 提供。

5
00:00:19,800 --> 00:00:21,070
正如你们今天将看到的，

6
00:00:21,240 --> 00:00:26,590
Temeis AI 是一家总部位于 Cambridge 的初创公司，

7
00:00:26,880 --> 00:00:33,430
我们的使命是设计、推进和部署人工智能和值得信赖的人工智能，

8
00:00:34,050 --> 00:00:36,790
我尤其对今天的演讲感到兴奋，

9
00:00:37,140 --> 00:00:40,240
因为我是 Themis 的联合创始人，就在 MIT ，

10
00:00:40,680 --> 00:00:42,370
就在这里，在这座大楼里，

11
00:00:42,930 --> 00:00:48,980
这一切都源于我们在这里创造的令人难以置信的科学创新和进步，

12
00:00:48,980 --> 00:00:51,610
就在比你们今天坐的地方高几层的地方，

13
00:00:52,380 --> 00:00:58,780
由于我们的背景是 MIT 真正的尖端科学创新，

14
00:00:58,830 --> 00:01:04,120
Themis 深深植根于科学，就像我说的，创新，

15
00:01:05,520 --> 00:01:09,810
我们的目标是推动深度学习和人工智能的未来，

16
00:01:09,810 --> 00:01:13,370
我们的许多技术已经从发表的研究成果中成长起来，

17
00:01:14,080 --> 00:01:21,740
我们在世界各地人工智能[场馆]的顶级同行评议会议上发表的，

18
00:01:21,820 --> 00:01:25,940
我们的工作得到了国际知名媒体的报道，

19
00:01:26,920 --> 00:01:29,810
通过这种科学创新，

20
00:01:30,040 --> 00:01:36,885
Themis 我们正在应对当今存在的安全关键人工智能中的一些最大挑战，

21
00:01:36,885 --> 00:01:39,165
这实际上源于这样一个事实，

22
00:01:39,165 --> 00:01:42,740
我们希望将所有这些令人惊叹的进步作为本课程的一部分，

23
00:01:42,940 --> 00:01:46,490
并在现实中作为我们日常生活的一部分来实现，

24
00:01:46,810 --> 00:01:51,450
我们正在与许多不同学科的全球领先行业合作伙伴合作，

25
00:01:51,450 --> 00:01:54,555
从机器人学、自主性医疗保健等等，

26
00:01:54,555 --> 00:01:56,030
开发一系列产品，

27
00:01:56,650 --> 00:01:59,060
以确保安全和值得信赖的人工智能，

28
00:01:59,440 --> 00:02:05,450
我们的技术工程和机器学习团队一起深入推动这一点，

29
00:02:05,900 --> 00:02:09,510
我们的重点是工程，

30
00:02:09,770 --> 00:02:12,570
非常灵活和非常模块化的平台，

31
00:02:13,010 --> 00:02:16,740
将算法扩展到健壮和值得信赖的人工智能，

32
00:02:17,210 --> 00:02:23,460
这使这种部署能够应对我们社会今天面临的重大挑战，

33
00:02:23,810 --> 00:02:28,020
特别是，今天的人工智能解决方案的能力根本不太值得信任，

34
00:02:28,190 --> 00:02:32,610
即使它们在我们作为本课程一部分学习的一些任务中可能表现得非常高。

35
00:02:33,110 --> 00:02:36,715
所以，对于 Themis 来说，这是一个令人难以置信的令人兴奋的时刻，

36
00:02:36,715 --> 00:02:39,355
特别是现在风险投资，

37
00:02:39,355 --> 00:02:42,660
我们的办公室就在 Cambridge ，所以我们是本地的，

38
00:02:43,130 --> 00:02:45,210
我们刚刚完成了融资，

39
00:02:45,920 --> 00:02:50,190
所以我们正在积极招聘最优秀、最聪明的工程师，像你们所有人一样，

40
00:02:50,840 --> 00:02:53,485
实现安全可靠的人工智能的未来，

41
00:02:53,485 --> 00:02:56,340
我们希望今天的演讲激励你，

42
00:02:56,570 --> 00:02:59,920
加入我们的使命，建设人工智能的未来。

43
00:02:59,920 --> 00:03:03,480
说到这里，我非常高兴地介绍一下 Sadhana ，

44
00:03:03,830 --> 00:03:06,400
Sadhana 是 Themis 的一位机器学习科学家，

45
00:03:07,080 --> 00:03:10,060
她也是这门课程的首席助教，

46
00:03:10,170 --> 00:03:11,860
MIT 的深度学习入门，

47
00:03:12,210 --> 00:03:14,705
她在 Themis 的研究专注于，

48
00:03:14,705 --> 00:03:19,190
我们如何为人工智能构建非常模块化和灵活的方法，

49
00:03:19,190 --> 00:03:22,270
并构建我们所说的安全可靠的人工智能。

50
00:03:22,590 --> 00:03:23,900
今天，她将教我们，

51
00:03:23,900 --> 00:03:29,260
更多关于人工智能算法的偏见和不确定性领域，

52
00:03:29,790 --> 00:03:32,500
这是两个关键或关键组件，

53
00:03:32,550 --> 00:03:38,890
实现安全可靠地部署我们周围人工智能的使命或愿景。

54
00:03:39,420 --> 00:03:43,750
所以谢谢你们，请给 Sadhana 热烈的掌声。

55
00:03:48,040 --> 00:03:49,610
Alexander ，非常感谢你的介绍。

56
00:03:50,800 --> 00:03:52,380
大家好。我是 Sadhana ，

57
00:03:52,380 --> 00:03:55,190
我是 Themis AI 的一名机器学习科学家，

58
00:03:55,570 --> 00:03:57,710
也是今年这门课程的首席助教，

59
00:03:57,910 --> 00:04:04,010
今天，我非常兴奋地代表 Themis 向你们所有人谈论健壮和值得信赖的深度学习。

60
00:04:06,230 --> 00:04:07,830
在过去的十年里，

61
00:04:07,850 --> 00:04:12,420
我们看到人工智能在安全关键领域取得了巨大的增长，

62
00:04:13,010 --> 00:04:15,270
在自主和机器人领域，

63
00:04:15,530 --> 00:04:20,580
我们现在的模型可以在一秒钟的时间内对自动驾驶等事情做出关键决定，

64
00:04:21,020 --> 00:04:24,360
这些模型为全自动车辆和机器人铺平道路，

65
00:04:25,010 --> 00:04:26,370
而这并没有停止，

66
00:04:26,480 --> 00:04:28,380
在医药和医疗保健领域，

67
00:04:28,850 --> 00:04:31,680
机器人现在已经装备好，可以进行救命手术，

68
00:04:32,180 --> 00:04:35,130
我们有算法来生成对关键药物的预测，

69
00:04:35,150 --> 00:04:38,250
这些药物可能会治愈我们之前认为无法治愈的疾病，

70
00:04:38,750 --> 00:04:41,880
我们的模型可以自动诊断疾病，

71
00:04:41,930 --> 00:04:44,850
而不需要任何卫生保健专业人员的干预。

72
00:04:45,770 --> 00:04:47,575
这些进步是革命性的，

73
00:04:47,575 --> 00:04:50,190
它们有可能改变我们今天所知的生活。

74
00:04:51,550 --> 00:04:53,540
但还有一个问题我们需要问，

75
00:04:53,620 --> 00:04:56,210
那就是这些模型在现实生活中处于什么位置，

76
00:04:56,620 --> 00:04:59,870
这些技术中的许多都是五年前、十年前创新的，

77
00:04:59,950 --> 00:05:02,300
但你我在日常生活中并没有看到它们，

78
00:05:02,950 --> 00:05:06,740
那么，创新和使用之间的差距是什么。

79
00:05:09,270 --> 00:05:15,940
你和我不能乘坐自动驾驶汽车或机器人去手术室的原因是这样的，

80
00:05:16,650 --> 00:05:20,590
这些是仅在过去几年关于人工智能失败的一些头条新闻，

81
00:05:21,450 --> 00:05:24,470
除了这些令人难以置信的进步，

82
00:05:24,470 --> 00:05:26,800
我们还看到出现了灾难性的故障，

83
00:05:26,910 --> 00:05:30,160
我刚才提到的每一个安全关键领域，

84
00:05:31,140 --> 00:05:33,730
这些问题包括自动驾驶汽车的撞车，

85
00:05:34,080 --> 00:05:37,150
以及并不适用于每个人的医疗保健算法，

86
00:05:37,230 --> 00:05:39,310
尽管它们部署在现实世界中，

87
00:05:39,360 --> 00:05:40,600
所以每个人都可以使用它们。

88
00:05:41,790 --> 00:05:43,180
现在，初看起来，

89
00:05:43,380 --> 00:05:44,860
这似乎真的让人士气低落，

90
00:05:45,360 --> 00:05:47,950
如果这些都是人工智能的问题所在，

91
00:05:48,330 --> 00:05:50,330
我们将如何实现这样的愿景，

92
00:05:50,330 --> 00:05:53,830
将我们的人工智能整合到我们的日常生活结构中，

93
00:05:54,090 --> 00:05:56,050
在安全关键部署方面，

94
00:05:57,450 --> 00:06:00,640
但在 Themis ，这正是我们解决的问题类型，

95
00:06:01,200 --> 00:06:03,770
我们希望将这些进步带到现实世界中，

96
00:06:03,770 --> 00:06:08,500
我们做到这一点的方式是在安全和值得信赖的人工智能领域进行创新，

97
00:06:08,850 --> 00:06:14,200
以便将世界各地研究实验室开发的东西带给像你我这样的客户。

98
00:06:16,450 --> 00:06:19,560
我们这样做，我们的核心意识形态是，

99
00:06:19,560 --> 00:06:24,530
我们相信这张幻灯片上的所有问题都有两个关键概念作为基础，

100
00:06:24,760 --> 00:06:26,270
首先是偏差，

101
00:06:27,110 --> 00:06:31,650
偏差是指机器学习模型在某些人口统计数据上表现得比其他更好，

102
00:06:32,390 --> 00:06:38,310
这导致面部检测系统，无法高精度检测某些人脸，

103
00:06:38,690 --> 00:06:41,460
Siri 无法识别带有口音的语音，

104
00:06:41,660 --> 00:06:44,400
或者针对不平衡数据集进行训练的算法，

105
00:06:44,510 --> 00:06:47,010
所以，算法相信的是一个好的解决方案，

106
00:06:47,450 --> 00:06:49,860
实际上并不适用于现实世界中的每个人。

107
00:06:52,030 --> 00:06:57,860
许多此类问题背后的第二个概念是无法缓解和无法传达的不确定性，

108
00:06:58,750 --> 00:07:02,450
这就是模型不知道什么时候可以信任或者不可以信任，

109
00:07:03,160 --> 00:07:04,785
这导致了一些场景，

110
00:07:04,785 --> 00:07:10,220
比如自动驾驶汽车在没有 100% 自信的情况下继续在环境中操作，

111
00:07:10,510 --> 00:07:11,990
而不是将控制权交给用户，

112
00:07:12,820 --> 00:07:18,590
或者机器人在它们以前从未进入过的环境中移动，并且高度不熟悉。

113
00:07:21,160 --> 00:07:27,860
现代人工智能中的许多问题都是彻头彻尾的偏差和不确定性的组合的结果。

114
00:07:30,980 --> 00:07:32,550
所以今天在这节课中，

115
00:07:32,750 --> 00:07:36,480
我们将重点研究所有这些问题的根本原因，

116
00:07:36,740 --> 00:07:39,510
这是健壮深度学习面临的两大挑战。

117
00:07:40,220 --> 00:07:42,100
我们还将讨论它们的解决方案，

118
00:07:42,100 --> 00:07:46,320
可以为每个人提高所有这些算法的健壮性和安全性。

119
00:07:46,850 --> 00:07:48,900
我们将从讨论偏差开始。

120
00:07:50,280 --> 00:07:53,590
在深度学习的背景下，我们都听说过 Bias 这个词，

121
00:07:53,850 --> 00:07:58,120
但在机器学习的背景下，它是可以量化和数学定义的。

122
00:07:59,130 --> 00:08:00,700
今天，我们将讨论如何做到这一点，

123
00:08:00,720 --> 00:08:03,880
从算法上缓解这种偏差的方法，

124
00:08:03,960 --> 00:08:06,130
以及 Themis 如何在这些领域进行创新，

125
00:08:06,210 --> 00:08:11,080
以便将该领域的新算法带到世界各地的行业。

126
00:08:12,240 --> 00:08:14,080
然后，我们将讨论不确定性，

127
00:08:14,460 --> 00:08:19,750
也就是，我们能教一个模型知道或不知道给定任务的答案吗，

128
00:08:20,100 --> 00:08:23,710
我们将讨论这对现实世界人工智能的影响。

129
00:08:27,900 --> 00:08:30,220
那么，偏差到底是什么意思，

130
00:08:30,480 --> 00:08:33,430
它在人工智能生命周期中处于什么位置，

131
00:08:34,860 --> 00:08:37,610
最直观的偏差形式来自数据。

132
00:08:38,260 --> 00:08:40,790
我们这里有两种不同的主要类型的偏差，

133
00:08:40,930 --> 00:08:42,800
第一种是抽样偏差，

134
00:08:43,030 --> 00:08:46,790
即从我们的输入数据分布的某些地区过度抽样，

135
00:08:47,170 --> 00:08:48,560
而从其他地区抽样不足，

136
00:08:49,060 --> 00:08:51,710
一个很好的例子是大量的临床数据集，

137
00:08:51,940 --> 00:08:56,750
其中包含的疾病患者的例子往往比健康患者少，

138
00:08:56,890 --> 00:09:01,280
因为获得健康患者的数据比获得疾病患者的数据容易得多。

139
00:09:02,610 --> 00:09:07,060
此外，在人工智能生命周期的数据部分，我们也存在选择偏差，

140
00:09:07,860 --> 00:09:10,930
想想苹果的一系列语音识别算法，

141
00:09:11,580 --> 00:09:15,280
这个模型主要是根据完美的美式英语训练的，

142
00:09:15,600 --> 00:09:17,450
但它被部署在现实世界中，

143
00:09:17,450 --> 00:09:20,770
以便能够识别来自世界各地的带有口音的声音，

144
00:09:21,850 --> 00:09:28,250
模型的训练数据的分布与现实世界中这类语言的分布不匹配，

145
00:09:28,570 --> 00:09:32,780
因为美国英语被严重高估了，与其他人口统计数据相反，

146
00:09:35,070 --> 00:09:38,350
但这并不是问题所在，偏差和数据也不会止步于此，

147
00:09:39,000 --> 00:09:43,270
这些偏差可以传播到模型训练循环本身，

148
00:09:43,440 --> 00:09:45,910
这是我们在本课程的后半部分将重点关注的。

149
00:09:48,130 --> 00:09:50,760
然后，一旦模型被实际部署，

150
00:09:50,760 --> 00:09:52,935
这意味着它被放到了现实世界中，

151
00:09:52,935 --> 00:09:56,240
客户或用户可以从它获得预测，

152
00:09:56,560 --> 00:10:00,980
我们可能会看到更多我们以前从未见过的偏差，

153
00:10:01,630 --> 00:10:03,860
第一个是分布的转变，

154
00:10:04,330 --> 00:10:05,570
假设我有一个模型，

155
00:10:05,620 --> 00:10:08,180
是我根据过去 20 年的数据训练的，

156
00:10:08,530 --> 00:10:10,340
然后我把它部署到现实世界中，

157
00:10:10,810 --> 00:10:13,700
在 2023 ，这个模型可能会做得很好，

158
00:10:13,840 --> 00:10:17,900
因为数据输入分布与训练分布中的数据非常相似，

159
00:10:18,900 --> 00:10:22,395
但这种模式在 2033 年会发生什么，

160
00:10:22,395 --> 00:10:24,680
如果它可能不会很好地发挥作用，

161
00:10:25,060 --> 00:10:29,660
因为数据来自的分布将在这十年内发生显着变化，

162
00:10:29,920 --> 00:10:33,680
如果我们不继续用这些输入数据流更新我们的模型，

163
00:10:33,880 --> 00:10:36,530
我们就会得到过时和不正确的预测。

164
00:10:38,510 --> 00:10:42,090
最后，部署之后，在评估方面，

165
00:10:42,470 --> 00:10:46,380
回想一下我们谈论的 Apple Siri 的例子，

166
00:10:46,820 --> 00:10:51,990
如果评估 Siri 的评估指标或评估数据集

167
00:10:52,160 --> 00:10:54,930
也主要由美国英语组成，

168
00:10:55,250 --> 00:10:59,620
那么在任何人看来，这个模型都会表现得非常好，

169
00:10:59,620 --> 00:11:04,050
它可以检测，它可以非常高的准确率识别美国英语的声音，

170
00:11:04,130 --> 00:11:06,120
此部署到现实世界中，

171
00:11:06,590 --> 00:11:09,010
但它在子组准确率会怎么样，

172
00:11:09,010 --> 00:11:13,440
对于带口音的人，那些英语不是他们的第一语言的人，

173
00:11:13,880 --> 00:11:17,130
如果我们不在我们的评估指标中对子组进行测试，

174
00:11:17,390 --> 00:11:19,320
我们将面临偏差。

175
00:11:20,640 --> 00:11:23,540
现在，让我们来谈谈现实世界中的另一个例子，

176
00:11:23,540 --> 00:11:27,640
关于偏差如何在人工智能生命周期的整个过程中持续存在，

177
00:11:30,310 --> 00:11:32,720
商用面部检测系统无处不在，

178
00:11:32,890 --> 00:11:36,090
在第二个实验中，你玩了其中一些，

179
00:11:36,090 --> 00:11:39,440
当你在面部检测数据集上训练你的 VAE 时。

180
00:11:40,520 --> 00:11:42,820
除了手机上的锁屏外，

181
00:11:44,040 --> 00:11:47,350
面部检测系统还安装在自动滤镜中，

182
00:11:47,370 --> 00:11:48,650
你的手机摄像头就会应用这些，

183
00:11:48,650 --> 00:11:49,810
每当你拍照时，

184
00:11:50,430 --> 00:11:52,840
它们也被用于刑事调查。

185
00:11:54,120 --> 00:11:57,700
这是三个部署的商用面部检测系统，

186
00:11:57,780 --> 00:12:03,670
我们将在接下来的几分钟内分析所有系统中可能存在的偏差。

187
00:12:05,730 --> 00:12:07,595
所以，你可能会注意到的第一件事是，

188
00:12:07,595 --> 00:12:13,420
在这张图中，两个不同的人口统计数据之间存在巨大的准确性差距，

189
00:12:14,520 --> 00:12:17,450
这个精度差距最高可达 34% ，

190
00:12:17,980 --> 00:12:22,220
请记住，这个面部检测是一个二进制分类任务，

191
00:12:22,720 --> 00:12:24,650
每件事要么是脸，要么不是脸，

192
00:12:25,240 --> 00:12:30,530
这意味着随机初始化的模型应该有 50% 的准确率，

193
00:12:31,270 --> 00:12:34,280
因为它将随机指定某个东西是否是人脸，

194
00:12:35,150 --> 00:12:39,240
其中一些面部检测分类器表现仅略好于随机，

195
00:12:39,290 --> 00:12:44,970
对这个群体这些代表性不足的数据，这些代表性不足的样本上。

196
00:12:46,850 --> 00:12:48,240
那么这是怎么发生的，

197
00:12:48,620 --> 00:12:52,830
为什么这些不同的人口群体在准确性方面存在如此明显的差距，

198
00:12:53,210 --> 00:12:56,490
这些模型最初是如何部署的，

199
00:12:56,960 --> 00:12:59,610
这些模型中存在哪些类型的偏差。

200
00:13:01,310 --> 00:13:05,760
许多人脸检测系统表现出非常明显的选择偏见，

201
00:13:06,050 --> 00:13:09,210
这个模型很可能主要是针对浅色皮肤的面孔进行训练，

202
00:13:09,560 --> 00:13:14,220
因此学习这些面孔比学习对深色皮肤的面孔进行分类要有效得多。

203
00:13:15,020 --> 00:13:16,920
但这并不是唯一存在的偏差，

204
00:13:17,600 --> 00:13:24,090
面部检测系统中经常出现的第二个偏差是评估偏差，

205
00:13:24,530 --> 00:13:28,015
因为最初你在屏幕上看到的这个数据集，

206
00:13:28,015 --> 00:13:30,510
并不是评估这些模型所依据的数据集，

207
00:13:30,800 --> 00:13:33,870
它们是在一个大数据集上进行评估的，

208
00:13:33,980 --> 00:13:36,810
根本没有对子组进行任何分类，

209
00:13:37,130 --> 00:13:38,550
因此，你可以想象，

210
00:13:38,570 --> 00:13:41,520
如果数据集也主要由白皮肤的人脸组成，

211
00:13:41,900 --> 00:13:44,340
这些精确度指标将被难以置信地夸大，

212
00:13:44,390 --> 00:13:46,620
因此会产生不必要的信心，

213
00:13:46,970 --> 00:13:49,020
我们可以将它们部署到现实世界中。

214
00:13:50,660 --> 00:13:53,845
事实上，这些模型中的偏差被发现，

215
00:13:53,845 --> 00:13:57,090
只有当一项独立研究真正构建了一个数据集，

216
00:13:57,170 --> 00:14:01,060
专门用于揭示这些类型的偏差，

217
00:14:01,060 --> 00:14:03,060
通过平衡种族和性别。

218
00:14:04,810 --> 00:14:07,620
然而，数据集可能存在偏见的其他方面，

219
00:14:07,620 --> 00:14:08,960
我们还没有讨论过。

220
00:14:11,060 --> 00:14:15,400
到目前为止，我们已经在我们的数据集中假设了一个非常关键的假设，

221
00:14:15,400 --> 00:14:20,310
那就是我们数据中的人脸数量与数据中的非人脸数量完全相同，

222
00:14:20,780 --> 00:14:21,600
但你可以想象，

223
00:14:21,680 --> 00:14:23,890
特别是如果你在查看安全提要之类的东西，

224
00:14:23,890 --> 00:14:25,230
情况可能并不总是如此，

225
00:14:25,550 --> 00:14:29,880
在你的数据集中，你可能会面临比正样本多得多的负样本。

226
00:14:31,470 --> 00:14:32,110
在最的情况下，

227
00:14:32,160 --> 00:14:33,610
那么这里有什么问题，

228
00:14:34,260 --> 00:14:35,620
在最极端的情况下，

229
00:14:35,760 --> 00:14:39,670
我们可能会为数据集中的每个项目分配标签 non-face ，

230
00:14:40,140 --> 00:14:42,640
因为模型很少看到被标记为 face 的项目，

231
00:14:42,780 --> 00:14:45,220
以至于它无法学习，

232
00:14:45,930 --> 00:14:49,420
两个分类之间，两个样本之间的准确分类边界。

233
00:14:52,490 --> 00:14:54,280
那么，我们如何才能缓解这种情况，

234
00:14:54,280 --> 00:14:55,570
这是一个非常大的问题，

235
00:14:55,570 --> 00:14:59,820
在许多不同类型的机器学习任务和数据集中都很常见。

236
00:15:00,440 --> 00:15:05,430
我们可以尝试缓解类别失衡的第一种方法是使用样本重新加权，

237
00:15:05,660 --> 00:15:09,810
即不是以速率从我们的数据集中统一采样，

238
00:15:10,070 --> 00:15:15,300
而是以与我们数据集中某个类别的发生率成反比的速率进行采样，

239
00:15:15,920 --> 00:15:17,340
因此，在前面的例子中，

240
00:15:17,630 --> 00:15:20,430
如果人脸的可能性很小，

241
00:15:21,020 --> 00:15:25,140
如果人脸的数量比我们数据集中的非人脸的数量少得多，

242
00:15:25,250 --> 00:15:28,740
我们将以比[负]更高的概率对人脸进行采样，

243
00:15:28,820 --> 00:15:30,840
这样模型就可以平等地看到这两种类别。

244
00:15:33,160 --> 00:15:37,460
第二个例子，我们可以缓解类别失衡的第二种方法是通过损失重新评级，

245
00:15:38,020 --> 00:15:45,165
即不是让模型中的每个错误对总损失函数做出相等的贡献，

246
00:15:45,165 --> 00:15:46,455
我们对样本进行加权，

247
00:15:46,455 --> 00:15:50,690
比如来自未被充分代表的类别的样本对损失函数有更大的贡献，

248
00:15:51,250 --> 00:15:56,720
因此，与模型将每个单一输入面分配为负数不同，

249
00:15:57,400 --> 00:15:59,570
如果它这样做，它将受到极大的惩罚，

250
00:15:59,830 --> 00:16:05,180
因为面数的损失将比负损失对总损失函数的贡献更大。

251
00:16:07,210 --> 00:16:12,140
我们可以缓解分类不平衡的最后一种方法是通过批量选择，

252
00:16:12,460 --> 00:16:14,480
这是当我们从类中随机选择时，

253
00:16:14,740 --> 00:16:18,590
这样每一批都有每个类相同数量的数据点。

254
00:16:22,300 --> 00:16:23,900
那么一切都解决了吗，

255
00:16:25,510 --> 00:16:29,175
显然，也存在其他形式的偏差，

256
00:16:29,175 --> 00:16:32,120
即使分类完全平衡，

257
00:16:32,530 --> 00:16:36,020
因为我们还没有考虑到的是潜在特征。

258
00:16:37,390 --> 00:16:40,460
如果你们还记得实验二和上一节课的内容，

259
00:16:40,900 --> 00:16:46,850
潜在特征实际代表，通过模型实际代表这个图像。

260
00:16:47,620 --> 00:16:52,910
到目前为止，我们已经缓解了当我们知道我们有代表不足的类时的问题，

261
00:16:53,410 --> 00:16:58,370
但我们还没有减轻当我们在同一个类中有大量可变性的问题。

262
00:16:59,110 --> 00:17:02,990
让我们假设我们的数据集中有相同数量的人脸和反面例子，

263
00:17:03,580 --> 00:17:07,005
如果大多数人脸来自特定的人群，

264
00:17:07,005 --> 00:17:08,360
或者他们有一套特定的特征，会发生什么，

265
00:17:09,190 --> 00:17:11,510
我们还能应用我们刚刚学到的技术，

266
00:17:12,300 --> 00:17:14,080
答案是我们不能这样做，

267
00:17:14,400 --> 00:17:18,190
问题是目前存在的偏差存在于我们的潜在特征中。

268
00:17:19,570 --> 00:17:22,400
所有这些图像都被贴上了完全相同的标签，

269
00:17:22,600 --> 00:17:27,380
所以根据模型，我们所知道的就是它们都是人脸，

270
00:17:28,210 --> 00:17:32,090
因此，我们没有关于这些功能的任何信息，只有标签上的信息，

271
00:17:33,130 --> 00:17:38,625
因此，我们不能应用以前用来缓解分类不平衡的任何方法，

272
00:17:38,625 --> 00:17:40,125
因为我们的分类是平衡的，

273
00:17:40,125 --> 00:17:41,720
但我们现在有特征不平衡。

274
00:17:42,640 --> 00:17:46,910
然而，我们可以调整前面的方法来解释潜在特征中的偏差，

275
00:17:47,200 --> 00:17:49,340
这将在几张幻灯片中完成。

276
00:17:52,060 --> 00:17:54,140
所以让我们进一步了解一下这个问题，

277
00:17:54,490 --> 00:17:56,810
我们有可能有偏差的数据集，

278
00:17:56,980 --> 00:17:59,310
我们试图建立和部署一个模型，

279
00:17:59,310 --> 00:18:02,300
在传统的训练管道中对人脸进行分类，

280
00:18:02,800 --> 00:18:04,500
这就是那条管道的样子，

281
00:18:04,500 --> 00:18:05,775
我们将训练我们的分类器，

282
00:18:05,775 --> 00:18:07,430
并将其部署到现实世界中，

283
00:18:07,720 --> 00:18:11,090
但这种训练管道丝毫不会 debias 我们的输入。

284
00:18:13,440 --> 00:18:18,160
.因此，我们可以做的一件事是标记我们的偏差特征，然后应用重新采样。

285
00:18:18,510 --> 00:18:19,750
因此，让我们假设在现实中，

286
00:18:20,040 --> 00:18:22,270
这个数据集是对头发颜色的偏见，

287
00:18:22,590 --> 00:18:25,240
大多数数据集由金发的人组成，

288
00:18:25,410 --> 00:18:28,300
黑发和红发的脸没有得到充分的代表，

289
00:18:29,160 --> 00:18:30,490
如果我们知道这个信息，

290
00:18:30,840 --> 00:18:34,270
我们就可以标记这个数据集中每个人的头发颜色，

291
00:18:34,410 --> 00:18:37,265
我们可以应用样本加权或损失重新加权，

292
00:18:37,265 --> 00:18:38,230
就像我们之前所做的那样。

293
00:18:39,720 --> 00:18:42,010
但有没有人想告诉我问题出在哪里？

294
00:18:45,920 --> 00:18:48,700
你要检查每个样本，要花很多时间。

295
00:18:48,970 --> 00:18:51,270
是的，所以这里有几个问题，

296
00:18:51,270 --> 00:18:52,580
这绝对是其中之一。

297
00:18:53,080 --> 00:18:53,870
第一个问题是，

298
00:18:53,920 --> 00:18:57,260
我们如何知道头发颜色在这个数据集中是一个有偏见的特征，

299
00:18:57,610 --> 00:19:01,260
除非我们肉眼检查这个数据集中的每一个样本，

300
00:19:01,260 --> 00:19:03,470
否则我们不会知道哪些是有偏差的特征。

301
00:19:04,180 --> 00:19:06,170
第二件事正是你所说的，

302
00:19:06,340 --> 00:19:08,540
那就是一旦我们有了我们有偏差的特征，

303
00:19:08,890 --> 00:19:13,880
浏览和注释每一张带有这个特征的图像是一项极其劳动密集型的任务，

304
00:19:14,080 --> 00:19:15,740
在现实世界中是不可行的。

305
00:19:17,370 --> 00:19:18,760
所以现在的问题是，

306
00:19:19,050 --> 00:19:22,420
如果我们有一种方法来自动学习潜在特征，

307
00:19:22,890 --> 00:19:26,290
并使用这种学习特征表示法来描述一个模型。

308
00:19:29,460 --> 00:19:32,950
因此，我们想要的是一种方法来学习这个数据集的特征，

309
00:19:33,060 --> 00:19:39,490
然后自动确定具有最高特征偏差的样本和具有最低特征偏差的样本，

310
00:19:40,140 --> 00:19:42,130
我们已经学习了这样做的方法，

311
00:19:42,450 --> 00:19:46,720
在生成建模课程中，你们都学过变分自编码器，

312
00:19:46,860 --> 00:19:49,870
这是一种从数据集种学习潜在特征的模型，

313
00:19:50,640 --> 00:19:56,650
回顾一下，变分自编码器从学习的潜在空间进行概率采样，

314
00:19:57,000 --> 00:20:01,630
然后它们将这个新的潜在向量解码到原始输入空间，

315
00:20:01,860 --> 00:20:04,805
测量输入和输出之间的重建损失，

316
00:20:04,805 --> 00:20:07,690
并继续更新它们对潜在空间的表示。

317
00:20:08,590 --> 00:20:11,270
我们之所以如此关心这个潜在空间，

318
00:20:11,440 --> 00:20:14,990
是因为我们希望输入中彼此相似的样本

319
00:20:15,160 --> 00:20:19,250
解码成在这个潜在空间中彼此非常接近的潜在向量，

320
00:20:19,690 --> 00:20:24,170
而输入中相距较远的样本或不相似的样本

321
00:20:24,400 --> 00:20:29,150
应解码编码为在潜在空间中彼此相距较远的潜在向量。

322
00:20:32,090 --> 00:20:35,455
所以，现在我们将逐步介绍一种 debias 算法，

323
00:20:35,455 --> 00:20:40,560
该算法自动通过变分自编码器使用潜在特征学习，

324
00:20:40,640 --> 00:20:44,460
对数据集中的区域进行欠采样和过采样。

325
00:20:45,140 --> 00:20:46,225
在我开始之前，

326
00:20:46,225 --> 00:20:50,790
我想指出这个 debias 模型实际上是 Themis 工作的基础，

327
00:20:51,200 --> 00:20:54,150
这项工作来自我们几年前发表的一篇论文，

328
00:20:54,230 --> 00:20:57,690
演示了 debias 商业面部检测算法，

329
00:20:57,830 --> 00:20:59,995
它的影响力如此之大，

330
00:20:59,995 --> 00:21:04,135
以至于我们决定提供它，并与公司和行业合作，

331
00:21:04,135 --> 00:21:05,490
Themis 就是这样开始的。

332
00:21:06,700 --> 00:21:10,250
所以，让我们首先对 VAE 进行关于这个数据集的训练，

333
00:21:10,630 --> 00:21:14,420
这张图中显示的 z 最终是我们的潜在空间，

334
00:21:14,800 --> 00:21:19,550
并且潜在空间自动捕获对分类重要的特征。

335
00:21:20,870 --> 00:21:24,090
这是一个例子，这个模型捕捉到的潜在特征，

336
00:21:24,530 --> 00:21:26,970
这是输入人脸的面部位置，

337
00:21:27,440 --> 00:21:30,220
这里真正关键的一点是，

338
00:21:30,220 --> 00:21:31,620
我们从来没有告诉模型，

339
00:21:31,940 --> 00:21:38,460
计算，编码给定人脸面部位置的特征向量，

340
00:21:38,720 --> 00:21:40,350
它会自动学习这一点，

341
00:21:40,970 --> 00:21:43,105
因为这一特征对于模型很重要，

342
00:21:43,105 --> 00:21:46,740
对于开发出一个很好的人脸是什么样子的表示。

343
00:21:48,660 --> 00:21:50,590
现在我们有了我们的潜在结构，

344
00:21:50,910 --> 00:21:55,540
我们可以用它来计算输入在每个潜在变量上的分布，

345
00:21:56,070 --> 00:21:58,270
我们可以估计概率分布，

346
00:21:58,830 --> 00:22:03,130
根据这个数据集中每一项的特征，

347
00:22:03,870 --> 00:22:05,525
本质上，这意味着，

348
00:22:05,525 --> 00:22:10,240
我们可以计算特定特征组合出现在我们的数据集中的概率，

349
00:22:10,380 --> 00:22:13,030
基于我们刚刚学习的潜在空间。

350
00:22:13,640 --> 00:22:17,375
然后我们可以对该数据集较稀疏的区域进行过采样，

351
00:22:17,375 --> 00:22:19,930
并从该数据集的较密集区域进行欠采样。

352
00:22:20,770 --> 00:22:23,355
假设我们的分布是这样的，

353
00:22:23,355 --> 00:22:24,500
这是过于简单化了，

354
00:22:24,610 --> 00:22:25,940
但为了可视化的目的，

355
00:22:26,590 --> 00:22:29,240
这个数据集的更密集的部分，

356
00:22:29,380 --> 00:22:35,000
我们希望有一个均匀的肤色和头发颜色的姿势，以及非常好的照明，

357
00:22:35,770 --> 00:22:38,000
然后在这个数据集的较稀疏部分，

358
00:22:38,080 --> 00:22:41,840
我们预计会看到不同的肤色、姿势和照明，

359
00:22:46,280 --> 00:22:48,030
现在我们有了这个分布，

360
00:22:48,080 --> 00:22:52,380
我们知道了我们分布的哪些区域是密集的，哪些区域是稀疏的，

361
00:22:52,550 --> 00:22:58,740
我们想要从落在这个分布的密集区域中的欠采样，

362
00:22:59,120 --> 00:23:03,720
在这个分布的稀疏区域中的过采样数据点。

363
00:23:04,760 --> 00:23:05,640
例如，

364
00:23:05,780 --> 00:23:11,785
我们可能会对普通的肤色、发色和良好光照的欠采样，

365
00:23:11,785 --> 00:23:13,830
在这个数据集中非常常见，

366
00:23:13,910 --> 00:23:17,160
对我们在上一张幻灯片中看到的各种图像进行过采样，

367
00:23:17,840 --> 00:23:21,090
这允许我们以公平和不偏不倚的方式进行训练。

368
00:23:24,170 --> 00:23:28,170
为了更深入地了解重采样背后的数学原理，

369
00:23:28,850 --> 00:23:35,010
这种方法基本上是通过对单个潜在变量的联合直方图来近似潜在空间，

370
00:23:35,450 --> 00:23:40,650
所以我们对每个潜在变量 zi 都有一个直方图，

371
00:23:41,060 --> 00:23:43,030
这个直方图主要做的是，

372
00:23:43,030 --> 00:23:45,270
它离散化连续分布，

373
00:23:45,590 --> 00:23:47,790
这样我们就可以更容易地计算概率。

374
00:23:49,370 --> 00:23:53,820
然后我们将所有潜在分布的概率相乘，

375
00:23:54,980 --> 00:24:00,840
然后我们可以了解所有样本在潜在空间中的联合分布。

376
00:24:03,170 --> 00:24:03,955
在此基础上，

377
00:24:03,955 --> 00:24:08,670
我们可以定义特定数据点的调整后的抽样概率如下，

378
00:24:09,260 --> 00:24:14,100
选择样本数据点 x 的概率将基于 x 的潜在空间，

379
00:24:14,480 --> 00:24:17,610
从而它是联合近似分布的逆，

380
00:24:18,710 --> 00:24:20,385
我们这里有一个参数 α ，

381
00:24:20,385 --> 00:24:22,080
这是一个偏置参数，

382
00:24:22,220 --> 00:24:23,520
随着 α 的增加，

383
00:24:23,840 --> 00:24:26,490
这个概率将趋于均匀分布，

384
00:24:26,870 --> 00:24:29,940
如果 α 增加，我们倾向于更强烈地去偏置。

385
00:24:32,570 --> 00:24:36,580
这给了我们数据集中样本的最终权重，

386
00:24:36,580 --> 00:24:38,250
我们可以动态计算，

387
00:24:38,480 --> 00:24:41,460
并在训练时使用它来自适应地重新采样。

388
00:24:43,770 --> 00:24:46,565
因此，一旦我们应用了这种偏差，

389
00:24:46,565 --> 00:24:48,400
我们就会有非常显著的结果，

390
00:24:48,750 --> 00:24:50,675
这是原始的图，

391
00:24:50,675 --> 00:24:56,350
显示了此数据集中深色男性和浅色男性之间的精度差距。

392
00:24:57,770 --> 00:24:59,890
一旦我们应用了 debias 算法，

393
00:24:59,890 --> 00:25:01,225
随着 α 变得越来越小，

394
00:25:01,225 --> 00:25:02,610
我们 debias 的越来越多，

395
00:25:02,690 --> 00:25:03,840
正如我们刚才所说的，

396
00:25:04,610 --> 00:25:06,810
这种精度差距显著减小，

397
00:25:07,820 --> 00:25:11,520
这是因为我们倾向于对肤色较深的样本进行采样，

398
00:25:11,720 --> 00:25:13,765
因此模型会更好地学习它们，

399
00:25:13,765 --> 00:25:15,390
并倾向于在它们身上做得更好。

400
00:25:16,380 --> 00:25:17,680
记住这个算法，

401
00:25:17,730 --> 00:25:19,930
因为你们在实验 3 的比赛中会用到它，

402
00:25:20,130 --> 00:25:22,390
我会在这节课的最后更多地讲到。

403
00:25:25,420 --> 00:25:30,230
到目前为止，我们主要关注面部识别系统和其他几个系统，

404
00:25:30,340 --> 00:25:32,360
作为偏见的典型例子。

405
00:25:33,100 --> 00:25:36,710
然而，在机器学习中，偏见实际上要普遍得多，

406
00:25:37,300 --> 00:25:39,260
以自动驾驶为例，

407
00:25:39,760 --> 00:25:44,390
许多数据集主要包括行驶在阳光明媚的笔直道路上的汽车，

408
00:25:44,440 --> 00:25:47,390
在非常好的天气条件下，能见度非常高，

409
00:25:47,710 --> 00:25:50,865
这是因为这些算法中这些汽车的数据

410
00:25:50,865 --> 00:25:53,990
是由行驶在道路上的汽车收集的，

411
00:25:55,220 --> 00:25:57,450
然而，在一些特定的情况下，

412
00:25:57,560 --> 00:26:02,820
你将面临恶劣的天气，糟糕的能见度，接近碰撞的场景，

413
00:26:02,900 --> 00:26:06,510
这些样本实际上是模型需要学习的最重要的样本，

414
00:26:06,890 --> 00:26:08,275
因为它们是最难的样本，

415
00:26:08,275 --> 00:26:10,830
也是模型最有可能失败的样本。

416
00:26:11,900 --> 00:26:14,350
但在传统的自动驾驶管道中，

417
00:26:14,550 --> 00:26:18,700
这些样本往往极低，代表性极低，

418
00:26:19,260 --> 00:26:24,280
因此，这是一个例子，使用我们刚才谈到的无监督潜在偏差，

419
00:26:24,360 --> 00:26:28,460
我们将能够对这些重要数据点进行过采样，

420
00:26:28,460 --> 00:26:32,560
并对沿着笔直和阳光明媚的道路行驶的数据点进行欠采样。

421
00:26:35,590 --> 00:26:38,630
同样，考虑一下大型语言模型的例子，

422
00:26:39,370 --> 00:26:43,080
几年前，一篇非常著名的论文表明，

423
00:26:43,080 --> 00:26:48,800
如果你在一个大型语言模型支持的求职搜索引擎中输入暗示女性或女性的条目，

424
00:26:49,090 --> 00:26:52,580
你将获得艺术家等人文学科的角色，

425
00:26:53,080 --> 00:26:56,415
但如果你输入类似的东西，但是男性的，

426
00:26:56,415 --> 00:26:58,790
你把男性之类的东西放进搜索引擎，

427
00:26:59,230 --> 00:27:02,090
你最终会得到科学家和工程师的角色，

428
00:27:02,800 --> 00:27:06,050
所以这种类型的偏见也会发生，

429
00:27:06,250 --> 00:27:09,140
而不管特定模型的手头任务是什么。

430
00:27:11,190 --> 00:27:14,350
最后，让我们来谈谈医疗保健推荐算法，

431
00:27:14,610 --> 00:27:17,740
这些推荐算法往往会放大种族偏见，

432
00:27:17,910 --> 00:27:20,165
几年前的一篇论文显示，

433
00:27:20,165 --> 00:27:23,990
黑人患者的病情需要比白人患者严重得多，

434
00:27:23,990 --> 00:27:25,480
才能得到同样水平的护理，

435
00:27:25,830 --> 00:27:29,260
这是因为这个模型的数据集存在固有的偏见。

436
00:27:29,730 --> 00:27:31,330
因此，在所有这些例子中，

437
00:27:31,380 --> 00:27:34,420
我们可以使用上面的算法偏差缓解方法

438
00:27:34,590 --> 00:27:36,760
来尝试解决这些问题和更多问题。

439
00:27:40,360 --> 00:27:44,810
因此，我们讨论了如何减轻人工智能中的某些形式的偏差，

440
00:27:45,040 --> 00:27:46,880
以及这些解决方案可能适用于哪里，

441
00:27:47,470 --> 00:27:50,720
我们谈到了 Themis 使用的一种基本算法，

442
00:27:50,830 --> 00:27:52,670
你们今天也将开发它。

443
00:27:53,410 --> 00:27:54,980
在课程的下一部分，

444
00:27:55,360 --> 00:27:56,870
我们将关注不确定性，

445
00:27:57,190 --> 00:27:59,420
或者模型不知道答案的时候，

446
00:28:00,560 --> 00:28:02,560
我们将讨论为什么不确定性很重要，

447
00:28:02,850 --> 00:28:04,565
我们如何估计它，

448
00:28:04,565 --> 00:28:07,270
以及不确定性估计的应用。

449
00:28:08,600 --> 00:28:10,890
那么，首先，什么是不确定性，

450
00:28:11,060 --> 00:28:12,810
为什么需要计算。

451
00:28:13,720 --> 00:28:15,090
让我们看一下下面的例子，

452
00:28:15,560 --> 00:28:19,650
这是一个对猫和狗的图像进行训练的二进制分类器，

453
00:28:20,240 --> 00:28:21,580
对于每一个输入，

454
00:28:21,580 --> 00:28:25,020
它将输出这两个类的概率分布。

455
00:28:27,610 --> 00:28:30,020
现在，让我们假设我给这个模型一个马的图像，

456
00:28:30,490 --> 00:28:31,790
它以前从来没有见过马，

457
00:28:32,080 --> 00:28:34,490
这匹马显然既不是猫也不是狗，

458
00:28:35,110 --> 00:28:38,960
然而，该模型别无选择，只能输出概率分布，

459
00:28:39,190 --> 00:28:40,910
因为这就是该模型的结构。

460
00:28:42,810 --> 00:28:45,010
然而，如果除了这个预测之外，

461
00:28:45,300 --> 00:28:47,980
我们还实现了一个置信度估计，

462
00:28:48,510 --> 00:28:50,950
在这种情况下，模型应该能够说，

463
00:28:51,630 --> 00:28:53,330
我以前从未见过这样的事情，

464
00:28:53,330 --> 00:28:55,600
我对这个预测的信心很低，

465
00:28:55,890 --> 00:28:58,840
所以，作为用户，你不应该相信我对这个模型的预测，

466
00:28:59,400 --> 00:29:02,050
这是不确定性估计背后的核心思想。

467
00:29:03,700 --> 00:29:04,880
因此，在现实世界中，

468
00:29:05,050 --> 00:29:07,790
不确定性估计对于这样的场景是有用的，

469
00:29:08,230 --> 00:29:12,590
这是特斯拉汽车跟在马车后面行驶的一个例子，

470
00:29:13,030 --> 00:29:15,320
这在美国一些地区非常常见，

471
00:29:15,760 --> 00:29:18,195
它根本不知道这辆马车是什么，

472
00:29:18,195 --> 00:29:21,770
它首先认为它是一辆卡车，然后是一辆汽车，然后是一个人，

473
00:29:22,120 --> 00:29:25,650
然后它继续输出预测，

474
00:29:25,650 --> 00:29:29,840
即使很明显，模型不知道这是什么图像。

475
00:29:32,160 --> 00:29:33,220
现在你可能会问，

476
00:29:33,450 --> 00:29:35,230
好吧，这有什么大不了的，

477
00:29:35,400 --> 00:29:37,510
它没有认出这辆马车，

478
00:29:37,620 --> 00:29:40,300
但它似乎还是开得很成功，

479
00:29:41,010 --> 00:29:44,320
然而，导致这段视频的完全相同的问题

480
00:29:44,670 --> 00:29:48,160
也导致了许多自动驾驶汽车相撞。

481
00:29:51,210 --> 00:29:54,010
所以让我们来看看为什么会发生这样的事情，

482
00:29:54,720 --> 00:29:57,730
神经网络中有多种不同类型的不确定性，

483
00:29:58,170 --> 00:30:00,790
这可能会导致像我们刚刚看到的那样的事件，

484
00:30:01,320 --> 00:30:05,200
我们将通过一个简单的例子来说明两种主要类型的不确定性，

485
00:30:05,280 --> 00:30:06,850
我们将在这节课中重点讨论。

486
00:30:09,980 --> 00:30:13,795
假设我正在尝试估计曲线 y 等于 x 的立方，

487
00:30:13,795 --> 00:30:15,210
作为回归任务的一部分，

488
00:30:15,620 --> 00:30:18,780
这里的输入 x 是一个实数，

489
00:30:18,920 --> 00:30:21,550
我们希望它输出 f(x) ，

490
00:30:21,550 --> 00:30:24,090
理想情况下应该是 x 的立方。

491
00:30:24,990 --> 00:30:29,380
你可能会立即注意到此数据集中存在一些问题，

492
00:30:29,400 --> 00:30:32,830
假设图像中的红点是你的训练样本，

493
00:30:37,040 --> 00:30:41,950
所以这张图的方框区域显示了我们数据集中的数据点，

494
00:30:41,950 --> 00:30:43,560
其中我们有非常高的噪声，

495
00:30:44,060 --> 00:30:46,945
这些点不遵循曲线 y 等于 x 立方，

496
00:30:46,945 --> 00:30:49,620
事实上，它们似乎根本不遵循任何分布，

497
00:30:50,120 --> 00:30:59,040
而且该模型将无法准确计算该区域内点的输出，

498
00:30:59,330 --> 00:31:03,180
因为非常相似的输入具有非常不同的输出，

499
00:31:03,230 --> 00:31:05,340
这是数据不确定性的定义。

500
00:31:09,720 --> 00:31:12,820
在这个数据集中，我们还有一些没有数据的地区，

501
00:31:13,320 --> 00:31:18,190
因此，如果我们在模型中查询这部分数据集的预测，

502
00:31:18,330 --> 00:31:21,130
我们不应该真的期望看到准确的结果，

503
00:31:21,180 --> 00:31:23,230
因为模型以前从未见过这样的事情，

504
00:31:24,000 --> 00:31:25,990
这就是所谓的模型不确定性，

505
00:31:26,430 --> 00:31:28,325
当模型没有看到足够多的数据点，

506
00:31:28,325 --> 00:31:31,030
或者不能足够准确地估计输入分布的区域

507
00:31:31,830 --> 00:31:34,810
以输出正确的预测时。

508
00:31:37,320 --> 00:31:38,560
那么会发生什么情况，

509
00:31:38,580 --> 00:31:41,110
如果我添加以下蓝色训练点，

510
00:31:41,340 --> 00:31:45,550
到模型不确定性较高的数据集区域，

511
00:31:46,200 --> 00:31:48,790
你认为模型的不确定性会减少吗，

512
00:31:49,230 --> 00:31:49,870
请举手。

513
00:31:52,020 --> 00:31:53,440
有人认为它不会改变吗？

514
00:31:55,520 --> 00:31:57,330
好的，是的，你们大多数人都是对的，

515
00:31:57,740 --> 00:32:00,010
模型不确定性通常可以被减少，

516
00:32:00,010 --> 00:32:02,335
通过将数据添加到任何区域，

517
00:32:02,335 --> 00:32:04,650
尤其是模型不确定性较高的区域。

518
00:32:06,020 --> 00:32:12,330
现在，如果我们将这些蓝色数据点添加到这个数据集中会发生什么，

519
00:32:12,860 --> 00:32:15,900
有人预计数据的不确定性会降低吗，

520
00:32:15,980 --> 00:32:16,710
请举手。

521
00:32:18,920 --> 00:32:22,350
没错，数据不确定性是不可减少的，

522
00:32:22,550 --> 00:32:23,490
在真实的世界中，

523
00:32:23,690 --> 00:32:29,790
这张图像上的蓝点和嘈杂的红点对应于机器人传感器之类的东西，

524
00:32:30,020 --> 00:32:31,705
比方说，我有一个机器人，

525
00:32:31,705 --> 00:32:36,750
它被训练成有一个传感器来测量深度，

526
00:32:37,130 --> 00:32:39,600
如果传感器中有噪音，

527
00:32:39,650 --> 00:32:44,460
我就无法向系统中添加更多数据来降低噪音，

528
00:32:44,540 --> 00:32:46,290
除非我完全更换传感器。

529
00:32:49,770 --> 00:32:54,250
因此，现在让我们为我们刚刚谈到的不确定性类型指定一些名称，

530
00:32:54,570 --> 00:32:59,680
蓝色区域或数据高度不确定的区域，被称为偶然不确定性，

531
00:33:00,480 --> 00:33:02,530
它是不可减少的，正如我们刚才提到的，

532
00:33:03,090 --> 00:33:05,350
它可以直接从数据中学习，

533
00:33:05,370 --> 00:33:06,880
我们稍后会谈到这一点。

534
00:33:08,650 --> 00:33:12,200
我们所说的绿色盒子，绿色区域，

535
00:33:12,280 --> 00:33:15,860
也就是模型的不确定性，被称为认知不确定性，

536
00:33:16,450 --> 00:33:18,830
这不能直接从数据中得知，

537
00:33:19,330 --> 00:33:23,570
然而，通过在我们的系统中向这些地区添加更多数据，可以减少这种情况。

538
00:33:30,410 --> 00:33:33,210
好的，那么首先让我们来看看偶然不确定性，

539
00:33:34,340 --> 00:33:38,095
因此，估计偶然不确定性的目标是

540
00:33:38,095 --> 00:33:41,550
学习一组与输入相对应的方差，

541
00:33:42,490 --> 00:33:45,170
请记住，我们看到的不是数据分布，

542
00:33:45,310 --> 00:33:47,925
因为我们人类不会估计差异，

543
00:33:47,925 --> 00:33:49,880
我们训练模型来完成这项任务，

544
00:33:50,470 --> 00:33:52,430
这通常意味着，

545
00:33:52,870 --> 00:33:53,900
当我们训练一个模型时，

546
00:33:53,950 --> 00:33:55,130
我们给它一个输入 x ，

547
00:33:55,330 --> 00:33:57,380
我们期望一个输出 ŷ ，

548
00:33:57,430 --> 00:33:58,940
这是模型的预测，

549
00:34:00,100 --> 00:34:03,200
现在我们还预测了额外的 σ 平方，

550
00:34:03,280 --> 00:34:05,120
因此我们在我们的模型中增加了另一层，

551
00:34:05,530 --> 00:34:06,860
我们有相同的输出大小，

552
00:34:06,970 --> 00:34:09,260
可以预测每个产出的方差。

553
00:34:11,230 --> 00:34:13,140
因此，我们这样做的原因是，

554
00:34:13,140 --> 00:34:18,620
我们预计数据集中具有高数据不确定性的区域将具有更高的方差，

555
00:34:20,650 --> 00:34:22,980
这里要记住的关键一点是，

556
00:34:22,980 --> 00:34:24,710
这种方差并不是恒定的，

557
00:34:25,270 --> 00:34:27,200
这取决于 x 的值，

558
00:34:27,490 --> 00:34:30,240
我们通常倾向于认为方差是一个单独的数字，

559
00:34:30,240 --> 00:34:32,240
它将整个分布参数化，

560
00:34:32,950 --> 00:34:34,220
然而，在这种情况下，

561
00:34:34,420 --> 00:34:37,880
我们的输入分布的区域可能具有非常高的方差，

562
00:34:37,930 --> 00:34:40,010
而我们可能具有非常低的方差，

563
00:34:40,270 --> 00:34:43,095
所以我们的方差不能独立于输入，

564
00:34:43,095 --> 00:34:44,930
它取决于我们的输入 x 。

565
00:34:47,250 --> 00:34:48,830
所以现在我们有了这个模型，

566
00:34:48,830 --> 00:34:50,705
我们有了一个额外的层，

567
00:34:50,705 --> 00:34:54,100
除了预测 ŷ ，我们还预测了 σ 平方，

568
00:34:54,810 --> 00:34:56,050
我们如何训练这个模型。

569
00:34:58,390 --> 00:35:02,300
我们的当前损失函数不考虑任何点的变化，

570
00:35:02,380 --> 00:35:06,560
这是用于训练回归模型的典型均方误差损失函数，

571
00:35:06,970 --> 00:35:09,380
不可能通过这个损失函数的训练，

572
00:35:09,670 --> 00:35:13,220
我们知道我们估计的方差是否准确。

573
00:35:15,210 --> 00:35:19,930
因此，除了增加另一层来估计偶然不确定性外，

574
00:35:20,100 --> 00:35:22,030
我们还必须改变我们的损失函数。

575
00:35:24,340 --> 00:35:30,045
所以均方误差实际上学习的是多元高斯函数，

576
00:35:30,045 --> 00:35:33,110
它有一个均值 yi ，一个常方差，

577
00:35:33,220 --> 00:35:37,460
我们想把这个损失函数推广到，当我们没有常方差时，

578
00:35:40,010 --> 00:35:44,070
我们做到这一点的方法是将损失函数改为负对数可能性，

579
00:35:44,330 --> 00:35:50,220
我们现在可以认为这是均方误差损失到非常数方差的推广，

580
00:35:50,720 --> 00:35:53,550
现在我们在损失函数中有了 σ 平方项，

581
00:35:53,990 --> 00:35:57,990
我们可以确定我们预测的 σ 和 y 对分布精度，

582
00:35:58,220 --> 00:36:00,750
对我们的输入分布进行参数化。

583
00:36:04,510 --> 00:36:07,370
现在我们知道了如何估计偶然不确定性，

584
00:36:07,750 --> 00:36:09,470
让我们来看一个真实世界的例子，

585
00:36:10,420 --> 00:36:13,430
在本任务中，我们将重点介绍语义分割，

586
00:36:13,900 --> 00:36:17,960
也就是用相应的类标记图像的每个像素，

587
00:36:18,820 --> 00:36:20,565
我们这样做是为了理解场景，

588
00:36:20,565 --> 00:36:24,260
因为它比典型的目标检测算法更细粒度。

589
00:36:25,300 --> 00:36:30,170
所以这个数据集的输入就是所谓的城市景观数据集，

590
00:36:30,400 --> 00:36:33,200
它的输入是场景的 RGB 图像，

591
00:36:34,030 --> 00:36:37,700
标签是整个图像的像素级别注释，

592
00:36:37,780 --> 00:36:40,250
每个像素都属于它的标签，

593
00:36:40,930 --> 00:36:42,855
并且输出试图模仿标签，

594
00:36:42,855 --> 00:36:45,110
也有预测的像素级别掩码，

595
00:36:45,850 --> 00:36:51,080
所以为什么我们会期望这个数据集具有高度的自然偶然不确定性，

596
00:36:51,460 --> 00:36:54,890
你认为这个数据集的哪些部分会有偶然不确定性。

597
00:36:58,880 --> 00:37:03,270
因为标记图像的每一个像素都是一项劳动密集型的任务，

598
00:37:03,500 --> 00:37:05,880
而且很难做到准确，

599
00:37:06,080 --> 00:37:12,480
所以我们预计这张图像中对象之间的边界具有高度的偶然不确定性，

600
00:37:13,040 --> 00:37:14,490
这正是我们所看到的，

601
00:37:14,570 --> 00:37:18,090
如果你训练一个模型来预测这个数据集上的偶然不确定性，

602
00:37:18,380 --> 00:37:21,270
角落和边界有最高的偶然不确定性，

603
00:37:21,710 --> 00:37:25,230
因为即使你的像素像一行或一列分开，

604
00:37:25,430 --> 00:37:27,120
这也会向模型中引入噪音，

605
00:37:27,620 --> 00:37:29,980
在这种噪音面前，模型仍然可以学习，

606
00:37:30,090 --> 00:37:32,320
但它确实存在，不能减少。

607
00:37:36,240 --> 00:37:40,270
既然我们已经了解了数据不确定性或偶然不确定性，

608
00:37:40,950 --> 00:37:43,630
让我们继续学习认知不确定性。

609
00:37:44,280 --> 00:37:49,720
总而言之，认知不确定性可以最好地描述为模型本身的不确定性，

610
00:37:50,130 --> 00:37:52,690
并且可以通过在模型中添加数据来减少。

611
00:37:56,360 --> 00:37:57,930
因此，在认知不确定性的情况下，

612
00:37:58,040 --> 00:37:59,820
本质上我们试图问的是，

613
00:37:59,990 --> 00:38:02,610
这个模型对预测有信心吗。

614
00:38:03,200 --> 00:38:07,020
一个非常简单和非常聪明的方法是，

615
00:38:07,340 --> 00:38:11,460
假设我用随机初始化多次训练同一个网络，

616
00:38:11,930 --> 00:38:15,900
我要求它预测，我在相同输入调用它。

617
00:38:16,340 --> 00:38:19,405
假设我给模型 1 一个完全相同的输入，

618
00:38:19,405 --> 00:38:21,810
蓝色的 X 是这个模型的输出，

619
00:38:23,270 --> 00:38:25,830
然后我再用模型 2 做同样的事情，

620
00:38:26,990 --> 00:38:28,530
然后用模型 3 ，

621
00:38:29,630 --> 00:38:30,900
然后在模型 4 ，

622
00:38:31,100 --> 00:38:35,100
这些模型都具有完全相同的超参数，完全相同的体系结构，

623
00:38:35,450 --> 00:38:37,110
相同的训练方式，

624
00:38:37,310 --> 00:38:39,220
它们之间的唯一区别是，

625
00:38:39,220 --> 00:38:41,370
它们的权重都是随机初始化的，

626
00:38:41,540 --> 00:38:43,530
因此它们从哪里开始是不同的。

627
00:38:45,330 --> 00:38:49,640
我们之所以能用它来确定认知的不确定性，

628
00:38:49,640 --> 00:38:53,500
是因为我们预计，在我们的网络中有熟悉的输入时，

629
00:38:53,880 --> 00:38:56,860
我们的网络应该都收敛到相同的答案，

630
00:38:57,150 --> 00:39:02,140
我们应该会看到对数或我们预测的输出的很小的变化。

631
00:39:03,100 --> 00:39:05,940
然而，如果一个模型以前从未见过特定的输入，

632
00:39:06,110 --> 00:39:08,070
或者该输入很难学习，

633
00:39:08,390 --> 00:39:11,220
所有这些模型应该预测略有不同的答案，

634
00:39:11,570 --> 00:39:15,690
并且它们的方差应该高于它们预测类似输入的情况。

635
00:39:18,520 --> 00:39:21,950
因此，创建一个网络集合非常简单，

636
00:39:22,210 --> 00:39:25,490
你从定义你想要的 num_ensembles 开始，

637
00:39:25,510 --> 00:39:27,560
你以完全相同的方式创建它们，

638
00:39:27,730 --> 00:39:31,580
然后你把它们都放在相同的训练数据。

639
00:39:33,090 --> 00:39:35,650
然后，当在推理时，

640
00:39:35,940 --> 00:39:41,410
我们调用所有模型，集合中的每个模型，关于我们的特定输入，

641
00:39:42,180 --> 00:39:47,200
然后我们可以将我们的新预测视为所有集合的平均值，

642
00:39:47,280 --> 00:39:50,110
这通常会产生更稳健和更准确的预测，

643
00:39:50,850 --> 00:39:55,000
我们可以将不确定性视为所有这些预测的方差，

644
00:39:56,070 --> 00:40:00,520
记住，如果我们看到熟悉的输入或具有低认知不确定性的输入，

645
00:40:00,870 --> 00:40:03,040
我们应该预期会有很小的方差，

646
00:40:03,210 --> 00:40:07,180
如果我们有一个非常不熟悉的输入，或者是分布之外的东西，

647
00:40:07,290 --> 00:40:08,980
或者是模型以前没有见过的东西，

648
00:40:09,300 --> 00:40:12,250
我们应该有非常高的认知不确定性或方差。

649
00:40:15,260 --> 00:40:17,035
那么，这有什么问题，

650
00:40:17,035 --> 00:40:18,970
有没有人能举手告诉我，

651
00:40:18,970 --> 00:40:21,210
训练一组网络有什么问题。

652
00:40:25,440 --> 00:40:28,330
训练一组网络是计算成本高昂的，

653
00:40:29,250 --> 00:40:31,180
即使你的模型不是很大，

654
00:40:31,410 --> 00:40:37,420
训练五个或十个副本往往会占用计算和时间，

655
00:40:37,710 --> 00:40:42,460
当我们在特定任务上进行训练时，这是不太可行的。

656
00:40:43,730 --> 00:40:46,645
然而，一组的关键洞察力是，

657
00:40:46,645 --> 00:40:51,090
通过在我们的网络中引入某种随机性或随机性的方法，

658
00:40:51,530 --> 00:40:53,790
我们能够估计认知的不确定性，

659
00:40:54,740 --> 00:41:01,530
因此，我们已经看到的另一种将随机性引入网络的方法是使用 dropout 层，

660
00:41:02,030 --> 00:41:05,190
我们把 dropout 层看作是一种减少过度拟合的方法，

661
00:41:05,420 --> 00:41:09,120
因为我们随机地丢弃了层中的不同节点，

662
00:41:09,380 --> 00:41:11,965
然后我们继续通过它们传播信息，

663
00:41:11,965 --> 00:41:14,100
这阻止了模型记忆数据。

664
00:41:15,190 --> 00:41:19,190
然而，在认知不确定性的情况下，

665
00:41:19,660 --> 00:41:23,270
我们可以在模型中的每一层之后添加 dropout 层，

666
00:41:23,620 --> 00:41:27,350
此外，我们可以在测试时保持这些 dropout 层处于启用状态，

667
00:41:27,520 --> 00:41:30,375
通常，我们在测试时不会使 dropout 层处于启用状态，

668
00:41:30,375 --> 00:41:37,490
因为我们不想在推理时丢失有关网络进程或权重的任何信息，

669
00:41:38,050 --> 00:41:40,520
然而，当我们估计认知不确定性时，

670
00:41:40,840 --> 00:41:43,340
我们确实希望在测试时保持 dropout 启用，

671
00:41:43,480 --> 00:41:47,270
因为这也是我们引入随机性和推理时间的方式。

672
00:41:48,270 --> 00:41:50,360
所以我们在这里做的是我们有一个模型，

673
00:41:50,360 --> 00:41:52,120
从头到尾都是一样的模型，

674
00:41:52,530 --> 00:41:54,760
我们以特定的概率添加 dropout 层，

675
00:41:54,960 --> 00:41:57,160
然后我们运行多个前向传递，

676
00:41:57,390 --> 00:41:58,660
在每一次前向传递中，

677
00:41:58,920 --> 00:42:02,050
不同的层在一层中获得不同的节点被丢弃，

678
00:42:02,280 --> 00:42:05,950
所以我们有随机性的度量。

679
00:42:07,930 --> 00:42:09,945
再说一次，为了实现这一点，

680
00:42:09,945 --> 00:42:13,370
我们拥有的是一个完全相同的模型，

681
00:42:13,480 --> 00:42:15,590
然后当我们运行我们的向前传递时，

682
00:42:15,910 --> 00:42:17,895
我们可以简单地运行 T 次向前传递，

683
00:42:17,895 --> 00:42:19,520
其中 T 通常是一个类似于 20 的数字，

684
00:42:19,840 --> 00:42:22,250
我们在测试时保持 dropout 开启，

685
00:42:22,300 --> 00:42:27,620
然后使用这些样本的平均值作为新的预测，

686
00:42:27,640 --> 00:42:31,490
并使用这些样本的方差作为认知不确定性的衡量标准。

687
00:42:34,300 --> 00:42:38,570
所以我们刚才谈到的这两种方法都涉及到抽样，

688
00:42:38,680 --> 00:42:40,080
而且抽样成本很高，

689
00:42:40,160 --> 00:42:41,840
反抽样成本非常高，

690
00:42:42,130 --> 00:42:43,880
但即使你有一个相当大的模型，

691
00:42:45,400 --> 00:42:51,240
引入 dropout 层和调用 20 个向前传递也可能是非常不可行的，

692
00:42:51,740 --> 00:42:57,780
在 Themis ，我们致力于开发评估认知不确定性的创新方法，

693
00:42:58,160 --> 00:43:00,280
这种方法不依赖于采样之类的东西，

694
00:43:00,280 --> 00:43:01,920
因此它们更具普遍性，

695
00:43:01,970 --> 00:43:04,680
可以被更多的行业和人使用。

696
00:43:05,680 --> 00:43:08,370
因此，我们开发了一种方法来估计，

697
00:43:08,570 --> 00:43:11,700
我们研究过的估计认知不确定性的方法，

698
00:43:12,080 --> 00:43:13,890
就是通过生成性建模。

699
00:43:14,450 --> 00:43:16,800
我们已经讨论过 VAE 几次了，

700
00:43:17,090 --> 00:43:22,230
假设我用我们之前讨论过的完全相同的数据集训练了 VAE ，

701
00:43:22,370 --> 00:43:23,910
也就是说，只有狗和猫，

702
00:43:24,710 --> 00:43:29,610
这个模型的潜在空间将由与狗和猫有关的特征组成，

703
00:43:29,870 --> 00:43:31,800
如果我给它一个原型狗，

704
00:43:32,090 --> 00:43:35,460
它应该能够产生一个很好的代表这只狗，

705
00:43:35,750 --> 00:43:38,130
它应该有相当低的重建损失。

706
00:43:40,580 --> 00:43:44,160
现在，如果我给这个 VAE 一个同样的马的例子，

707
00:43:45,110 --> 00:43:51,240
这匹马将被解码到的潜在向量对于这个网络的解码者来说是无法理解的，

708
00:43:51,620 --> 00:43:56,850
解码器将不知道如何将潜在向量投影回原始输入空间，

709
00:43:57,200 --> 00:44:00,870
因此我们应该预期在这里会看到更糟糕的重建，

710
00:44:01,100 --> 00:44:04,200
我们应该看到，重建损失更高，

711
00:44:04,220 --> 00:44:07,950
比我们给模型一个熟悉的输入或它习惯看到的东西。

712
00:44:12,970 --> 00:44:14,655
现在让我们来看看，

713
00:44:14,655 --> 00:44:18,950
我认为最令人兴奋的估计认知不确定性的方法，

714
00:44:18,970 --> 00:44:20,120
我们今天要谈到的。

715
00:44:20,950 --> 00:44:22,790
因此，在前面的两个例子中，

716
00:44:23,080 --> 00:44:24,920
采样是计算密集型的，

717
00:44:25,180 --> 00:44:27,560
但生成式建模也可以是计算密集型的，

718
00:44:27,670 --> 00:44:31,040
比如，你的任务实际上不需要变分自编码器，

719
00:44:31,420 --> 00:44:33,920
然后你无缘无故地训练整个解码器，

720
00:44:34,180 --> 00:44:36,590
除了估计认知不确定性，

721
00:44:37,540 --> 00:44:39,060
那么如果我们有一种方法，

722
00:44:39,060 --> 00:44:43,970
不依赖于生成性建模或采样来估计认知不确定性，

723
00:44:44,730 --> 00:44:48,400
这正是我们在 Themis 开发的方法所做的。

724
00:44:49,140 --> 00:44:52,570
因此，我们认为学习是一个以证据为基础的过程，

725
00:44:52,980 --> 00:44:56,540
所以，如果你还记得之前我们训练全体，

726
00:44:56,540 --> 00:44:59,350
我们在同一个输入上调用多个全体，

727
00:44:59,760 --> 00:45:01,445
我们收到了多个预测，

728
00:45:01,445 --> 00:45:03,130
我们计算了那个方差。

729
00:45:04,260 --> 00:45:07,190
现在，我们框架证据学习的方式是，

730
00:45:07,190 --> 00:45:10,180
如果我们假设这些数据点，那些预测，

731
00:45:10,290 --> 00:45:12,550
实际上是从分布本身得出的，

732
00:45:13,230 --> 00:45:17,170
如果我们能够估计这种高阶证据分布的参数，

733
00:45:17,700 --> 00:45:22,150
我们就能够自动学习这种方差或认知不确定性的这种测量，

734
00:45:22,560 --> 00:45:25,090
而不需要进行任何抽样或生成性建模，

735
00:45:25,230 --> 00:45:27,550
而这正是证据不确定性所做的。

736
00:45:30,920 --> 00:45:36,570
现在我们的工具箱中有许多方法来估计认知不确定性，

737
00:45:36,950 --> 00:45:39,000
让我们回到现实世界中的例子。

738
00:45:40,120 --> 00:45:42,870
让我们再说一次，输入和以前一样，

739
00:45:42,950 --> 00:45:45,780
它是城市中某个场景的 RGB 图像，

740
00:45:46,310 --> 00:45:49,090
输出也是像素级掩码，

741
00:45:49,090 --> 00:45:52,890
该图像中每个像素所属的类别，

742
00:45:53,700 --> 00:45:57,790
你预计数据集的哪些部分会有很高的认知不确定性，

743
00:45:58,500 --> 00:46:01,990
在本例中，我们来看看模型本身的输出，

744
00:46:02,340 --> 00:46:05,050
模型在语义切分方面做得很好，

745
00:46:05,550 --> 00:46:07,450
然而，它把人行道弄错了，

746
00:46:08,070 --> 00:46:10,300
它会将某些人行道指定给道路，

747
00:46:10,500 --> 00:46:13,420
而其他部分的人行道标记不正确。

748
00:46:15,610 --> 00:46:18,140
我们可以，利用认知的不确定性，

749
00:46:18,460 --> 00:46:19,790
我们可以明白为什么会这样，

750
00:46:20,170 --> 00:46:24,680
变色的人行道区域具有高度的认知不确定性，

751
00:46:25,270 --> 00:46:30,110
这可能是因为该模型以前从未见过具有多种不同颜色的人行道的示例，

752
00:46:30,490 --> 00:46:33,680
或者可能它没有在具有人行道的示例上进行过训练，

753
00:46:34,390 --> 00:46:35,090
无论哪种方式，

754
00:46:35,920 --> 00:46:41,300
认知的不确定性将图像的这一特定区域隔离为高度不确定的区域。

755
00:46:45,040 --> 00:46:49,850
今天，我们经历了实现稳健的深度学习两个主要挑战，

756
00:46:50,170 --> 00:46:51,495
我们已经谈到了偏差，

757
00:46:51,495 --> 00:46:54,950
这是当模型被敏感的特征输入扭曲时发生的事情，

758
00:46:55,090 --> 00:46:59,690
以及不确定性，也就是我们可以衡量某个模型的置信度水平时发生的事情。

759
00:47:00,700 --> 00:47:03,525
现在，我们将讨论 Themis 如何使用这些概念

760
00:47:03,525 --> 00:47:05,360
来构建转变模型的产品，

761
00:47:05,440 --> 00:47:06,830
使它们更具风险意识，

762
00:47:06,970 --> 00:47:11,090
以及我们如何在安全和值得信赖的人工智能方面改变人工智能的格局。

763
00:47:14,230 --> 00:47:15,300
因此，在 Themis 中，

764
00:47:15,300 --> 00:47:17,480
我们相信不确定性和偏见的缓解，

765
00:47:17,500 --> 00:47:20,570
开启了一系列解决方案，

766
00:47:20,650 --> 00:47:23,630
为了解决安全和负责任的人工智能的问题，

767
00:47:24,490 --> 00:47:29,270
我们可以使用偏见和不确定性来降低人工智能生命周期每个部分的风险。

768
00:47:29,770 --> 00:47:31,250
让我们从标记数据开始，

769
00:47:31,570 --> 00:47:33,710
今天我们讨论了偶然不确定性，

770
00:47:34,030 --> 00:47:36,440
这是一种检测错误标记的样本，

771
00:47:36,550 --> 00:47:37,820
突出标记噪音的方法，

772
00:47:37,900 --> 00:47:43,340
通常可能会告诉标签员重新标记他们获得的图像或样本，

773
00:47:43,390 --> 00:47:44,330
可能是错误的。

774
00:47:45,340 --> 00:47:46,640
在这个周期的第二部分中，

775
00:47:46,780 --> 00:47:48,410
我们已经分析了数据，

776
00:47:48,700 --> 00:47:51,050
甚至在对任何数据进行模型训练之前，

777
00:47:51,100 --> 00:47:54,110
我们可以分析这个数据集中存在的偏差，

778
00:47:54,250 --> 00:47:57,690
告诉创建者他们是否应该添加更多的样本，

779
00:47:57,690 --> 00:48:01,970
哪些人口统计数据，数据集中的哪些领域在当前数据集中没有得到充分代表，

780
00:48:02,110 --> 00:48:03,860
甚至在我们对它们进行模型训练之前。

781
00:48:05,160 --> 00:48:07,120
然后让我们去训练这个模型，

782
00:48:07,710 --> 00:48:09,050
一旦我们真正训练一个模型，

783
00:48:09,050 --> 00:48:11,710
如果它已经在有偏差的数据集上进行了训练，

784
00:48:11,820 --> 00:48:14,200
我们可以在训练过程中自适应地 debias ，

785
00:48:14,250 --> 00:48:16,030
使用我们今天讨论的方法。

786
00:48:17,300 --> 00:48:23,850
然后，我们还可以验证或认证部署的机器学习模型，

787
00:48:24,410 --> 00:48:29,490
确保实际存在的模型如它们声称的那样安全和公正，

788
00:48:29,660 --> 00:48:30,925
我们可以做到这一点的方法是，

789
00:48:30,925 --> 00:48:33,660
通过利用认知的不确定性或偏差

790
00:48:33,830 --> 00:48:37,770
来计算模型在最差情况下会做的样本或数据点，

791
00:48:37,910 --> 00:48:42,040
模型上有有最困难的学习，最差的样本，

792
00:48:42,040 --> 00:48:44,790
在模型数据集中最不能被代表的数据集样本，

793
00:48:45,210 --> 00:48:47,210
如果我们可以在这些样本上测试模型，

794
00:48:47,210 --> 00:48:49,180
特别是模型的最困难样本，

795
00:48:49,470 --> 00:48:50,440
并且它做得很好，

796
00:48:50,670 --> 00:48:54,700
那么我们就知道模型可能已经以一种公平和公正的方式进行了训练，

797
00:48:54,810 --> 00:48:55,990
以减少不确定性。

798
00:48:57,310 --> 00:48:58,970
最后，我们可以考虑一下，

799
00:48:59,050 --> 00:49:02,840
我们正在 Themis 开发一款名为 AI Guardian 的产品，

800
00:49:02,980 --> 00:49:07,310
这本质上是人工智能算法和用户之间的一层，

801
00:49:07,690 --> 00:49:09,080
它的工作原理是，

802
00:49:09,130 --> 00:49:10,410
这是一种算法，

803
00:49:10,410 --> 00:49:12,320
如果你驾驶一辆自动驾驶汽车，

804
00:49:12,670 --> 00:49:17,870
会说，这个模型实际上并不知道它周围的世界现在发生了什么，

805
00:49:17,890 --> 00:49:20,630
作为使用者，你应该控制这辆自动驾驶汽车，

806
00:49:20,980 --> 00:49:24,170
我们也可以将这一点应用于自动驾驶之外的领域。

807
00:49:27,050 --> 00:49:30,300
所以你会注意到我跳过了一个周期的一部分，

808
00:49:30,410 --> 00:49:32,370
我跳过了关于构建模型的部分，

809
00:49:32,480 --> 00:49:38,520
这是因为今天我们将稍微关注一下新兴市场著名的人工智能产品 CAPSA ，

810
00:49:38,600 --> 00:49:41,670
这是一个模型不可知的风险评估框架，

811
00:49:42,380 --> 00:49:44,580
所以 CAPSA 是一个开源库，

812
00:49:44,750 --> 00:49:47,370
你们今天将在你们的实验室中使用它，

813
00:49:47,480 --> 00:49:48,805
它可以转换模型，

814
00:49:48,805 --> 00:49:50,100
让它们意识到风险。

815
00:49:50,750 --> 00:49:52,530
因此，这是一个典型的训练管道，

816
00:49:52,550 --> 00:49:54,480
到目前为止，你们在课程中已经看过很多次，

817
00:49:54,740 --> 00:49:56,490
我们已经有了数据，我们有了模型，

818
00:49:56,600 --> 00:49:58,315
它被输入到训练算法中，

819
00:49:58,315 --> 00:49:59,890
最后我们得到了一个训练有素的模型，

820
00:49:59,890 --> 00:50:02,250
它为每一次输入输出一个预测。

821
00:50:04,320 --> 00:50:06,170
但有了 CAPSA ，我们可以做的是，

822
00:50:06,170 --> 00:50:09,130
通过在任何训练流程中添加一行，

823
00:50:09,480 --> 00:50:12,190
我们可以将此模型转变为具有风险意识的变体，

824
00:50:12,390 --> 00:50:16,390
本质上为你计算偏差、不确定性和标签噪声，

825
00:50:16,800 --> 00:50:19,940
因为今天，正如你现在所听到的，

826
00:50:19,940 --> 00:50:23,200
有如此多的方法来估计不确定性和偏差，

827
00:50:23,370 --> 00:50:25,720
有时某些方法比其他方法更好，

828
00:50:25,980 --> 00:50:29,735
真的很难确定你试图估计的是哪种不确定性，

829
00:50:29,735 --> 00:50:30,820
以及如何估计，

830
00:50:30,960 --> 00:50:32,920
所以 CAPSA 会帮你处理这件事，

831
00:50:32,970 --> 00:50:35,410
通过在你的训练流程中插入一行，

832
00:50:35,460 --> 00:50:37,460
你可以获得一个风险感知模型，

833
00:50:37,460 --> 00:50:39,070
然后你可以进一步分析。

834
00:50:41,500 --> 00:50:44,210
这就是我一直在谈论的一行，

835
00:50:44,320 --> 00:50:45,870
在构建模型之后，

836
00:50:45,870 --> 00:50:48,630
你可以创建一个包装器，也可以调用一个包装器，

837
00:50:48,630 --> 00:50:51,230
CAPSA 拥有扩展库，

838
00:50:51,550 --> 00:50:55,880
然后，除了实现预测，从你的模型接收预测之外，

839
00:50:56,080 --> 00:51:00,080
你还可以得到你试图估计的任何偏差或不确定性指标。

840
00:51:03,180 --> 00:51:04,955
CAPSA 的工作方式是，

841
00:51:04,955 --> 00:51:06,490
它通过包装模型实现这个，

842
00:51:07,110 --> 00:51:09,820
对于我们想要估计的每个不确定性指标，

843
00:51:09,990 --> 00:51:13,720
我们可以根据需要应用和创建最小的模型修改，

844
00:51:13,950 --> 00:51:16,690
同时保留初始架构和预测能力，

845
00:51:17,700 --> 00:51:19,330
在偶然不确定性的情况下，

846
00:51:19,470 --> 00:51:20,800
这可能会增加一层新的东西，

847
00:51:21,090 --> 00:51:23,045
在变分自编码器的情况下，

848
00:51:23,045 --> 00:51:25,265
这可能是创建和训练解码器，

849
00:51:25,265 --> 00:51:27,520
并在运行中计算重建损失。

850
00:51:29,990 --> 00:51:32,220
这是一个 CAPSA 的例子，

851
00:51:32,540 --> 00:51:35,340
处理我们今天讨论的其中一个数据集，

852
00:51:35,420 --> 00:51:38,010
那就是增加了噪声的立方数据集，

853
00:51:38,120 --> 00:51:40,350
还有另一项简单的分类任务，

854
00:51:40,580 --> 00:51:42,910
我之所以想展示这张图片，

855
00:51:42,910 --> 00:51:44,545
是为了展示使用 CAPSA ，

856
00:51:44,545 --> 00:51:47,040
我们可以实现所有这些不确定性估计，

857
00:51:47,120 --> 00:51:49,320
在几乎不增加额外工作的情况下。

858
00:51:53,840 --> 00:51:57,870
所以，使用我今天刚刚谈到的所有产品，使用 CAPSA ，

859
00:51:58,040 --> 00:52:02,250
Themis 解锁了跨领域安全部署深度学习模型的关键，

860
00:52:02,930 --> 00:52:06,330
我们现在可以回答早些时候头条新闻提出的许多问题，

861
00:52:06,590 --> 00:52:09,990
即人类应该在什么时候控制自动驾驶汽车，

862
00:52:10,550 --> 00:52:14,340
在商业自动驾驶管道中，哪些类型的数据代表不足，

863
00:52:14,720 --> 00:52:17,250
我们现在已经对这些问题有了有根据的答案，

864
00:52:17,570 --> 00:52:19,350
由于 Themis 正在开发的产品。

865
00:52:21,440 --> 00:52:23,820
在医学和医疗保健等领域，

866
00:52:23,930 --> 00:52:25,680
我们现在可以回答这样的问题，

867
00:52:25,820 --> 00:52:28,740
一个模型什么时候对危及生命的诊断是不确定的，

868
00:52:29,060 --> 00:52:31,650
应在什么时候将此诊断传递给医学专业人员，

869
00:52:31,970 --> 00:52:34,050
在将此信息传达给患者之前，

870
00:52:34,790 --> 00:52:38,850
或者药物发现算法可能对哪类患者有偏见。

871
00:52:39,980 --> 00:52:44,590
今天，你们将关注的应用程序是面部检测，

872
00:52:44,910 --> 00:52:46,690
你将在今天的实验室中使用 CAPSA ，

873
00:52:46,950 --> 00:52:51,520
来彻底分析常见面部检测数据集，

874
00:52:51,570 --> 00:52:53,480
我们以某些方式扰乱的，

875
00:52:53,480 --> 00:52:55,030
以便你可以自己发现它们，

876
00:52:55,470 --> 00:52:58,690
我们强烈鼓励你参加比赛，

877
00:52:59,160 --> 00:53:01,210
比赛的细节在实验室中描述，

878
00:53:01,350 --> 00:53:03,905
但从根本上讲，它是关于分析这些数据集，

879
00:53:03,905 --> 00:53:05,500
创建风险意识模型，

880
00:53:05,850 --> 00:53:09,310
以减少特定训练管道中的偏见和不确定性。

881
00:53:11,410 --> 00:53:13,170
所以，在 Themis ，我们的目标是，

882
00:53:13,170 --> 00:53:17,600
在各个行业和世界各地设计、推进和部署值得信赖的人工智能，

883
00:53:18,100 --> 00:53:20,840
我们热衷于科学创新，

884
00:53:21,160 --> 00:53:23,840
我们发布了像你们今天将使用的开源工具，

885
00:53:24,250 --> 00:53:29,000
我们的产品改变了人工智能工作流程，使人工智能对每个人都更安全，

886
00:53:29,590 --> 00:53:31,640
我们与全球各地的行业合作，

887
00:53:31,930 --> 00:53:35,090
我们正在为即将到来的夏季和全职职位招聘，

888
00:53:35,380 --> 00:53:36,390
因此，如果你感兴趣，

889
00:53:36,390 --> 00:53:39,260
请发一封电子邮件到 careers@themisai.io ，

890
00:53:39,490 --> 00:53:43,050
或者通过向深度学习简历投递来申请，

891
00:53:43,050 --> 00:53:45,050
我们会看到这些简历并回复你。

892
00:53:45,070 --> 00:53:45,680
谢谢。

